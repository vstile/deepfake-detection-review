"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Deepfake Detection Using Robust Spatial and Temporal Features from Facial Landmarks","M. Li; B. Liu; Y. Hu; L. Zhang; S. Wang","South China University of Technology, Guangzhou, China; South China University of Technology, Guangzhou, China; South China University of Technology, Guangzhou, China; GRGBanking, Guangzhou, China; City University of Hong Kong, Hong Kong, China",2021 IEEE International Workshop on Biometrics and Forensics (IWBF),"29 Jun 2021","2021","","","1","6","Most current deepfake detectors may suffer the decrease of detection accuracy under common video processing like compression. To deal with this issue, we proposed a new way of using biometric features for robust deepfake detection. Our biometric features are derived from a set of selected facial landmarks. We first presented a metric to select robust facial landmarks, and then constructed facial feature vectors with the selected landmarks. The spatial angles and the temporal rotation angles are introduced to facilitate the construction of the SVM feature vector. In essence, we use the spatial angles and temporal rotation angles to characterize the inherent consistency of facial landmarks at both frame level and video level. Experimental results have demonstrated that our detector has the best robustness compared with 6 current methods. It also has good scores in AUC (Area Under the Receiver Operating Characteristic Curve) and detection accuracy.","","978-1-7281-9556-8","10.1109/IWBF50991.2021.9465076","Research and Development; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9465076","Deepfake detection;Facial landmarks;Spatial features;Temporal features;Robustness","Support vector machines;Measurement;Biometrics (access control);Forensics;Detectors;Receivers;Feature extraction","","13","","15","IEEE","29 Jun 2021","6-7 May 2021","6-7 May 2021","IEEE","IEEE Conferences"
"Exposing Deep Fakes Using Inconsistent Head Poses","X. Yang; Y. Li; S. Lyu","University at Albany, State University of New York, USA; University at Albany, State University of New York, USA; University at Albany, State University of New York, USA","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","8261","8265","In this paper, we propose a new method to expose AI-generated fake face images or videos (commonly known as the Deep Fakes). Our method is based on the observations that Deep Fakes are created by splicing synthesized face region into the original image, and in doing so, introducing errors that can be revealed when 3D head poses are estimated from the face images. We perform experiments to demonstrate this phenomenon and further develop a classification method based on this cue. Using features based on this cue, an SVM classifier is evaluated using a set of real face images and Deep Fakes.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8683164","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8683164","Media Forensics;DeepFake Detection;Head Pose Estimation","Face;Videos;Support vector machines;Three-dimensional displays;Cameras;Neural networks","","730","","18","IEEE","17 Apr 2019","12-17 May 2019","12-17 May 2019","IEEE","IEEE Conferences"
"AV-Lip-Sync+: Leveraging AV-HuBERT to Exploit Multimodal Inconsistency for Deepfake Detection of Frontal Face Videos","S. A. Shahzad; A. Hashmi; Y. -T. Peng; Y. Tsao; H. -M. Wang","Social Networks and Human-Centered Computing Program, Taiwan International Graduate Program, Academia Sinica, Taipei, Taiwan; Social Networks and Human-Centered Computing Program, Taiwan International Graduate Program, Academia Sinica, Taipei, Taiwan; Department of Computer Science, National Chengchi University, Taipei, Taiwan; Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan; Institute of Information Science, Academia Sinica, Taipei, Taiwan",IEEE Transactions on Human-Machine Systems,"2 Dec 2025","2025","55","6","973","982","Multimodal manipulations (also known as audio-visual deepfakes) make it difficult for unimodal deepfake detectors to detect forgeries in multimedia content. To avoid the spread of false propaganda and fake news, timely detection is crucial. The damage to either modality (i.e., visual or audio) can only be discovered through multimodal models that can exploit both pieces of information simultaneously. However, previous methods mainly adopt unimodal video forensics and use supervised pretraining for forgery detection. This study proposes a new method based on a multimodal self-supervised-learning (SSL) feature extractor to exploit inconsistency between audio and visual modalities for multimodal video forgery detection. We use the transformer-based SSL pretrained Audio-Visual HuBERT (AV-HuBERT) model as a visual and acoustic feature extractor and a multiscale temporal convolutional neural network to capture the temporal correlation between the audio and visual modalities. Since AV-HuBERT only extracts visual features from the lip region, we also adopt another transformer-based video model to exploit facial features and capture spatial and temporal artifacts caused during the deepfake generation process. Experimental results show that our model outperforms all existing models and achieves new state-of-the-art performance on the FakeAVCeleb and DeepfakeTIMIT datasets.","2168-2305","","10.1109/THMS.2025.3618409","National Science and Technology Council(grant numbers:NSTC 111-2221-E-001-002,NSTC 113-2221-E-004-001-MY3,NSTC 113-2221-E-004-006-MY2); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11214430","Audio-visual;audio-visual deepfake detection;deepfake detection;deepfakes;inconsistency;lip syn;multimedia forensics;multimodality;video forgery","Deepfakes;Visualization;Feature extraction;Forgery;Lips;Detectors;Forensics;Faces;Streaming media;Social networking (online);Audio-visual systems","","","","83","IEEE","22 Oct 2025","Dec. 2025","","IEEE","IEEE Journals"
"AVSecure: An Audio-Visual Watermarking Framework for Proactive Deepfake Detection","B. Guo; H. Tai; G. Luo; Y. Zhu","School of Electronic and Computer Engineering, Shenzhen Graduate School Peking University, Shenzhen, China; School of Electronic and Computer Engineering, Shenzhen Graduate School Peking University, Shenzhen, China; School of Electronic and Computer Engineering, Shenzhen Graduate School Peking University, Shenzhen, China; School of Electronic and Computer Engineering, Shenzhen Graduate School Peking University, Shenzhen, China",2024 IEEE 14th International Conference on Electronics Information and Emergency Communication (ICEIEC),"20 Jun 2024","2024","","","1","4","The rise of Deepfake technology presents a significant challenge to the integrity of information. Most existing Deepfake detection methods rely on visual artifacts to distinguish between the authentic and manipulated content, but they are unable to cope with unseen tampering method and easily affected by post-processing. Although recent investigations have tried to proactively protect facial images using deep watermarking techniques, more deceptive Deepfakes often incorporate both visual and audio modalities. To address this issue, we propose a novel proactive Deepfake detection framework for both audio and visual modalities by utilizing a unified encoder-decoder architecture to embed audio-visual watermarks. Also, an audiovisual feature encoder is developed to align the audio and visual information. The multi-modal watermarking is designed to embed a watermark as the detection clue in each modality respectively and conduct verification of both modalities together to detect Deepfaked multimedia. By adding a distortion layer between embedding and extracting during training, the embedded watermark is able to be robust against common post-processing operations (e.g., JPEG compression) while remaining sensitive to Deepfake manipulations (e.g., SimSwap) in the water-mark verification. Our experimental results on VidTIMIT have demonstrated that the proposed watermarking framework can effectively detect various advanced Deepfake manipulations and achieve good robustness to different kinds of common distortions compared with passive uni-modal and multi-modal Deepfake detection methods.","2377-844X","979-8-3503-6189-6","10.1109/ICEIEC61773.2024.10561738","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10561738","Deepfake Detection;Watermarking;Multi-modal","Training;Deepfakes;Visualization;Ecosystems;Transform coding;Watermarking;Feature extraction","","1","","18","IEEE","20 Jun 2024","24-25 May 2024","24-25 May 2024","IEEE","IEEE Conferences"
"Deepfake Detection: Demodulate Synthetic Videos Using Deep Learning Models","P. Hirpara; H. Valangar; V. Kachhadiya; U. Chauhan","Department of Computer Engineering, Vishwakarma Government Engineering College, Gujarat, India; Department of Computer Engineering, Vishwakarma Government Engineering College, Gujarat, India; Department of Computer Engineering, Vishwakarma Government Engineering College, Gujarat, India; Department of Computer Engineering, Vishwakarma Government Engineering College, Gujarat, India",2025 12th International Conference on Computing for Sustainable Global Development (INDIACom),"21 Aug 2025","2025","","","01","06","A deepfake detection system that uses machine learning (ML) and deep learning (DL) models to detect manipulated videos and images is presented in the study. Being aware of such synthetic content is crucial considering the emergence of deepfake technology, which might alter photos, videos, and audio for malevolent objectives including fraud, extortion, and disinformation. Deepfake technology has been applied to solve various real-time problems but is also exploited for unethical and illegal purposes. As a result, developing research and detection models is crucial to prevent its misuse. We proposed a CNN-LSTM hybrid model for analysis of cropped images to improve the performance of fake video detection. The suggested method focuses on identifying fake videos using the Celeb-DF dataset, which consists of 1203 videos (795 fake, 408 real). Moreover, the benefits and drawbacks of the various deepfake detection techniques are examined. The paper indicates potential improvements in model accuracy through more datasets and improved architectures, and it emphasizes the significance of sophisticated detection techniques to mitigate the negative consequences of deepfakes. With cropped video frames and deep learning techniques, the model's accuracy increased from 79.06% with the original dataset to $\mathbf{8 6. 8 2 \%}$ with cropped videos.","","978-93-80544-60-1","10.23919/INDIACom66777.2025.11115707","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11115707","Deepfake Detection;Deep Learning;Artificial Intelligence;Face Manipulation;CNN-LSTM","Deep learning;Deepfakes;Analytical models;Accuracy;Computational modeling;Computer architecture;Real-time systems;Fraud;Faces","","","","32","","21 Aug 2025","2-4 April 2025","2-4 April 2025","IEEE","IEEE Conferences"
"Dynamic Lip Motion Analysis for Deepfake Detection","A. Castiglione; L. Cimmino; V. Loia; M. Nappi; C. Sorrentino","Dept. of Management & Innovation Systems, University of Salerno, Italy; Dept. of Computer Science, University of Salerno, Italy; Dept. of Management & Innovation Systems, University of Salerno, Italy; Dept. of Computer Science, University of Salerno, Italy; Dept. of Computer Science, University of Salerno, Italy",2025 25th International Conference on Control Systems and Computer Science (CSCS),"30 Sep 2025","2025","","","452","459","The proliferation of deepfake videos poses a significant threat to the integrity of digital media, given their capacity to disseminate misinformation and undermine the reliability of visual content. As synthetic audiovisual forgeries become increasingly realistic, they are being used in coordinated disinformation efforts, contributing to the broader issue of information disorder, which compromises public trust, media authenticity, and the verifiability of digital evidence. This study investigates the effectiveness of spatio-temporal features, extracted using Local Binary Patterns on Three Orthogonal Planes (LBP-TOP), in distinguishing synthetic from authentic video content. The approach focuses on the dynamic characteristics of the labial region, where inconsistencies in facial motion are more likely to occur in deepfake videos. LBP-TOP is employed to capture subtle texture and motion variations across spatial and temporal dimensions. Preliminary empirical evaluations conducted on benchmark deepfake datasets demonstrate the efficacy of the proposed approach, emphasizing the importance of localized temporal analysis in enhancing detection accuracy. The results highlight the potential of region-specific facial modelling as a computationally efficient yet discriminative strategy in the context of video forensics and the mitigation of synthetic media-based disinformation.","2379-0482","979-8-3315-7343-0","10.1109/CSCS66924.2025.00073","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11181647","Deepfake Detection;Misinformation;Spatiotemporal Feature Extraction;Local Binary Patterns on Three Orthogonal Planes (LBP-TOP);Digital Video Forensics","Deepfakes;Adaptation models;Visualization;Forensics;Computational modeling;Dynamics;Benchmark testing;Feature extraction;Robustness;Forgery","","","","29","IEEE","30 Sep 2025","27-30 May 2025","27-30 May 2025","IEEE","IEEE Conferences"
"Unmasking the Reality: A Comprehensive Study of Deepfake Identification Techniques and Their Expanding Terrain","S. Sharma; D. M. Pathak; D. Jain; S. Srivastava; P. Vats; G. M. Upadhyay","Department of Computer Science, ABES Engineering College, Ghaziabad, U.P, India; Department of Computer Science, ABES Engineering College, Ghaziabad, U.P, India; Department of Computer Science Engineering-AIML, ABES Engineering College, Ghaziabad, U.P, India; Department of Computer Science, ABES Engineering College, Ghaziabad, U.P, India; Dept. of CSE, School of CSE, Manipal University Jaipur, Jaipur, Rajasthan, India; Dept. of Computer Application, Manipal University Jaipur, Jaipur, Rajasthan, India","2025 2nd International Conference on Computational Intelligence, Communication Technology and Networking (CICTN)","26 Mar 2025","2025","","","293","298","The swift progression of deepfake-generating technologies has elicited much apprehension about their potential misuse in digital media, necessitating the development of efficient detection methods. This research aims to improve the precision of deepfake detection by the application of spatial-temporal feature engineering methods. A comparative comparison of advanced preprocessing techniques is performed to enhance the extraction of spatial and temporal indicators essential for detecting deepfake abnormalities. The study investigates the amalgamation of sophisticated machine learning and deep learning models with designed characteristics to get enhanced detection efficacy. Experimental assessments are conducted on benchmark datasets to verify the effectiveness of the suggested methodologies. The findings highlight the importance of effective preprocessing strategies in enhancing model generalizability and dependability, hence supporting the overarching goal of preserving digital authenticity.","","979-8-3315-3038-9","10.1109/CICTN64563.2025.10932620","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10932620","Deepfake Detection;Spatial-Temporal Preprocessing;Deepfake detection;spatial-temporal features;preprocessing techniques;feature engineering;machine learning;deep learning;digital media authenticity;anomaly detection;benchmark datasets;detection accuracy;model generalizability","Deep learning;Deepfakes;Accuracy;Computational modeling;Refining;Media;Benchmark testing;Feature extraction;Real-time systems;Resilience","","","","30","IEEE","26 Mar 2025","6-7 Feb. 2025","6-7 Feb. 2025","IEEE","IEEE Conferences"
"Deepfake Video Detection by Combining Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN)","Y. Al-Dhabi; S. Zhang","College of Software, Northeastern University, Shenyang, Liaoning, China; College of Software, Northeastern University, Shenyang, Liaoning, China","2021 IEEE International Conference on Computer Science, Artificial Intelligence and Electronic Engineering (CSAIEE)","4 Oct 2021","2021","","","236","241","Nowadays, people are facing an emerging problem called deepfake videos. These videos were created using deep learning technology. Some are created just for fun, while others are trying to manipulate your opinions, cause threats to your privacy, reputation, and so on. Sometimes, deepfake videos created using the latest algorithms can be hard to distinguish with the naked eye. That's why we need better algorithms to detect deepfake. The system we are going to present is based on a combination of CNN and RNN, as research shows that using CNN and RNN combined achieve better results. We are going to use a pre-trained CNN model called Resnext50. Using this, we save the time of training the model from scratch. The proposed system uses Resnext pretrained model for Feature Extraction and these extracted features are used to train the Long short-term memory (LSTM). Using CNN and RNN combined, we capture the inter frames as well as intra frames features which will be used to detect if the video is real or fake. We evaluated our method using a large collection of deepfake videos gathered from a variety of distribution sources. We demonstrate how our system may obtain competitive results while utilizing a simplistic architecture.","","978-1-6654-2204-8","10.1109/CSAIEE54046.2021.9543264","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9543264","Deep learning;Deepfake Detection;convolutional Neural Network (CNN);Recurrent Neural Network (RNN)","Training;Privacy;Recurrent neural networks;Computer architecture;Feature extraction;Solids;Convolutional neural networks","","38","","23","IEEE","4 Oct 2021","20-22 Aug. 2021","20-22 Aug. 2021","IEEE","IEEE Conferences"
"Spatio-Temporal Convolutional Neural Networks for Deepfake Detection: An Empirical Study","V. K. Sharma; R. Garg; Q. Caudron","Amity University, Noida, Uttar Pradesh, India; Amity University, Noida, Uttar Pradesh, India; Sound Agriculture, Emeryville, CA, United States",2023 Second International Conference on Informatics (ICI),"8 Feb 2024","2023","","","1","7","As the creation of deepfakes becomes more prevalent and sophisticated, the need for accurate and robust detection methods intensifies. This paper presents a comprehensive empirical study on the efficacy of S patio-Temporal Convolutional Neural Networks (ST-CNNs) for deepfake detection. It explores how the rich spatio-temporal information contained within video frames can be exploited by ST-CNNs to distinguish between genuine and manipulated content. The study is underpinned by a robust testing framework, wherein a range of deepfake generation techniques are used to evaluate the detection model. It further investigates the effect of various layers and architectural elements on detection performance. The results demonstrate that ST-CNNs, by leveraging spatio-temporal correlations, can offer superior deepfake detection performance compared to the conventional CNN models. This work can guide the development of more efficient and effective deepfake detection strategies by providing empirical insights into the utilization of ST-CNNs.","","979-8-3503-4383-0","10.1109/ICI60088.2023.10420892","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10420892","deepfake detection;spatio temporal;video forgery;convolutional neural network;synthetic media","Deepfakes;Correlation;Media;Convolutional neural networks;Informatics;Testing","","6","","31","IEEE","8 Feb 2024","23-25 Nov. 2023","23-25 Nov. 2023","IEEE","IEEE Conferences"
"Deepfake Detection using a Two-Stream Capsule Network","Z. Joseph; C. Nyirenda","Department of Computer Science, University of the Western Cape, Robert Sobukwe Road, Bellville, South Africa; Department of Computer Science, University of the Western Cape, Robert Sobukwe Road, Bellville, South Africa",2021 IST-Africa Conference (IST-Africa),"26 Oct 2021","2021","","","1","8","This paper aims to address the problem of Deepfake Detection using a Two-Stream Capsule Network. First we review methods used to create Deepfake content, as well as methods proposed in the literature to detect such Deepfake content. We then propose a novel architecture to detect Deepfakes, which consists of a two-stream Capsule network running in parallel that takes in both RGB images/frames as well as Error Level Analysis images. Results show that the proposed approach exhibits the detection accuracy of 73.39 % and 57.45 % for the Deepfake Detection Challenge (DFDC) and the Celeb-DF datasets respectively. These results are, however, from a preliminary implementation of the proposed approach. As part of future work, population-based optimization techniques such as Particle Swarm Optimization (PSO) will be used to tune the hyper parameters for better performance.","2576-8581","978-1-905824-67-0","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9577010","Deepfake;Deepfake detection;face tampering;deep learning;convolutional neural networks;Capsule networks;Error Level Analysis","Training;Analytical models;Computational modeling;Neural networks;Computer architecture;Particle swarm optimization;Optimization","","1","","21","","26 Oct 2021","10-14 May 2021","10-14 May 2021","IEEE","IEEE Conferences"
"Abbreviated View of Deepfake Videos Detection Techniques","M. A. Younus; T. M. Hasan","Department of Computer Science, College of Science, University of Diyala, Diyala, Iraq; Department of Computer Science, College of Science, University of Diyala, Diyala, Iraq","2020 6th International Engineering Conference “Sustainable Technology and Development"" (IEC)","23 Jun 2020","2020","","","115","120","In the era of technological advances and a qualitative breakthrough in the artificial intelligence field and deep neural networks, a new age of hyper-realistic digital videos forgery called DeepFake has been born, with that new technology, it is difficult to distinguish between real videos and fake ones which are uploaded daily on various websites across the Internet. Many open-source DeepFake creation methods have risen, leading to a growing number of synthesized media clips over the internet. There are many efficient fast methods and techniques which have been designed to detect and spot such phenomenon. Background Comparison, Temporal Pattern Analysis, Eye blinking, Facial Artifacts, Mesoscopic Analysis, and Pose Estimation are some of those techniques. Some of these approaches designed to detect and identify the video forgery without any prior enlightenment concerning the videos under analysis. The primary scope of this study is to provide an abbreviate review of these methodologies of a method-comparison study that has been presented to assist the researcher's evaluation of such studies.","","978-1-7281-5910-2","10.1109/IEC49899.2020.9122916","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9122916","Digital videos forgery;Deepfake Detection techniques;Mesoscopic;Facial Artifacts","Training;Deepfakes;Reviews;Pose estimation;Pipelines;Symbols;Programming;Transformers;Forgery;Artificial intelligence","","9","","26","IEEE","23 Jun 2020","26-27 Feb. 2020","26-27 Feb. 2020","IEEE","IEEE Conferences"
"Audio-Visual Temporal Forgery Detection Using Embedding-Level Fusion and Multi-Dimensional Contrastive Loss","M. Liu; J. Wang; X. Qian; H. Li","School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Computer and Communication, University of Science and Technology Beijing, Beijing, China; Guangdong Provincial Key Laboratory of Big Data Computing, The Chinese University of Hong Kong, Shenzhen, China",IEEE Transactions on Circuits and Systems for Video Technology,"12 Aug 2024","2024","34","8","6937","6948","Audio-visual deepfake detection is the process of identifying and detecting deepfakes that have been generated using both audio and visual content with AI algorithms. Most existing methods primarily focus on the overall authenticity while neglecting the position of forgeries in time. This can be particularly problematic, as even a small alteration in a clip can significantly impact its meaning. Such brand new attacks are dangerous and how to tackle such attacks remains an open question. In this paper, we present a novel neural network-based model to tackle the temporal forgery detection (TFD) problem. It consists of new audio and visual encoders with cross-modal attention for embedding extraction, and an embedding-level fusion mechanism with self-attention for forgery localization. Besides, a multi-dimensional contrastive loss is proposed which helps the model not only to capture audio-visual inconsistency for deepfake detection but also to exploit temporal inconsistency by coherently constraining the extracted embeddings. Extensive experiments on the LAV-DF dataset show that the presented method outperforms several state-of-the-art temporal forgery localization methods by up to 23.4% on AP@0.5 and 13.8% on AR@100. In addition, we also show the effectiveness of the proposed model on deepfake detection.","1558-2205","","10.1109/TCSVT.2023.3326694","National Natural Science Foundation of China(grant numbers:62071039); Beijing Natural Science Foundation(grant numbers:L223033); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10290956","Audio-visual deepfake detection;temporal forgery localization;embedding-level fusion;multi-dimensional contrastive;audio-visual inconsistency","Deepfakes;Forgery;Location awareness;Visualization;Proposals;Audio-visual systems;Contrast resolution;Detection algorithms","","9","","71","IEEE","23 Oct 2023","Aug. 2024","","IEEE","IEEE Journals"
"A Multi-Layer Capsule-based Forensics Model for Fake Detection of Digital Visual Media","S. S. Khalil; S. M. Youssef; S. N. Saleh","Computer Engineering Department, College of Engineering and Technology, Arab Academy for Science, Technology and Maritime Transport, Abu Qir, Alexandria, Egypt; Computer Engineering Department, College of Engineering and Technology, Arab Academy for Science, Technology and Maritime Transport, Abu Qir, Alexandria, Egypt; Computer Engineering Department, College of Engineering and Technology, Arab Academy for Science, Technology and Maritime Transport, Abu Qir, Alexandria, Egypt","2020 International Conference on Communications, Signal Processing, and their Applications (ICCSPA)","2 Apr 2021","2021","","","1","6","The dangers generated from synthesized multimedia are increasing every day. The creation of the so-called Deepfakes multimedia is vastly evolving, making the detection task harder every day. Researchers and corporations are interested in exploring the technology limits and are coming up with new tools every year to create more robust fake media. In this paper, a new enhanced fake video detection model is introduced addressing many of the face-swapping threats and the low generalization problem. A preprocessing stage is proposed to minimize the noise in the data to enhance their quality. The proposed architecture uses a modified application of capsule neural networks (CapsNet) with an enhanced routing technique. It does not require a lot of training data and generates a small number of training parameters making it fast to build. The model was trained and tested using the DFDC-P dataset and the results have proven that it outperformed other detectors in terms of detection recall, weighted precision, and F1 score.","","978-1-7281-6535-6","10.1109/ICCSPA49915.2021.9385719","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9385719","deepfake detection;capsule network;capsnet","Training;Visualization;Training data;Media;Tools;Videos;Information integrity","","8","","41","IEEE","2 Apr 2021","16-18 March 2021","16-18 March 2021","IEEE","IEEE Conferences"
"Autonomous Detection and Evaluation of Deepfakes: A Comprehensive Study","R. Sunil; P. Mer; A. Diwan","Computer Engineering Department, Marwadi University, Rajkot, India; Computer Engineering Department, Marwadi University, Rajkot, India; CE - AI & Bigdata, Marwadi University, Rajkot, India",2023 Seventh International Conference on Image Information Processing (ICIIP),"28 May 2024","2023","","","35","40","In recent times, there has been a notable advancement in deepfake techniques and the accessibility of extensive, cost-free databases. Consequently, even folks lacking technological expertise can now edit or produce visually authentic samples for various goals, both benign and harmful in nature. This paper provides a comprehensive analysis of the classification of methods used for deepfake generation and detection. The paper considers numerous factors, including the identified forgery, methodology or techniques used, evaluation metrics used for performance analysis, and the utilized dataset. By studying the development of deepfakes and the most up-to-date deepfake detecting methods, this study gives a full picture of deepfake techniques and makes it easier to come up with new, more reliable methods to fight the growing difficulty of deepfakes.","2640-074X","979-8-3503-7140-6","10.1109/ICIIP61524.2023.10537789","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10537789","Deepfakes;CNN;Artifacts;Face Swap;Facial Reenactment;Synthetic Media;GANs;Deepfake Detection","Measurement;Deepfakes;Databases;Information processing;Forgery;Performance analysis;Reliability","","3","","38","IEEE","28 May 2024","22-24 Nov. 2023","22-24 Nov. 2023","IEEE","IEEE Conferences"
"Exploiting spatiotemporal inconsistencies to detect deepfake videos in the wild","A. Khedkar; A. Peshkar; A. Nagdive; M. Gaikwad; S. Baudha","Dept. of Artificial Intelligence, G.H. Raisoni College of Engineering, Nagpur, India; Dept. of Information Technology, G.H. Raisoni College of Engineering, Nagpur, India; Dept. of Information Technology, G.H. Raisoni College of Engineering, Nagpur, India; Dept. of Information Technology, G.H. Raisoni College of Engineering, Nagpur, India; Dept. of Electronics & Electrical Engineering, BITS Pilani, Goa, India",2022 10th International Conference on Emerging Trends in Engineering and Technology - Signal and Information Processing (ICETET-SIP-22),"15 Jun 2022","2022","","","1","6","Cyberspace is an emerging battlefield and deepfakes are being constantly weaponized by malicious actors. With rapid advancements in media synthesis technologies, detecting deepfakes is becoming increasingly difficult. The following paper presents a unified approach focusing on the fusion of Convolutional Neural Networks and Long Short Term Memory Networks for spatial and temporal analysis of deepfake videos. This study compares the performance of the most prevalent and frequently used deepfake detection methods- convolutional neural networks (CNN) and convolutional neural networks combined with long-short term memory networks (CNN-LSTM) with our architecture on a combined dataset consisting of videos from Face Forensics++ and Deepfake Detection Challenge Dataset, which consists of multiple types of manipulated media- Deepfakes, Faceswaps, Neural Textures, Face Shifter and Face2Face. We find that our architecture provides a 2.5% increase in detection accuracy over the most frequently used current deepfake detection method (CNN-LSTM).","2157-0485","978-1-6654-6741-4","10.1109/ICETET-SIP-2254415.2022.9791719","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9791719","Deepfake Detection;Image Processing;Deep learning;GAN;Generalization;Interpretation","Weapons;Focusing;Cyberspace;Information processing;Media;Market research;Spatiotemporal phenomena","","2","","44","IEEE","15 Jun 2022","29-30 April 2022","29-30 April 2022","IEEE","IEEE Conferences"
"Enhancing Authenticity Verification with Transfer Learning and Ensemble Techniques in Facial Feature-Based Deepfake Detection","N. Qazi; I. Ahmed","Computer and Digitial Technolgies, University of East London, London, UK; Research and Development, Tietoevry Finland Oy, Finland",2024 14th International Conference on Pattern Recognition Systems (ICPRS),"23 Sep 2024","2024","","","1","6","Deepfake technology, facilitated by deep learning algorithms, has emerged as a significant concern due to its potential to deceive humans with fabricated content indistinguishable from reality. The proliferation of deepfake videos presents a formidable challenge, propagating misinformation across various sectors such as social media, politics, and healthcare. Detecting and mitigating these threats is imperative for fortifying defenses and safeguarding information integrity.This paper tackles the complexities associated with deepfake detection, emphasizing the necessity for innovative approaches given the constraints of available data and the evolving nature of forgery techniques. Our proposed solution focuses on leveraging facial features and transfer learning to discern fake videos from genuine ones, aiming to identify subtle manipulations in visual content. We systematically break down videos into frames, employ the Haar cascade algorithm for facial recognition, and utilize transfer learning to extract discriminative features. We evaluate multiple pre-trained models, including VGG16, ConvNeXtTiny, EfficientNetB0, EfficientNetB7, DenseNet201, ResNet152V2, Xception, NASNetMobile, and MobileNetV2, for feature extraction. Subsequently, we feed these features into a Deep Artificial Neural Network (DANN) for deepfake detection and employ ensemble learning to combine the strengths of the best-performing models for enhanced accuracy.We found that the ensemble model comprising ConvNextTiny, EfficientNetB0, and EfficientNetB7 showed enhanced accuracy in detecting deep fakes compared to alternative models achieving up to 98% accuracy through ensemble learning.","","979-8-3503-7565-7","10.1109/ICPRS62101.2024.10677831","Technische Universiteit Eindhoven; European Commission; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10677831","Deepfake detection;video classification;Transfer learning;EfficentNetB0;DenseNet;Ensemble learning","Deepfakes;Visualization;Accuracy;Social networking (online);Transfer learning;Medical services;Feature extraction","","2","","20","IEEE","23 Sep 2024","15-18 July 2024","15-18 July 2024","IEEE","IEEE Conferences"
"Circumventing shortcuts in audio-visual deepfake detection datasets with unsupervised learning","S. Smeu; D. -A. Boldisor; D. Oneata; E. Oneata",Bitdefender; Bitdefender; Politehnica Bucharest; Bitdefender,2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),"13 Aug 2025","2025","","","18815","18825","Good datasets are essential for developing and benchmarking any machine learning system. Their importance is even more extreme for safety critical applications such as deepfake detection—the focus of this paper. Here we reveal that two of the most widely used audio-video deepfake datasets suffer from a previously unidentified spurious feature: the leading silence. Fake videos start with a very brief moment of silence and, on the basis of this feature alone, we can separate the real and fake samples almost perfectly. As such, previous audio-only and audio-video models exploit the presence of silence in the fake videos and consequently perform worse when the leading silence is removed. To circumvent latching on such an unwanted artifact and possibly other unrevealed ones, we propose a shift from supervised to unsupervised learning by training models exclusively on real data. We show that by aligning self-supervised audio-video representations we remove the risk of relying on dataset-specific biases and improve robustness in deepfake detection.","2575-7075","979-8-3315-4364-8","10.1109/CVPR52734.2025.01753","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11092549","deepfake detection;unsupervised learning;dataset bias","Training;Deepfakes;Computer vision;Machine learning;Benchmark testing;Robustness;Data models;Safety;Pattern recognition;Unsupervised learning","","1","","60","IEEE","13 Aug 2025","10-17 June 2025","10-17 June 2025","IEEE","IEEE Conferences"
"Deepfake Detection Using Deep Learning","P. R. S; P. D; S. G; S. R. K; G. B","Department of Computer Science and Engineering, Sri Eshwar College of Engineering, Coimbatore, India; Department of Computer Science and Engineering, Sri Eshwar College of Engineering, Coimbatore, India; Department of Computer Science and Engineering, Sri Eshwar College of Engineering, Coimbatore, India; Department of Computer Science and Engineering, Sri Eshwar College of Engineering, Coimbatore, India; Department of Computer Science and Engineering, Sri Eshwar College of Engineering, Coimbatore, India",2024 10th International Conference on Advanced Computing and Communication Systems (ICACCS),"23 Oct 2024","2024","1","","1768","1774","In recent decades, rapid advancements in AI, machine learning, and deep learning have yielded new methods and tools for manipulating multimedia. While this technology has primarily found applications in legitimate fields such as entertainment and education, there have been instances of malicious users exploiting it for unlawful or nefarious purposes. For instance, individuals have used these techniques to create highly realistic fake videos, images, or audio recordings, with the intention of spreading misinformation, propaganda, inciting political discord, promoting hate, or even engaging in harassment and blackmail. These manipulated and hyper-realistic media have gained notoriety as “Deepfakes” in recent times. The literature has documented various approaches to address the challenges posed by Deepfakes.","2575-7288","979-8-3503-8436-9","10.1109/ICACCS60874.2024.10717155","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10717155","Deepfake detection;video or image manipulation;digital media forensics","Deep learning;Deepfakes;Visualization;Weapons;Neural networks;Organizations;Media;Streaming media;Robustness;Protection","","1","","24","IEEE","23 Oct 2024","14-15 March 2024","14-15 March 2024","IEEE","IEEE Conferences"
"Identification of Deepfakes using Strategic Models and Architectures","S. R. Nallapati; D. Dommeti; S. Medhalavalasa; K. K. Bonku; P. V. V. S. Srinivas; D. Bhattacharyya","Department of CSE, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India; Department of CSE, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India; Department of CSE, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India; Department of CSE, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India; Department of CSE, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India; Department of CSE, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India",2023 International Conference on Sustainable Computing and Data Communication Systems (ICSCDS),"25 Apr 2023","2023","","","75","82","Deepfake technology has been rapidly evolving and expanding in recent years. It has become increasingly easy to manipulate multimedia content, making it harder to detect what is real and what is manipulated. The research aims to explore how neural networks can be used to detect deepfake in multimedia, helping to protect users from potentially malicious and deceptive content. The aim is to explore what neural networks are, how they can be used to detect deepfakes and the potential implications of this technology. The research also aims to evaluate the advantages and disadvantages of using neural networks for deepfake detection. As the world of deepfake technology continues to evolve, this research will provide an overview of the latest developments in deepfake detection and their potential impact. The goal of this research is to use neural networks to detect deepfakes and to identify suspicious content to alert users. This could help protect users from being exposed to malicious content and help content producers ensure the integrity of their work. As deepfake technology continues to evolve, neural networks may become an essential tool for quickly and accurately detecting deepfakes in multimedia. The research explores topics like, CNN, 3D CNN, GATED RECURRENT UNIT and Architectures like Xception, VGG16, InceptionV3 and ResNet50V2. The outcomes are graphically represented and analyzed. the comparative stratification of the approach is done to analyze and detect deepfakes.","","978-1-6654-9199-0","10.1109/ICSCDS56580.2023.10104880","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10104880","Deepfake Detection;Deep Learning;Convolutional Neural Network;Gated Recurrent Unit;Image Noise Patterns","Deepfakes;Visualization;Three-dimensional displays;Neural networks;Computer architecture;Media;Logic gates","","1","","18","IEEE","25 Apr 2023","23-25 March 2023","23-25 March 2023","IEEE","IEEE Conferences"
"Context-Preserving and Sparsity-Aware Temporal Graph Network for Unified Face Forgery Detection","K. D. K. Yadav; I. Kavati; A. S. Kurella; S. Jain; Y. Katare","National Institute of Technology Warangal, India; National Institute of Technology Warangal, India; National Institute of Technology Warangal, India; National Institute of Technology Warangal, India; National Institute of Technology Warangal, India",IEEE Transactions on Consumer Electronics,"","2025","PP","99","1","1","Deepfakes and face forgeries continue to evolve, posing significant threats to consumer privacy, reputation, and public security. Existing deep learning approaches often focus on spatial inconsistencies but fail to capture relational context across facial regions and long-term temporal anomalies such as unnatural blinking or lip synchronization errors. We propose EDRL, a lightweight model that effectively captures spatiotemporal relational dependencies for robust face forgery detection. The architecture incorporates a Spatio-Temporal Attention (STA) module built upon a lightweight MC318 3D convolutional backbone, enabling motion-aware feature extraction and region-specific attention mapping. A Sparsity-Aware Edge Dropping Relation Learner (EDRL) constructs adaptive facial graphs by pruning redundant and less informative edges. A Temporal Adaptive Aggregation Network (TAAN) then aggregates frame-level features, ensuring that temporally significant representations are preserved even after edge pruning. Extensive evaluations show that EDRL achieves 98.4% accuracy on CASIA-FASD and reduces HTER by 6.2% on Replay-Attack compared to state-of-the-art baselines, while maintaining competitive results on digital forgery datasets. By enhancing robustness to diverse manipulations while reducing computational overhead, EDRL contributes towards a secure, lightweight, and deployable framework suitable for real-world applications.","1558-4127","","10.1109/TCE.2025.3633697","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11250982","Spatio-Temporal attention;DeepFake detection;Face Forgery;graph convolution network;relation learning","Forgery;Faces;Adaptation models;Robustness;Image edge detection;Transformers;Deepfakes;Computational modeling;Training;Feature extraction","","","","","IEEE","17 Nov 2025","","","IEEE","IEEE Early Access Articles"
"Detecting Deepfakes and Artificial Intelligence-Generated Art","F. P. Rajeev; S. D. Shetty","Computer Science and Engineering Birla Institute of Technology and Science, Pilani Dubai Campus, Dubai, United Arab Emirates; Computer Science and Engineering Birla Institute of Technology and Science, Pilani Dubai Campus, Dubai, United Arab Emirates",2024 International Conference on Computational Intelligence and Network Systems (CINS),"10 Feb 2025","2024","","","1","7","Recent years have seen innovative advancements in Artificial Intelligence (AI) in the realms of image and video processing, speech and audio recognition, and pattern recognition, leading to the boom in AI art and deepfakes. The evolution of ChatGPT, Dalle-2, and Midjourney has sparked debate about whether AI art qualifies as true art and whether it will eventually displace human artists and creators. AI art generation models are trained on large datasets, often consisting of copyrighted art. Due to this, the resulting picture produced is frequently a manipulated version of the art piece, namely through various techniques - CutMix, Adversarial Data Poisoning, Inpainting, and Style Transfer. This manipulation constitutes a violation of the rights held by the artists. On a similar note, deep fakes pose threats to privacy and security. Society is entering a new age of misinformation and confusion, where they are victims of deepfake phishing scams, identity theft, and malicious political interference. These issues necessitate the development of state-of-the-art algorithms to detect real-life photos and videos, as well as painting and art manipulation. This paper dives deep into the topic of AI art and Deepfake detection, highlighting the most efficient machine learning classification techniques on the DeepfakeArt Challenge and Deepfake Detection Challenge dataset. It aims to highlight the best algorithm that provides reliable results and assists future research in this newly emerging area.","","979-8-3315-0410-6","10.1109/CINS63881.2024.10864456","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10864456","Deepfake Detection;AI Art;Visual Manipulation;Image Authenticity","Training;Deepfakes;Art;Machine learning algorithms;Computational modeling;Speech recognition;Classification algorithms;Artificial intelligence;Speech processing;Video recording","","","","18","IEEE","10 Feb 2025","28-29 Nov. 2024","28-29 Nov. 2024","IEEE","IEEE Conferences"
"Beyond Accuracy: Explainable Multimodal Deepfake Detection Through Cross-Modal Feature Analysis and Dynamic Attention Weighting","T. Rahman; R. Chakma; T. Mahmud","Department of Computer Science and Engineering, Rangamati Science and Technology University; Department of Computer Science and Engineering, Rangamati Science and Technology University; Department of Computer Science and Engineering, Rangamati Science and Technology University","2025 International Conference on Quantum Photonics, Artificial Intelligence, and Networking (QPAIN)","29 Sep 2025","2025","","","1","6","The advent of deepfake technology in recent years has significantly transformed the domain of video synthesis, facilitating the production of convincing synthetic films. The study explains a method for detecting deepfakes that uses both visual and sound analysis with special neural networks and a technique that combines the two types of information. We have a system that uses an EfficientNetB0- based CNN to analyze face images and a bidirectional LSTM to process audio features, showing that combining both types of data makes detection stronger than using just one type. Our research on the AVLips dataset shows that different types of data learn in different ways-visual features help with quick learning at first but are more likely to overfit, while audio features lead to a more consistent learning process. Using explainable AI methods, we find that visual deepfake signs are mainly seen around the eyes and mouth, while specific MFCC coefficients (specifically 2 and 9) offer important distinguishing information in the audio part. The fusion model attains an accuracy of 87.25 %, surpassing the visual-only model at 85.25 % and the audio-only model at 81 %. In addition to performance measurements, our study offers important information regarding feature relevance across modalities and illustrates how attention mechanisms may adjust modality contributions depending on the reliability of individual samples. This study improves the field by highlighting the benefits of understanding multimodal methods and identifying specific patterns across different types of data that characterize deepfake content.","","979-8-3315-9694-1","10.1109/QPAIN66474.2025.11171737","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11171737","CNN;EfficientNetBO;LSTM;MFCC;AVLips;Deepfake Detection;Multimodal","Deepfakes;Visualization;Accuracy;Attention mechanisms;Mouth;Production;Media;Feature extraction;Robustness;Mel frequency cepstral coefficient","","","","24","IEEE","29 Sep 2025","31 July-2 Aug. 2025","31 July-2 Aug. 2025","IEEE","IEEE Conferences"
"Deepfake Detection: A Systematic Literature Review","M. S. Rana; M. N. Nobi; B. Murali; A. H. Sung","Department of Computer Science, Northern Kentucky University, Highland Heights, KY, USA; Department of Computer Science, The University of Texas at San Antonio, San Antonio, TX, USA; School of Computing Sciences and Computer Engineering, The University of Southern Mississippi, Hattiesburg, MS, USA; School of Computing Sciences and Computer Engineering, The University of Southern Mississippi, Hattiesburg, MS, USA",IEEE Access,"11 Mar 2022","2022","10","","25494","25513","Over the last few decades, rapid progress in AI, machine learning, and deep learning has resulted in new techniques and various tools for manipulating multimedia. Though the technology has been mostly used in legitimate applications such as for entertainment and education, etc., malicious users have also exploited them for unlawful or nefarious purposes. For example, high-quality and realistic fake videos, images, or audios have been created to spread misinformation and propaganda, foment political discord and hate, or even harass and blackmail people. The manipulated, high-quality and realistic videos have become known recently as Deepfake. Various approaches have since been described in the literature to deal with the problems raised by Deepfake. To provide an updated overview of the research works in Deepfake detection, we conduct a systematic literature review (SLR) in this paper, summarizing 112 relevant articles from 2018 to 2020 that presented a variety of methodologies. We analyze them by grouping them into four different categories: deep learning-based techniques, classical machine learning-based methods, statistical techniques, and blockchain-based techniques. We also evaluate the performance of the detection capability of the various methods with respect to different datasets and conclude that the deep learning-based methods outperform other methods in Deepfake detection.","2169-3536","","10.1109/ACCESS.2022.3154404","Northern Kentucky University; University of Southern Mississippi; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9721302","Deepfake detection;video or image manipulation;digital media forensics;systematic literature review","Videos;Information integrity;Measurement;Faces;Deep learning;Computational modeling;Web pages","","324","","147","CCBY","24 Feb 2022","2022","","IEEE","IEEE Journals"
"AVoiD-DF: Audio-Visual Joint Learning for Detecting Deepfake","W. Yang; X. Zhou; Z. Chen; B. Guo; Z. Ba; Z. Xia; X. Cao; K. Ren","School of Cyber Science and Technology, Sun Yat-sen University, Shenzhen Campus, Shenzhen, China; School of Software Engineering, University of Electronic Science and Technology of China, Chengdu, China; Zhuque Laboratory, Tencent Security, Shenzhen, China; School of Electronic and Computer Engineering, Peking University, Shenzhen, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; College of Cyber Security, Jinan University, Guangzhou, China; School of Cyber Science and Technology, Sun Yat-sen University, Shenzhen Campus, Shenzhen, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China",IEEE Transactions on Information Forensics and Security,"4 Apr 2023","2023","18","","2015","2029","Recently, deepfakes have raised severe concerns about the authenticity of online media. Prior works for deepfake detection have made many efforts to capture the intra-modal artifacts. However, deepfake videos in real-world scenarios often consist of a combination of audio and visual. In this paper, we propose an Audio-Visual Joint Learning for Detecting Deepfake (AVoiD-DF), which exploits audio-visual inconsistency for multi-modal forgery detection. Specifically, AVoiD-DF begins by embedding temporal-spatial information in Temporal-Spatial Encoder. A Multi-Modal Joint-Decoder is then designed to fuse multi-modal features and jointly learn inherent relationships. Afterward, a Cross-Modal Classifier is devised to detect manipulation with inter-modal and intra-modal disharmony. Since existing datasets for deepfake detection mainly focus on one modality and only cover a few forgery methods, we build a novel benchmark DefakeAVMiT for multi-modal deepfake detection. DefakeAVMiT contains sufficient visuals with corresponding audios, where any one of the modalities may be maliciously modified by multiple deepfake methods. The experimental results on DefakeAVMiT, FakeAVCeleb, and DFDC demonstrate that the AVoiD-DF outperforms many state-of-the-arts in deepfake detection. Our proposed method also yields superior generalization on various forgery techniques.","1556-6021","","10.1109/TIFS.2023.3262148","National Key Research and Development Program of China(grant numbers:2022YFB3103504); Shenzhen Science and Technology Program(grant numbers:20220016); National Natural Science Foundation of China(grant numbers:62261160653,62122032,62172359); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10081373","Deepfake detection;multi-modal;audio-visual;joint learning","Deepfakes;Visualization;Forgery;Detectors;Feature extraction;Faces;Electronic mail","","110","","67","IEEE","27 Mar 2023","2023","","IEEE","IEEE Journals"
"Improving Video Vision Transformer for Deepfake Video Detection Using Facial Landmark, Depthwise Separable Convolution and Self Attention","K. N. Ramadhani; R. Munir; N. P. Utama","Bandung Institute of Technology, Bandung, Indonesia; Bandung Institute of Technology, Bandung, Indonesia; Bandung Institute of Technology, Bandung, Indonesia",IEEE Access,"19 Jan 2024","2024","12","","8932","8939","In this paper, we present our result of research in video deepfake detection. We built a deepfake detection system to detect whether a video is a deepfake or real. The deepfake detection algorithm still struggle in providing a sufficient accuracy values, especially in challenging deepfake dataset. Our deepfake detection system utilized spatiotemporal feature that extracted using Video Vision Transformer (ViViT). The main contribution of our research is providing a deepfake detection system that based on ViViT architecture and using landmark area images for the input of the system. Our system extracted the feature from a number of spatial features. The spatial feature was extracted using Depthwise Separable Convolution (DSC) block combined with Convolution Block Attention Module (CBAM) from tubelet. The tubelet was a representation of facial landmark area that was extracted from the input video. In our system, we used 25 facial landmark area for an input video. In our experiment we used Celeb-DF version 2 dataset because it is considered to be a challenging deepfake dataset. We conducted augmentation to the dataset, so we obtained 8335 videos for training set, 390 videos for validation set, and 1123 videos for testing set. We trained our deepfake detection system using Adam optimizer, with learning rate of 10–4 and 100 epoch. From the experiment, we obtained the accuracy score of 87.18% and F1 score of 92.52%. We also conducted the ablation study to display the effect of each part of our model to the overall system performance. From this research, we obtained that by using landmark area images, our ViViT based deepfake detection system had a good performance in detecting deepfake videos.","2169-3536","","10.1109/ACCESS.2024.3352890","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10388363","Deepfake detection;facial landmark;depthwise separable convolution;convolution block attention module;video vision transformer","Deepfakes;Feature extraction;Visualization;Face recognition;Convolutional neural networks;Head;Transformers","","28","","28","CCBYNCND","11 Jan 2024","2024","","IEEE","IEEE Journals"
"Exposing Deepfake Face Forgeries With Guided Residuals","Z. Guo; G. Yang; J. Chen; X. Sun","School of Information Science and Engineering, Hunan University, Changsha, China; School of Information Science and Engineering, Hunan University, Changsha, China; School of Information Science and Engineering, Hunan University, Changsha, China; School of Computer and Software, Nanjing University of Information Science and Technology, Nanjing, China",IEEE Transactions on Multimedia,"12 Dec 2023","2023","25","","8458","8470","For Deepfake detection, residual-based features can preserve tampering traces and suppress irrelevant image content. However, inappropriate residual prediction brings side effects on detection accuracy. Meanwhile, residual-domain features are easily affected by some image operations such as lossy compression. Most existing works exploit either spatial-domain or residual-domain features, which are fed into the backbone network for feature learning. Actually, both types of features are mutually correlated. In this work, we propose an adaptive fusion based guided residuals network (AdapGRnet), which fuses spatial-domain and residual-domain features in a mutually reinforcing way, for Deepfake detection. Specifically, we present a fine-grained manipulation trace extractor (MTE), which is a key module of AdapGRnet. Compared with the prediction-based residuals, MTE can avoid the potential bias caused by inappropriate prediction. Moreover, an attention fusion mechanism (AFM) is designed to selectively emphasize feature channel maps and adaptively allocate the weights for two streams. Experimental results show that AdapGRnet achieves better detection accuracies than the state-of-the-art works on four public fake face datasets including HFF, FaceForensics++, DFDC and CelebDF. Especially, AdapGRnet achieves an accuracy up to 96.52% on the HFF-JP60 dataset, which improves about 5.50%. That is, AdapGRnet achieves better robustness than the existing works.","1941-0077","","10.1109/TMM.2023.3237169","National Natural Science Foundation of China(grant numbers:61972143,61972142); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10017352","Deepfake detection;image forensics;guided residuals;attention fusion mechanism","Faces;Feature extraction;Deepfakes;Forgery;Robustness;Image forensics;Biology","","24","","65","IEEE","18 Jan 2023","2023","","IEEE","IEEE Journals"
"A Study on Combating Emerging Threat of Deepfake Weaponization","R. Katarya; A. Lal","Department of Computer Science and Engineering, Delhi Technological University, New Delhi, India; Department of Computer Science and Engineering, Delhi Technological University, New Delhi, India","2020 Fourth International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)","10 Nov 2020","2020","","","485","490","A breakthrough in the emerging use of machine learning and deep learning is the concept of autoencoders and GAN (Generative Adversarial Networks), architectures that can generate believable synthetic content called deepfakes. The threat lies when these low-tech doctored images, videos, and audios blur the line between fake and genuine content and are used as weapons to cause damage to an unprecedented degree. This paper presents a survey of the underlying technology of deepfakes and methods proposed for their detection. Based on a detailed study of all the proposed models of detection, this paper presents SSTNet as the best model to date, that uses spatial, temporal, and steganalysis for detection. The threat posed by document and signature forgery, which is yet to be explored by researchers, has also been highlighted in this paper. This paper concludes with the discussion of research directions in this field and the development of more robust techniques to deal with the increasing threats surrounding deepfake technology.","","978-1-7281-5464-0","10.1109/I-SMAC49090.2020.9243588","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9243588","Deep Learning;Generative Adversarial Networks;autoencoders;Deepfake detection;Fake image;Fake Video","Deep learning;Weapons;Medical services;Generative adversarial networks;Forgery;Videos;Information integrity","","19","","39","IEEE","10 Nov 2020","7-9 Oct. 2020","7-9 Oct. 2020","IEEE","IEEE Conferences"
"eKYC-DF: A Large-Scale Deepfake Dataset for Developing and Evaluating eKYC Systems","H. Felouat; H. H. Nguyen; T. -N. Le; J. Yamagishi; I. Echizen","Informatics Program, The Graduate University for Advanced Studies, SOKENDAI, Kanagawa, Japan; Informatics Program, The Graduate University for Advanced Studies, SOKENDAI, Kanagawa, Japan; Information and Society Research Division, National Institute of Informatics, Tokyo, Japan; Informatics Program, The Graduate University for Advanced Studies, SOKENDAI, Kanagawa, Japan; Informatics Program, The Graduate University for Advanced Studies, SOKENDAI, Kanagawa, Japan",IEEE Access,"1 Mar 2024","2024","12","","30876","30892","The reliability of remote identity-proofing systems (i.e., electronic Know Your Customer, or eKYC, systems) is challenged by the development of deepfake generation tools, which can be used to create fake videos that are difficult to detect using existing deepfake detection models and are indistinguishable by facial recognition systems. This poses a serious threat to eKYC systems and a danger to individuals’ personal information and property. Existing deepfake datasets are not particularly appropriate for developing and evaluating eKYC systems, which require specific motions, such as head movement, for liveness detection. Furthermore, they do not contain ID information or protocols for facial verification evaluation, which is vital for eKYC. We found that eKYC systems without the ability to detect deepfakes can be easily compromised. We have thus created a large-scale collection of high-quality fake videos (more than 228,000 videos) that are diverse in terms of age, gender, and ethnicity, plus a corresponding facial image subset. The videos include a variety of head movements and facial expressions. This large collection of high-quality diverse videos is well-suited for developing and evaluating various tasks related to eKYC systems. Furthermore, we provide protocols for traditional deepfake detection and facial verification, which are widely used in eKYC systems. It is worth mentioning that systematic evaluation of facial recognition systems on deepfake detection has not been reported. The entire eKYC-DF dataset, evaluation toolkit, and trained models are open access to researchers on GitHub: https://github.com/hichemfelouat/eKYC-DF.","2169-3536","","10.1109/ACCESS.2024.3369187","Japan Society for the Promotion of Science (JSPS) KAKENHI(grant numbers:JP16H06302,JP18H04120,JP20K23355,JP21H04907,JP21K18023); Japan Science and Technology Agency (JST) CREST(grant numbers:JPMJCR18A6,JPMJCR20D3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10444105","Deepfake detection;electronic Know Your Customer;eKYC;facial verification;face swapping;face recognition","Deepfakes;Videos;Face recognition;Feature extraction;Facial features;Cameras;Customer profiles;Remote handling equipment;Identity management systems;Identification of persons","","12","","81","CCBYNCND","23 Feb 2024","2024","","IEEE","IEEE Journals"
"SDHF: Spotting DeepFakes with Hierarchical Features","T. Liang; P. Chen; G. Zhou; H. Gao; J. Liu; Z. Li; J. Dai","School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China",2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI),"24 Dec 2020","2020","","","675","680","DeepFake videos are widely distributed on social media platforms, which has seriously affected the authenticity of digital media content, calling for robust DeepFake detection methods. Although numerous detection methods are formulated as frame-based binary classification, less attention has been paid to aggregate the features over individual frames to get a video-based judgement. We observed that for the detection of DeepFake videos, three different level forgery features from frame, clip and video can complement each other. We also found that discrete, large interval sampling strategy is more suitable for DeepFake detection, which can sample more complex video scenes, including multiple subjects, diverse facial expressions and head poses. In this work, we propose a hierarchical framework, using 2D convolutional neural networks for frame-level features extraction followed by a 1D convolutional aggregator to extract clip-level and video-level features, which can comprehensively exploit three different levels of features to make decisions. Evaluation was performed on four datasets, including DFDC, Celeb-DF, FaceForensics++ and UADFV, which provides competitive results compared to other methods. Experimental results of cross-test demonstrate that our hierarchical framework has excellent generalization performance in the face of unknown datasets.","2375-0197","978-1-7281-9228-4","10.1109/ICTAI50040.2020.00108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288325","DeepFake detection;Hierarchical features","Two dimensional displays;Tools;Feature extraction;Convolutional neural networks;Faces;Videos;Information integrity","","8","","39","IEEE","24 Dec 2020","9-11 Nov. 2020","9-11 Nov. 2020","IEEE","IEEE Conferences"
"A Residual Fingerprint-Based Defense Against Adversarial Deepfakes","J. Jiang; B. Li; S. Yu; C. Liu; S. An; M. Liu; M. Yu","Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China","2021 IEEE 23rd Int Conf on High Performance Computing & Communications; 7th Int Conf on Data Science & Systems; 19th Int Conf on Smart City; 7th Int Conf on Dependability in Sensor, Cloud & Big Data Systems & Application (HPCC/DSS/SmartCity/DependSys)","30 May 2022","2021","","","797","804","The authenticity and integrity of digital visual media have always been a crucial branch in the domain of multimedia forensics and information security. Currently, the emerging Deepfakes destroy the authenticity and integrity as well as trump up a person's behaviors that do not exist in reality, which pose potential threats to individual, social and even national security. Although multiple well-designed deep neural networks have achieved satisfactory performance on Deepfake detection, by adding imperceptible but purposeful adversarial perturbations to fake images or videos, the crafted adversarial Deepfakes are demonstrated to cause the malfunction of detectors. In response to such threats, little recent research attempts to take defensive measures but shows scarce applicability, and the effective conventional defenses are insufficient to protect the particular Deepfake detectors. Therefore, to defend against adversarial Deepfakes, we propose a residual fingerprint-based defense customized for Deepfake detectors. By analyzing the impacts of adversarial perturbations on detectors, we construct a reconstruction network, and propose novel strategies to degrade the adversarial efficacy as well as extract discriminative residual fingerprints. Ultimately, we transform the extracted residual fingerprints for Deepfake detection. The evaluation results indicate the performance of compromised detectors is regained by our proposed defense, which is qualified for enhancing the security and reliability of multiple Deepfake detectors.","","978-1-6654-9457-1","10.1109/HPCC-DSS-SmartCity-DependSys53884.2021.00129","Youth Innovation Promotion Association CAS(grant numbers:2021155); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9781144","multimedia forensics and information security;Deepfake detection;adversarial Deepfakes;residual fingerprints","Visualization;Smart cities;Perturbation methods;Forensics;Neural networks;Detectors;Transforms","","4","","26","IEEE","30 May 2022","20-22 Dec. 2021","20-22 Dec. 2021","IEEE","IEEE Conferences"
"You’re not acting like yourself: Deepfake Detection Based on Facial Behavior","A. Libourel; J. -L. Dugelay","Digital Security, Eurecom, Biot, France; Digital Security, Eurecom, Biot, France","2025 IEEE 6th International Conference on Image Processing, Applications and Systems (IPAS)","21 Mar 2025","2025","CFP2540Z-ART","","1","6","Politicians and government leaders are critical targets for deepfake attacks. A single deepfake involving these individuals can severely damage their careers or, in extreme cases, pose a national security threat. Attackers can leverage vast amounts of publicly available audio and video recordings to train their models, making this threat even more pressing. In response, specialized deepfake detectors have been developed to focus on detecting deepfakes targeting a specific Person of Interest (POI). By learning facial expressions and movements unique to the POI, these detectors can identify inconsistencies in deepfakes where these authentic attributes are absent. However, previous methods relied on Facial Action Units, which offer an incomplete representation of the POI’s behavior. In this paper, we propose a novel approach to learning POI-specific movements without requiring deepfake samples during training, making it independent of any deepfake generation methods. Although our technique is speaker-dependent, it provides a robust solution for protecting high-profile individuals who are particularly exposed to deepfake threats.","","979-8-3315-0652-0","10.1109/IPAS63548.2025.10924537","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10924537","deepfake detection;biometrics;media forensics;behavioral analysis;POI recognition","Training;Deepfakes;Image recognition;Forensics;Government;Detectors;Pressing;Media;National security;Video recording","","1","","24","IEEE","21 Mar 2025","9-11 Jan. 2025","9-11 Jan. 2025","IEEE","IEEE Conferences"
"DeepFakeGuard: Real-Time Deepfake Video Detection Leveraging Celeb-DF Dataset and CNN-LSTM Framework","V. S R; P. K. M; A. S. V N G; S. G","Department of Information Technology, Velammal College of Engineering and Technology, Madurai, Tamilnadu; Department of Information Technology, Velammal College of Engineering and Technology, Madurai, Tamilnadu; Department of Information Technology, Velammal College of Engineering and Technology, Madurai, Tamilnadu; Department of Information Technology, Velammal College of Engineering and Technology, Madurai, Tamilnadu",2025 5th International Conference on Expert Clouds and Applications (ICOECA),"13 Aug 2025","2025","","","744","750","Deepfake technology has significantly eroded the veracity of digital media across the world, raising concerns of misinformation and media manipulation. To counteract this, we have developed DeepFakeGuard, a powerful deepfake detection system with robust deep learning algorithms present on the web. The system works to identify deepfake videos by checking each subsequent frame for irregularities, for instance, unbalanced lip movements, abrupt light changes, or unnatural cuts. DeepFakeGuard has been pre-trained on a wide variety of datasets primarily focused on the Celeb-DF dataset with high-quality and challenging-to-detect deepfake content. This provides the system with flexibility and precision for multiple applications such as short-form broadcast, high-definition video streams, and live streams. The initial step was preprocessing of data meticulously with focus on neatness and elimination of data noise to ensure the model works at its best. We then employed the latest deep learning architectures, a combination of Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs), to detect the slightest disparities between subsequent frames. Our models have been exhaustively tested to identify tampered content from real media at high accuracy levels. The web-based system provides real-time detection of deepfake, with the ability to upload media files to be detected in real-time. In addition, its robust backend infrastructure for processing video prevents disruption in smooth processing, making DeepFakeGuard deployable on a wide variety of environments such as content moderation, digital forensics, and media verification. The result of our work is evidence of how DeepFakeGuard can enhance digital media security through effective deepfake content detection.","","979-8-3315-2447-0","10.1109/ICOECA66273.2025.00133","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11113856","Deepfake detection;Deep learning algorithms;Celeb-DF dataset;Real-time detection;Convolutional Neural Networks (CNNs);Recurrent Neural Networks (RNNs)","Deep learning;Deepfakes;Recurrent neural networks;Accuracy;Lips;Media;Real-time systems;Robustness;Convolutional neural networks;Long short term memory","","","","15","IEEE","13 Aug 2025","6-7 March 2025","6-7 March 2025","IEEE","IEEE Conferences"
"Fighting Malicious Media Data: A Survey on Tampering Detection and Deepfake Detection","J. Wang; Z. Li; C. Zhang; J. Chen; Z. Wu; L. S. Davis; Y. -G. Jiang","Institute of Trustworthy Embodied AI, Fudan University, Shanghai, China; Institute of Trustworthy Embodied AI, Fudan University, Shanghai, China; Institute of Trustworthy Embodied AI, Fudan University, Shanghai, China; Institute of Trustworthy Embodied AI, Fudan University, Shanghai, China; Institute of Trustworthy Embodied AI, Fudan University, Shanghai, China; Center for Automation Research, University of Maryland, College Park, MD, USA; Institute of Trustworthy Embodied AI, Fudan University, Shanghai, China",Proceedings of the IEEE,"28 Jul 2025","2025","113","3","287","311","Online media data, in the form of images and videos, are becoming mainstream communication channels. However, recent advances in deep learning (DL), particularly deep generative models, open the doors for producing perceptually convincing images and videos at a low cost, which not only poses a serious threat to the trustworthiness of digital information but also has severe societal implications. This motivates a growing interest in research in media tampering detection (TD), i.e., using DL techniques to examine whether media data have been maliciously manipulated. Depending on the content of the targeted images, media forgery could be divided into image tampering and Deepfake techniques. The former typically moves or erases the visual elements in ordinary images, while the latter manipulates the expressions and even the identity of human faces. Accordingly, the means of defense include image TD and Deepfake detection (DFD), which share a wide variety of properties. In this article, we provide a comprehensive review of the current media TD approaches and discuss the challenges and trends in this field for future research.","1558-2256","","10.1109/JPROC.2025.3576367","National Natural Science Foundation of Project(grant numbers:62072116); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11048678","Deepfake detection (DFD);media forensics;tampering detection (TD)","Media;Deepfakes;Surveys;Forgery;Forensics;Visualization;Training;Fake news;Social networking (online);Information integrity","","","","384","IEEE","23 Jun 2025","March 2025","","IEEE","IEEE Journals"
"Critical Contour Prior-Guided Graph Learning With Pose Calibration for Identity-Aware Deepfake Detection","L. Ming; P. He; H. Li; S. Wang; X. Jiang","School of Cyber Science and Engineering, Sichuan University, Chengdu, China; School of Cyber Science and Engineering, Sichuan University, Chengdu, China; Department of Electrical Engineering, City University of Hong Kong, Hong Kong; Department of Computer Science, City University of Hong Kong, Kowloon, Hong Kong; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China",IEEE Transactions on Multimedia,"","2025","PP","99","1","13","Deepfake has recently raised severe public concerns about security issues, such as creating fake news of celebrities. As countermeasures, identity-aware detection methods leverage identity information to expose forged videos by measuring identity consistency between the suspicious input and its reference samples. However, the performance of existing methods suffers from notable degradation due to undesired variations of head poses and capturing environments. In this work, we first conduct a statistical analysis to illustrate the influence of different facial regions for forensic purposes, which infers more reliable identity information is located in critical face regions. Motivated by this analysis, we propose a graph learning-based identity-aware deepfake detection framework considering critical contour prior as guidance. First, feature sampling based on contour landmarks is applied to construct the graph data as the input of our critical contour prior-guided graph attention network (CP-GAT), where a node position prediction task is constructed as auxiliary supervision to explore rich relationships between nodes. To enhance pose-invariant ability, a rotation compensation block is integrated into CP-GAT and trained using a pose-calibrated contrastive learning to extract identity features, which takes high-quality front faces as the calibration goal with a progressively updating selection. Besides, an adversarial node masking-based training strategy is proposed as feature augmentation to further enhance the reliability. During the inference stage, the similarity between identity features of the input sample and its reference samples extracted by the trained CP-GAT is used to obtain the detection result. Extensive experiments are conducted on various face forgery datasets and state-of-the-art methods are compared to verify the superiority of the proposed method in terms of detection capability and robustness.","1941-0077","","10.1109/TMM.2025.3613159","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11175558","Deepfake detection;video forensics;graph learning;contrastive learning","Feature extraction;Faces;Face recognition;Deepfakes;Training;Data mining;Forensics;Contrastive learning;Security;Calibration","","","","","IEEE","22 Sep 2025","","","IEEE","IEEE Early Access Articles"
"A Hybrid Xception-LSTM Model with Channel and Spatial Attention Mechanism for Deepfake Video Detection","D. Dagar; D. K. Vishwakarma","Dept. of Information Technolgy, Delhi Technological University (DTU), Delhi, India; Dept. of Information Technolgy, Delhi Technological University (DTU), Delhi, India",2023 3rd International Conference on Mobile Networks and Wireless Communications (ICMNWC),"22 Feb 2024","2023","","","1","5","The great strides taken in recent times in image and video manipulation have raised serious concerns. Deepfake technology uses deep learning approaches to create highly realistic, astonishing content. Detecting such videos is the only promising defense against such fraudulent data. To counter the malicious intent of the user, a deepfake detection model is proposed that employs channel and spatial attention mechanisms(CBAM) along with Xception and LSTM pretrained models. Xception uses depthwise separable convolution to capture the latent spatial artifacts. LSTM captures the discrepancies among the manipulated sequences; hence, this hybrid ensembling of models allows the learning of powerful features. The evaluation is performed on the recently proposed Div-DF dataset consisting of varied video manipulation like face swap, facial reenactment, and lip-sync. It shows that the model works well (Accuracy~ 93 % & AUC ~ 0.98) on the diversified dataset and easily beats the score of various state-of-the-art deepfake detection and image classification models.","","979-8-3503-1702-2","10.1109/ICMNWC60182.2023.10435983","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10435983","deepfake detection;deepfake dataset;video manipulation detection;channel attention;spatial attention","Wireless communication;Deep learning;Deepfakes;Image coding;Convolution;Faces;Image classification","","7","","31","IEEE","22 Feb 2024","4-5 Dec. 2023","4-5 Dec. 2023","IEEE","IEEE Conferences"
"DeepMark: A Platform Ensuring Content Integrity","S. Chirakkarottu; A. M. S; A. Manoj; A. M. Nair; D. K. S","Dept. of CSE, FISAT, Cochin, Kerala, India; Dept. of CSE, FISAT, Cochin, Kerala, India; Dept. of CSE, FISAT, Cochin, Kerala, India; Dept. of CSE, FISAT, Cochin, Kerala, India; Dept. of CSE, FISAT, Cochin, Kerala, India",2025 Advanced Computing and Communication Technologies for High Performance Applications (ACCTHPA),"24 Sep 2025","2025","","","1","6","Social media content integrity evaluation is necessary to avoid unauthorized redistribution and alteration of multimedia content. The traditional approaches are primarily based on metadata or watermarking methods, which are easily tampered with or deleted, and thus are insufficient to guarantee long-term content authenticity. This renders it difficult to maintain ownership authentication and prevent content tampering. To counter these weaknesses, we suggest an improved system that employs DWT-based watermarking, facial feature hashing, and cryptographic metadata embedding to ensure content integrity. The system delves into the spatial coordinates of facial landmarks to generate unique hash values that are securely stored in a database to enable verification. The system, through the integration of multi-layer security techniques, manages to eliminate the risk of content re-posting and monitors unauthorized tampering, even when it is covert. Moreover, our method minimizes computational overhead while still being able to verify in real-time, thereby making the system scalable to mass use. The suggested architecture enhances the security and reliability of user-generated media on social networks, offering an end-to-end solution for preventing media forgery and abuse.","","979-8-3315-4437-9","10.1109/ACCTHPA65749.2025.11168595","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11168595","Deepfake Detection;Digital Watermarking;Media Integrity;Forensic Metadata Analysis;Multimodal Verification;Cryptographic Watermarking;Synthetic Media Manipulation","Social networking (online);Face recognition;Watermarking;Metadata;Real-time systems;Libraries;Discrete wavelet transforms;Reliability;Sustainable development;Facial features","","","","8","IEEE","24 Sep 2025","18-19 July 2025","18-19 July 2025","IEEE","IEEE Conferences"
"Localization of Deepfake Facial Images Through U-NET Architecture","K. K. Sheelavantmath; V. Isloor; B. Sheetal; N. Bhuvisha; B. J. Sandesh","Dept. of CSE, PES University, Bangalore, Karnataka, India; Dept. of CSE, PES University, Bangalore, Karnataka, India; Dept. of CSE, PES University, Bangalore, Karnataka, India; Dept. of CSE, PES University, Bangalore, Karnataka, India; Dept. of CSE, PES University, Bangalore, Karnataka, India",2025 11th International Conference on Computing and Artificial Intelligence (ICCAI),"11 Aug 2025","2025","","","102","107","Traditional deep fake detection methods predominantly rely on binary classification, categorizing images as either real or fake, which often limits their transparency and interpretability for real-world applications. To address this, we propose a novel approach that integrates Histogram of Oriented Gradients (HOG) features into a U-Net architecture, enabling the capture of both fine-grained texture patterns and highlevel contextual information in deep fake regions. For enhanced interpretability, Class Activation Maps (CAM) are transformed into the HSV color space, facilitating intuitive color-based analysis. Contour detection is then employed to localize manipulated regions, and bounding boxes are generated using Dlib to precisely identify these features. By iterating through 68 facial landmarks, textual descriptions are generated to highlight alterations in facial features, providing a detailed understanding of the modifications. To further quantify the extent of manipulation, the resulting feature map undergoes a quantitative assessment by calculating the percentage of contour-detected areas. This method offers a comprehensive framework for identifying and analyzing subtle differences between genuine and modified images, advancing the transparency and accuracy of deep fake detection.","","979-8-3315-2491-3","10.1109/ICCAI66501.2025.00023","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11106172","Deepfake Detection;Histogram of Oriented Gradients (HOG);U-Net Architecture;Class Activation Maps (CAM);HSV Color Space;Contour Detection;Dlib;Facial Landmark Analysis","Location awareness;Deepfakes;Histograms;Attention mechanisms;Image color analysis;Data visualization;Computer architecture;Feature extraction;Real-time systems;Facial features","","","","14","IEEE","11 Aug 2025","28-31 March 2025","28-31 March 2025","IEEE","IEEE Conferences"
"Comparative Analysis of DeepFake Detection Methods","V. Chawla; T. Baraskar","Dept of Computer Science & Technology, Dr. Vishwanath Karad MIT World Peace University, Pune, Maharashtra, India; Dept of Computer Science & Technology, Dr. Vishwanath Karad MIT World Peace University, Pune, Maharashtra, India",2024 4th Asian Conference on Innovation in Technology (ASIANCON),"21 Jan 2025","2024","","","1","8","Deep Learning has played an immensely significant role in leading towards the revolutionary developments in numerous fields namely computer vision, big data analytics, healthcare, finance, cyber security and manufacturing industry. This rapid advancement has led to the emergence of diverse tools and technologies capable of manipulating multimedia. One of the major concerns is the DeepFake Technology which poses a real threat to the national security, democracy and privacy. It can be defined as a technique used to produce images, videos or any digital content that appear to be of high quality and hyper-realistic in nature, which have been produced with the intention of spreading propaganda, false information, inciting hatred and political unrest, or even harassing and blackmailing people. This technique is being actively employed in many different areas of the television industry for the recreation of videos by synthetically producing digital content without reshooting them at a very minimal cost. Additionally, the production and distribution of such content is growing rapidly across all media domains. Thus, it is crucial to develop effective technologies capable of detecting the DeepFake in these type of multimedia in order to abate the eventual harm caused in public. In the initial phases of deepfake detection, conventional methods such as signal processing, image processing, and lip-sync analysis were employed. However, these techniques achieved limited accuracy when integrated with modern deep learning technologies. Therefore, this paper primarily proposes a comparative study of all the diverse techniques which can be employed for the task of deepfake detection on the Celeb-DF dataset using diverse performance metrics. In addition to this, this study also discusses the future trends that should be taken into account to make progress in this field.","","979-8-3503-5421-8","10.1109/ASIANCON62057.2024.10838081","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10838081","DeepFake Detection;GANs;AutoKeras NAS Model;CNN;Accuracy;Celeb-DF;multimedia","Deep learning;Deepfakes;Analytical models;Technological innovation;TV;Streaming media;Signal processing;Data models;Resilience;Testing","","","","14","IEEE","21 Jan 2025","23-25 Aug. 2024","23-25 Aug. 2024","IEEE","IEEE Conferences"
"Vision-based Multimodal Deepfake Detection using Explainable AI","J. Joseph; S. Juliet; A. J","Division of Data Science and Cybersecutity, Karunya Institute of Technology and Sciences, Coimbatore, India; Division of Artificial Intelligence and Machine Learning, Karunya Institute of Technology and Sciences, Coimbatore, India; Division of Computer Science and Engineering, Karunya Institute of Technology and Sciences, Coimbatore, India",2025 Third International Conference on Augmented Intelligence and Sustainable Systems (ICAISS),"24 Jun 2025","2025","","","609","615","The rise of deepfake technology has raised critical issues concerning digital security, disinformation, and identity theft. Detection models of deepfakes have conventionally relied greatly on convolutional neural networks (CNNs), powerful as they are, but they lack transparency and suffer from generalizability to multiple manipulation techniques. This paper proposes a vision-based multimodal deepfake detection architecture that uses CNNs, Vision Transformers (ViTs), and Explainable AI (XAI) techniques to enhance performance as well as trustworthiness. The proposed model uses spatiotemporal inconsistencies in facial texture, eye blinking, and visual consistency for enhanced detection. The model's mean accuracy of 97.2%, as demonstrated by experimental findings on the FaceForensics++, Celeb-DF, and DFDC datasets, is superior to the most advanced deepfake detection techniques. In addition, Grad-CAM and SHAP-based visual explanations have explainable results, further increasing forensic usability. This research advances towards more accurate, explainable, and effective detection against evolving adversarial attacks and defending digital integrity and fighting misinformation will help achieve Sustainable Development Goal (SDG) 16: Peace, Justice, and Strong Institutions.","","979-8-3315-0724-4","10.1109/ICAISS61471.2025.11042185","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11042185","Deepfake Detection;Vision Transformers;Multimodal AI;Explainable AI;Digital Forensics;Machine Learning;UN SDG 16","Deepfakes;Computer vision;Visualization;Accuracy;Explainable AI;Transformers;Robustness;Spatiotemporal phenomena;Usability;Sustainable development","","","","16","IEEE","24 Jun 2025","21-23 May 2025","21-23 May 2025","IEEE","IEEE Conferences"
"A Hybrid Approach for Deepfake Image Detection with Frequency Analysis and Biological Analysis","J. C. Ng; M. B. Jasser; B. Issa; S. -S. M. Ajibade; H. N. Chua","Faculty of Engineering and Technology, School of Computing and Artificial Intelligence, Sunway University, Bandar Sunway, Selangor Darul Ehsan, Malaysia; Faculty of Engineering and Technology, School of Computing and Artificial Intelligence, Sunway University, Bandar Sunway, Selangor Darul Ehsan, Malaysia; Faculty of Informatics Engineering, University of Aleppo, Syria; Faculty of Engineering and Technology, School of Computing and Artificial Intelligence, Sunway University, Bandar Sunway, Selangor Darul Ehsan, Malaysia; Faculty of Engineering and Technology, School of Computing and Artificial Intelligence, Sunway University, Bandar Sunway, Selangor Darul Ehsan, Malaysia",2025 IEEE 15th International Conference on System Engineering and Technology (ICSET),"16 Dec 2025","2025","","","25","30","Deepfake is well-known to be extremely capable of mimicking real person, not only physical appearance but includes the facial expressions and voice specifications. Consequently, Deepfake technologies are being widely used in various malicious activities and crime cases, such as financial frauds and scams, as well as sexual abuse and harassment, etc. Therefore, Deepfake detection is extremely vital. In this project, several existing Deepfake detection techniques are explored and discussed, concluding the technology advancements, advantages and differences between the currently available mechanisms for Deepfake detection. Most of the existing project focuses only on biological analysis with signals like eye-blinking, heartbeat rates, etc., but biological analysis can include biological features like skin features. Besides, there are also lacking of research to combine biological analysis and other feature analyses. Hence, a hybrid approach is proposed - combining both the frequency analysis and the biological analysis with skin features while implementing Deepfake detection. The proposed approach utilizes mid-level model fusion with ResNet and MLP to combine different analyses, as to improve Deepfake detection results. This project implemented several models to evaluate and compare each model according to the feature analysis method applied and model fusion techniques utilized. The results show that biological analysis with skin texture and skin tone features can greatly help in Deepfake detection on images, and mid-level fusion model serves better generalization and detection capabilities as compared to early fusion approach.","2470-640X","979-8-3315-3906-1","10.1109/ICSET65917.2025.11283958","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11283958","Deepfake detection;Hybrid/Fusion model;Neural Network;Frequency Analysis;Biological Analysis","Wavelet transforms;Deepfakes;Analytical models;Biological system modeling;Software algorithms;Artificial neural networks;Prediction algorithms;Feature extraction;Wavelet analysis;Skin","","","","","IEEE","16 Dec 2025","4-4 Oct. 2025","4-4 Oct. 2025","IEEE","IEEE Conferences"
"AI/ML-Based Solution for Detecting Face-Swap Deepfakes","S. S. Patil; A. M; P. M; P. P. C","Dept. Of Computer Science And Engineering, Sri Venkateshwara College Of Engineering, Bengaluru; Dept. Of Computer Science And Engineering, Sri Venkateshwara College Of Engineering, Bengaluru; Dept. Of Computer Science And Engineering, Sri Venkateshwara College Of Engineering, Bengaluru; Dept. Of Computer Science And Engineering, Sri Venkateshwara College Of Engineering, Bengaluru",2025 International Conference on Emerging Trends in Industry 4.0 Technologies (ICETI4T),"26 Aug 2025","2025","","","1","7","The rapid advancement of deepfake technology, particularly in face-swap applications, poses significant challenges to the integrity of digital media and personal security. This research introduces a hybrid system using Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) to detect deepfakes. The model combines spatial and temporal feature analysis to spot inconsistencies in manipulated media. Facial landmarks are detected using the Dlib library, while classifiers like Support Vector Machines (SVM) and Artificial Neural Networks (ANN) enhance detection accuracy. Data augmentation and bidirectional LSTM processing improve the system’s robustness in real-world scenarios. By leveraging AI-driven techniques, the model offers a reliable solution to counter the growing misuse of deepfake technology, ensuring high precision and adaptability.","","979-8-3315-0696-4","10.1109/ICETI4T63625.2025.11132146","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11132146","deepfake detection;face-swap;Convolutional Neural Networks (CNNs);Recurrent Neural Networks (RNNs);Support Vector Machines (SVM);Artificial Neural Networks (ANN);AI/ML","Support vector machines;Deepfakes;Ethics;Adaptation models;Technological innovation;Computational modeling;Collaboration;Data augmentation;Convolutional neural networks;Security","","","","20","IEEE","26 Aug 2025","6-7 June 2025","6-7 June 2025","IEEE","IEEE Conferences"
