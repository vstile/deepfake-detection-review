"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Assessing the Performance of Efficient Face Anti-Spoofing Detection Against Physical and Digital Presentation Attacks","L. S. Luevano; Y. Martínez-Díaz; H. Méndez-Vázquez; M. González-Mendoza; D. Frey","Inria, CNRS, IRISA, Univ Rennes, Rennes, France; Advanced Technologies Application Center (CENATAV), Havana, Cuba; Advanced Technologies Application Center (CENATAV), Havana, Cuba; School of Engineering and Sciences, Tecnologico de Monterrey, N.L., Mexico; Inria, CNRS, IRISA, Univ Rennes, Rennes, France",2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW),"27 Sep 2024","2024","","","1021","1028","In this paper, we examine how pre-processing and training methods impact on the performance of Lightweight CNNs through evaluations on MobileNetV3 with a spoofing detection head, dubbed ""MobileNetV3-Spoof"". Using the UniAttackData dataset from the 5th Face Anti-Spoofing Challenge@CVPR2024, which covers a broad spectrum of spoofing scenarios including deepfake and adversarial attack samples, we assess how well the model performs over different setups, including pre-trained models and models trained from scratch with or without initial face detection and alignment. Our results show that pre-processing steps significantly boost the model’s ability to identify spoof samples, especially against complex attacks. Through detailed comparisons, we offer insights that could guide data curation and the creation of more effective and efficient anti-spoofing techniques suitable for real-world use in the era of digital face attacks. We make our code publicly available at: https://github.com/Inria-CENATAV-Tec/Assessing-Efficient-FAS-CVPR2024","2160-7516","979-8-3503-6547-4","10.1109/CVPRW63382.2024.00108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10678145","Efficient Face Anti-Spoofing;Lightweight Face Anti-Spoofing;Digital Face Anti-Spoofing;Face Anti-Spoofing;Lightweight CNNs;Face Spoofing Deepfake Detection","Training;Deepfakes;Accuracy;Sensitivity;Face recognition;Computational modeling;Conferences","","1","","33","IEEE","27 Sep 2024","17-18 June 2024","17-18 June 2024","IEEE","IEEE Conferences"
"Towards Unified Face Verification Against Quality Variations and Deepfake","F. -Z. Ou; H. Guo; S. Kwong","Department of Computer Science, City University of Hong Kong, Hong Kong, SAR, China; Department of Computer Science, City University of Hong Kong, Hong Kong, SAR, China; School of Data Science, Lingnan University, Hong Kong, SAR, China",2025 International Symposium on Machine Learning and Media Computing (MLMC),"10 Oct 2025","2025","","","1","6","Face verification aims to provide reliable biological verification results for applications in areas such as security biometric identification, judicial analysis, and digital identity platforms. However, low-quality and malicious deepfake samples caused by complex collection environments may lead to erroneous outcomes in face verification. This paper introduces a unified system for reliable face verification designed to counteract deepfakebased identity spoofing while ensuring input quality reliability. The system processes an input pair of face images or videos through a multi-module pipeline. Specifically, a face detection module crops and aligns firstly the facial regions of input sample pairs. Then, in order to measure and reject low-quality samples, we design a dual metric-driven quality assessment module via class-centric deviation and embedding uncertainty fusion. Sequentially, the deepfake detection module will filter out the input of illegally synthetic face-swapping samples for anti-spoofing. For genuine samples, a quality-aware verification module trained by self-distillation is proposed for the final face verification. Herein, during the training process, low-quality samples are guided by high-quality samples to converge toward class centroids by minimizing the Wasserstein distance between their feature distributions, thereby enhancing model accuracy without increasing spatial complexity. Extensive experiments verify the reliability of our system.","","979-8-3315-2259-9","10.1109/MLMC65154.2025.11189881","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11189881","Face detection and alignment;face quality assessment;deepfake detection;and face verification","Training;Deepfakes;Uncertainty;Pipelines;Reliability engineering;Biometric identification;Quality assessment;Face detection;Security;Faces","","","","40","IEEE","10 Oct 2025","28-30 July 2025","28-30 July 2025","IEEE","IEEE Conferences"
"DeepFake Detection with 3D Face Perception","Z. Zheng; G. Qi; Y. Cao; M. Wei; Y. Li","Shiji College, Beijing University of Posts and Telecommunications, Beijing, China; Shiji College, Beijing University of Posts and Telecommunications, Beijing, China; Shiji College, Beijing University of Posts and Telecommunications, Beijing, China; Shiji College, Beijing University of Posts and Telecommunications, Beijing, China; Shiji College, Beijing University of Posts and Telecommunications, Beijing, China",2024 6th International Conference on Frontier Technologies of Information and Computer (ICFTIC),"13 Mar 2025","2024","","","112","115","With the development of deep learning technology, the emergence of DeepFake technology makes fake video and image become more real, it brought many safe hidden trouble to the society. In this paper, we propose a DeepFake detection method based on 3D face perception, which aims to effectively identify fake face images. By generating and detecting facial features, we use a binary classifier to discriminate the generated weights. In addition, combining Generative adversarial Network (GAN) and Convolutional Neural Network (CNN) technology, we designed a feature detection and extraction mechanism to improve the accuracy and robustness of detection. The experimental results show that the proposed method has significant performance advantages in DeepFake detection task.","","979-8-3315-4175-0","10.1109/ICFTIC64248.2024.10913253","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10913253","DeepFake detection task;3D face perception;facial features","Deepfakes;Technological innovation;Three-dimensional displays;Accuracy;Face recognition;Streaming media;Generative adversarial networks;Feature extraction;Robustness;Convolutional neural networks","","","","11","IEEE","13 Mar 2025","13-15 Dec. 2024","13-15 Dec. 2024","IEEE","IEEE Conferences"
"Learnable Information-Preserving Image Resizer for Face Forgery Detection","H. She; Y. Hu; B. Liu; J. Li; C. -T. Li","School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China; School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China; School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China; School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China; School of Information Technology, Deakin University, Geelong, VIC, Australia",IEEE Signal Processing Letters,"15 Nov 2023","2023","30","","1657","1661","Resizing input face images of arbitrary sizes to a uniform size is an essential preprocessing to satisfy the architectural requirements of face forgery detectors. In this letter, we reveal an important observation that traditional resizing methods degrade the performance of face forgery detectors due to the loss of high-frequency information. To address this issue, we propose a simple yet effective learnable information-preserving resizer to replace its lossy traditional counterparts. Specifically, we use Haar transform to separate low- and high-frequency components, and then perform learnable resizing on the high-frequency sub-bands. We conduct experiments to compare our learnable resizer with other methods and evaluate three existing detectors with and without incorporating our resizer. Experimental results show that our resizer outperforms other resizers and consistently enhances the detection performance of tested detectors, confirming the effectiveness of our proposed resizer.","1558-2361","","10.1109/LSP.2023.3330316","Science and Technology Foundation of Guangzhou Huangpu Development District(grant numbers:2022GH15); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10309221","Face forgery detection;deepfake detection;information-preserving resizer;learnable resizer","Forgery;Faces;Detectors;Face recognition;Interpolation;Transforms;Task analysis","","2","","28","IEEE","6 Nov 2023","2023","","IEEE","IEEE Journals"
"3D Attention Network for Face Forgery Detection","Z. Ma; X. Mei; J. Shen","College of Electrical Engineering and Control Science, Nanjing Tech University, Nanjing, China; College of Electrical Engineering and Control Science, Nanjing Tech University, Nanjing, China; College of Electrical Engineering and Control Science, Nanjing Tech University, Nanjing, China",2023 4th Information Communication Technologies Conference (ICTC),"23 Jun 2023","2023","","","396","401","With the rapid development of face forgery techniques, a large number of face synthesis videos are widely spread on the Internet, which threatens the security and trustworthiness of digital content online. It is necessary to develop face forgery detection methods. Many existing methods use only 2D CNNs to detect video frames. There are few 3D networks designed for face forgery detection. In this work, we propose to use 3D CNN for video-level face forgery detection and add a lightweight attention module to construct a 3D attention network. The network extracts both spatial and temporal features. The attention maps generated by the attention module focus on several forged regions of the fake face. To avoid the discrepancy of different regions affecting the detection results, a global attention pool is designed to replace the global average pool. The experiments implemented on FaceForensics++ show that our model achieves great accuracy and exceeds most existing methods. Cross-dataset evaluation implemented on Celeb-DF verifies that our model has strong transferability and generalization ability.","","978-1-6654-6258-7","10.1109/ICTC57116.2023.10154671","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10154671","Face forgery detection;DeepFake detection;Face forgery;Digital video forensics;3D convolutional neural network","Solid modeling;Three-dimensional displays;Feature extraction;Forgery;Internet;Security;Data mining","","5","","40","IEEE","23 Jun 2023","17-19 May 2023","17-19 May 2023","IEEE","IEEE Conferences"
"Face Swapping Attack Detection Using Multistream Feature Embeddings","G. Kotov; O. Nakov; M. Lazarova; P. Nakov; G. Georgiev","Department of Computer Systems, Faculty of Computer Systems and Technologies, Technical University of Sofia, Sofia, Bulgaria; Department of Computer Systems, Faculty of Computer Systems and Technologies, Technical University of Sofia, Sofia, Bulgaria; Department of Computer Systems, Faculty of Computer Systems and Technologies, Technical University of Sofia, Sofia, Bulgaria; Department of Computer Systems, Faculty of Computer Systems and Technologies, Technical University of Sofia, Sofia, Bulgaria; Department of Computer Systems, Faculty of Computer Systems and Technologies, Technical University of Sofia, Sofia, Bulgaria",2025 13th International Scientific Conference on Computer Science (COMSCI),"13 Nov 2025","2025","","","1","6","The paper presents a novel multi-stream feature embedding approach to detect face swapping attacks and distinguish them from fully AI-generated face images. The suggested multi-stream feature embedding architecture combines global features from Vision Transformers, local artifacts from convolutional neural networks, and frequency-domain analysis. Thus the model captures complementary forensic cues often missed by single-stream approaches. The processing pipeline employs image preprocessing and face alignment stage to standardize the input data as required by the tree different streams utilized in the suggested architecture. Attention-based modular fusion is applied for the feature embeddings extracted from each stream to generate unified representation with dynamic weighting thus improving both robustness and interpretability of the model as it selectively relies on the most informative stream based on the input's generative characteristics. Based on the suggested approach a classification model is trained for three classes: real, face-swapped, AI-generated images using diverse mix of images from both curated and real-world datasets. The experimental results demonstrate strong performance of the model that effectively detects AI-generated faces using global and spectral anomalies, while identifying face swaps through localized inconsistencies.","","979-8-3315-9814-3","10.1109/COMSCI67172.2025.11225271","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11225271","deepfake detection;AI-generated faces;face swapping;multi-stream;feature embeddings","Trees (botanical);Frequency-domain analysis;Forensics;Pipelines;Computer architecture;Feature extraction;Transformers;Robustness;Image preprocessing;Faces","","","","33","IEEE","13 Nov 2025","13-15 Sept. 2025","13-15 Sept. 2025","IEEE","IEEE Conferences"
"3DDGD: 3D Deepfake Generation and Detection Using 3D Face Meshes","H. Felouat; H. H. Nguyen; J. Yamagishi; I. Echizen","Informatics Program, The Graduate University for Advanced Studies, SOKENDAI, Hayama, Kanagawa, Japan; Informatics Program, The Graduate University for Advanced Studies, SOKENDAI, Hayama, Kanagawa, Japan; Informatics Program, The Graduate University for Advanced Studies, SOKENDAI, Hayama, Kanagawa, Japan; Informatics Program, The Graduate University for Advanced Studies, SOKENDAI, Hayama, Kanagawa, Japan",IEEE Access,"26 Jun 2025","2025","13","","107429","107441","3D face technology is revolutionizing various fields by providing superior security and realism compared with 2D methods. In biometric authentication, 3D facial features serve as unique, hard-to-forge identifiers, improving accuracy in facial recognition for border control and criminal identification. Additionally, 3D avatars enhance virtual interactions. In this study, we aimed to strengthen 3D facial biometric systems against deepfakes. Key contributions include proving the superior protection of 3D faces over 2D ones, creating a dataset of real and fake 3D faces, and developing advanced models for accurate 3D deepfake detection. We evaluated our models for generalization to other datasets and stability when changing training data. Our experiments used the mesh multi-layer perceptron model for deepfake detection along with self-attention mechanisms and the newly introduced TabTransformer model. Results indicate that 3D face meshes greatly improve security by distinguishing real faces from deepfakes. Future work will focus on enhancing detection tools and integrating geometric features with facial textures for more accurate 3D deepfake detection. The dataset and models are publicly available on GitHub, excluding licensed elements: https://github.com/hichemfelouat/3DDGD","2169-3536","","10.1109/ACCESS.2025.3580950","Japan Society for the Promotion of Science (JSPS) under KAKENHI(grant numbers:JP21H04907,JP24H00732); Japan Science and Technology Agency (JST) under CREST(grant numbers:JPMJCR18A6,JPMJCR20D3); AIP Challenge Program; by JST AIP Acceleration(grant numbers:JPMJCR24U3); JST K Program(grant numbers:JPMJKP24C2); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11039631","3D deepfake detection;3D deepfake generation;3D face reconstruction;3D biometric systems","Three-dimensional displays;Face recognition;Deepfakes;Solid modeling;Shape;Image reconstruction;Faces;Point cloud compression;Accuracy;Feature extraction","","","","64","CCBY","18 Jun 2025","2025","","IEEE","IEEE Journals"
"FSFM: A Generalizable Face Security Foundation Model via Self-Supervised Facial Representation Learning","G. Wang; F. Lin; T. Wu; Z. Liu; Z. Ba; K. Ren","State Key Laboratory of Blockchain and Data Security, Zhejiang University; State Key Laboratory of Blockchain and Data Security, Zhejiang University; State Key Laboratory of Blockchain and Data Security, Zhejiang University; State Key Laboratory of Blockchain and Data Security, Zhejiang University; State Key Laboratory of Blockchain and Data Security, Zhejiang University; State Key Laboratory of Blockchain and Data Security, Zhejiang University",2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),"13 Aug 2025","2025","","","24364","24376","This work asks: with abundant, unlabeled real faces, how to learn a robust and transferable facial representation that boosts various face security tasks with respect to generalization performance? We make the first attempt and propose a self-supervised pretraining framework to learn fundamental representations of real face images, FSFM, that leverages the synergy between masked image modeling (MIM) and instance discrimination (ID). We explore various facial masking strategies for MIM and present a simple yet powerful CRFR-P masking, which explicitly forces the model to capture meaningful intra-region Consistency and challenging inter-region Coherency. Furthermore, we devise an ID network that naturally couples with MIM to establish underlying local-to-global Correspondence through tailored self-distillation. These three learning objectives, namely 3C, empower encoding both local features and global semantics of real faces. After pretraining, a vanilla ViT serves as a universal vision Foundation Model for downstream Face Security tasks: cross-dataset deepfake detection, cross-domain face anti-spoofing, and unseen diffusion facial forgery detection. Extensive experiments on 10 public datasets demonstrate that our model transfers better than supervised pretraining, visual and facial self-supervised learning arts, and even outperforms task-specialized SOTA methods.","2575-7075","979-8-3315-4364-8","10.1109/CVPR52734.2025.02269","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11092767","deepfake detection;facial representation learning;self-supervised learning;face anti-spoofing;diffuion facial forgery detection;face security","Representation learning;Deepfakes;Visualization;Foundation models;Semantics;Self-supervised learning;Forgery;Pattern recognition;Security;Faces","","2","","116","IEEE","13 Aug 2025","10-17 June 2025","10-17 June 2025","IEEE","IEEE Conferences"
"Adversarial Samples Generated by Self-Forgery for Face Forgery Detection","H. Duan; Q. Jiang; X. Xu; Y. Wang; H. Yi; S. Yao; X. Jin","School of Software, Yunnan University, Kunming, China; School of Software, Yunnan University, Kunming, China; School of Journalism, Yunnan University, Kunming, China; Department of Information Technology, The Second Affiliated Hospital of Kunming Medical University, Kunming, China; School of Software, Yunnan University, Kunming, China; School of Software, Yunnan University, Kunming, China; School of Software, Yunnan University, Kunming, China","IEEE Transactions on Biometrics, Behavior, and Identity Science","26 Jun 2025","2025","7","3","432","443","As deep learning techniques continue to advance making face synthesis realistic and indistinguishable. Algorithms need to be continuously improved to cope with increasingly sophisticated forgery techniques. Current face forgery detectors achieve excellent results when detecting training and testing from the same dataset. However, the detector performance degrades when generalized to unknown forgery methods. One of the most effective ways to address this problem is to train the model using synthetic data. This helps the model learn a generic representation for deep forgery detection. In this article, we propose a new strategy for synthesis of training data. To improve the quality and sensitivity to forgeries, we include a Multi-scale Feature Aggregation Module and a Forgery Identification Module in the generator and discriminator. The Multi-scale Feature Aggregation Module captures finer details and textures while reducing forgery traces. The Forgery Identification Module more acutely detects traces and irregularities in the forgery images. It can better distinguish between real and fake images and improve overall detection accuracy. In addition, we employ an adversarial training strategy to dynamically construct the detector. This effectively explores the enhancement space of forgery samples. Through extensive experiments, we demonstrate the effectiveness of the proposed synthesis strategy. Our code can be found at: https://github.com/1241128239/ASG-SF.","2637-6407","","10.1109/TBIOM.2025.3529026","Yunnan Fundamental Research Projects(grant numbers:202401AT070470,202301AW070007,202301AU070210); National Natural Science Foundation of China(grant numbers:62261060); Yunnan Province Major Science and Technology Project(grant numbers:202202AD080002); Yunnan Province Expert Workstations(grant numbers:202305AF150078); Yunnan University Scientific Research and Innovation Program(grant numbers:KC-23234709,TM-23236807); Xingdian Talent Project in Yunnan Province of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10839332","Deepfake detection;face forgery detection;deep learning;adversarial samples","Forgery;Face recognition;Training;Feature extraction;Generators;Faces;Detectors;Deepfakes;Deep learning;Adversarial machine learning","","","","53","IEEE","13 Jan 2025","July 2025","","IEEE","IEEE Journals"
"AI-Face: A Million-Scale Demographically Annotated AI-Generated Face Dataset and Fairness Benchmark","L. Lin; Santosh; M. Wu; X. Wang; S. Hu","Purdue University, West Lafayette, USA; Purdue University, West Lafayette, USA; Purdue University, West Lafayette, USA; University at Albany, State University of New York, New York, USA; Purdue University, West Lafayette, USA",2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),"13 Aug 2025","2025","","","3503","3515","AI-generated faces have enriched human life, such as entertainment, education, and art. However, they also pose misuse risks. Therefore, detecting AI-generated faces becomes crucial, yet current detectors show biased performance across different demographic groups. Mitigating biases can be done by designing algorithmic fairness methods, which usually require demographically annotated face datasets for model training. However, no existing dataset encompasses both demographic attributes and diverse generative methods simultaneously, which hinders the development of fair detectors for AI-generated faces. In this work, we introduce the AI-Face dataset, the first million-scale demographically annotated AI-generated face image dataset, including real faces, faces from deepfake videos, and faces generated by Generative Adversarial Networks and Diffusion Models. Based on this dataset, we conduct the first comprehensive fairness benchmark to assess various AI face detectors and provide valuable insights and findings to promote the future fair design of AI face detectors. Our AI-Face dataset and benchmark code are publicly available at https://github.com/Purdue-M2/AI-Face-FairnessBench.","2575-7075","979-8-3315-4364-8","10.1109/CVPR52734.2025.00332","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11095050","deepfake detection;dataset;benchmark;fairness;ai-generated face","Training;Annotations;Social networking (online);Refining;Detectors;Benchmark testing;Licenses;Prediction algorithms;Pattern recognition;Faces","","8","","118","IEEE","13 Aug 2025","10-17 June 2025","10-17 June 2025","IEEE","IEEE Conferences"
"Face Forgery Video Detection via Temporal Forgery Cue Unraveling","Z. Guo; Y. Liu; J. Zhang; H. Zheng; S. Shan","Faculty of Information Science and Engineering, Ocean University of China; Faculty of Information Science and Engineering, Ocean University of China; State Key Lab of AI Safety, Institute of Computing Technology, Chinese Academy of Sciences; Faculty of Information Science and Engineering, Ocean University of China; State Key Lab of AI Safety, Institute of Computing Technology, Chinese Academy of Sciences",2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),"13 Aug 2025","2025","","","7396","7405","Face Forgery Video Detection (FFVD) is a critical yet challenging task in determining whether a digital facial video is authentic or forged. Existing FFVD methods typically focus on isolated spatial or coarsely fused spatiotemporal information, failing to leverage temporal forgery cues thus resulting in unsatisfactory performance. We strive to unravel these cues across three progressive levels: momentary anomaly, gradual inconsistency, and cumulative distortion. Accordingly, we design a consecutive correlate module to capture momentary anomaly cues by correlating interactions among consecutive frames. Then, we devise a future guide module to unravel inconsistency cues by iteratively aggregating historical anomaly cues and gradually propagating them into future frames. Finally, we introduce a historical review module that unravels distortion cues via momentum accumulation from future to historical frames. These three modules form our Temporal Forgery Cue Unraveling (TFCU) framework, sequentially highlighting spatial discriminative features by unraveling temporal forgery cues bidirectionally between historical and future frames. Extensive experiments and ablation studies demonstrate the effectiveness of our TFCU method, achieving state-of-the-art performance across diverse unseen datasets and manipulation methods. Code is available at https://github.com/zhenglab/TFCU.","2575-7075","979-8-3315-4364-8","10.1109/CVPR52734.2025.00693","National Natural Science Foundation of China; Youth Innovation Promotion Association; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11094401","face forgery video detection;deepfake detection;face forgery detection;transformer","Reviews;Face recognition;Information security;Distortion;Feature extraction;Forgery;Spatiotemporal phenomena;Copper;Faces;Videos","","","","49","IEEE","13 Aug 2025","10-17 June 2025","10-17 June 2025","IEEE","IEEE Conferences"
"FA3-CLIP: Frequency-Aware Cues Fusion and Attack-Agnostic Prompt Learning for Unified Face Attack Detection","Y. Li; N. Li; A. Liu; H. Ma; L. Yang; X. Chen; Z. Liang; Y. Liang; J. Wan; Z. Lei","School of Computer Science and Engineering, Faculty of Innovation Engineering, Macau University of Science and Technology, Macau, China; School of Computer Science and Engineering, Faculty of Innovation Engineering, Macau University of Science and Technology, Macau, China; School of Computer Science and Engineering, Faculty of Innovation Engineering, Macau University of Science and Technology, Macau, China; School of Computer Science and Engineering, Faculty of Innovation Engineering, Macau University of Science and Technology, Macau, China; School of Computer Science and Engineering, Faculty of Innovation Engineering, Macau University of Science and Technology, Macau, China; School of Software Engineering, Beijing Jiaotong University (BJTU), Beijing, China; School of Computer Science and Engineering, Faculty of Innovation Engineering, Macau University of Science and Technology, Macau, China; School of Computer Science and Engineering, Faculty of Innovation Engineering, Macau University of Science and Technology, Macau, China; School of Computer Science and Engineering, Faculty of Innovation Engineering, Macau University of Science and Technology, Macau, China; School of Computer Science and Engineering, Faculty of Innovation Engineering, Macau University of Science and Technology, Macau, China",IEEE Transactions on Information Forensics and Security,"12 Aug 2025","2025","20","","8167","8177","Facial recognition systems are vulnerable to physical (e.g., printed photos) and digital (e.g., DeepFake) face attacks. Existing methods struggle to simultaneously detect physical and digital attacks due to: 1) significant intra-class variations between these attack types, and 2) the inadequacy of spatial information alone to comprehensively capture live and fake cues. To address these issues, we propose a unified attack detection model termed Frequency-Aware and Attack-Agnostic CLIP (FA3-CLIP), which introduces attack-agnostic prompt learning to express generic live and fake cues derived from the fusion of spatial and frequency features, enabling unified detection of live faces and all categories of attacks. Specifically, the attack-agnostic prompt module generates generic live and fake prompts within the language branch to extract corresponding generic representations from both live and fake faces, guiding the model to learn a unified feature space for unified attack detection. Meanwhile, the module adaptively generates the live/fake conditional bias from the original spatial and frequency information to optimize the generic prompts accordingly, reducing the impact of intra-class variations. We further propose a dual-stream cues fusion framework in the vision branch, which leverages frequency information to complement subtle cues that are difficult to capture in the spatial domain. In addition, a frequency compression block is utilized in the frequency stream, which reduces redundancy in frequency features while preserving the diversity of crucial cues. We also establish new challenging protocols to facilitate unified face attack detection effectiveness. Experimental results on multiple benchmarks demonstrate that FA3-CLIP significantly improves performance, reducing ACER by over 1.2% on UniAttackData, and increasing AUC by more than 3% as well as reducing EER by over 4% on the JFSFDB dataset. The source code is available at https://github.com/YongzeLi/FA3-CLIP","1556-6021","","10.1109/TIFS.2025.3593167","Science and Technology Development Fund of Macau(grant numbers:0140/2024/AGJ,0096/2023/RIA2,0123/2022/A3,0044/2024/AGJ,0084/2024/RIB2); Beijing Natural Science Foundation(grant numbers:JQ23016); National Natural Science Foundation of China(grant numbers:62476273,62406320,U23B2054,62276254); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11097296","Face anti-spoofing;deepfake detection;unified feature space;frequency-aware;cues fusion","Feature extraction;Faces;Face recognition;Visualization;Frequency diversity;Training;Deepfakes;Data mining;Protocols;Noise","","","","62","IEEE","28 Jul 2025","2025","","IEEE","IEEE Journals"
"Semantics-Oriented Multitask Learning for DeepFake Detection: A Joint Embedding Approach","M. Zou; B. Yu; Y. Zhan; S. Lyu; K. Ma","Department of Computer Science, City University of Hong Kong, Kowloon Tong, Hong Kong; Lee Kong Chian School of Medicine, Nanyang Technological University, Jurong West, Singapore; Yunnan United Vision Technology Company Ltd., Yunnan, China; Department of Computer Science and Engineering, University at Buffalo, The State University of New York at Buffalo, Buffalo, NY, USA; Department of Computer Science, City University of Hong Kong, Kowloon Tong, Hong Kong",IEEE Transactions on Circuits and Systems for Video Technology,"3 Oct 2025","2025","35","10","9950","9963","In recent years, the multimedia forensics and security community has seen remarkable progress in multitask learning for DeepFake (i.e., face forgery) detection. The prevailing approach has been to frame DeepFake detection as a binary classification problem augmented by manipulation-oriented auxiliary tasks. This scheme focuses on learning features specific to face manipulations with limited generalizability. In this paper, we delve deeper into semantics-oriented multitask learning for DeepFake detection, capturing the relationships among face semantics via joint embedding. We first propose an automated dataset expansion technique that broadens current face forgery datasets to support semantics-oriented DeepFake detection tasks at both the global face attribute and local face region levels. Furthermore, we resort to the joint embedding of face images and labels (depicted by text descriptions) for prediction. This approach eliminates the need for manually setting task-agnostic and task-specific parameters, which is typically required when predicting multiple labels directly from images. In addition, we employ bi-level optimization to dynamically balance the fidelity loss weightings of various tasks, making the training process fully automated. Extensive experiments on six DeepFake datasets show that our method improves the generalizability of DeepFake detection and renders some degree of model interpretation by providing human-understandable explanations.","1558-2205","","10.1109/TCSVT.2025.3572508","Hong Kong Research Grants Council (RGC) General Research Fund(grant numbers:11220224); CityU Strategic Research(grant numbers:7005848,7005983); Industry Gift Fund(grant numbers:9229179); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11010889","DeepFake detection;face semantics;multitask learning;joint embedding","Faces;Deepfakes;Face recognition;Semantics;Detectors;Training;Mouth;Forgery;Computer architecture;Lips","","1","","109","IEEE","22 May 2025","Oct. 2025","","IEEE","IEEE Journals"
"Exploiting Facial Relationships and Feature Aggregation for Multi-Face Forgery Detection","C. Lin; F. Yi; H. Wang; J. Deng; Z. Zhao; Q. Li; C. Shen","School of Cyber Science and Engineering, Xi’an Jiaotong University, Xi’an, China; School of Software Engineering, Xi’an Jiaotong University, Xi’an, China; School of Cyber Science and Engineering, Xi’an Jiaotong University, Xi’an, China; School of Cyber Science and Engineering, Xi’an Jiaotong University, Xi’an, China; School of Cyber Science and Engineering, Xi’an Jiaotong University, Xi’an, China; School of Cyber Science and Engineering, Xi’an Jiaotong University, Xi’an, China; School of Cyber Science and Engineering, Xi’an Jiaotong University, Xi’an, China",IEEE Transactions on Information Forensics and Security,"30 Sep 2024","2024","19","","8832","8844","The emergence of advanced Deepfake technologies has gradually raised concerns in society, prompting significant attention to Deepfake detection. However, in real-world scenarios, Deepfakes often involve multiple faces. Despite this, most existing detection methods still detect these faces individually, overlooking the informative correlation between them and the relationship between the global information of the image and the local information of the faces. In this paper, we address this limitation by proposing FILTER, a novel framework for multi-face forgery detection that explicitly captures underlying correlations. FILTER consists of two main modules: Multi-face Relationship Learning (MRL) and Global Feature Aggregation (GFA). Specifically, MRL learns the correlation of local facial features in multi-face images, and GFA constructs the relationship between image-level labels and individual facial features to enhance performance from a global perspective. In particular, a contrastive learning loss function is used to better discriminate between real and fake faces. Extensive experiments on two publicly available multi-face forgery datasets demonstrate the state-of-the-art performance of FILTER in multi-face forgery detection. For example, on Openforensics Test-Challenge dataset, FILTER outperforms the previous state-of-the-art methods with a higher AUC score (0.980) and higher detection accuracy (92.04%).","1556-6021","","10.1109/TIFS.2024.3461469","National Key Research and Development Program of China(grant numbers:2021YFB3100700); National Natural Science Foundation of China(grant numbers:T2341003,62376210,62161160337,62132011,U21B2018,U20A20177,62206217); Shaanxi Province Key Industry Innovation Program(grant numbers:2023-ZDLGY-38); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10689267","Deepfake detection;multi-face relationship learning;global feature aggregation","Forgery;Faces;Feature extraction;Deepfakes;Facial features;Information filters;Frequency-domain analysis","","7","","61","IEEE","23 Sep 2024","2024","","IEEE","IEEE Journals"
"UniForensics: Face Forgery Detection via General Facial Representation","Z. Fang; H. Zhao; T. Wei; W. Zhou; M. Wan; Z. Wang; W. Zhang; N. Yu","University of Science and Technology of China, Hefei, Anhui, China; University of Science and Technology of China, Hefei, Anhui, China; University of Science and Technology of China, Hefei, Anhui, China; University of Science and Technology of China, Hefei, Anhui, China; Qianxin Technology Group Co. Ltd, Beijing, China; Qianxin Technology Group Co. Ltd, Beijing, China; University of Science and Technology of China, Hefei, Anhui, China; University of Science and Technology of China, Hefei, Anhui, China",IEEE Transactions on Dependable and Secure Computing,"","2025","PP","99","1","15","The rise of deepfakes has significantly heightened concerns for privacy and the authenticity of digital media, bringing widespread attention to face forgery detection. Previous deepfake detection methods mostly depend on low-level textural features vulnerable to perturbations and fall short of detecting unseen forgery methods. In contrast, high-level semantic features are less susceptible to perturbations and not limited to forgery-specific artifacts, thus having stronger generalization. Motivated by this, we propose a detection method that utilizes high-level semantic features of faces to identify inconsistencies in temporal domain. We introduce UniForensics, a novel deepfake detection framework that leverages a transformer-based video classification network, initialized with a meta-functional face encoder for enriched facial representation. In this way, we can take advantage of both the powerful spatio-temporal model and the high-level semantic information of faces. Furthermore, to leverage easily accessible real face data and guide the model in focusing on spatio-temporal features, we design a Dynamic Video Self-Blending (DVSB) method to efficiently generate training samples with diverse spatio-temporal forgery traces using real facial videos. Based on this, we advance our framework with a two-stage training approach: The first stage employs a novel self-supervised contrastive learning, where we encourage the network to focus on forgery traces by impelling videos generated by the same forgery process to have similar representations. On the basis of the representation learned in the first stage, the second stage involves fine-tuning on face forgery detection dataset to build a deepfake detector. Extensive experiments validates that UniForensics outperforms existing face forgery detection methods in generalization ability and robustness. In particular, our method achieves 95.3% and 77.2% cross dataset AUC on the challenging Celeb-DFv2 and DFDC respectively. Code will be made publicly available.","1941-0018","","10.1109/TDSC.2025.3627420","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11250851","Deepfake detection;self-supervised contrastive learning;data synthesis","Forgery;Faces;Deepfakes;Semantics;Face recognition;Feature extraction;Training;Robustness;Data models;Contrastive learning","","","","","IEEE","17 Nov 2025","","","IEEE","IEEE Early Access Articles"
"FCD-Net: Learning to Detect Multiple Types of Homologous Deepfake Face Images","R. Han; X. Wang; N. Bai; Q. Wang; Z. Liu; J. Xue","School of Computer Science and Engineering, Xi’an University of Technology, Xi’an, China; School of Computer Science and Engineering, Xi’an University of Technology, Xi’an, China; Department of Mathematics, Xi’an University of Technology, Xi’an, China; School of Computer Science and Engineering, Xi’an University of Technology, Xi’an, China; School of Computer Science and Engineering, Xi’an University of Technology, Xi’an, China; Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China",IEEE Transactions on Information Forensics and Security,"1 May 2023","2023","18","","2653","2666","With the rapid development of artificial intelligence technology, a variety of GAN generated deepfake face images/videos have emerged endlessly. The abuse of deepfake has brought serious negative effects to many industries. Therefore, there is an urgent need to develop advanced methods to combat the abuse of deepfake. As far as we know, there are almost no techniques that can distinguish multiple types of homologous deepfake face images. In this study, we propose a method based on the multi-classification task to address this issue. The proposed method relies on a novel network framework named FCD-Net that consists of the facial synaptic saliency module (FSS), the contour detail feature extraction module (CDFE), and the distinguishing feature fusion module (DFF). Utilizing this method, the imperceptible features introduced by deepfake can be exposed, and the differences caused by different types of deepfake can be distinguished, even if deepfake images are homologous. To test the proposed method and compare it with other SOTA methods, we establish a new homologous dataset named HDFD that contains real face images, entire face synthesis images, face swap images, and facial attribute manipulation images. Among them, the three types of deepfake images are all generated from the same real face images through different deepfake techniques. Abundant experiment results demonstrate that the proposed method has a high-level detection accuracy and relatively strong robustness against content-preserving manipulations. Moreover, the generalization of our method is superior to other SOTA methods.","1556-6021","","10.1109/TIFS.2023.3269152","National Natural Science Foundation of China(grant numbers:61772416); Shaanxi Science Foundation of China(grant numbers:2022GY-087); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10106503","Deepfake detection;homologous face images;facial synaptic saliency (FSS);contour detail feature extraction;distinguishable feature fusion (DFF)","Deepfakes;Faces;Feature extraction;Face recognition;Generative adversarial networks;Image color analysis;Frequency-domain analysis","","19","","57","IEEE","21 Apr 2023","2023","","IEEE","IEEE Journals"
"HF-Detect A Hybrid Detector for Manipulated Face Detection*","A. Shakya; K. Jenni; M. Perumal; M. Srinivas","Department of Computer Science and Engineering, National Institute of Technology Warangal, India; Computer Science Department, King Khalid University, Abha, Saudi Arabia; Department of Computer Science and Engineering, National Institute of Technology Warangal, India; Department of Computer Science and Engineering, National Institute of Technology Warangal, India",TENCON 2023 - 2023 IEEE Region 10 Conference (TENCON),"22 Nov 2023","2023","","","1","5","The recent advancement of fake face creation and fake face generation motivates the development of an excellent fake face detection method that can effectively detect the difference between fake and real. Various fake detection methods are available with adequate performance, but the limitation of those available methods is they are not performing well with highly compressed images with degraded quality. Manipulation of face images is getting advanced, and becoming difficult to trust the content over the media, and generating and detection should go parallelly to balance society. Therefore we are proposing a novel approach to solve this problem which uses the hybrid model HF-Detect, which combines the advantage of the Xception network along with the F3Net.","2159-3450","979-8-3503-0219-6","10.1109/TENCON58879.2023.10322540","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10322540","DeepFake Detection;Computer Vision;Deep Learning;Artificial Intelligence","Deepfakes;Image coding;Focusing;Detectors;Media;Feature extraction;Face detection","","1","","30","IEEE","22 Nov 2023","31 Oct.-3 Nov. 2023","31 Oct.-3 Nov. 2023","IEEE","IEEE Conferences"
"Deepfake Detection Method Based on Face Edge Bands","Z. Deng; B. Zhang; S. He; Y. Wang","School of Information Science and Technology, Hainan Normal University, Haikou, China; School of Information Science and Technology, Hainan Normal University, Haikou, China; School of Information Science and Technology, Hainan Normal University, Haikou, China; School of Physics and Electronic Engineering, Hainan Normal University, Haikou, China",2022 9th International Conference on Digital Home (ICDH),"19 Dec 2022","2022","","","251","256","The rapid development of face forgery technology and the generation of realistic fake videos have caused serious harm to individuals, society and even the country, so it is important to detect deepfake videos. There are many detection methods available for forged videos, but the overall performance is yet to be improved and does not cope well with high quality forged images or videos. Observing that existing forgery algorithms leave synthetic forgery traces at the edges of faces when creating videos, this paper proposes a new method for detecting forged videos. It first finds the face edges from the video frames, then extracts the face edge bands as deep learning inputs and trains them based on EfficientNet-B3 to achieve effective detection of deepfake videos. Experiments show that the method in this paper can achieve more than 99.8% AUC values on all four forgery methods of the Face-Forensics++ dataset.","","978-1-6654-5478-0","10.1109/ICDH57206.2022.00046","Guilin University of Electronic Technology; Guangxi Key Laboratory of Image and Graphic Intelligent Processing; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9978520","deepfake;detection;face edge;Efficient-Net","Training;Deep learning;Deepfakes;Image edge detection;Interference;Benchmark testing;Feature extraction","","13","","16","IEEE","19 Dec 2022","28-30 Oct. 2022","28-30 Oct. 2022","IEEE","IEEE Conferences"
"4DPM: Deepfake Detection With a Denoising Diffusion Probabilistic Mask","R. Yang; Z. Deng; Y. Zhang; X. Luo; R. Lan","Guangxi Key Laboratory of Images and Graphics Intelligent Processing, Guilin University of Electronic Technology, Guilin, China; Guangxi Key Laboratory of Images and Graphics Intelligent Processing, Guilin University of Electronic Technology, Guilin, China; School of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; Guangxi Key Laboratory of Images and Graphics Intelligent Processing, Guilin University of Electronic Technology, Guilin, China; Guangxi Key Laboratory of Images and Graphics Intelligent Processing, Guilin University of Electronic Technology, Guilin, China",IEEE Signal Processing Letters,"1 Apr 2024","2024","31","","914","918","In the face of increasingly realistic fake human faces, research on enhancing the differences between real and fake images is valuable for improving the generalization capabilities of fake face detection models. In this letter, we propose a method called DPMask (Diffusion Probabilistic Mask) to amplify the distinctions between authentic and counterfeit human facial images. Specifically, we use a dataset consisting of real human facial images and Simplex noise to train a denoising diffusion probabilistic model for the proposed DPMask. Subsequently, we separately apply the DPMask and U-Net to real and fake human facial images to create noticeably distinct genuine and counterfeit human facial images. A lightweight classification network blue is further designed based on RepVGG to classify the newly generated real and fake human faces. Experimental results demonstrate that our model achieves high accuracy on a manually created fake face dataset (RFFD), a GAN-generated fake face dataset (Seq-DeepFake), and a DDPM-generated face dataset (HiFi-IFDL). Furthermore, the addition of DPMask significantly improves the performance of some public fake face detection models.","1558-2361","","10.1109/LSP.2024.3378127","Guangxi Science and Technology(grant numbers:AB20238013,AB22035052); National Natural Science Foundation of China(grant numbers:62172120,62002082,6202780103); Guangxi Key Laboratory of Image and Graphic Intelligent Processing Project(grant numbers:GIIP2209); Innovation Project of GUET Gurduate Education(grant numbers:2023YCXB09); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10473172","DDPM;deepfake detection;DPMask;lightweight model","Faces;Training;Probabilistic logic;Noise reduction;Face detection;Signal processing algorithms;Iterative methods","","14","","34","IEEE","19 Mar 2024","2024","","IEEE","IEEE Journals"
"Forensics Adapter: Adapting CLIP for Generalizable Face Forgery Detection","X. Cui; Y. Li; A. Luo; J. Zhou; J. Dong","School of Computer Science and Technology, Ocean University of China; School of Computer Science and Technology, Ocean University of China; Southwest Jiaotong University; School of Computer Science and Technology, Ocean University of China; School of Computer Science and Technology, Ocean University of China",2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),"13 Aug 2025","2025","","","19207","19217","We describe the Forensics Adapter, an adapter network designed to transform CLIP into an effective and generalizable face forgery detector. Although CLIP is highly versatile, adapting it for face forgery detection is nontrivial as forgery-related knowledge is entangled with a wide range of unrelated knowledge. Existing methods treat CLIP merely as a feature extractor, lacking task-specific adaptation, which limits their effectiveness. To address this, we introduce an adapter to learn face forgery traces – the blending boundaries unique to forged faces, guided by task-specific objectives. Then we enhance the CLIP visual tokens with a dedicated interaction strategy that communicates knowledge across CLIP and the adapter. Since the adapter is alongside CLIP, its versatility is highly retained, naturally ensuring strong generalizability in face forgery detection. With only 5.7M trainable parameters, our method achieves a significant performance boost, improving by approximately 7% on average across five standard datasets. We believe the proposed method can serve as a baseline for future CLIP-based face forgery detection methods. The code is available at https://github.com/OUCVAS/ForensicsAdapter.","2575-7075","979-8-3315-4364-8","10.1109/CVPR52734.2025.01789","National Natural Science Foundation of China; China Postdoctoral Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11095177","deepfake detection","Visualization;Face recognition;Forensics;Transforms;Detectors;Performance gain;Feature extraction;Forgery;Standards;Faces","","3","","74","IEEE","13 Aug 2025","10-17 June 2025","10-17 June 2025","IEEE","IEEE Conferences"
"Forgery-Domain-Supervised Deepfake Detection With Non-Negative Constraint","Y. Yuan; X. Fu; G. Wang; Q. Li; X. Li","College of Computer Science, Zhejiang University, Hangzhou, China; College of Computer Science, Zhejiang University, Hangzhou, China; International Campus, Zhejiang University, Haining, China; Guangdong OPPO Mobile Telecommunications Corp., Ltd., Guandong, China; College of Computer Science, Zhejiang University, Hangzhou, China",IEEE Signal Processing Letters,"22 Dec 2022","2022","29","","2512","2516","Fake faces produced by deepfake techniques have attracted public concerns in recent years. Deepfake detection is a binary classification task that distinguishes fake faces from real ones. As the training data for deepfake detection is usually generated from real faces via various face forgery methods, it is difficult for a single binary decision boundary to distinguish fake faces. Besides that, the learned features often involve irrelevant information for identifying fake faces that are generated from diverse forgery methods. To deal with such challenges, unlike existing approaches that regard fake detection as a binary classification, we re-model the task as a multiclass forgery-domain classification task, where each forgery method is treated as a distinct class. This simplifies the complex decision boundary brought by the diversity of forgery patterns and provides more forgery-relevant information for the learning process. In addition, we introduce a non-negative constrained learning framework composed of non-negative features and a non-negative constrained classifier (NCC) to block irrelevant features with zero weights and enhance forgery-relevant features with positive weights, leading to a sparse structure of the classifier. Furthermore, to capture subtle and discriminative forgery-relevant features, we propose an integration module over augmented faces based on cross-attention. We demonstrate that our approach achieves competitive performance and generalization ability on widely-used benchmarks through extensive experiments.","1558-2361","","10.1109/LSP.2022.3193590","OPPO Research Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9839430","Classifier regularization;deepfake detection;face classification;face forensics;feature integration","Faces;Forgery;Deepfakes;Task analysis;Feature extraction;Crops;Training","","15","","27","IEEE","25 Jul 2022","2022","","IEEE","IEEE Journals"
"Faces Blind Your Eyes: Unveiling the Content-Irrelevant Synthetic Artifacts for Deepfake Detection","X. Fu; B. Fu; S. Chen; T. Yao; Y. Wang; S. Ding; X. Liang; X. Li","College of Computer Science and Technology, Zhejiang University, Hangzhou, China; Polytechnic Institute, Zhejiang University, Hangzhou, China; Youtu Laboratory, Tencent, Shanghai, China; Youtu Laboratory, Tencent, Shanghai, China; Youtu Laboratory, Tencent, Shanghai, China; Youtu Laboratory, Tencent, Shanghai, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China",IEEE Transactions on Image Processing,"17 Sep 2025","2025","34","","5686","5696","Data synthesis methods have shown promising results in general deepfake detection tasks. This is attributed to the inherent blending process in deepfake creation, which leaves behind distinct synthetic artifacts. However, the existence of content-irrelevant artifacts has not been explicitly explored in the deepfake synthesis. Unveiling content-irrelevant synthetic artifacts helps uncover general deepfake features and enhances the generalization capability of detection models. To capture the content-irrelevant synthetic artifacts, we propose a learning framework incorporating a synthesis process for diverse contents and specially designed learning strategies that encourage using content-irrelevant forgery information across deepfake images. From the data perspective, we disentangle the blending operation from face data and propose a universal synthetic module that generates images from various classes with common synthetic artifacts. From the learning perspective, a domain-adaptive learning head is introduced to filter out forgery-irrelevant features and optimize the decision on deepfake face detection. To efficiently learn the content-irrelevant artifacts for detection with a large sampling space, we propose a batch-wise sample selection strategy that actively mines the hard samples based on their effect on the adaptive decision boundary. Extensive cross-dataset experiments show that our method achieves state-of-the-art performance in general deepfake detection.","1941-0042","","10.1109/TIP.2025.3592576","National Science Foundation for Distinguished Young Scholars(grant numbers:62225605); “Pioneer” and “Leading Goose” Research and Development Program of Zhejiang(grant numbers:2025C02014); Ningbo Science and Technology Special Projects(grant numbers:2025Z028); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11112767","Deepfake detection;data synthesis;self-supervised learning;adversarial learning","Deepfakes;Faces;Forgery;Feature extraction;Training data;Training;Detectors;Data models;Synthetic data;Overfitting","Artifacts;Humans;Face;Image Processing, Computer-Assisted;Algorithms;Deep Learning;Databases, Factual;Biometric Identification","","","72","IEEE","4 Aug 2025","2025","","IEEE","IEEE Journals"
"Training Deepfake Detection Model from Photos with Face Mask","Y. -H. Lin; Y. -S. Xu","Dept. of IEEM, National Tsing Hua University, Hsinchu, Taiwan R.O.C.; Dept. of IEEM, National Tsing Hua University, Hsinchu, Taiwan R.O.C.",2024 International Joint Conference on Neural Networks (IJCNN),"9 Sep 2024","2024","","","1","6","Deepfake is becoming a major security threat nowadays. The development of robust deepfake detection algorithm is booming in recent years. However, the existing works require many face images for model training and the frontal face images collection would have privacy concerns. Therefore, this privacy issue inspires our research work that a deepfake detection model is trained from photos with face mask. We found that training a deepfake detection model from photos with face mask is rarely discussed in the literature. In order to resolve the challenges from face mask, we incorporate sub-regions (e.g., eye, nose, jaw) in a face during the training process. In addition to the extension by including facial sub-regions, we found that the associate training strategy is another important design factor for performance improvement. Our method improved the result significantly and the AUC of FaceForensics++ (FF++) test dataset evaluation is increased from 87.67% to 98.93%. As a result, we can develop a promising deepfake detection model even from the photos with face mask. We expected this work can be a stepping stone to inspire more research works with privacy considerations.","2161-4407","979-8-3503-5931-2","10.1109/IJCNN60899.2024.10650461","National Science and Technology Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10650461","Deepfake Detection;Face Mask;Training Strategy;Partial Blending","Training;Deepfakes;Privacy;Image resolution;Neural networks;Nose;Data models","","","","32","IEEE","9 Sep 2024","30 June-5 July 2024","30 June-5 July 2024","IEEE","IEEE Conferences"
"FakeLocator: Robust Localization of GAN-Based Face Manipulations","Y. Huang; F. Juefei-Xu; Q. Guo; Y. Liu; G. Pu","School of Software Engineering, East China Normal University, Shanghai, China; Alibaba Group, Sunnyvale, CA, USA; School of Computer Science and Engineering, Nanyang Technological University, Jurong West, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Jurong West, Singapore; School of Software Engineering, East China Normal University, Shanghai, China",IEEE Transactions on Information Forensics and Security,"29 Jul 2022","2022","17","","2657","2672","Full face synthesis and partial face manipulation by virtue of the generative adversarial networks (GANs) and its variants have raised wide public concerns. In the multi-media forensics area, detecting and ultimately locating the image forgery has become an imperative task. In this work, we investigate the architecture of existing GAN-based face manipulation methods and observe that the imperfection of upsampling methods therewithin could be served as an important asset for GAN-synthesized fake image detection and forgery localization. Based on this basic observation, we have proposed a novel approach, termed FakeLocator, to obtain high localization accuracy, at full resolution, on manipulated facial images. To the best of our knowledge, this is the very first attempt to solve the GAN-based fake localization problem with a gray-scale fakeness map that preserves more information of fake regions. To improve the universality of FakeLocator across multifarious facial attributes, we introduce an attention mechanism to guide the training of the model. To improve the universality of FakeLocator across different DeepFake methods, we propose partial data augmentation and single sample clustering on the training images. Experimental results on popular FaceForensics++, DFFD datasets and seven different state-of-the-art GAN-based face generation methods have shown the effectiveness of our method. Compared with the baselines, our method performs better on various metrics. Moreover, the proposed method is robust against various real-world facial image degradations such as JPEG compression, low-resolution, noise, and blur.","1556-6021","","10.1109/TIFS.2022.3141262","National Key Research and Development Program(grant numbers:2020AAA0107800); Shanghai Collaborative Innovation Center of Trusted Industry Internet Software; NSFC(grant numbers:61632005,61532019); National Research Foundation, Singapore, under its AI Singapore Program(grant numbers:AISG2-RP-2020-019); National Research Foundation, Prime Ministers Office, Singapore, under its National Cybersecurity Research and Development Program(grant numbers:NRF2018NCR-NCR005-0001); NRF Investigatorship(grant numbers:NRFI06-2020-0001); National Research Foundation through its National Satellite of Excellence in Trustworthy Software Systems (NSOE-TSS) Project under the National Cybersecurity Research and Development (NCR)(grant numbers:NRF2018NCR-NSOE003-0001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9673747","DeepFake;face manipulation;DeepFake detection and localization","Faces;Location awareness;Videos;Information integrity;Robustness;Forensics;Image resolution","","73","","54","IEEE","7 Jan 2022","2022","","IEEE","IEEE Journals"
"GenFace: A Large-Scale Fine-Grained Face Forgery Benchmark and Cross Appearance-Edge Learning","Y. Zhang; Z. Yu; T. Wang; X. Huang; L. Shen; Z. Gao; J. Ren","Computer Vision Institute, College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; School of Computing and Information Technology, Great Bay University, Dongguan, China; College of Computing and Data Science, Nanyang Technological University, Jurong West, Singapore; Computer Vision Institute, College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; Computer Vision Institute, College of Computer Science and Software Engineering, the National Engineering Laboratory for Big Data System Computing Technology, and Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen University, Shenzhen, China; Shandong Artificial Intelligence Institute, Qilu University of Technology (Shandong Academy of Sciences), Jinan, China; School of Computer Science, University of Nottingham Ningbo China (UNNC), Ningbo, China",IEEE Transactions on Information Forensics and Security,"25 Sep 2024","2024","19","","8559","8572","The rapid advancement of photorealistic generators has reached a critical juncture where the discrepancy between authentic and manipulated images is increasingly indistinguishable. Thus, benchmarking and advancing techniques detecting digital manipulation become an urgent issue. Although there have been a number of publicly available face forgery datasets, the forgery faces are mostly generated using GAN-based synthesis technology, which does not involve the most recent technologies like diffusion. The diversity and quality of images generated by diffusion models have been significantly improved and thus a much more challenging face forgery dataset shall be used to evaluate SOTA forgery detection literature. In this paper, we propose a large-scale, diverse, and fine-grained high-fidelity dataset, namely GenFace, to facilitate the advancement of deepfake detection, which contains a large number of forgery faces generated by advanced generators such as the diffusion-based model and more detailed labels about the manipulation approaches and adopted generators. In addition to evaluating SOTA approaches on our benchmark, we design an innovative Cross Appearance-Edge Learning (CAEL) detector to capture multi-grained appearance and edge global representations, and detect discriminative and general forgery traces. Moreover, we devise an Appearance-Edge Cross-Attention (AECA) module to explore the various integrations across two domains. Extensive experiment results and visualizations show that our detection model outperforms the state of the arts on different settings like cross-generator, cross-forgery, and cross-dataset evaluations. Code and datasets will be available at https://github.com/Jenine-321/GenFace.","1556-6021","","10.1109/TIFS.2024.3461958","National Natural Science Foundation of China(grant numbers:82261138629,62306061,62372325); Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2023A1515010688); Shenzhen Municipal Science and Technology Innovation Council(grant numbers:JCYJ20220531101412030); Open Project of National Engineering Laboratory for Big Data System Computing Technology, Shenzhen University, Shenzhen, China; Shandong Province National Talents Supporting Program(grant numbers:2023GJJLJRC-070); Natural Science Foundation of Tianjin Municipality(grant numbers:23JCZDJC00280); Shandong Project Toward the Integration of Education and Industry(grant numbers:2022JBZ01-03); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10681109","Face forgery benchmark;transformer;deepfake detection;appearance-edge fusion","Forgery;Faces;Deepfakes;Image edge detection;Feature extraction;Transformers;Generators","","4","","62","IEEE","16 Sep 2024","2024","","IEEE","IEEE Journals"
"Face forgery detection with a fused attention mechanism","J. Wang; Y. Qi; J. Hu; J. Hu","Northwest Normal University, Lanzhou City, Gansu Province, China; Northwest Normal University, Lanzhou City, Gansu Province, China; Northwest Normal University, Lanzhou City, Gansu Province, China; Northwest Normal University, Lanzhou City, Gansu Province, China","2022 3rd International Conference on Computer Vision, Image and Deep Learning & International Conference on Computer Engineering and Applications (CVIDL & ICCEA)","18 Jul 2022","2022","","","722","725","In recent years, the technology of forged faces has become more and more sophisticated, and the human eye cannot even distinguish these forged products. The fake face images or videos generated by this series of technologies are widely disseminated on the Internet, causing a serious impact on society, thus drawing attention to DeepFake detection, and more research is also inclined to this, but The current research has the problem that the extracted artifact features are relatively single, which leads to the relatively low performance of the artifact detection algorithm. To solve the limitations of the existing methods, the DeepFake detection method fused with attention mechanism is proposed, which extracts the global and local features of the face respectively. Artifact features are found in multiple regions of the face. The method is trained on the FaceForensics++ dataset, and the detection accuracy is improved in different network structures.","","978-1-6654-5911-2","10.1109/CVIDLICCEA56201.2022.9824499","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9824499","DeepFake Detection;attention mechanism;feature fusion","Deepfakes;Privacy;Focusing;Feature extraction;Forgery;Internet;Security","","6","","23","IEEE","18 Jul 2022","20-22 May 2022","20-22 May 2022","IEEE","IEEE Conferences"
"MDCF-Net: Multi-Scale Dual-Branch Network for Compressed Face Forgery Detection","J. Zhou; X. Zhao; Q. Xu; P. Zhang; Z. Zhou","Shanghai Film Academy, Shanghai University, Shanghai, China; Shanghai Film Academy, Shanghai University, Shanghai, China; Shanghai Film Academy, Shanghai University, Shanghai, China; Shanghai Film Academy, Shanghai University, Shanghai, China; Shanghai Film Academy, Shanghai University, Shanghai, China",IEEE Access,"30 Apr 2024","2024","12","","58740","58749","Face forgery detection aims to identify manipulated or altered facial images or videos created using artificial intelligence. Existing detection methods exhibit favorable performance on high-quality videos, but the videos in daily applications are commonly compressed into low-quality formats via social media. The detection difficulty is increased by the poor quality, indistinct detail features, and noises such as artifacts in these images or videos. To address this challenge, we propose a multi-scale dual-branch network for compressed face forgery, called MDCF-Net, effectively capturing cross-domain forgery features at various scales in compressed facial images. The MDCF-Net comprises two branches: an RGB domain branch utilizing Transformers to extract multi-scale fine-texture features from the original RGB images; a frequency domain branch designed to capture artifacts in low-quality videos by extracting global spectral features as a supplementary measure. Then, we introduce a feature fusion module (FFM) based on multi-head attention to merge diverse feature representations in a spatial-frequency complementary manner. Extensive comparative experiments on public datasets such as FaceForensics++, Celeb-DF, and WildDeepfake demonstrate the significant advantage of MDCF-Net in detecting highly compressed and low-quality forged images or videos, especially in achieving state-of-the-art performance on the FaceForensics++ low-quality dataset. Our approach presents a new perspective and technology for low-quality face forgery detection.","2169-3536","","10.1109/ACCESS.2024.3390217","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10504285","Face forgery;deepfake detection;transformers;frequency domain;two-branch;feature fusion","Feature extraction;Frequency-domain analysis;Face recognition;Forgery;Transformers;Deepfakes;Image coding","","8","","44","CCBYNCND","17 Apr 2024","2024","","IEEE","IEEE Journals"
"Critical Contour Prior-Guided Graph Learning With Pose Calibration for Identity-Aware Deepfake Detection","L. Ming; P. He; H. Li; S. Wang; X. Jiang","School of Cyber Science and Engineering, Sichuan University, Chengdu, China; School of Cyber Science and Engineering, Sichuan University, Chengdu, China; Department of Electrical Engineering, City University of Hong Kong, Hong Kong; Department of Computer Science, City University of Hong Kong, Kowloon, Hong Kong; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China",IEEE Transactions on Multimedia,"","2025","PP","99","1","13","Deepfake has recently raised severe public concerns about security issues, such as creating fake news of celebrities. As countermeasures, identity-aware detection methods leverage identity information to expose forged videos by measuring identity consistency between the suspicious input and its reference samples. However, the performance of existing methods suffers from notable degradation due to undesired variations of head poses and capturing environments. In this work, we first conduct a statistical analysis to illustrate the influence of different facial regions for forensic purposes, which infers more reliable identity information is located in critical face regions. Motivated by this analysis, we propose a graph learning-based identity-aware deepfake detection framework considering critical contour prior as guidance. First, feature sampling based on contour landmarks is applied to construct the graph data as the input of our critical contour prior-guided graph attention network (CP-GAT), where a node position prediction task is constructed as auxiliary supervision to explore rich relationships between nodes. To enhance pose-invariant ability, a rotation compensation block is integrated into CP-GAT and trained using a pose-calibrated contrastive learning to extract identity features, which takes high-quality front faces as the calibration goal with a progressively updating selection. Besides, an adversarial node masking-based training strategy is proposed as feature augmentation to further enhance the reliability. During the inference stage, the similarity between identity features of the input sample and its reference samples extracted by the trained CP-GAT is used to obtain the detection result. Extensive experiments are conducted on various face forgery datasets and state-of-the-art methods are compared to verify the superiority of the proposed method in terms of detection capability and robustness.","1941-0077","","10.1109/TMM.2025.3613159","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11175558","Deepfake detection;video forensics;graph learning;contrastive learning","Feature extraction;Faces;Face recognition;Deepfakes;Training;Data mining;Forensics;Contrastive learning;Security;Calibration","","","","","IEEE","22 Sep 2025","","","IEEE","IEEE Early Access Articles"
"Domain-Invariant Feature Learning for General Face Forgery Detection","J. Zhang; J. Ni","School of Computer Science and Engineering, Sun Yat-Sen University, Guangzhou, China; School of Cyber Science and Technology, Sun Yat-Sen University, Shenzhen, China",2023 IEEE International Conference on Multimedia and Expo (ICME),"25 Aug 2023","2023","","","2321","2326","Though existing methods for face forgery detection achieve fairly good performance under the intra-dataset scenario, few of them gain satisfying results in the case of cross-dataset testing with more practical value. To tackle this issue, in this paper, we propose a novel domain-invariant feature learning framework - DIFL for face forgery detection. In the framework, an adversarial domain generalization is introduced to learn the domain-invariant features from the forged samples synthesized by various algorithms. Then a center loss in fractional form (CL) is utilized to learn more discriminative features by aggregating the real faces while separating the fake faces from the real ones in the embedding space. In addition, a global and local random crop augmentation strategy is utilized to generate more data views of forged facial images at various scales. Extensive experimental results demonstrate the effectiveness and generalization of the proposed method compared with other state-of-the-art methods.","1945-788X","978-1-6654-6891-6","10.1109/ICME55011.2023.00396","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10219778","DeepFake detection;adversarial domain generalization;center loss","Representation learning;Deepfakes;Crops;Interference;Forgery;Task analysis;Faces","","5","","29","IEEE","25 Aug 2023","10-14 July 2023","10-14 July 2023","IEEE","IEEE Conferences"
"Face Swap Detection: A Systematic Literature Review","S. Hriez","Cyber Security Department, Al Hussein Technical University, Amman, Jordan",IEEE Access,"27 Aug 2025","2025","13","","143957","143984","Face swap technology, often associated with deepfakes, has rapidly advanced in recent years, raising serious concerns around misinformation, digital impersonation, and privacy. As a result, the development of reliable face swap detection methods has become a critical area of research. This survey provides a comprehensive review of existing approaches to face swap detection, addressing key research questions such as commonly used datasets, evaluation metrics, comparative model performance, and persistent challenges in the field. It includes a detailed taxonomy of detection methods, categorizing approaches into spatial, temporal, and spatiotemporal techniques. The survey further examines cross-dataset generalization performance to assess how well models adapt to domain shifts between training and testing data. Recent innovative directions are explored, covering adversarial defense strategies, explainability techniques, lightweight models for edge deployment, and privacy-preserving training. Additionally, best practices for building and releasing face swap detection tools are discussed to promote ethical, robust, and practical implementations. Finally, the paper outlines future research directions aimed at advancing model robustness, generalization, and compliance with legal and ethical standards. The discussions provide valuable insights that help researchers and practitioners gain a clear understanding of the face swap detection field, supporting and guiding their future research efforts.","2169-3536","","10.1109/ACCESS.2025.3598980","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11124889","Face swap detection;deepfake detection;adversarial attacks;deepfake evaluation metrics;digital forensics","Deepfakes;Faces;Face recognition;Surveys;Accuracy;Robustness;Ethics;Adaptation models;Visualization;Training","","","","190","CCBYNCND","14 Aug 2025","2025","","IEEE","IEEE Journals"
"A Robust Deepfake Video Detection Method based on Continuous Frame Face-swapping","D. Liu; Z. Yang; R. Zhang; J. Liu","School of Cyberspace Security Beijing University of Posts and Telecommunications, Beijing, China; School of Cyberspace Security Beijing University of Posts and Telecommunications, Beijing, China; School of Cyberspace Security Beijing University of Posts and Telecommunications, Beijing, China; School of Cyberspace Security Beijing University of Posts and Telecommunications, Beijing, China","2022 International Conference on Artificial Intelligence, Information Processing and Cloud Computing (AIIPCC)","27 Mar 2023","2022","","","188","191","Detection of deepfake videos faces serious generalization problem in real world application scenarios. Existing robust deepfake detection methods can only works on single frame image but not continuous frame videos. In this paper, we propose a robust deepfake video detection method based on continuous frame face-swapping. We design our face-swapping dataset with Delaunay triangulation and piecewise affine transform to achieve continuous frame face-swapping. We design a feature enhancement module with facial and background information covered to make the method focus on the mask fusion zone. We build our detection model with Efficient Net to extract intra-frame fusion feature and LSTM to extract inter-frame time feature. Cross-domain experiments show that our method achieves better detection AUC than existing methods, which proves our method is robust because of generalization.","","978-1-6654-6287-7","10.1109/AIIPCC57291.2022.00048","National Natural Science Foundation of China(grant numbers:U1936216,U21B2020,62002197); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10070215","deepfake detection;continuous frame face-swapping;generalization;Efficient Net;LSTM","Deepfakes;Cloud computing;Computational modeling;Transforms;Information processing;Feature extraction;Artificial intelligence","","4","","10","IEEE","27 Mar 2023","19-21 Aug. 2022","19-21 Aug. 2022","IEEE","IEEE Conferences"
"Methods of Deepfake Detection Based on Machine Learning","A. A. Maksutov; V. O. Morozov; A. A. Lavrenov; A. S. Smirnov","Department of Computer Systems and Technology, National Research Nuclear University “MEPhI”, Moscow, Russian Federation; Department of Computer Systems and Technology, National Research Nuclear University “MEPhI”, Moscow, Russian Federation; Department of Computer Systems and Technology, National Research Nuclear University “MEPhI”, Moscow, Russian Federation; Department of Computer Systems and Technology, National Research Nuclear University “MEPhI”, Moscow, Russian Federation",2020 IEEE Conference of Russian Young Researchers in Electrical and Electronic Engineering (EIConRus),"19 Mar 2020","2020","","","408","411","Nowadays, people faced an emerging problem of AI-synthesized face swapping videos, widely known as the DeepFakes. This kind of videos can be created to cause threats to privacy, fraudulence and so on. Sometimes good quality DeepFake videos recognition could be hard to distinguish with people eyes. That's why researchers need to develop algorithms to detect them. In this work, we present overview of indicators that can tell us about the fact that face swapping algorithms were used on photos. Main purpose of this paper is to find algorithm or technology that can decide whether photo was changed with DeepFake technology or not with good accuracy.","2376-6565","978-1-7281-5761-0","10.1109/EIConRus49466.2020.9039057","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9039057","deep learning;DeepFake detection;neural networks;face swapping indicators","Videos;Face recognition;Information integrity;Faces;Conferences;Gallium nitride;Neural networks","","45","","20","IEEE","19 Mar 2020","27-30 Jan. 2020","27-30 Jan. 2020","IEEE","IEEE Conferences"
"ADA-FInfer: Inferring Face Representations From Adaptive Select Frames for High-Visual-Quality Deepfake Detection","J. Hu; J. Liang; Z. Qin; X. Liao; W. Zhou; X. Lin","College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; Department of Computing, The Hong Kong Polytechnic University, Hong Kong; College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; CAS Key Laboratory of Electromagnetic Space Information, University of Science and Technology of China, Anhui, China; School of Computer Science, University of Guelph, Guelph, ON, Canada",IEEE Transactions on Dependable and Secure Computing,"14 May 2025","2025","22","3","3011","3027","Interpretable deepfake detection is gaining attention for providing explainable, trustworthy results, avoiding the limitations of ‘black-box’ models. Current interpretable methods focus on visible artifacts in low-visual-quality deepfakes, but these artifacts become less apparent in high-visual-quality deepfakes generated by advanced models. With advancements in deep generative models, producing high-visual-quality deepfakes has become a strategy to evade detection. To address this, we propose ${\sf ADA-FInfer}$ADA-FInfer, an adaptive frame selection and interpretable face representation inference method for detecting high-visual-quality deepfakes. ${\sf ADA-FInfer}$ADA-FInfer adaptively selects frames by analyzing optical flow to reveal manipulations. We also introduce an adaptive attack method that manipulates specific frames, and our adaptive selection strategy shows resistance to such attacks. ${\sf ADA-FInfer}$ADA-FInfer uses an encoder to learn face representations from source and target faces, applying a representation-prediction loss to maximize the distinction between real and fake videos. To provide further insights, we employ the joint entropy, mutual information, and conditional entropy analyses to explain the method's effectiveness. Extensive experiments and ablation studies demonstrate that ${\sf ADA-FInfer}$ADA-FInfer achieves promising performance in detecting high-visual-quality deepfakes.","1941-0018","","10.1109/TDSC.2024.3523289","National Natural Science Foundation of China(grant numbers:U22A2030,U20A20174,61972142,62402062); National Key Research and Development Program of China(grant numbers:2024YFF0618800,2022YFB3103500); Science Fund for Distinguished Young Scholars of Hunan Province(grant numbers:2024JJ2025); Natural Science Foundation of Changsha City, China(grant numbers:kq2402031); MOE AcRF TIER 3(grant numbers:MOE-MOET32022-0001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10818493","Adaptive frame selection;deepfake detection;high-visual-quality deepfake videos;inferring face representations","Deepfakes;Faces;Feature extraction;Entropy;Predictive models;Color;Biological system modeling;Adaptation models;Training;Prediction algorithms","","3","","74","IEEE","30 Dec 2024","May-June 2025","","IEEE","IEEE Journals"
"An Advanced Deep Learning Approach for Detecting Deepfake Video Manipulation","P. G. Reddy; P. A. Reddy; S. S. Narayan; B. Siddartha; V. Kulkarni; S. K. Rout","Department of Information Technology, Vardhaman College of Engineering (Autonomous), Hyderabad, India; Department of Information Technology, Vardhaman College of Engineering (Autonomous), Hyderabad, India; Department of Computer Science and Engineering, Vardhaman College of Engineering (Autonomous), Hyderabad, India; Department of Information Technology, Vardhaman College of Engineering (Autonomous), Hyderabad, India; Department of Information Technology, Vardhaman College of Engineering (Autonomous), Hyderabad, India; Department of Information Technology, Vardhaman College of Engineering (Autonomous), Hyderabad, India",2025 6th International Conference for Emerging Technology (INCET),"4 Sep 2025","2025","","","1","6","Deepfake technology poses several challenges from the legal, ethics, and sociological aspects since it utilizes deep-learning models that are relatively very advanced for creating lifelike synthetic media. Detecting fake synthetic content goes a long way in ensuring trust and integrity in the use of digital media. This paper presents an improved deepfake detection method that utilizes a Variational Autoencoder (VAE) for feature extraction, Vision Transformers (ViTs) to capture spatial and temporal dependencies, and a generator-discriminator pair inspired by Generative Adversarial Networks (GANs) for classification and Multi-task Cascaded Convolutional Networks (MTCNN) for efficient face detection and alignment. The proposed framework capitalizes on the strengths of these models to identify temporal and spatial anomalies often present in manipulated video content. The system integrates all these techniques and offers a holistic and robust approach to deepfake detection, thereby addressing challenges like occlusions, diverse lighting conditions, and sophisticated manipulation strategies. Experimental evaluations on benchmark datasets have demonstrated the high accuracy and low false-positive rates of the framework, even in the most sophisticated deepfake generation techniques. It has contributed to the growing body of work in deepfake detection as it presents a modular, scalable, and fully automated approach towards adapting to further advancements in the generation of synthetic media.","2996-4490","979-8-3315-3103-4","10.1109/INCET64471.2025.11140926","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11140926","Deep Learning;Deepfake detection;Variational Autoencoder (VAE);Vision Transformers (ViTs);Generator;Discriminator;Multi-task Cascaded Convolutional Networks (MTCNN)","Deepfakes;Accuracy;Lighting;Media;Generative adversarial networks;Transformers;Multitasking;Feature extraction;Face detection;Faces","","","","15","IEEE","4 Sep 2025","23-25 May 2025","23-25 May 2025","IEEE","IEEE Conferences"
"LIED: A Lightweight and Ensemble learning approach for fake face Detection","R. Budhiraja; M. Kumar; M. K. Das; A. S. Bafila; S. Singh","Institute of Informatics and Communication University of Delhi South Campus, New Delhi, India; School of Computer and Information Sciences, Indira Gandhi National Open University, New Delhi, India; Institute of Informatics and Communication University of Delhi South Campus, New Delhi, India; Institute of Informatics and Communication University of Delhi South Campus, New Delhi, India; Institute of Informatics and Communication University of Delhi South Campus, New Delhi, India","2023 IEEE 3rd International Conference on Technology, Engineering, Management for Societal impact using Marketing, Entrepreneurship and Talent (TEMSMET)","16 Jun 2023","2023","","","1","6","For many years, machine learning problems have primarily been driven by the availability and quality of data. Being the key, data has been equally vulnerable and got a savior in the form of generative adversarial networks (GANs) which opened the floodgates for generating almost any type of real, yet synthetic data. Human face became one of the initial victims to this superior technology, where in highly realistic and convincing fake content is generated using deep learning technologies or ‘‘DeepFakes’’. Taking a giant leap forward from manipulating facial attributes, to be now able to swap expressions seamlessly and even generate new (non-existent) synthetic faces poses a grave threat not only to chosen few, but for the entire society. This upshoot has been reciprocated with significant efforts and investments for its detection, but the techniques are often marred with either lower accuracies, or, higher computation costs. This is where convolutional reservoir networks (CoRN) come to rescue owing to their lightweight nature, able to do ensemble feature extraction and its generalization ability. This paper investigates, implements and demonstrates the application of CoRN based architectures to the task of human fake face detection. The steep performance improvements as evident from our results further ratify the effectiveness of this approach, which is also shown to perform exceedingly well against smaller datasets.","","979-8-3503-9781-9","10.1109/TEMSMET56707.2023.10149972","University of Delhi; Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10149972","DeepFake Detection;Fake Face Detection;Convolutional Reservoir Networks;Convolution Neural Networks;Reservoir Computing;Ensemble Feature Extraction","Privacy;Neural networks;Computer architecture;Propulsion;Reservoirs;Feature extraction;Security","","","","14","IEEE","16 Jun 2023","10-11 Feb. 2023","10-11 Feb. 2023","IEEE","IEEE Conferences"
"Context-Preserving and Sparsity-Aware Temporal Graph Network for Unified Face Forgery Detection","K. D. K. Yadav; I. Kavati; A. S. Kurella; S. Jain; Y. Katare","National Institute of Technology Warangal, India; National Institute of Technology Warangal, India; National Institute of Technology Warangal, India; National Institute of Technology Warangal, India; National Institute of Technology Warangal, India",IEEE Transactions on Consumer Electronics,"","2025","PP","99","1","1","Deepfakes and face forgeries continue to evolve, posing significant threats to consumer privacy, reputation, and public security. Existing deep learning approaches often focus on spatial inconsistencies but fail to capture relational context across facial regions and long-term temporal anomalies such as unnatural blinking or lip synchronization errors. We propose EDRL, a lightweight model that effectively captures spatiotemporal relational dependencies for robust face forgery detection. The architecture incorporates a Spatio-Temporal Attention (STA) module built upon a lightweight MC318 3D convolutional backbone, enabling motion-aware feature extraction and region-specific attention mapping. A Sparsity-Aware Edge Dropping Relation Learner (EDRL) constructs adaptive facial graphs by pruning redundant and less informative edges. A Temporal Adaptive Aggregation Network (TAAN) then aggregates frame-level features, ensuring that temporally significant representations are preserved even after edge pruning. Extensive evaluations show that EDRL achieves 98.4% accuracy on CASIA-FASD and reduces HTER by 6.2% on Replay-Attack compared to state-of-the-art baselines, while maintaining competitive results on digital forgery datasets. By enhancing robustness to diverse manipulations while reducing computational overhead, EDRL contributes towards a secure, lightweight, and deployable framework suitable for real-world applications.","1558-4127","","10.1109/TCE.2025.3633697","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11250982","Spatio-Temporal attention;DeepFake detection;Face Forgery;graph convolution network;relation learning","Forgery;Faces;Adaptation models;Robustness;Image edge detection;Transformers;Deepfakes;Computational modeling;Training;Feature extraction","","","","","IEEE","17 Nov 2025","","","IEEE","IEEE Early Access Articles"
"Deepfake Face Images: Explainable Detection using Deep Neural Networks and Class Activation Mapping","B. Sugiantoro","Department of Informatics Faculty of Science and Technology, Universitas Islam Negeri Sunan Kalijaga, Yogyakarta, Indonesia",2024 IEEE International Symposium on Consumer Technology (ISCT),"17 Dec 2024","2024","","","86","90","Our study presents an improved method for detecting deepfake content using advanced explainable artificial intelligence (XAI) techniques. We focused on enhancing deep neural networks, specifically Residual Network (ResNet) models such as ResNet50V2, ResNet101V2, and ResNet152V2, with Gradient-weighted Class Activation Mapping (Grad-CAM) to more accurately differentiate between real and artificial faces. The addition of XAI principles through Grad-CAM not only increases the detection accuracy but also makes the decision-making process of the models transparent, fostering trust, and making the technology more accessible for real-world applications. We evaluated our models using the FFHQ dataset, which comprises a vast array of real and fake facial images. The results demonstrated significant improvements in both precision and recall rates across all models with the integration of Grad-CAM. Specifically, the enhanced ResNet50V2 model achieved a precision of 87% for fake images and 94% for real images, with recall rates of 94% for fake images and 86% for real images, resulting in f1 scores of 90% for both classes. The ResNet101V2 and ResNet152V2 models with Grad-CAM also showed notable improvements, with the ResNet101V2 + Grad-CAM model reaching a precision of 87% for fake and 96% for real, and the ResNet152V2 + Grad-CAM model achieving a precision of 90% for fake and 92% for real, both with high recall and f1 scores, highlighting the precision and reliability of the method. Our approach not only addresses the challenge of detecting deepfakes with high accuracy but also balances the model complexity with computational efficiency. Despite some limitations, such as data set biases and occasional misclassifications, our method significantly advances digital media authentication and shows promising prospects for identity and security verification. Future work will focus on refining these models, emphasizing the importance of XAI, and exploring their application to broader image-classification challenges to strengthen defenses against the evolving threat of deepfake technology.","2159-1423","979-8-3503-6519-1","10.1109/ISCT62336.2024.10791156","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10791156","Deepfake;Detection;Explainable Artificial Intelligence;Grad-CAM;ResNet","Training;Deepfakes;Accuracy;Explainable AI;Computational modeling;Decision making;Media;Complexity theory;Faces;Testing","","2","","18","IEEE","17 Dec 2024","13-16 Aug. 2024","13-16 Aug. 2024","IEEE","IEEE Conferences"
"Using Local Phase Quantization to Identify Fake Faces in Online Social Networks","S. Kundu; T. Ghosh; R. Naskar","Dept. of Computing Technologies, S.R.M. Institute of Science and Technology, Chennai, India; Dept. of Information Technology, Indian Institute of Engineering Science and Technology, Shibpur, India; Dept. of Information Technology, Indian Institute of Engineering Science and Technology, Shibpur, India",TENCON 2024 - 2024 IEEE Region 10 Conference (TENCON),"5 Mar 2025","2024","","","323","326","The rapid advancement of Generative AI, especially Generative Adversarial Networks (GANs), has increased the issue of fake news on Online Social Networks (OSNs) by generating deceptive face images for social media profiles. Although existing detection methods are accurate, their effectiveness decreases when images are post-processed, which is common on OSNs. In this paper, we present LPQ-Net, a model combining Local Phase Quantization (LPQ) for feature extraction with a CNN-based classifier. We explore two variants: one sets a new benchmark in detecting StyleGAN2-generated images, and the other excels in identifying images shared on Facebook, WhatsApp, and Instagram. LPQ-Net also operates with minimal parameters, outperforming state-of-the-art methods and making it ideal for resource-constraint applications. Furthermore, our solution demonstrates its effectiveness by performing exceptionally well in detecting images generated by various Diffusion models. We further show that incorporating LPQ features into fine-tuned classifiers like ResNet50, ResNet101, InceptionV3, and DenseNet121 significantly improves performance.","2159-3450","979-8-3503-5082-1","10.1109/TENCON61640.2024.10903070","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10903070","Deepfake Detection;GAN;Diffusion Models;Digital Image Forensics","Freeware;Quantization (signal);Accuracy;Social networking (online);Feature extraction;Web sites;Multimedia communication;Internet telephony;Faces;Residual neural networks","","1","","13","IEEE","5 Mar 2025","1-4 Dec. 2024","1-4 Dec. 2024","IEEE","IEEE Conferences"
"Advanced Temporal Analysis for Deepfake Detection using XceptionNet in Media Forensics","K. M; L. S; K. S; A. D. J","Department of CSE, Karpagam Academy of Higher Education, Coimbatore, India; Department of CSE, Karpagam Academy of Higher Education, Coimbatore, India; Department of CSE, Karpagam Academy of Higher Education, Coimbatore, India; Department of CSE, Faculty of Engineering, Karpagam Academy of Higher Education, Coimbatore, India",2025 8th International Conference on Computing Methodologies and Communication (ICCMC),"4 Sep 2025","2025","","","1224","1228","Deepfakes videos through advanced AI models, pose a significant threat due to their deceptive realism. This paper presents a deepfake detection framework based on XceptionNet, which provides depthwise separable convolutions for fine-grained image analysis. The proposed system processes both static images and video by detecting and aligning faces, enabling consistent frame-level analysis. Furthermore, for videos, each frame is analyzed using XceptionNet, followed by temporal feature extraction through LSTM and CNN to capture subtle facial expressions and motion variations. The model was evaluated on multiple datasets, achieving strong precision, recall, and F1-scores at both frame and video levels. Results show that the XceptionNet-based approach reliably distinguishes real from manipulated content. However, limitations remain due to dataset diversity and computational complexity, highlighting directions for future research.","","979-8-3315-1211-8","10.1109/ICCMC65190.2025.11140668","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11140668","Deepfake Detection;Media Forensics. XceptionNet;Generative Models;Artificial Intelligence;Synthetic Media;Face Detection;Temporal Feature Analysis","Deepfakes;Computational modeling;Forensics;Media;Feature extraction;Real-time systems;Face detection;Computational complexity;Artificial intelligence;Long short term memory","","","","15","IEEE","4 Sep 2025","23-25 July 2025","23-25 July 2025","IEEE","IEEE Conferences"
"Artifacts-Disentangled Adversarial Learning for Deepfake Detection","X. Li; R. Ni; P. Yang; Z. Fu; Y. Zhao","Institute of Information Science, Beijing Jiaotong University, Beijing, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China; Hubei Key Laboratory of Intelligent Vision Based Monitoring for Hydroelectric Engineering, China Three Gorges University, Yichang, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China",IEEE Transactions on Circuits and Systems for Video Technology,"4 Apr 2023","2023","33","4","1658","1670","Due to the development of facial manipulation technologies, the generated deepfake videos cause a severe trust crisis in society. Existing methods prove that effective extraction of the artifacts introduced during the forgery process is essential for deepfake detection. However, since the features extracted by supervised binary classification contain a lot of artifact-irrelevant information, existing algorithms suffer severe performance degradation in the case of the mismatch between training and testing datasets. To overcome this issue, we propose an Artifacts-Disentangled Adversarial Learning (ADAL) framework to achieve accurate deepfake detection by disentangling the artifacts from irrelevant information. Furthermore, the proposed algorithm provides visual evidence by effectively estimating artifacts. Specifically, Multi-scale Feature Separator (MFS) in the disentanglement generator is designed to precisely transmit the artifact features and optimize the connection between the encoder and decoder. In addition, we design an Artifacts Cycle Consistency Loss (ACCL) which uses the disentangled artifacts to construct new samples and enables pixel-level supervised training for the generator to estimate more accurate artifacts. The symmetric discriminators are paralleled to differentiate the constructed samples from the original images in both fake and real domains, making the adversarial training process more stable. Extensive experiments on existing benchmarks demonstrate that the proposed method outperforms the state-of-the-art approaches.","1558-2205","","10.1109/TCSVT.2022.3217950","National Key Research and Development Program of China(grant numbers:2021ZD0112100); National Natural Science Foundation of China(grant numbers:U1936212,62120106009); Beijing Natural Science Foundation(grant numbers:4222014); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9931753","Deepfake detection;video forensics;artifacts;disentanglement learning","Deepfakes;Feature extraction;Forgery;Face recognition;Faces;Visualization;Training","","60","","48","IEEE","28 Oct 2022","April 2023","","IEEE","IEEE Journals"
"Real-Time Binary Classification of Real and Fake Faces via MobileNetV2 and Transfer Learning","K. Mehta; R. Jain; M. Raval; S. Ajakiya; I. Jotaniya","Department of Information Technology, Marwadi University, Rajkot, India; Department of Information Technology, Marwadi University, Rajkot, India; Department of Information Technology, Marwadi University, Rajkot, India; Department of Information Technology, Marwadi University, Rajkot, India; Department of Information Technology, Marwadi University, Rajkot, India",2025 International Conference on Engineering Innovations and Technologies (ICoEIT),"31 Oct 2025","2025","","","710","715","In this paper, we present a real time binary classification for classifying real and fake Human face images using MobileNetV2 and transfer learning. In order to overcome the high computational cost and scalability limitation of the existing deepfake detection methods, we propose the frame level-based analysis model from the dataset Celeb-DF (v2). Through the frame extraction, data augmentation, and normalization steps, a generalization is reinforced. With the help of dropout and early stopping, the validation accuracy improved to 95.14 % after fine tuning the MobileNetV2 architecture. This is also accompanied by good recall and precision for both classes. Deployment on resource constrained devices is possible due to the lightweight nature of the model, allowing for the use of it in real time digital forensics and content verification. The contributions of this work are a scalable and fast method for deepfake detection with more accurate, faster, and deployable performance than existing methods.","","979-8-3315-2595-8","10.1109/ICoEIT63558.2025.11211661","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11211661","convolutional neural networks;deepfake detection;mobilenetv2;real-time classification;transfer learning","Deepfakes;Accuracy;Computational modeling;Scalability;Transfer learning;Digital forensics;Real-time systems;Data mining;Convolutional neural networks;Faces","","","","23","IEEE","31 Oct 2025","4-5 July 2025","4-5 July 2025","IEEE","IEEE Conferences"
"An Investigation of Face Detection and Feature Extraction Techniques in Deepfake Detection Using a Multi-Model Machine Learning Approach","M. M. Rahman; M. M. R. Computer; N. Das; M. S. Uddin; R. S. Shammah; M. M. Rahman","College of Technology & Engineering, Westcliff University, Irvine, California, USA; Systems Technology, Louisiana State University Shreveport, Louisiana, USA; Management Information Systems, International American University, Los Angeles, California, USA; College of Technology & Engineering, Westcliff University, Irvine, California, USA; Technology & Engineering, Westcliff University, Irvine, California, USA; System Engineer, sBIT Inc, California, USA",2025 3rd International Conference on Business Analytics for Technology and Security (ICBATS),"3 Dec 2025","2025","","","1","8","The development of deepfake technologies has outpaced the development of means to detect manipulated videos, presenting challenges in media security and forensic digital analysis. In this work, we applied a multimodel machine learning approach that incorporates both traditional and modern deep learning classifiers to deepfake video detection. The research used a subset of the dataset, which contained 401 training samples and 400 test samples, but with a large imbalance in classes towards FAKE videos. Our approach consisted of data preprocessing, conducting EDA, face detection using Haar Cascade Classifiers in OpenCV, and data feature extraction. Various models including Random Forest, Support Vector Machines, and Convolutional Neural Networks (CNNs) were taught and measured based on the model's accuracy, precision, recall and F1 score. The deep learning model outperformed the others in every measurement, proving its proficiency in detecting deepfake video artifacts. This study illustrates deepfake detection underscores the fusion of classical machine learning with contemporary deep learning models provides a powerful response to the ever-increasing threat of deepfake videos.","","979-8-3315-3827-9","10.1109/ICBATS66542.2025.11258249","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11258249","Deepfake Detection;Machine Learning;Convolutional Neural Networks (CNN);Face Detection;Feature Extraction;Deepfake Artifacts;Media Security;Data Augmentation;Video Manipulation","Deep learning;Deepfakes;Accuracy;Computational modeling;Machine learning;Media;Feature extraction;Face detection;Security;Convolutional neural networks","","","","52","IEEE","3 Dec 2025","1-2 May 2025","1-2 May 2025","IEEE","IEEE Conferences"
"Towards a Universal Synthetic Video Detector: From Face or Background Manipulations to Fully AI-Generated Content","R. Kundu; H. Xiong; V. Mohanty; A. Balachandran; A. K. Roy-Chowdhury","Google LLC; Google LLC; Google LLC; Google LLC; University of California, Riverside",2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),"13 Aug 2025","2025","","","28050","28060","Existing DeepFake detection techniques primarily focus on facial manipulations, such as face-swapping or lip-syncing. However, advancements in text-to-video (T2V) and image-to-video (I2V) generative models now allow fully AI-generated synthetic content and seamless background alterations, challenging face-centric detection methods and demanding more versatile approaches.To address this, we introduce the Universal Network for Identifying Tampered and synthEtic videos (UNITE) model, which, unlike traditional detectors, captures full-frame manipulations. UNITE extends detection capabilities to scenarios without faces, non-human subjects, and complex background modifications. It leverages a transformer-based architecture that processes domain-agnostic features extracted from videos via the SigLIP-So400M foundation model. Given limited datasets encompassing both facial/background alterations and T2V/I2V content, we integrate task-irrelevant data alongside standard DeepFake datasets in training. We further mitigate the model’s tendency to over-focus on faces by incorporating an attention-diversity (AD) loss, which promotes diverse spatial attention across video frames. Combining AD loss with cross-entropy improves detection performance across varied contexts. Comparative evaluations demonstrate that UNITE outperforms state-of-the-art detectors on datasets featuring face/background manipulations and fully synthetic T2V/I2V videos, showcasing its adaptability and generalizable detection capabilities.","2575-7075","979-8-3315-4364-8","10.1109/CVPR52734.2025.02612","Google; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11094438","deepfake detection;synthetic video detection;video authenticity","Training;Deepfakes;Technological innovation;Detectors;Feature extraction;Transformers;Text to video;Faces;Standards;Synthetic data","","","","64","IEEE","13 Aug 2025","10-17 June 2025","10-17 June 2025","IEEE","IEEE Conferences"
"eKYC-DF: A Large-Scale Deepfake Dataset for Developing and Evaluating eKYC Systems","H. Felouat; H. H. Nguyen; T. -N. Le; J. Yamagishi; I. Echizen","Informatics Program, The Graduate University for Advanced Studies, SOKENDAI, Kanagawa, Japan; Informatics Program, The Graduate University for Advanced Studies, SOKENDAI, Kanagawa, Japan; Information and Society Research Division, National Institute of Informatics, Tokyo, Japan; Informatics Program, The Graduate University for Advanced Studies, SOKENDAI, Kanagawa, Japan; Informatics Program, The Graduate University for Advanced Studies, SOKENDAI, Kanagawa, Japan",IEEE Access,"1 Mar 2024","2024","12","","30876","30892","The reliability of remote identity-proofing systems (i.e., electronic Know Your Customer, or eKYC, systems) is challenged by the development of deepfake generation tools, which can be used to create fake videos that are difficult to detect using existing deepfake detection models and are indistinguishable by facial recognition systems. This poses a serious threat to eKYC systems and a danger to individuals’ personal information and property. Existing deepfake datasets are not particularly appropriate for developing and evaluating eKYC systems, which require specific motions, such as head movement, for liveness detection. Furthermore, they do not contain ID information or protocols for facial verification evaluation, which is vital for eKYC. We found that eKYC systems without the ability to detect deepfakes can be easily compromised. We have thus created a large-scale collection of high-quality fake videos (more than 228,000 videos) that are diverse in terms of age, gender, and ethnicity, plus a corresponding facial image subset. The videos include a variety of head movements and facial expressions. This large collection of high-quality diverse videos is well-suited for developing and evaluating various tasks related to eKYC systems. Furthermore, we provide protocols for traditional deepfake detection and facial verification, which are widely used in eKYC systems. It is worth mentioning that systematic evaluation of facial recognition systems on deepfake detection has not been reported. The entire eKYC-DF dataset, evaluation toolkit, and trained models are open access to researchers on GitHub: https://github.com/hichemfelouat/eKYC-DF.","2169-3536","","10.1109/ACCESS.2024.3369187","Japan Society for the Promotion of Science (JSPS) KAKENHI(grant numbers:JP16H06302,JP18H04120,JP20K23355,JP21H04907,JP21K18023); Japan Science and Technology Agency (JST) CREST(grant numbers:JPMJCR18A6,JPMJCR20D3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10444105","Deepfake detection;electronic Know Your Customer;eKYC;facial verification;face swapping;face recognition","Deepfakes;Videos;Face recognition;Feature extraction;Facial features;Cameras;Customer profiles;Remote handling equipment;Identity management systems;Identification of persons","","12","","81","CCBYNCND","23 Feb 2024","2024","","IEEE","IEEE Journals"
"Pixel Bleach Network for Detecting Face Forgery Under Compression","C. Li; Z. Zheng; Y. Bin; G. Wang; Y. Yang; X. Li; H. T. Shen","Center for Future Multimedia and School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; Center for Future Multimedia and School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; Center for Future Multimedia and School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; Center for Future Multimedia and School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; Center for Future Multimedia and School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Aeronautics and Astronautics, University of Electronic Science and Technology of China, Chengdu, China; Center for Future Multimedia and School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China",IEEE Transactions on Multimedia,"24 Jul 2024","2024","26","","2585","2597","The existing face forgery algorithms have achieved remarkable progress in how to generate reasonable facial images and can even successfully deceive human beings. Considering public security, face forgery detection is of vital importance, making it essential to design face forgery detection algorithms to detect forgery images over the Internet. Despite the great success achieved by the existing Deepfake detection algorithms, they usually failed to achieve satisfactory Deepfake detection performance when deployed to handle the forgery videos in practice. One significant reason is compression. The videos over the Internet are inevitably compressed considering the transmission efficiency. The video compression results in significant Deepfake detection performance degradation for the existing Deepfake detection algorithms. To address this issue, in this article, we propose a generic, simple yet effective “bleaching” pre-processing module based on the generative model and the high-level feature representations to produce a bleached image, which shares a similar appearance with the compressed images. The bleached images with recovered information can be identified accurately by the optimized Deepfake detection models without retraining. The proposed method has utilized a redesigned feature representation, which serves as a navigator to effectively and sufficiently alter the feature distribution in the high-dimensional space to remedy the difference between real facial images and forgery counterparts. Thus, the proposed method can successfully avoid misclassification. Comprehensive and extensive experiments are carried out on four low-quality Faceforensics++ datasets, demonstrating the effectiveness of our method in recovering the information loss caused by the compression artifacts across various backbones and compression.","1941-0077","","10.1109/TMM.2023.3301242","National Natural Science Foundation of China(grant numbers:U20B2063,62220106008,62102070); Sichuan Science and Technology Program(grant numbers:2023NSFSC1392); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10202582","Deepfake detection;robust deepfake detection under compression;adversarial learning","Deepfakes;Image coding;Forgery;Faces;Detection algorithms;Feature extraction;Generators","","3","","67","IEEE","2 Aug 2023","2024","","IEEE","IEEE Journals"
"Facial Action Unit-Based Deepfake Video Detection Using Deep Learning","Q. Jaleel; I. Hadi","Software Department, University of Babylon, Babylon, Iraq; Software Department, University of Babylon, Babylon, Iraq",2022 4th International Conference on Current Research in Engineering and Science Applications (ICCRESA),"25 Dec 2023","2022","","","228","233","Deepfake videos are becoming more realistic, making them a menace. As a result of the development of deep learning techniques such as Generative adversarial networks (GAN), Deepfake has become closer to the truth. Widespread use of falsified videos and images on social media requires accurate detection. An identity switch (DeepFake) and an expression swap create facial modifications. This paper can detect deepfakes that are perfectly created. Traditional detection approaches that observe artifacts and pixel irregularities cannot keep up with modern technology. The paper is divided into two stages. In the first stage, the paper extracts facial action units from a person and creates a profile for him. This profile represents the behavior of his facial expressions, which differ from one person to another. This was done by building a deep learning network and training it based on a dataset. The second stage is testing, which involves taking videos, extracting facial action units, and testing them on the network to classify them as fake or real. The network has proven its ability to classify with high accuracy of %95.75 compared to traditional methods.","","979-8-3503-3494-4","10.1109/ICCRESA57091.2022.10352085","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10352085","GAN;facial action unit;Facial expression recognition;Media Forensics;DeepFake Detection;face detection","Deep learning;Training;Deepfakes;Social networking (online);Face recognition;Psychology;Switches","","6","","21","IEEE","25 Dec 2023","20-21 Dec. 2022","20-21 Dec. 2022","IEEE","IEEE Conferences"
"Deepfake Face Detection Algorithm Based on Multi-Scale Attention Reconstruction","Z. Yu; Y. Dai; W. Dai; Y. Lin","School of Automation, Beijing Institute of Technology, Beijing, P. R. China; Beijing Institute of Technology, Zhuhai, Guangdong, P. R. China; River Security Technology Co., LTD, Shanghai, China; River Security Technology Co., LTD, Shanghai, China",2025 44th Chinese Control Conference (CCC),"10 Oct 2025","2025","","","7989","7996","Recent advances in deepfake facial technology have enabled its misuse for creating deceptive content and spreading false information, posing serious risks to personal privacy, social order, and national security. However, early deepfake detection methods fell short. For instance, the traditional reconstruction model couldn't adapt to data distribution changes, and the single-scale structure struggled to fully uncover various forgery artifacts. Therefore, we propose a deepfake face detection framework named Multi-scale Attention Reconstruction (MSAR). The framework reconstructs real faces to learn their feature distributions, enhancing detector generalization. Firstly, we introduce the adaptive neighborhood aggregation (ANA) module. It integrates information from adjacent regions at different scales and realizes selective feature fusion at the same scale, improving reconstruction quality. Moreover, we propose the attention collaborative guidance (ACG) module. It takes the mask difference between the reconstructed and source real-face images as input and captures long-range dependencies and local detail information. This guides the model to focus more on key features related to reconstruction errors, thus enhancing the classifier's performance. Experiments on public datasets such as FaceForensics++ and CelebDF show that MSAR outperforms existing methods in key metrics such as ACC and AUC. Ablation experiments also verify the effectiveness of each module.","1934-1768","978-988-75816-1-1","10.23919/CCC64809.2025.11178373","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11178373","Deepfake Detection;Multi-scale Feature Fusion;Reconstruction Learning;Attention Mechanism","Deepfakes;Adaptation models;Privacy;Navigation;Collaboration;Feature extraction;Forgery;Face detection;Image reconstruction;Periodic structures","","","","34","","10 Oct 2025","28-30 July 2025","28-30 July 2025","IEEE","IEEE Conferences"
"Transformer And Node-Compressed Dnn Based Dual-Path System For Manipulated Face Detection","Z. Luo; S. -I. Kamata; Z. Sun","Graudate School of Information Production and Systems, Waseda University, Japan; Graudate School of Information Production and Systems, Waseda University, Japan; Graudate School of Information Production and Systems, Waseda University, Japan",2021 IEEE International Conference on Image Processing (ICIP),"23 Aug 2021","2021","","","3882","3886","Deep neural networks (DNNs) have extensively promoted data generation development; the quality of these generated content has achieved an impressive new level. Therefore, manipulated content, especially facial manipulation, is a growing concern for online information legitimacy. Most current deep learning-based methods depend on local features sampled by convolutional kernels and lack knowledge globally. To address the problem, we propose a dual-path pipeline using Neural Ordinary Differential Equations (NODE) based neural network and facial-feature biased transformer to deal with the visual content from a different view. The transformer path could link these landmarks in a long-range, moreover, we adopt an attention guided augmentation based self-ensemble for more robust performance. Extensive experiments show that our system could surpass several commonly used approaches in terms of video-level accuracy and AUC with better interpretability.","2381-8549","978-1-6654-4115-5","10.1109/ICIP42928.2021.9506222","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9506222","Image forensics;DeepFake detection;neural network;face manipulation","Learning systems;Deep learning;Visualization;Image processing;Pipelines;Neural networks;Ordinary differential equations","","7","","24","IEEE","23 Aug 2021","19-22 Sept. 2021","19-22 Sept. 2021","IEEE","IEEE Conferences"
"Face Forgery Detection Algorithm Based on Improved MobileViT Network","T. Wang; X. Lu","School of Information Engineering, Inner Mongolia University of Science and Technology, Baotou, China; School of Information Engineering, Inner Mongolia University of Science and Technology, Baotou, China",2023 8th International Conference on Intelligent Computing and Signal Processing (ICSP),"19 Sep 2023","2023","","","1396","1400","DeepFakes blur the boundaries between reality and forgery, resulting in the collapse of exiting credit system, causing immeasurable consequences for national security and social order. Through analysis of existing face forgery techniques, it is found that most generation techniques rely on random noise distribution, and global information will be lost after up sampling. Therefore, we propose a deepfake detection algorithm based on improved MobileViT, which uses CNN local space biasing and the global space representation of the Transformer network to learn the local features and global representation of forged faces, respectively. Coordinate attention is introduced to obtain directional perception and position sensitive information, making the model locate synthetic traces of fake faces better and fusion local and global representation more effectively. For the improved generalization of the model, with the GELU activation function to solve the problem of neuron death. Our model achieved 96.2% on FF++(C23) datasets, and 93.7%,94.1%,96.3%,87.9% on DF, F2F, FS, and NT datasets, respectively. Comparing with previous methods, our model has shown detection robustness and better generalization.","","979-8-3503-0245-5","10.1109/ICSP58490.2023.10248802","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10248802","Deepfake Detection;MobileViT;Coordinate Attention;GELU","Deepfakes;Computational modeling;Neurons;Signal processing;Transformers;Forgery;Robustness","","5","","20","IEEE","19 Sep 2023","21-23 April 2023","21-23 April 2023","IEEE","IEEE Conferences"
"On the use of Stable Diffusion for creating realistic faces: from generation to detection","L. Papa; L. Faiella; L. Corvitto; L. Maiano; I. Amerini","Sapienza University of Rome, Italy; Sapienza University of Rome, Italy; Sapienza University of Rome, Italy; Sapienza University of Rome, Italy; Sapienza University of Rome, Italy",2023 11th International Workshop on Biometrics and Forensics (IWBF),"26 Jun 2023","2023","","","1","6","The mass adoption of diffusion models has shown that artificial intelligence (AI) systems can be used to easily generate realistic images. The spread of these technologies paves the way to previously unimaginable creative uses while also raising the possibility of malicious applications. In this work, we propose a critical analysis of the overall pipeline, i.e., from creating realistic human faces with Stable Diffusion v1.5 [1] to recognizing fake ones. We first propose an analysis of the prompts that allow the generation of extremely realistic faces with a human-in-the-loop approach. Our objective is to identify the text prompts that drive the image generation process to obtain realistic photos that resemble everyday portraits captured with any camera. Next, we study how complex it is to recognize these fake contents for both AI-based models and non-expert humans. We conclude that similar to other deepzfake creation techniques, despite some limitations in generalization across different datasets, it is possible to use AI to recognize these contents more accurately than non-expert humans would.","","979-8-3503-3607-8","10.1109/IWBF57495.2023.10156981","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10156981","Computer vision;Deepfake detection;Diffusion models;Prompt engineering;Security","Deepfakes;Image synthesis;Forensics;Face recognition;Pipelines;Human in the loop;Security","","16","","34","IEEE","26 Jun 2023","19-20 April 2023","19-20 April 2023","IEEE","IEEE Conferences"
"Enhancing Face Forgery Detection with Augmented Feature Distillation","Y. He; W. Zhou; H. Zhao; Z. Fang; L. Xing; M. Huangfu; W. Zhang; N. Yu","University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China; China Telecommunications Corporation; University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China",2025 11th IEEE International Conference on Privacy Computing and Data Security (PCDS),"29 Sep 2025","2025","","","01","09","Detecting face forgery has emerged as a critical task due to the profound societal implications associated with advanced facial manipulation technologies. Unlike conventional visual classification tasks, the subtle and often imperceptible discrepancies between authentic and forged images present substantial challenges for detection, particularly concerning robustness and generalization. To overcome these limitations, we propose a novel feature-level alignment strategy inspired by knowledge distillation. Our method promotes feature invariance against image perturbations through a quality-diversified selfdistillation framework. Moreover, we introduce a forgery feature augmentation strategy aimed at enhancing generalization by distinctly isolating authentic image representations from those of forged images. Experimental evaluations demonstrate that our method is compatible with various backbone architectures, consistently outperforming state-of-the-art face forgery detection techniques, especially under rigorous assessments of generalization and robustness.","","978-1-6654-7746-8","10.1109/PCDS65695.2025.00025","Natural Science Foundation of China(grant numbers:62372423,62121002,62072421); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11172769","Deepfake Detection;Knowledge Distillation;Feature Augmentation;Generalization","Representation learning;Training;Deepfakes;Visualization;Refining;Feature extraction;Forgery;Robustness;Faces;Standards","","","","51","IEEE","29 Sep 2025","1-4 Aug. 2025","1-4 Aug. 2025","IEEE","IEEE Conferences"
"FRIDAY: Mitigating Unintentional Facial Identity in Deepfake Detectors Guided by Facial Recognizers","Y. Kim; M. -J. Kwon; W. Lee; C. Kim","Graduate School of Green Growth and Sustainability, KAIST, Daejeon, South Korea; School of Electrical Engineering, KAIST, Daejeon, South Korea; School of Electrical Engineering, KAIST, Daejeon, South Korea; Graduate School of Green Growth and Sustainability, KAIST, Daejeon, South Korea",2024 IEEE International Conference on Visual Communications and Image Processing (VCIP),"27 Jan 2025","2024","","","1","5","Previous Deepfake detection methods perform well within their training domains, but their effectiveness diminishes significantly with new synthesis techniques. Recent studies have revealed that detection models make decision boundaries based on facial identity instead of synthetic artifacts, leading to poor cross-domain performance. To address this issue, we propose FRIDAY, a novel training method that attenuates facial identity utilizing a face recognizer. To be specific, we first train a face recognizer using the same backbone as the Deepfake detector. We then freeze the recognizer and use it during the detector’s training to mitigate facial identity information. This is achieved by feeding input images into both the recognizer and the detector, then minimizing the similarity of their feature embeddings using our Facial Identity Attenuating loss. This process encourages the detector to produce embeddings distinct from the recognizer, effectively attenuating facial identity. Comprehensive experiments demonstrate that our approach significantly improves detection performance on both in-domain and cross-domain datasets.","2642-9357","979-8-3315-2954-3","10.1109/VCIP63160.2024.10849915","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10849915","Deepfake Detection;Unintentional Facial Identity;Face Recognition;Image Forensics","Training;Deepfakes;Image recognition;Visual communication;Face recognition;Forensics;Detectors;Feature extraction;Artificial intelligence","","","","18","IEEE","27 Jan 2025","8-11 Dec. 2024","8-11 Dec. 2024","IEEE","IEEE Conferences"
"Exposing Deepfake Face Forgeries With Guided Residuals","Z. Guo; G. Yang; J. Chen; X. Sun","School of Information Science and Engineering, Hunan University, Changsha, China; School of Information Science and Engineering, Hunan University, Changsha, China; School of Information Science and Engineering, Hunan University, Changsha, China; School of Computer and Software, Nanjing University of Information Science and Technology, Nanjing, China",IEEE Transactions on Multimedia,"12 Dec 2023","2023","25","","8458","8470","For Deepfake detection, residual-based features can preserve tampering traces and suppress irrelevant image content. However, inappropriate residual prediction brings side effects on detection accuracy. Meanwhile, residual-domain features are easily affected by some image operations such as lossy compression. Most existing works exploit either spatial-domain or residual-domain features, which are fed into the backbone network for feature learning. Actually, both types of features are mutually correlated. In this work, we propose an adaptive fusion based guided residuals network (AdapGRnet), which fuses spatial-domain and residual-domain features in a mutually reinforcing way, for Deepfake detection. Specifically, we present a fine-grained manipulation trace extractor (MTE), which is a key module of AdapGRnet. Compared with the prediction-based residuals, MTE can avoid the potential bias caused by inappropriate prediction. Moreover, an attention fusion mechanism (AFM) is designed to selectively emphasize feature channel maps and adaptively allocate the weights for two streams. Experimental results show that AdapGRnet achieves better detection accuracies than the state-of-the-art works on four public fake face datasets including HFF, FaceForensics++, DFDC and CelebDF. Especially, AdapGRnet achieves an accuracy up to 96.52% on the HFF-JP60 dataset, which improves about 5.50%. That is, AdapGRnet achieves better robustness than the existing works.","1941-0077","","10.1109/TMM.2023.3237169","National Natural Science Foundation of China(grant numbers:61972143,61972142); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10017352","Deepfake detection;image forensics;guided residuals;attention fusion mechanism","Faces;Feature extraction;Deepfakes;Forgery;Robustness;Image forensics;Biology","","24","","65","IEEE","18 Jan 2023","2023","","IEEE","IEEE Journals"
"DomainForensics: Exposing Face Forgery Across Domains via Bi-Directional Adaptation","Q. Lv; Y. Li; J. Dong; S. Chen; H. Yu; H. Zhou; S. Zhang","College of Computer Science and Technology, Ocean University of China, Qingdao, China; College of Computer Science and Technology, Ocean University of China, Qingdao, China; College of Computer Science and Technology, Ocean University of China, Qingdao, China; College of Computer Science and Technology, Ocean University of China, Qingdao, China; School of Creative Technologies, Faculty of Creative and Cultural Industries, University of Portsmouth, Portsmouth, U.K.; School of Computing and Mathematic Sciences, University of Leicester, Leicester, U.K.; College of Computer Science and Technology, Ocean University of China, Qingdao, China",IEEE Transactions on Information Forensics and Security,"2 Aug 2024","2024","19","","7275","7289","Recent DeepFake detection methods have shown excellent performance on public datasets but are significantly degraded on new forgeries. Solving this problem is important, as new forgeries emerge daily with the continuously evolving generative techniques. Many efforts have been made for this issue by seeking the commonly existing traces empirically on data level. In this paper, we rethink this problem and propose a new solution from the unsupervised domain adaptation perspective. Our solution, called DomainForensics, aims to transfer the forgery knowledge from known forgeries (fully labeled source domain) to new forgeries (label-free target domain). Unlike recent efforts, our solution does not focus on data view but on learning strategies of DeepFake detectors to capture the knowledge of new forgeries through the alignment of domain discrepancies. In particular, unlike the general domain adaptation methods which consider the knowledge transfer in the semantic class category, thus having limited application, our approach captures the subtle forgery traces. We describe a new bi-directional adaptation strategy dedicated to capturing the forgery knowledge across domains. Specifically, our strategy considers both forward and backward adaptation, to transfer the forgery knowledge from the source domain to the target domain in forward adaptation and then reverse the adaptation from the target domain to the source domain in backward adaptation. In forward adaptation, we perform supervised training for the DeepFake detector in the source domain and jointly employ adversarial feature adaptation to transfer the ability to detect manipulated faces from known forgeries to new forgeries. In backward adaptation, we further improve the knowledge transfer by coupling adversarial adaptation with self-distillation on new forgeries. This enables the detector to expose new forgery features from unlabeled data and avoid forgetting the known knowledge of known forgery. Extensive experiments demonstrate that our method is surprisingly effective in exposing new forgeries, and can be plug-and-play on other DeepFake detection architectures.","1556-6021","","10.1109/TIFS.2024.3426317","National Key Research and Development Program of China(grant numbers:2022ZD0117201); Sanya Science and Technology Special Fund(grant numbers:2022KJCX92); China Postdoctoral Science Foundation(grant numbers:2021TQ0314,2021M703036); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10601589","Digital forensics;DeepFake detection;DomainForensics","Forgery;Deepfakes;Detectors;Feature extraction;Faces;Training;Bidirectional control","","4","","77","IEEE","18 Jul 2024","2024","","IEEE","IEEE Journals"
"Frequency-Assisted Temporal Upsampling Artifacts Representation Learning for Face Forgery Detection","R. Sun; X. Yu; F. Wang; Z. Da; Y. Zhang; J. Gao","Key Laboratory of Knowledge Engineering with Big Data, Ministry of Education, School of Computer and Information, Anhui Province Key Laboratory of Industry Safety and Emergency Technology, Hefei University of Technology, Hefei, China; Key Laboratory of Knowledge Engineering with Big Data, Ministry of Education, School of Computer and Information, Anhui Province Key Laboratory of Industry Safety and Emergency Technology, Hefei University of Technology, Hefei, China; Key Laboratory of Knowledge Engineering with Big Data, Ministry of Education, School of Computer and Information, Anhui Province Key Laboratory of Industry Safety and Emergency Technology, Hefei University of Technology, Hefei, China; Key Laboratory of Knowledge Engineering with Big Data, Ministry of Education, School of Computer and Information, Anhui Province Key Laboratory of Industry Safety and Emergency Technology, Hefei University of Technology, Hefei, China; Key Laboratory of Knowledge Engineering with Big Data, Ministry of Education, School of Computer and Information, Anhui Province Key Laboratory of Industry Safety and Emergency Technology, Hefei University of Technology, Hefei, China; Key Laboratory of Knowledge Engineering with Big Data, Ministry of Education, School of Computer and Information, Anhui Province Key Laboratory of Industry Safety and Emergency Technology, Hefei University of Technology, Hefei, China","IEEE Transactions on Biometrics, Behavior, and Identity Science","25 Sep 2025","2025","7","4","728","739","Recently, the highly realistic deepfake images have aroused the potential for deepfake abuse, and both the detection and its generalization remain challenging. Existing deepfake video detection methods strive to capture distinguishing features between fake and real faces through temporal modeling. However, these works provide local supervision between sampled video frames, but overlook intra-frame generative artifacts, which can function as an useful indicators for detection. To mitigate the issue, we propose a temporal-frequential convolutional network based on the representation of upsampling artifacts, which can automatically capture incoherent artifacts representation in different ends. Specifically, we design the Upsampling Artifacts Representation Module (UARM), which captures upsampling artifacts introduced in generation end based on the relationship between pixels, and then we probe the deep coupling of intra-frame global frequency information with inter-frame incoherence, and design the Frequency-Assisted Temporal Incoherence Module (FATIM), which can facilitate the detection of temporal information in RGB domain by frequency domain information, and the Self-tuned Convolutions Module (SCM) is designed to supplement information and adjust it automatically in the learning process. In addition, the Information Fusion Module (IFM) is designed to couple multiple information and establish a more comprehensive representation. With the above modules, our proposed method can learn robust features in both generation end and detection end. Extensive experiments demonstrate that our method outperforms other state-of-the-art video detection methods by a large margin on the challenging DFDC and FF++ in low-quality.","2637-6407","","10.1109/TBIOM.2025.3569645","China Postdoctoral Science Foundation(grant numbers:2022M720981); National Natural Science Foundation of China Youth Foud(grant numbers:62302142); National Natural Science Foundation of China(grant numbers:61876057); Anhui Province Natural Science Foundation(grant numbers:2208085MF158); Key Research Plan of Anhui Province - Strengthening Police with Science and Technology(grant numbers:202004d07020012); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11003101","DeepFake detection;upsampling artifacts;multiple end;temporal-frequential convolution","Faces;Deepfakes;Frequency-domain analysis;Forgery;Feature extraction;Data mining;Kernel","","","","55","IEEE","13 May 2025","Oct. 2025","","IEEE","IEEE Journals"
"Deepfake Face Extraction and Detection Using MTCNN-Vision Transformers","R. Singh; K. Ashwini; B. Chandu Priya; K. Pavan Kumar","dept electronics and communication, vardhaman college of engineering, Hyderabad, India; dept electronics and communication, vardhaman college of engineering, Hyderabad, India; dept electronics and communication, vardhaman college of engineering, Hyderabad, India; dept electronics and communication, vardhaman college of engineering, Hyderabad, India",2024 Third International Conference on Distributed Computing and Electrical Circuits and Electronics (ICDCECE),"12 Jun 2024","2024","","","01","08","Deepfake detection is a major problem nowadays. The deepfake detection can be done using face extraction and detection. Strong solutions for face extraction and detection are required in light of the growing prevalence of deepfake technology. This paper combines Vision Transformers with Multi-Task Cascaded Convolutional Networks (MTCNN) to propose a novel method. This approach leverages the real-time face identification skills of MTCNN and the long-range dependency capture ability of Vision Transformers to improve the accuracy of detecting manipulated faces in deepfake footage. We carry out extensive experiments on several deepfake datasets, demonstrating the efficacy of the suggested hybrid strategy. The proposed model findings show that this approach performs better than conventional face identification techniques, particularly when dealing with situations where minor facial alterations are involved. This integration strikes a good compromise between computing efficiency and precision, which makes it a viable option for practical uses. The proposed MT-VIT (Multi-Task Vision Transformer) model provides good accuracy as compared to other state-of-the-art like Residual Networks, Mobile Net, CNN, and Meso-Net.","","979-8-3503-1860-9","10.1109/ICDCECE60827.2024.10549578","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549578","multitask cascaded convolutional neural network (MTCNN);vision transformer (VIT);deepfake detection","Deepfakes;Computer vision;Computational modeling;Computer architecture;Transformers;Multitasking;Convolutional neural networks","","3","","25","IEEE","12 Jun 2024","26-27 April 2024","26-27 April 2024","IEEE","IEEE Conferences"
"The Deepfake Dilemma: Enhancing Deepfake Detection with Vision Transformers","D. Sumathi; A. Singh; A. Sinha; D. Aditya; M. R. K. F","Department of Computer Science and Engineering, Alliance University, Bangalore, India; Department of Information Technology, Alliance University, Bangalore, India; Department of Information Technology, Alliance University, Bangalore, India; Department of Computer Science and Engineering, Alliance University, Bangalore, India; Department of Computer Science and Engineering, Alliance University, Bangalore, India","2025 International Conference on Intelligent and Innovative Technologies in Computing, Electrical and Electronics (IITCEE)","14 Mar 2025","2025","","","1","7","The emergence of deepfake videos at an alarming pace has compromised the integrity of digital multimedia and mandates progressive research into detection strategies. A new forensic method for subjecting face tampering detection in videos using the FaceForensics++ dataset is introduced in this work. A Convolutional Neural Network (CNN) based architecture is enhanced with Vision Transformer encoders for identifying facial manipulations introduced at microscopic precision. The hybrid model integrates CNNs and ViTs, allowing for the capturing of both local and global features that help in detecting subtle manipulations. ViTs have a built-in self-attention mechanism, which allows the model to concentrate on essential facial characteristics, thereby enhancing precision even if the manipulations are confirmed in less than optimal situations. Additionally, the pre-trained Gemini 1.5 Pro model is fine-tuned for optimal performance. The classification of faces into authentic or fake is accurately done using the key points by 90%accuracy as shown through experimentation. Moreover, the Haar cascade method is used for human face detection technique as part of integrated design which augments its complete application in real-world functionalities.","","979-8-3315-1591-1","10.1109/IITCEE64140.2025.10915365","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10915365","CNN;Vision Transformer;Haar cascade Face Forensics++;Data augmentation;Deepfake Detection","Deepfakes;Microscopy;Streaming media;Predictive models;Media;Integrated design;Transformers;Skin;Convolutional neural networks;Faces","","","","20","IEEE","14 Mar 2025","16-17 Jan. 2025","16-17 Jan. 2025","IEEE","IEEE Conferences"
"DeepFake Face Detection using Machine Learning with LSTM","T. Vignesh; P. H. Tarun; R. Parthav; V. Bhargavi","IT Department, B V Raju Institute of Technology, Narsapur, India; IT Department, B V Raju Institute of Technology, Narsapur, India; IT Department, B V Raju Institute of Technology, Narsapur, India; IT Department, B V Raju Institute of Technology, Narsapur, India",2024 10th International Conference on Communication and Signal Processing (ICCSP),"6 Jun 2024","2024","","","1633","1638","Fake face images that are increasingly convincing and realistic can be created because to the development of face image manipulation (FIM) technologies like Face to Face and Deepfake, which can damage the legitimacy and trustworthiness of online content. Malicious uses of these technology include blackmailing people, posing as celebrities, and disseminating false information. As a result, creating trustworthy and strong techniques to identify FIM and safeguard the integrity of digital media is essential. Numerous current techniques utilize on models built on convolutional neural networks (CNNs), which are capable of detecting FIM by examining a face’s visual characteristics. But because these models are frequently tested and trained on certain datasets or circumstances. Furthermore, they might not be able to record the temporal information that is included in video data and can be used to identify irregularities or strange anomalies in FIM videos. We provide a novel method that uses both geographical and temporal information to detect FIM in order to get over these difficulties. We present a new type of residual network called CRNet, which is dependent on Convolutional Long Short-Term Memory (LSTM) and is capable of processing a series of consecutive pictures taken from a movie. The model can learn temporal information because to its design, which is essential for spotting oddities that occur in between frames of FIM movies. We performed extensive tests with several kinds of FIM videos from the Kaggle dataset.","2836-1873","979-8-3503-5306-8","10.1109/ICCSP60870.2024.10544299","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10544299","Deepfake detection;Long-Short Term Memory (LSTM);Kaggle;Residual next convolution neural network (Xception CNN);Image manipulation","Deepfakes;Visualization;Convolution;Transfer learning;Neural networks;Motion pictures;Data models","","1","","13","IEEE","6 Jun 2024","12-14 April 2024","12-14 April 2024","IEEE","IEEE Conferences"
"Exposing Deep Fakes Using Inconsistent Head Poses","X. Yang; Y. Li; S. Lyu","University at Albany, State University of New York, USA; University at Albany, State University of New York, USA; University at Albany, State University of New York, USA","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","8261","8265","In this paper, we propose a new method to expose AI-generated fake face images or videos (commonly known as the Deep Fakes). Our method is based on the observations that Deep Fakes are created by splicing synthesized face region into the original image, and in doing so, introducing errors that can be revealed when 3D head poses are estimated from the face images. We perform experiments to demonstrate this phenomenon and further develop a classification method based on this cue. Using features based on this cue, an SVM classifier is evaluated using a set of real face images and Deep Fakes.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8683164","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8683164","Media Forensics;DeepFake Detection;Head Pose Estimation","Face;Videos;Support vector machines;Three-dimensional displays;Cameras;Neural networks","","730","","18","IEEE","17 Apr 2019","12-17 May 2019","12-17 May 2019","IEEE","IEEE Conferences"
"MIFAE-Forensics: Masked Image-Frequency AutoEncoder for DeepFake Detection","H. Wang; Z. Liu; S. Wang","School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University","ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","7 Mar 2025","2025","","","1","5","With continuously evolving generative models and increasingly diverse face forgery products, there is a growing demand for DeepFake detectors with stronger generalization ability and robustness. Previous works mainly capture method-specific forgery artifacts in the training set, thus failing to generalize well to unseen manipulations. In this paper, our key insight is that exploring common characteristics of natural faces is more ideal to alleviate overfitting rather than relying on specific forgery clues, as all sorts of manipulated images have intrinsic distributional differences from those captured by cameras. Hence, we propose a two-stage method, termed MIFAE-Forensics. Specifically, it reconstructs both facial semantics and local details from masked facial regions and high-frequency components, respectively, aiming to capture natural facial consistency in spatial domain and high-frequency details in frequency domain simultaneously. This facilitates the learning of a robust and transferable facial representation specialized for DeepFake detection. Subsequently, the pre-trained model is further fine-tuned to perform binary forgery classification along with reconstructing real faces in spatial domain, which ensures that the detector can maintain the ability to model real faces and encourages it to make decisions based on reconstruction discrepancies. Extensive experiments show superior results over state-of-the-arts on a wide range of DeepFake detection benchmarks. Our code is available at https://github.com/Mark-Dou/Forensics.","2379-190X","979-8-3503-6874-1","10.1109/ICASSP49660.2025.10889125","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10889125","Masked Image Modeling;DeepFake Detection","Training;Deepfakes;Face recognition;Semantics;Detectors;Benchmark testing;Forgery;Speech processing;Image reconstruction;Overfitting","","1","","35","IEEE","7 Mar 2025","6-11 April 2025","6-11 April 2025","IEEE","IEEE Conferences"
"Deepfake Detection: Demodulate Synthetic Videos Using Deep Learning Models","P. Hirpara; H. Valangar; V. Kachhadiya; U. Chauhan","Department of Computer Engineering, Vishwakarma Government Engineering College, Gujarat, India; Department of Computer Engineering, Vishwakarma Government Engineering College, Gujarat, India; Department of Computer Engineering, Vishwakarma Government Engineering College, Gujarat, India; Department of Computer Engineering, Vishwakarma Government Engineering College, Gujarat, India",2025 12th International Conference on Computing for Sustainable Global Development (INDIACom),"21 Aug 2025","2025","","","01","06","A deepfake detection system that uses machine learning (ML) and deep learning (DL) models to detect manipulated videos and images is presented in the study. Being aware of such synthetic content is crucial considering the emergence of deepfake technology, which might alter photos, videos, and audio for malevolent objectives including fraud, extortion, and disinformation. Deepfake technology has been applied to solve various real-time problems but is also exploited for unethical and illegal purposes. As a result, developing research and detection models is crucial to prevent its misuse. We proposed a CNN-LSTM hybrid model for analysis of cropped images to improve the performance of fake video detection. The suggested method focuses on identifying fake videos using the Celeb-DF dataset, which consists of 1203 videos (795 fake, 408 real). Moreover, the benefits and drawbacks of the various deepfake detection techniques are examined. The paper indicates potential improvements in model accuracy through more datasets and improved architectures, and it emphasizes the significance of sophisticated detection techniques to mitigate the negative consequences of deepfakes. With cropped video frames and deep learning techniques, the model's accuracy increased from 79.06% with the original dataset to $\mathbf{8 6. 8 2 \%}$ with cropped videos.","","978-93-80544-60-1","10.23919/INDIACom66777.2025.11115707","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11115707","Deepfake Detection;Deep Learning;Artificial Intelligence;Face Manipulation;CNN-LSTM","Deep learning;Deepfakes;Analytical models;Accuracy;Computational modeling;Computer architecture;Real-time systems;Fraud;Faces","","","","32","","21 Aug 2025","2-4 April 2025","2-4 April 2025","IEEE","IEEE Conferences"
"Exploring Bi-Level Inconsistency via Blended Images for Generalizable Face Forgery Detection","P. Jiang; H. Xie; L. Yu; G. Jin; Y. Zhang","School of Information Science and Technology, University of Science and Technology of China, Hefei, China; School of Information Science and Technology, University of Science and Technology of China, Hefei, China; School of Information Science and Technology, University of Science and Technology of China, Hefei, China; State Key Laboratory of Communication Content Cognition, People’s Daily Online, Beijing, China; School of Information Science and Technology, University of Science and Technology of China, Hefei, China",IEEE Transactions on Information Forensics and Security,"4 Jul 2024","2024","19","","6573","6588","The challenge of generalization in face forgery detection has become increasingly prominent as manipulation techniques continue to evolve. Although recent image blending-based methods have demonstrated remarkable potential, they often encounter a significant performance drop when applied to datasets exhibiting significant domain gaps. This limitation stems from the exclusive reliance of prior methods on blending unaltered faces with various augmentations to produce common artifacts, which ignores the inherent characteristics of the forged regions. To fully exploit the potential of image blending-based methods for generalizable Deepfake detection, we propose a novel image synthesis framework called Bi-Level Inconsistency Generator (Bi-LIG) to introduce bi-level inconsistency in the synthesized images. Specifically, Bi-LIG generates synthetic images by blending source and target images from both pristine and forged image sets, introducing a) Extrinsic-Inconsistency between real and pseudo-forged regions, and b) Inherent-Inconsistency between real and manipulated areas. In this way, Bi-LIG creates a diverse synthesized image set and establishes a generalizable training domain. Furthermore, we propose a novel face forgery detection network named Token Consistency Constrained Vision Transformer, in which two modules are developed based on patch consistency learning. Firstly, a Patch Token Contrast module is employed to learn the bi-level patch inconsistencies. Secondly, a Progressive Patch Token Assemble module is adopted to aggregate local patch relations and enhance the inconsistency representations. Experimental results demonstrate the effectiveness and superiority of our method on both in-dataset and cross-dataset evaluations. Notably, our approach outperforms state-of-the-art methods by 5.09% and 10.15% on cross-dataset evaluations in DFDCp and DFDC, respectively.","1556-6021","","10.1109/TIFS.2024.3417266","National Natural Science Foundation of China(grant numbers:U23B2028,62121002,62232006,62102127); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10565921","Deepfake detection;consistency learning;vision transformer","Forgery;Faces;Transformers;Training data;Training;Deepfakes;Generators","","5","","67","IEEE","20 Jun 2024","2024","","IEEE","IEEE Journals"
"2D-Malafide: Adversarial Attacks Against Face Deepfake Detection Systems","C. Galdi; M. Panariello; M. Todisco; N. Evans","Digital Security Dep, EURECOM Sophia Antipolis, France; Digital Security Dep, EURECOM Sophia Antipolis, France; Digital Security Dep, EURECOM Sophia Antipolis, France; Digital Security Dep, EURECOM Sophia Antipolis, France",2024 International Conference of the Biometrics Special Interest Group (BIOSIG),"11 Dec 2024","2024","","","1","7","We introduce 2D-Malafide, a novel and lightweight adversarial attack designed to deceive face deepfake detection systems. Building upon the concept of 1D convolutional perturbations explored in the speech domain, our method leverages 2D convolutional filters to craft perturbations which significantly degrade the performance of state-of-the-art face deepfake detectors. Unlike traditional additive noise approaches, 2D-Malafide optimises a small number of filter coefficients to generate robust adversarial perturbations which are transferable across different face images. Experiments, conducted using the FaceForensics++ dataset, demonstrate that 2D-Malafide substantially degrades detection performance in both white-box and black-box settings, with larger filter sizes having the greatest impact. Additionally, we report an explainability analysis using GradCAM which illustrates how 2D-Malafide misleads detection systems by altering the image areas used most for classification. Our findings highlight the vulnerability of current deepfake detection systems to convolutional adversarial attacks as well as the need for future work to enhance detection robustness through improved image fidelity constraints.","1617-5468","979-8-3503-7371-4","10.1109/BIOSIG61931.2024.10786754","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10786754","deepfake detection;adversarial attacks;lightweight adversarial attacks;convolutional filters;image perturbations","Training;Deepfakes;Filters;Image color analysis;Face recognition;Perturbation methods;Closed box;Detectors;Robustness;Glass box","","1","","26","IEEE","11 Dec 2024","25-27 Sept. 2024","25-27 Sept. 2024","IEEE","IEEE Conferences"
"Learning Face Forgery Detection in Unseen Domain with Generalization Deepfake Detector","V. Tran; S. Lee; H. Le; B. Kim; K. Kwon","Dept. of Artificial Intelligence Convergence, Pukyong National University, Busan, Korea; Dept. of Computer Engineering, Dong-A University, Busan, Korea; Faculty of Information Systems, University of Economics and Law Vietnam Vietnam National University Ho Chi Minh city, Ho Chi Minh, Vietnam; SZM Co. Ltd, Busan, Korea; Dept. of Artificial Intelligence Convergence, Pukyong National University, Busan, Korea",2023 IEEE International Conference on Consumer Electronics (ICCE),"17 Feb 2023","2023","","","01","06","Face forgery generation algorithms have advanced rapidly, resulting in a diverse range of manipulated videos and images which are difficult to identify. As a result, face manipulation using deepfake technique has a significantly increased societal anxiety and posed serious security problems. Recently, a variety of deep fake detection techniques have been presented. Convolutional neural networks (CNN) architecture are used for most of the deepfake detection models as binary classification problems. These methods usually achieve very good accuracy for specific dataset. However, when evaluated across datasets, the performance of these approaches drastically declines. In this paper, we propose a face forgery detection method to increase the generalization of the model, named Generalization Deepfake Detector (GDD). The Generalization Deepfake Detector model has ability to instantly solve new unseen domains without the requirement for model updates.","2158-4001","978-1-6654-9130-3","10.1109/ICCE56470.2023.10043436","National Research Foundation of Korea (NRF); Ministry of Education(grant numbers:2020R111A306659411,2020R1F1A1069124); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10043436","Deepfake detection;meta learning;machine learning;deepfake dataset","Deepfakes;Anxiety disorders;Detectors;Benchmark testing;Forgery;Convolutional neural networks;Security","","3","","28","IEEE","17 Feb 2023","6-8 Jan. 2023","6-8 Jan. 2023","IEEE","IEEE Conferences"
"SDHF: Spotting DeepFakes with Hierarchical Features","T. Liang; P. Chen; G. Zhou; H. Gao; J. Liu; Z. Li; J. Dai","School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China",2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI),"24 Dec 2020","2020","","","675","680","DeepFake videos are widely distributed on social media platforms, which has seriously affected the authenticity of digital media content, calling for robust DeepFake detection methods. Although numerous detection methods are formulated as frame-based binary classification, less attention has been paid to aggregate the features over individual frames to get a video-based judgement. We observed that for the detection of DeepFake videos, three different level forgery features from frame, clip and video can complement each other. We also found that discrete, large interval sampling strategy is more suitable for DeepFake detection, which can sample more complex video scenes, including multiple subjects, diverse facial expressions and head poses. In this work, we propose a hierarchical framework, using 2D convolutional neural networks for frame-level features extraction followed by a 1D convolutional aggregator to extract clip-level and video-level features, which can comprehensively exploit three different levels of features to make decisions. Evaluation was performed on four datasets, including DFDC, Celeb-DF, FaceForensics++ and UADFV, which provides competitive results compared to other methods. Experimental results of cross-test demonstrate that our hierarchical framework has excellent generalization performance in the face of unknown datasets.","2375-0197","978-1-7281-9228-4","10.1109/ICTAI50040.2020.00108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288325","DeepFake detection;Hierarchical features","Two dimensional displays;Tools;Feature extraction;Convolutional neural networks;Faces;Videos;Information integrity","","8","","39","IEEE","24 Dec 2020","9-11 Nov. 2020","9-11 Nov. 2020","IEEE","IEEE Conferences"
"Exploring Generalization Capability for Video Forgery and Detection based on Generative Adversarial Network","Y. Lin; Y. Qu; Y. Li; Z. Nie","School of Software, Yunnan University, Kunming, China; School of Computer Science, Colorado Technical Univ., Colorado Springs, USA; School of Software, Zhengzhou University, Zhengzhou, China; School of Software, Yunnan University, Kunming, China",2020 International Conference on Computational Science and Computational Intelligence (CSCI),"23 Jun 2021","2020","","","1575","1580","With the development of digital image processing technology based on deep learning, the potential risk of using related technologies to threaten the security of multimedia information is increasing. Because the generated human face effect largely depends on the completeness of the input sample set, most of the current deep forgery models have the problem of human side-face collapse. This paper has studied the deep forgery technology of Deepfacelab and Faceswap, and adjusts the original auto-encoder-based model architecture to a generative adversarial network. By using the harmonic mean of cross entropy and mean square error as the loss function, the improved model can reduce the probability of some frames being discarded during training. Meanwhile, by adjusting key characteristics and the weights of features in different frames, it further optimizes the cross-dataset detection performance. Experimental results have shown that the improved model can keep more facial details while still maintain high human face clarity. The detection performance is improved and the cross-dataset average error rate of the deep detection model is about 35%.","","978-1-7281-7624-6","10.1109/CSCI51800.2020.00291","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9458220","Deepfake;Deepfake Detection;Generative Adversarial Network;Face Swap;Detection Generalization","Training;Computational modeling;Mean square error methods;Harmonic analysis;Generative adversarial networks;Feature extraction;Forgery","","2","","17","IEEE","23 Jun 2021","16-18 Dec. 2020","16-18 Dec. 2020","IEEE","IEEE Conferences"
"A Dual-Branch CNN for Robust Detection of AI-Generated Facial Forgeries","X. Zhang; Y. Song; F. Zuo","Computer Science Department, University of Southern Maine, Portland, United States; Computer Science Department, University of Southern Maine, Portland, United States; The Department of Computer Science, University of Central Oklahoma, Edmond, United States",2025 IEEE 12th International Conference on Cyber Security and Cloud Computing (CSCloud),"2 Dec 2025","2025","","","1","6","The rapid advancement of generative AI has enabled the creation of highly realistic forged facial images, posing significant threats to AI security, digital media integrity, and public trust. Face forgery techniques-ranging from face swapping and attribute editing to powerful diffusion-based image synthesis-are increasingly being used for malicious purposes such as misinformation, identity fraud, and defamation. This growing challenge underscores the urgent need for robust and generalizable face forgery detection methods as a critical component of AI security infrastructure. In this work, we propose a novel dual-branch convolutional neural network for face forgery detection that leverages complementary cues from both spatial and frequency domains. The RGB branch captures semantic information, while the frequency branch focuses on high-frequency artifacts that are difficult for generative models to suppress. A channel attention module is introduced to adaptively fuse these heterogeneous features, highlighting the most informative channels for forgery discrimination. To guide the network's learning process, we design a unified loss function-FSC Loss-that combines focal loss, supervised contrastive loss, and a frequency center margin loss to enhance class separability and robustness. We evaluate our model on the DiFF benchmark, which includes forged images generated from four representative methods: text-to-image, image-to-image, face swap, and face edit. Our method achieves strong performance across all categories and outperforms average human accuracy. These results demonstrate the model's effectiveness and its potential contribution to safeguarding AI ecosystems against visual forgery attacks.","2693-8928","979-8-3315-8781-9","10.1109/CSCloud66326.2025.00023","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11261496","AI Security;Multimedia Forensics;Computer Vision;Face Forgery Detection;Deepfake Detection","Visualization;Adaptation models;Biological system modeling;Semantics;Text to image;Forgery;Robustness;Security;Convolutional neural networks;Faces","","","","30","IEEE","2 Dec 2025","7-9 Nov. 2025","7-9 Nov. 2025","IEEE","IEEE Conferences"
"RLGC: Reconstruction Learning Fusing Gradient and Content Features for Efficient Deepfake Detection","K. Xu; X. Hu; X. Zhou; X. Xu; L. Qi; C. Chen","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; Faculty of Business Data Science, Kansai University, Osaka, Japan; School of Computer and Software, Nanjing University of Information Science and Technology, Nanjing, China; College of Computer Science and Technology, China University of Petroleum (East China), Qingdao, China; State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China",IEEE Transactions on Consumer Electronics,"13 Dec 2024","2024","70","3","6084","6094","Current deepfake detection methods, which utilize noise features, localized textures, or frequency statistics, may perform well in special domains or forgery methods. But the generalization performance of these methods is often unsatisfactory because of the ignorance of mining intrinsic facial features. To address this problem, we re-evaluated the fusion of image gradient features in neural networks and delved deeper into the intrinsic structure of input images. Consequently, we propose a reconstruction-classification network that initially learns face content and gradient separately from a reconstruction perspective and then detects forged faces by fusing them together. This paper introduces three well-designed components: 1) a dual-branch feature extraction module to excite distributional inconsistencies between real and forged faces; 2) a content-gradient feature fusion module to investigate the relationship between face content and image gradient; 3) a reconstruction disparity based Bi-Directional attention module that guides the model in efficiently categorizing the fused features. Extensive experiments on large-scale benchmark datasets demonstrate that our method significantly enhances performance, especially for generalization ability, compared to state-of-the-art methods.","1558-4127","","10.1109/TCE.2024.3435032","National Natural Science Foundation of China(grant numbers:62172227); National Key Research and Development Program(grant numbers:2021YFF0602101); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10612835","Deepfake detection;deep generative model;multi-scale feature fusion;reconstruction learning","Image reconstruction;Feature extraction;Forgery;Faces;Face recognition;Deepfakes;Generative adversarial networks","","11","","58","IEEE","29 Jul 2024","Aug. 2024","","IEEE","IEEE Journals"
"MINTIME: Multi-Identity Size-Invariant Video Deepfake Detection","D. A. Coccomini; G. K. Zilos; G. Amato; R. Caldelli; F. Falchi; S. Papadopoulos; C. Gennaro","ISTI-CNR, Pisa, Italy; Faculty of Electrical Engineering, Czech Technical University in Prague, Prague, Czech Republic; ISTI-CNR, Pisa, Italy; CNIT, Florence, Italy; ISTI-CNR, Pisa, Italy; ITI-CERTH, Thessaloniki, Greece; ISTI-CNR, Pisa, Italy",IEEE Transactions on Information Forensics and Security,"20 Jun 2024","2024","19","","6084","6096","In this paper, we present MINTIME, a video deepfake detection method that effectively captures spatial and temporal inconsistencies in videos that depict multiple individuals and varying face sizes. Unlike previous approaches that either employ simplistic a-posteriori aggregation schemes, i.e., averaging or max operations, or only focus on the largest face in the video, our proposed method learns to accurately detect spatio-temporal inconsistencies across multiple identities in a video through a Spatio-Temporal Transformer combined with a Convolutional Neural Network backbone. This is achieved through an Identity-aware Attention mechanism that applies a masking operation on the face sequence to process each identity independently, which enables effective video-level aggregation. Furthermore, our system incorporates two novel embedding schemes: (i) the Temporal Coherent Positional Embedding, which encodes the temporal information of the face sequences of each identity, and (ii) the Size Embedding, which captures the relative sizes of the faces to the video frames. MINTIME achieves state-of-the-art performance on the ForgeryNet dataset, with a remarkable improvement of up to 14% AUC in videos containing multiple people. Moreover, it demonstrates very robust generalization capabilities in cross-forgery and cross-dataset settings. The code is publicly available at: https://github.com/davide-coccomini/MINTIME-Multi-Identity-size-iNvariant-TIMEsformer-for-Video-Deepfake-Detection.","1556-6021","","10.1109/TIFS.2024.3409054","NextGeneration EU (EU-NGEU) through the Project SERICS under the National Recovery and Resilience Plan (NRRP) Ministry of University and Research [Ministero dell’Università e della Ricerca (MUR)] Program(grant numbers:PE00000014); EU–NGEU through Empowering Knowledge Extraction to Empower Learners (EKEEL)(grant numbers:P20227PEPK,ERC PE6_7); H2020 Project AI4Media(grant numbers:951911); Italian MUR (Research Projects of National Relevance [Progetti di Rilevante Interesse Nazionale (PRIN)] 2022) through the FOSTERER Project; Junior Star Czech Science Foundation (GACR)(grant numbers:GM 21-28830M); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10547206","Deepfake detection;computer vision;deep learning;vision transformers;convolutional neural networks","Deepfakes;Faces;Transformers;Vectors;Face recognition;Convolutional neural networks;Task analysis","","7","","74","CCBY","3 Jun 2024","2024","","IEEE","IEEE Journals"
"Deepfake Detection and Localization Using Multi-View Inconsistency Measurement","B. Zhang; Q. Yin; W. Lu; X. Luo","School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; School of Computer Science and Engineering, Ministry of Education Key Laboratory of Information Technology, Guangdong Province Key Laboratory of Information Security Technology, Sun Yat-sen University, Guangzhou, China; School of Computer Science and Engineering, Ministry of Education Key Laboratory of Information Technology, Guangdong Province Key Laboratory of Information Security Technology, Sun Yat-sen University, Guangzhou, China; State Key Laboratory of Mathematical Engineering and Advanced Computing, Zhengzhou, China",IEEE Transactions on Dependable and Secure Computing,"13 Mar 2025","2025","22","2","1796","1809","As deepfake technology advances, forgery detection techniques have evolved beyond simple classification to include fine-grained localization. However, existing deepfake localization methods struggle with with real-world deepfake videos, which are often multi-face scenarios with only some parts manipulated. To address the above-mentioned problems, we propose a Multi-View Inconsistency Measurement (MVIM) network that simultaneously measures inconsistencies from noise and temporal view to detect and locate tampered regions. Specifically, considering the noise inconsistencies in multi-face scenarios where fake faces have inconsistent noise patterns compared to real faces and backgrounds, we design a Noise Inconsistency Measurement (Noise-IM) module that measures noise similarity among faces and between faces and backgrounds using a masked attention mechanism to identify suspected tampered regions in noise domain. Since facial jitter of tampered regions in deepfake videos is observed to be more intense than that of real regions, we design a Temporal Inconsistency Measurement (Temporal-IM) module which adopts self-attention mechanism and fine-grained bi-direction convolutions to capture tampering traces between frames in temporal domain. Inconsistency features obtained by the two modules are fused for detecting and locating tampered regions. The superiority of our MVIM network is verified by extensive experiments with many state-of-the-art methods in different benchmark datasets.","1941-0018","","10.1109/TDSC.2024.3472064","National Natural Science Foundation of China(grant numbers:U2001202,62072480,U23A20305,62172435); Guangdong Provincial Key Laboratory of Information Security Technology(grant numbers:2023B1212060026); Communication University of China(grant numbers:SKLMCC2022KF003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10702428","Deepfake detection;face forgery localization;multi-face forensics;inconsistency measurement","Noise;Faces;Noise measurement;Deepfakes;Location awareness;Forgery;Feature extraction;Attention mechanisms;Forensics;Decoding","","7","","62","IEEE","1 Oct 2024","March-April 2025","","IEEE","IEEE Journals"
"Towards Generalizable DEEPFAKE Face Forgery Detection with Semi-Supervised Learning and Knowledge Distillation","Y. Lin; H. Chen; B. Li; J. Wu","Guangdong Key Lab of Intelligent Information Processing, Shenzhen Key Lab of Media Security, Shenzhen Institute of Articial Intelligence and Robotics for Society, Shenzhen University Shenzhen, China; Guangdong Key Lab of Intelligent Information Processing, Shenzhen Key Lab of Media Security, Shenzhen Institute of Articial Intelligence and Robotics for Society, Shenzhen University Shenzhen, China; Guangdong Key Lab of Intelligent Information Processing, Shenzhen Key Lab of Media Security, Shenzhen Institute of Articial Intelligence and Robotics for Society, Shenzhen University Shenzhen, China; Guangdong Key Lab of Intelligent Information Processing, Shenzhen Key Lab of Media Security, Shenzhen Institute of Articial Intelligence and Robotics for Society, Shenzhen University Shenzhen, China",2022 IEEE International Conference on Image Processing (ICIP),"18 Oct 2022","2022","","","576","580","Existing methods for deepfake face forgery detection have already achieved tremendous progress in well-controlled laboratory conditions. However, under wild scenarios where the training and testing forgeries are synthesized by different algorithms and when labeled data are insufficient, the performance always drops greatly. In this work, we present a Semi-supervised Contrastive Learning and Knowledge Distillation-based framework (SCL-KD) for deepfake detection to reduce the aforementioned performance gap. Our proposed framework contains three stages: self-supervised pre-training, supervised training, and knowledge distillation. Specifically, a feature encoder is firstly trained in a self-supervised manner with a large number of unlabeled samples through a momentum contrastive mechanism. Secondly, a fully-connected classifier on top of the feature encoder is trained in a supervised manner with a small amount of labeled samples to build a teacher model. Finally, a compact student model is trained with the help of the teacher model using knowledge distillation, in order to avoid overfitting to labeled data and have better generalizability on mismatched datasets. Evaluations on several benchmark datasets corroborate the good performance of our approach in cross-dataset situations and few labeled data scenarios. It reveals the potential of our proposed method for real-world deepfake detection.","2381-8549","978-1-6654-9620-9","10.1109/ICIP46576.2022.9897792","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9897792","Deepfake detection;self-supervised contrastive learning;knowledge distillation","Training;Deepfakes;Semisupervised learning;Benchmark testing;Feature extraction;Forgery;Data models","","6","","24","IEEE","18 Oct 2022","16-19 Oct. 2022","16-19 Oct. 2022","IEEE","IEEE Conferences"
"Using Graph Neural Networks to Improve Generalization Capability of the Models for Deepfake Detection","H. She; Y. Hu; B. Liu; J. Li; C. -T. Li","School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China; School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China; School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China; School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China; School of Information Technology, Deakin University, Geelong, VIC, Australia",IEEE Transactions on Information Forensics and Security,"23 Sep 2024","2024","19","","8414","8427","Deepfake detection plays a key role in preventing the misuses of artificial intelligence in video editing. Current deep learning-based deepfake detection methods often perform quite well in intra-dataset testing, but they may lose good performance in cross-dataset testing. In other words, generalization capability is still a crucial problem to be resolved. In this paper, we address deepfake detection by treating an image as non-Euclidean data and representing it as a graph so as to infer the informative connections between image patches/nodes to improve the detector’s generalization capability. Specifically, we propose a graph neural network-based paradigm that casts deepfake detection as a graph binary classification problem. First, we propose a dual-branch network to extract node features from both RGB images and their color difference images (CDIs) via the Transformer-based trainable node encoder module (TNEM). Second, we adopt the adjacency matrix to establish the connections of the nodes and further optimize the graph representation by applying the adaptive threshold to the adjacency matrix. Third, multi-head graph convolutional neural networks are carried out for node feature extraction. RGB node features and CDI node features are concatenated and separately fed into the graph classifier and node classifier for forgery detection and forgery localization. Experimental results demonstrate that our method can overall outperform other state-of-the-art methods on 7 popular benchmark datasets. Notably, our model achieves the highest AUC values of 96.19%, 80.99% and 87.68% on Celeb-DF-V2, DFDC and DFDCP in turn when trained on FF++ (C23). The visualization of node classification results also provides good interpretability of our proposed approach.","1556-6021","","10.1109/TIFS.2024.3451356","Science and Technology Foundation of Guangzhou Huangpu Development District(grant numbers:2022GH15); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10654318","Deepfake detection;graph neural network;generalization;transformer;color difference;graph classification","Deepfakes;Feature extraction;Faces;Forgery;Graph neural networks;Face recognition;Image edge detection","","10","","68","IEEE","28 Aug 2024","2024","","IEEE","IEEE Journals"
"EffiSwinNet: A Cross-Architecture Deepfake Detection with Style GAN Generated Faces","S. Basu; S. Sharma; A. Banerjee; P. Yanduri","Cybersecurity and Digital Identity, THALES, Noida, India; Amity Centre for Artificial Intelligence, Amity University, Noida, India; Department of Statistics, University of Kalyani, West Bengal, India; Computer Science and Engineering, Prasad V Potluri Siddhartha Institute of Technology, Vijayawada, Andhra Pradesh, India","2025 International Conference on Computing, Intelligence, and Application (CIACON)","9 Oct 2025","2025","","","1","7","The threat of deepfakes to our security has been present for a while. The development of Generative Adversarial Networks (GANs), a network that assists in creating new datasets from existing datasets based on specific traits and statistics, has made these digitally produced images unrecognizable to human sight. Malicious activities including identity theft and cyberbullying have been carried out using these deepfakes, which contributes to cybercrime. The goal of this study is to use Shifting Window Transformer to identify deepfake images produced by GANs. Contrary to vision transformers (ViT), this transformer uses a shifting window-based Transformer block that helps to integrate picture patches and simplify the transformer model. It can also do feature level extraction similar to CNN. Three methods were employed in this study to detect deepfake photos using Swin-Transformer: Base Swin-Transformer, Swin-Transformer utilizing Transfer Learning, and Hybrid-Swin Transformer. StyleGAN-based deepfake photos from a dataset of 140K genuine and fake faces were employed. With an accuracy of 99% and a cross-entropy loss of 0.25, the hybrid model of EfficientNetB0+SwinTransformer outperformed the other two tests.","","979-8-3315-4411-9","10.1109/CIACON65473.2025.11189359","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11189359","Deepfake detection;Vsion Transformers;EfficientNet;Swin-Transformer;StyleGAN","Training;Deepfakes;Accuracy;Transfer learning;Transformers;Generative adversarial networks;Feature extraction;Time factors;Faces;Testing","","","","26","IEEE","9 Oct 2025","18-19 July 2025","18-19 July 2025","IEEE","IEEE Conferences"
"Detection of Deepfake Videos Using Long-Distance Attention","W. Lu; L. Liu; B. Zhang; J. Luo; X. Zhao; Y. Zhou; J. Huang","School of Computer Science and Engineering, Guangdong Province Key Laboratory of Information Security Technology, Ministry of Education Key Laboratory of Machine Intelligence and Advanced Computing, Sun Yat-sen University, Guangzhou, China; School of Computer Science and Engineering, Guangdong Province Key Laboratory of Information Security Technology, Ministry of Education Key Laboratory of Machine Intelligence and Advanced Computing, Sun Yat-sen University, Guangzhou, China; School of Computer Science and Engineering, Guangdong Province Key Laboratory of Information Security Technology, Ministry of Education Key Laboratory of Machine Intelligence and Advanced Computing, Sun Yat-sen University, Guangzhou, China; School of Computer Science and Engineering, Guangdong Province Key Laboratory of Information Security Technology, Ministry of Education Key Laboratory of Machine Intelligence and Advanced Computing, Sun Yat-sen University, Guangzhou, China; State Key Laboratory of Information Security, Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Department of Computer and Information Science, University of Macau, Macau, China; Guangdong Key Laboratory of Intelligent Information Processing and Shenzhen Key Laboratory of Media Security, Shenzhen University, Shenzhen, China",IEEE Transactions on Neural Networks and Learning Systems,"8 Jul 2024","2024","35","7","9366","9379","With the rapid progress of deepfake techniques in recent years, facial video forgery can generate highly deceptive video content and bring severe security threats. And detection of such forgery videos is much more urgent and challenging. Most existing detection methods treat the problem as a vanilla binary classification problem. In this article, the problem is treated as a special fine-grained classification problem since the differences between fake and real faces are very subtle. It is observed that most existing face forgery methods left some common artifacts in the spatial domain and time domain, including generative defects in the spatial domain and interframe inconsistencies in the time domain. And a spatial-temporal model is proposed which has two components for capturing spatial and temporal forgery traces from a global perspective, respectively. The two components are designed using a novel long-distance attention mechanism. One component of the spatial domain is used to capture artifacts in a single frame, and the other component of the time domain is used to capture artifacts in consecutive frames. They generate attention maps in the form of patches. The attention method has a broader vision which contributes to better assembling global information and extracting local statistic information. Finally, the attention maps are used to guide the network to focus on pivotal parts of the face, just like other fine-grained classification methods. The experimental results on different public datasets demonstrate that the proposed method achieves state-of-the-art performance, and the proposed long-distance attention method can effectively capture pivotal parts for face forgery.","2162-2388","","10.1109/TNNLS.2022.3233063","National Natural Science Foundation of China(grant numbers:U2001202,62072480,U19B2022,U1636202); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10008209","Attention mechanism;deepfake detection;face manipulation;spatial and temporal artifacts","Deepfakes;Face detection;Forgery;Time-domain analysis;Transformers;Semantics;Attention mechanisms;Spatial temporal resolution","","36","","79","IEEE","6 Jan 2023","July 2024","","IEEE","IEEE Journals"
"Making DeepFakes More Spurious: Evading Deep Face Forgery Detection via Trace Removal Attack","C. Liu; H. Chen; T. Zhu; J. Zhang; W. Zhou","Centre for Cyber Security and Privacy and the School of Computer Science, University of Technology Sydney, Sydney, NSW, Australia; Centre for Cyber Security and Privacy and the School of Computer Science, University of Technology Sydney, Sydney, NSW, Australia; Centre for Cyber Security and Privacy and the School of Computer Science, University of Technology Sydney, Sydney, NSW, Australia; Cybersecurity Lab, Swinburne University of Technology, Melbourne, VIC, Australia; Institute of Data Science, City University of Macau, Macao SAR, China",IEEE Transactions on Dependable and Secure Computing,"10 Nov 2023","2023","20","6","5182","5196","DeepFakes are raising significant social concerns. Although various Despite various DeepFake detectors having been developed as countermeasures, their vulnerability under attacks remains further explorations. Recently, several attacks, such as adversarial attacks, have successfully fooled DeepFake detectors. However, existing attacks suffer from detector-specific designs, requiring detector-side knowledge, leading to poor transferability. Moreover, they only consider simplified security scenarios; but less is known about the attacking performance in complex scenarios where the capability of detectors or attackers varies. To fill the gap, we propose a novel, detector-agnostic trace removal attack. The attack removes all possible counterfeiting traces arising from the original DeepFake manufacture procedure to make DeepFakes essentially more ""realistic"" and thus able to defeat arbitrary or unknown detectors. Concretely, we first perform an in-depth DeepFake trace discovery, identifying three intrinsic traces: spatial anomalies, spectral disparities, and noise fingerprints. Then an adversarial learning-based trace removal network (TR-Net) involving one generator and multiple discriminators is proposed. Each discriminator is responsible for one individual trace representation to avoid inner-trace interference. All discriminators are optimized in parallel to enforce the generator to remove various traces simultaneously. We additionally craft heterogeneous security scenarios where the detectors are embedded with different levels of defense and the attackers own varying background data knowledge. The experimental results show that the proposed trace removal attack can significantly compromise the detection accuracy of six state-of-the-art DeepFake detectors while causing only a negligible degradation in visual quality.","1941-0018","","10.1109/TDSC.2023.3241604","ARC Discovery Project(grant numbers:DP200100946); Australian Research Council Australia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10035845","Adversarial attack;anti-forensics;deepfake detection;image forgery","Deepfakes;Detectors;Faces;Fingerprint recognition;Pipelines;Image reconstruction;Generators","","27","","59","IEEE","2 Feb 2023","Nov.-Dec. 2023","","IEEE","IEEE Journals"
"Deepfake Image Detection using Transfer Learning: A Comparative Analysis","M. Rai; K. P. Kour; A. Sharma; V. S. Mukhekar","Department of Computer Science and Engineering(AI&ML), Manipal University Jaipur, Jaipur, India; Department of Computer Science and Engineering(AI&ML), Manipal University Jaipur, Jaipur, India; Department of Computer Science and Engineering(AI&ML), Manipal University Jaipur, Jaipur, India; Department of Computer Science and Engineering(AI&ML), Manipal University Jaipur, Jaipur, India",2025 5th International Conference on Soft Computing for Security Applications (ICSCSA),"25 Sep 2025","2025","","","1380","1384","Rapid advancements in the field of generative adversarial network (GAN) technologies have made the detection of AI-generated facial imagery extremely crucial. In this paper, we investigate the efficacy of transfer learning in distinguishing between real and AI-generated fake facial images. We used a comprehensive data set comprising 70,000 real face images from the Flickr data set and 70,000 synthetic faces sampled from a large-scale StyleGAN-generated data set. The combined data set was preprocessed by resizing all images to 256 pixels and partitioning them into training, validation, and testing sets. We evaluated the performance of several pre-trained deep learning architectures, including a Custom Convolutional Neural Network (CNN), MesoNet, ResNet50, EfficientNetB0, and Xception, through fine-tuning on our curated dataset. The results we achieved in this experiment show the importance of the use of, we managed to achieve accuracy of 98. 57% while using the Xception model in successfully distinguishing between real and fake faces. This study highlights the effectiveness of using established convolutional architectures for robust deep-fake detection.","","979-8-3315-9491-6","10.1109/ICSCSA66339.2025.11171087","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11171087","Deepfake Detection;Transfer Learning;CNN;ResNet50;StyleGAN;XceptionNet;EfficientNet;MesoNet","Deepfakes;Visualization;Accuracy;Transfer learning;Computer architecture;Generative adversarial networks;Convolutional neural networks;Web sites;Faces;Residual neural networks","","","","11","IEEE","25 Sep 2025","4-6 Aug. 2025","4-6 Aug. 2025","IEEE","IEEE Conferences"
"DefakeHop: A Light-Weight High-Performance Deepfake Detector","H. -S. Chen; M. Rouhsedaghat; H. Ghani; S. Hu; S. You; C. . -C. Jay Kuo","University of Southern California, Los Angeles, California, USA; University of Southern California, Los Angeles, California, USA; University of Southern California, Los Angeles, California, USA; Army Research Laboratory, Adelphi, Maryland, USA; Army Research Laboratory, Adelphi, Maryland, USA; University of Southern California, Los Angeles, California, USA",2021 IEEE International Conference on Multimedia and Expo (ICME),"9 Jun 2021","2021","","","1","6","A light-weight high-performance Deepfake detection method, called DefakeHop, is proposed in this work. State-of-the-art Deepfake detection methods are built upon deep neural networks. DefakeHop uses the successive subspace learning (SSL) principle to extracts features automatically from various parts of face images. The features are extracted by channel-wise (c/w) Saab transform and further processed by our feature distillation module using spatial dimension re-duction and soft classification for each channel to get a more concise description of the face. Extensive experiments are conducted to demonstrate the effectiveness of the proposed DefakeHop method. With a small model size of 42,845 parameters, DefakeHop achieves state-of-the-art performance with the area under the ROC curve (AUC) of 100%, 94.95%, and 90.56% on UADFV, Celeb-DF v1, and Celeb-DF v2 datasets, respectively. Our codes are available on GitHub 1.","1945-788X","978-1-6654-3864-3","10.1109/ICME51207.2021.9428361","Army Research Laboratory; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9428361","Light-weight;Deepfake detection;Successive subspace learning (SSL)","Training;Neural networks;Transforms;Detectors;Streaming media;Feature extraction;Faces","","64","","20","IEEE","9 Jun 2021","5-9 July 2021","5-9 July 2021","IEEE","IEEE Conferences"
"Detection of Artificially Created Faces with Convolutional Networks","V. Balara; K. Machová","Department of Cybernetics and Artificial Intelligence, Technical University of Košice, Košice, Slovakia; Department of Cybernetics and Artificial Intelligence, Technical University of Košice, Košice, Slovakia",2024 International Conference on Emerging eLearning Technologies and Applications (ICETA),"28 Jan 2025","2024","","","1","6","The automatic detection of artificially generated content presents one of the most current topics in the field of artificial intelligence. It may help disguise deceitful users, spread misinformation or help in the dissemination of false accusations and therefore it is may prove vital in terms of teaching and improving the information literacy at schools,public institutions or general public. The automatic recognition of various forms of toxicity and artificially created faces in online space can help teachers to teach an information literacy and a critical thinking.This paper focuses on the detection of artificially generated faces depicted on still images with the utilization various types of convolutional neural networks.The paper presents an experiment aimed at multitude of methods which share the same convolutional basis. The focus is the creation of a efficient tool for image classification, which for our purposes was conducted with the use of ResNet, DenseNet and VGG architectures.","","979-8-3315-2771-6","10.1109/ICETA63795.2024.10850853","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10850853","convolutional neural networks;deepfake detection;deep learning","Image recognition;Toxicology;Social networking (online);Computational modeling;Large language models;Computer architecture;Convolutional neural networks;Security;Faces;Image classification","","","","13","IEEE","28 Jan 2025","24-25 Oct. 2024","24-25 Oct. 2024","IEEE","IEEE Conferences"
"Detecting Sequential Deepfake Manipulation via Spectral Transformer With Pyramid Attention in Consumer IoT","G. Zhang; Q. Li; M. Gao; S. Guo; G. Jeon","School of Electrical and Electronic Engineering, Shandong University of Technology, Zibo, China; School of Electronic Engineering and Computer Science, Queen Mary University of London, London, U.K.; School of Electrical and Electronic Engineering, Shandong University of Technology, Zibo, China; School of Electrical and Electronic Engineering, Shandong University of Technology, Zibo, China; School of Electrical and Electronic Engineering, Shandong University of Technology, Zibo, China",IEEE Transactions on Consumer Electronics,"18 Aug 2025","2025","71","2","6371","6380","Recently, the Consumer Internet of Things (CIoT) has brought great convenience to people. In CIoT, face image information is indispensable for payment and checking the identity of the user in the transaction. However, the misuse of deepfake face information in CIoT transactions is a growing problem. It has seriously violated the property and privacy of individuals. Moreover, with the proliferation of easily accessible facial editing applications, individuals can effortlessly manipulate facial components through sequential multi-step manipulations. To solve this issue, we propose a Spectral Transformer with a Pyramid Attention (STPA) model to detect sequence permutations in manipulated facial images. Specifically, we introduce a pyramid attention module that integrates both spatial and channel attention mechanisms to prioritize the face region over the background region. Additionally, a spectral Transformer is employed concurrently to extract global and local features to facilitate the fine-grained extraction of the face forgery region. Comprehensive experiments prove that the proposed method can enhance the detection accuracy of the sequential deepfake manipulation task through the fine-grained extraction of features in the face forgery region.","1558-4127","","10.1109/TCE.2024.3414319","National Natural Science Foundation of Shandong Province(grant numbers:ZR2022MF307); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10556749","Consumer security;privacy preservation;sequential deepfake detection;spectral transformer;pyramid attention","Deepfakes;Feature extraction;Transformers;Privacy;Face recognition;Forgery;Internet of Things","","3","","41","IEEE","13 Jun 2024","May 2025","","IEEE","IEEE Journals"
"Detection of Diffusion Model-Generated Faces by Assessing Smoothness and Noise Tolerance","B. Liu; B. Liu; M. Ding; T. Zhu","School of Computer Science, University of Technology Sydney, NSW, Australia; School of Computer Science, University of Technology Sydney, NSW, Australia; Data61, CSIRO, NSW, Australia; Faculty of Data Science, City University of Macau, Macau, China",2024 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB),"31 Jul 2024","2024","","","1","6","The fast growth of artificial intelligence (AI) raises much concern about the misinformation brought by AI-generated content (AIGC), especially Deepfake techniques that generate fake human faces. The recent development of Diffusion Models (DMs) moves another critical step forward to generate high-resolution and realistic human faces, which has become a challenge for existing Deepfake detectors. In this paper, we propose a DM-generated image detector by looking into the generation pipeline of DMs and the details of DM-generated images. The detector is based on the observation that DM-generated human faces show over-smooth textures and do not contain details as real human faces. Through a comprehensive analysis of DM-generated faces in spatial and frequency domains, we noticed that the over-smoothness improves the tolerance of Gaussian noise since excessive smoothness mitigates some of the impact of noise. Inspired by the observations, we propose a Deepfake detector capable of recognizing challenging DM-generated faces. We mainly propose the Noise Residual Unit (NRD) in our framework to collect the frequency response of images to Gaussian noise as distinctive features for classification. In detail, for an input face image, we add Gaussian noise to it and get the noise-degraded image. Then, the NRU generates the Noise Residual Image (NRI) by calculating the residual of the high-pass-filtered original image and the high-pass-filtered degraded image. The NRI indicates the high-frequency impact brought by the Gaussian noise and, therefore, suggests the tolerance of the original image to noise degradation. The original image and NRI are encoded and fused to obtain the joint representation, which is then fed to a classifier to predict the binary label. We conducted comprehensive experiments to evaluate the effectiveness of the proposed detector. The results indicate that our proposed detector achieves state-of-the-art detection performance on DM-generated faces and generalizes well to unseen DM-generated and GAN-generated face datasets.","2155-5052","979-8-3503-6426-2","10.1109/BMSB62888.2024.10608232","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10608232","Deepfake detection;diffusion models;frequency analysis","Deepfakes;Analytical models;Gaussian noise;Frequency-domain analysis;Pipelines;Detectors;Frequency response","","2","","37","IEEE","31 Jul 2024","19-21 June 2024","19-21 June 2024","IEEE","IEEE Conferences"
"Common Forgery Artifact Driven Deepfake Face Detection","H. Wu; X. Wang; R. Wang; J. Xiang; L. Ren","Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China",2024 27th International Conference on Computer Supported Cooperative Work in Design (CSCWD),"10 Jul 2024","2024","","","1585","1590","Given the substantial security risks associated with Deepfake technology, the identification of manipulated facial images has become a focal point of research. Regrettably, the majority of current Deepfake detection methods struggle to effectively discern forgery artifacts across various resolutions. Variations in image or video resolutions present substantial challenges to maintaining identity security in cooperative work environments. In this study, we introduce a Deepfake face detection model that relies on the identification of common forgery artifacts. Our model utilizes CFNet (Common Forgery Artifact Extraction Network) to automatically filter regions containing forged artifacts. These common forged artifacts are found in images of various resolutions, substantially enhancing the model’s accuracy in low-resolution images. Furthermore, our custom-designed multi-modal features ensure the model excels in high-resolution scenarios. Comprehensive experiments validate the efficacy of our model, achieving accuracy rates of 90.464% for Deepfakes, 75.520% for Face2Face, and 83.536% for FaceSwap within the Low Quality (LQ) category of the FF+ dataset.","2768-1904","979-8-3503-4918-4","10.1109/CSCWD61410.2024.10580312","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10580312","Adversarial detection;Deepfake detection;Multi-modal","Image quality;Deepfakes;Accuracy;Image resolution;Federated learning;Feature extraction;Forgery","","1","","28","IEEE","10 Jul 2024","8-10 May 2024","8-10 May 2024","IEEE","IEEE Conferences"
"Detecting and Grounding Multi-Modal Media Manipulation and Beyond","R. Shao; T. Wu; J. Wu; L. Nie; Z. Liu","School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China; S-Lab, Nanyang Technological University, Singapore; School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China; School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China; S-Lab, Nanyang Technological University, Singapore",IEEE Transactions on Pattern Analysis and Machine Intelligence,"2 Jul 2024","2024","46","8","5556","5574","Misinformation has become a pressing issue. Fake media, in both visual and textual forms, is widespread on the web. While various DeepFake detection and text fake news detection methods have been proposed, they are only designed for single-modality forgery based on binary classification, let alone analyzing and reasoning subtle forgery traces across different modalities. In this paper, we highlight a new research problem for multi-modal fake media, namely Detecting and Grounding Multi-Modal Media Manipulation (DGM$^{4}$4). DGM$^{4}$4 aims to not only detect the authenticity of multi-modal media, but also ground the manipulated content (i.e., image bounding boxes and text tokens), which requires deeper reasoning of multi-modal media manipulation. To support a large-scale investigation, we construct the first DGM$^{4}$4 dataset, where image-text pairs are manipulated by various approaches, with rich annotation of diverse manipulations. Moreover, we propose a novel HierArchical Multi-modal Manipulation rEasoning tRansformer (HAMMER) to fully capture the fine-grained interaction between different modalities. HAMMER performs: 1) manipulation-aware contrastive learning between two uni-modal encoders as shallow manipulation reasoning and 2) modality-aware cross-attention by multi-modal aggregator as deep manipulation reasoning. Dedicated manipulation detection and grounding heads are integrated from shallow to deep levels based on the interacted multi-modal information. To exploit more fine-grained contrastive learning for cross-modal semantic alignment, we further integrate Manipulation-Aware Contrastive Loss with Local View and construct a more advanced model HAMMER++. Finally, we build an extensive benchmark and set up rigorous evaluation metrics for this new research problem. Comprehensive experiments demonstrate the superiority of HAMMER and HAMMER++; several valuable observations are also revealed to facilitate future research in multi-modal media manipulation.","1939-3539","","10.1109/TPAMI.2024.3367749","National Natural Science Foundation of China(grant numbers:62306090,62236003,62376069); Young Elite Scientists Sponsorship Program by CAST(grant numbers:2023QNRC001); Ministry of Education - Singapore; MOE AcRF Tier 2(grant numbers:MOE-T2EP20221- 0012); NTU NAP; RIE2020 Industry Alignment Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10440475","Media manipulation detection;DeepFake detection;multi-modal learning","Deepfakes;Grounding;Forgery;Cognition;Faces;Semantics;Visualization","","22","","72","IEEE","20 Feb 2024","Aug. 2024","","IEEE","IEEE Journals"
"Deepfaceguard: A Lightweight CNN Framework for Robust Face Manipulation Detection","M. Tauseef; L. S. Viji; J. Fenwick","School of ECE, REVA University, Bengaluru, India; School of ECE, REVA University, Bengaluru, India; School of ECE, REVA University, Bengaluru, India","2025 Third International Conference on Networks, Multimedia and Information Technology (NMITCON)","10 Oct 2025","2025","","","1","6","The rapid proliferation of deep-fake technology threatens the credibility of digital media, with face-swap deep fakes posing significant detection challenges due to their high visual fidelity. This paper presents Deep Faceguard, a lightweight CNN-based deepfake detection framework optimized for high accuracy, cross-dataset generalization, and real-time edge deployment. Unlike prior models limited to single-dataset performance, Deep Faceguard integrates transfer learning with Efficient Net and XceptionNet backbones, combined with OpenCV-based facial region alignment to enhance artifact localization. The system effectively detects subtle manipulation artifacts such as illumination inconsistencies, blending anomalies, and edge discontinuities. Trained on FaceForensics ++ and DFDC, it achieves 96.5 % accuracy, 95.8 % precision, 97.2 % recall, and a ROC AUC of 0.982, while cross-dataset testing yields 88.2 % accuracy, indicating robustness to domain shift. Optimized via TensorFlow Lite, Deep Faceguard sustains 45 FPS real-time inference and reduces the model size by 40 % without accuracy loss, making it suitable for scalable and deployment-ready deepfake detection applications.","","979-8-3315-1308-5","10.1109/NMITCON65824.2025.11188219","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11188219","Deepfake detection;Convolutional Neural Net works (CNNs);face-swap manipulation;digital media forensics;cross-dataset generalization;TensorFlow Lite;real-time infer ence;edge deployment","Deepfakes;Visualization;Accuracy;Image edge detection;Transfer learning;Media;Real-time systems;Robustness;Convolutional neural networks;Testing","","","","15","IEEE","10 Oct 2025","1-2 Aug. 2025","1-2 Aug. 2025","IEEE","IEEE Conferences"
"Towards Benchmarking and Evaluating Deepfake Detection","J. Deng; C. Lin; P. Hu; C. Shen; Q. Wang; Q. Li; Q. Li","Faculty of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China; Faculty of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China; Faculty of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China; Faculty of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China; School of Cyber Science and Engineering, Wuhan University, Wuhan, China; Institute For Network Sciences and Cyberspace, Tsinghua University, Beijing, China; Guangdong OPPO Mobile Telecommunications Corporation, Ltd., Shenzhen, China",IEEE Transactions on Dependable and Secure Computing,"12 Nov 2024","2024","21","6","5112","5127","Deepfake detection automatically recognizes the manipulated media by analyzing whether it contains forgeries generated through deep learning. It is natural to ask which among the existing deepfake detection approaches stand out as top performers. This question is pivotal for identifying promising research directions and offering practical guidance. Unfortunately, conducting a sound benchmark comparison of popular detection approaches based on literature results is challenging due to inconsistent evaluation conditions across studies. In this paper, our objective is to achieve a sound comparison between detection approaches by establishing a comprehensive and consistent benchmark, developing a repeatable evaluation procedure, and performing extensive performance evaluation. Accordingly, a challenging dataset consisting of the manipulated samples generated by more than 12 different methods is collected. Subsequently, we implement and evaluate 13 prominent detection approaches (comprising 11 algorithms) from existing literature, utilizing five fair-minded and practical evaluation metrics. Finally, we provide up to 882 comprehensive evaluations by training 117 detection models. The results, along with the shared data and evaluation methodology, constitute a benchmark for comparing deepfake detection approaches and measuring progress.","1941-0018","","10.1109/TDSC.2024.3369711","National Key Research and Development Program of China(grant numbers:2021YFB3100700); National Natural Science Foundation of China(grant numbers:62006181,62161160337,62132011,U21B2018,U20A20177,62206217,U20B2049); Shaanxi Province Key Industry Innovation Program(grant numbers:2023-ZDLGY-38,2021ZDLGY01-02); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10444780","Benchmark;deepfake detection;face swapping;forensic datasets","Deepfakes;Faces;Benchmark testing;Forensics;Measurement;Training;Forgery","","8","","70","IEEE","26 Feb 2024","Nov.-Dec. 2024","","IEEE","IEEE Journals"
"Generalization of Forgery Detection With Meta Deepfake Detection Model","V. -N. Tran; S. -G. Kwon; S. -H. Lee; H. -S. Le; K. -R. Kwon","Department of Artificial Intelligence Convergence, Pukyong National University, Busan, South Korea; Department of Electronics Engineering, Kyungil University, Gyeongsan, South Korea; Department of Computer Engineering, Dong-A University, Busan, South Korea; Faculty of Information Systems, University of Economics and Law, Vietnam National University Ho Chi Minh City, Ho Chi Minh, Vietnam; Department of Artificial Intelligence Convergence, Pukyong National University, Busan, South Korea",IEEE Access,"4 Jan 2023","2023","11","","535","546","Face forgery generating algorithms that produce a range of manipulated videos/images have developed quickly. Consequently, this causes an increase in the production of fake information, making it difficult to identify. Because facial manipulation technologies raise severe concerns, face forgery detection is gaining increasing attention in the area of computer vision. In real-world applications, face forgery detection systems frequently encounter and perform poorly in unseen domains, due to poor generalization. In this paper, we propose a deepfake detection method based on meta-learning called Meta Deepfake Detection (MDD). The goal of the model is to develop a generalized model capable of directly solving new unseen domains without the need for model updates. The MDD algorithm establishes various weights for facial images from various domains. Specifically, MDD uses meta-weight learning to shift information from the source domains to the target domains with meta-optimization steps, which aims for the model to generate effective representations of the source and target domains. We build multi-domain sets using meta splitting strategy to create a meta-train set and meta-test set. Based on these sets, the model determines the gradient descent and obtains backpropagation. The inner and outer loop gradients were aggregated to update the model to enhance generalization. By introducing pair-attention loss and average-center alignment loss, the detection capabilities of the system were substantially enhanced. In addition, we used some evaluation benchmarks established from several popular deepfake datasets to compare the generalization of our proposal in several baselines and assess its effectiveness.","2169-3536","","10.1109/ACCESS.2022.3232290","Basic Science Research Program through the National Research Foundation of Korea (NRF); Ministry of Education(grant numbers:2020R1I1A306659411,2020R1F1A1069124); Ministry of Science and ICT (MSIT), South Korea, through the Information Technology Research Center (ITRC) Support Program; Institute for Information & Communications Technology Planning & Evaluation (IITP)(grant numbers:IITP-2022-2020-0-01797); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9999180","Deepfake detection;meta-learning;artificial intelligence;computer vision","Face recognition;Artificial intelligence;Deepfakes;Forgery;Task analysis;Feature extraction;Computer vision","","25","","63","CCBY","26 Dec 2022","2023","","IEEE","IEEE Journals"
"FakePoI: A Large-Scale Fake Person of Interest Video Detection Benchmark and a Strong Baseline","L. Tian; H. Yao; M. Li","Department of Computer Science, National University of Singapore, Lower Kent Ridge Road, Singapore; Faculty of Computing, Harbin Institute of Technology, Harbin, China; Institute of Data Science, National University of Singapore, Cluny Road, Singapore",IEEE Transactions on Circuits and Systems for Video Technology,"26 Oct 2023","2023","33","11","6819","6831","Deepfake technique can synthesize realistic images, audios, and videos, facilitating the thriving of entertainment, education, healthcare, and other industries. However, its abuse may pose potential threats to personal privacy, social stability, and even national security. Therefore, the development of deepfake detection methods is attracting more and more attention. Existing works mainly focus on the detection of common videos for entertainment purposes. In contrast, fake videos maliciously synthesized for Person of Interest (PoI, i.e., who is in an authoritative position and has broadly public influences) are much more harmful to society because of celebrity endorsement. However, there is no particular benchmark for driving related research in the community. Motivated by this observation, we present the first large-scale benchmark dataset, named FakePoI, to enable the research on fake PoI detection. It contains numerous fake videos of important people from all walks of life, e.g., police chiefs, city mayors, famous artists, and well-known Internet bloggers. In summary, our FakePoI includes 11092 synthesized videos where only a few clips rather than the entire are fake. Previous fake detection algorithms deteriorate heavily or even fail on our FakePoI due to two main challenges. On the one hand, the rich diversity of our fake videos makes it pretty difficult to find universally applicable patterns for detection. On the other hand, the high credibility contributed by the presence of real frames easily confuses a common detector. To tackle these challenges, we present an amplifier framework, highlighting the feature gap between real and generated video frames. Specifically, we present a quadruplet loss to narrow the distance of all real PoIs and meanwhile push away each real and fake PoI in embedding space. We implement our framework and conduct extensive experiments on the proposed benchmark. The quantitative results demonstrate that our approach outperforms existing methods significantly, setting a strong baseline on FakePoI. The qualitative analysis also shows its superiority. We will release our dataset and code at https://github.com/cslltian/deepfake-detection to encourage future research on this valuable area.","1558-2205","","10.1109/TCSVT.2023.3269742","National Key Research and Development Program of China(grant numbers:2021ZD0110901); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10107587","Person of interest;face swap;face reconstruction;deepfake detection;video clustering","Faces;Deepfakes;Video on demand;Benchmark testing;Internet;Entertainment industry;Detectors","","6","","89","IEEE","24 Apr 2023","Nov. 2023","","IEEE","IEEE Journals"
"EXDF: Explainable Deepfake Detection with Vision-Language Model","S. -T. Lo; T. -M. Huang; Y. -H. Han; K. -L. Hua; J. -C. Chen",National Taiwan University of Science and Technology; National Taiwan University; National Taiwan University; National Taiwan University of Science and Technology; Academia Sinica,2025 IEEE International Conference on Image Processing (ICIP),"18 Aug 2025","2025","","","2384","2389","Although many deepfake detection methods have been proposed to fight against severe misuse of generative AI, none provide detailed human-interpretable explanations beyond simple real/fake responses. This limitation makes it challenging for humans to assess the accuracy of detection results, especially when the models encounter unseen deepfakes. To address this issue, we propose a novel deepfake detector based on a large Vision-Language Model (VLM), capable of explaining manipulated facial regions. We frame the deepfake detection task as Visual Question Answering (VQA) and perform visual instruction tuning to train the model on our collected Explainable Deepfake Face (ExDF) dataset. The dataset consists of fake images from diverse generative adversarial networks (GANs) and diffusion models (DMs), with explanations produced by GPT-4o guided by the corresponding ground-truth masks of the manipulated regions. Moreover, a facial mask encoder is introduced to guide the model to focus on key facial features, thereby improving the detection and explanation performances. Extensive experiments demonstrate that training the proposed model on the full ExDF dataset not only enhances detection accuracy compared to baseline methods but also provides detailed, human-interpretable explanations. To our knowledge, ExDF is the first explainable deepfake face dataset covering both GANs and DMs with comprehensive descriptions of altered facial regions. Our code and dataset are available at https://github.com/aiiu-lab/ExDF.","2381-8549","979-8-3315-2379-4","10.1109/ICIP55913.2025.11084529","National Science and Technology Council; Academia Sinica; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11084529","Deepfake Detection;Vision-Language Model;Dataset;Explainable AI","Training;Deepfakes;Visualization;Accuracy;Pipelines;Transforms;Media;Question answering (information retrieval);Faces;Tuning","","","","49","IEEE","18 Aug 2025","14-17 Sept. 2025","14-17 Sept. 2025","IEEE","IEEE Conferences"
"3D Morphable Models Meet Surface Frames for Generalizable and Robust Deepfake Detection","G. Affatato; A. Ciamarra; E. D. Cannas; S. Mandelli; B. Tondi; R. Caldelli; P. Bestagini","Politecnico di Milano, Milan, Italy; CNIT, Florence, Italy; Politecnico di Milano, Milan, Italy; Politecnico di Milano, Milan, Italy; University of Siena, Siena, Italy; CNIT, Florence, Italy; Politecnico di Milano, Milan, Italy",2025 33rd European Signal Processing Conference (EUSIPCO),"17 Nov 2025","2025","","","1223","1227","With the rapid advancements in AI-generated imagery, particularly diffusion-based models, detecting synthetic human faces has become increasingly challenging. In this paper, we introduce a synthetic face detection framework that leverages two complementary features: (i) UV textures extracted using 3D Morphable Models (3DMM) and (ii) surface frames capturing geometric structures. These modalities are fused using both featurelevel and score-level fusion strategies to enhance generalization to unseen generators and robustness against post-processing operations. Experimental evaluations on diverse datasets demonstrate that our proposed method outperforms single-modality and CLIP-based approaches and provides improved generalization across different diffusion generative models, as well as improved robustness against common and strong processing operations.","","978-9-4645-9362-4","10.23919/EUSIPCO63237.2025.11226603","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11226603","Synthetic image detection;3D Morphable Models;Surface frame;Robust deepfake detection","Solid modeling;Deepfakes;Three-dimensional displays;Signal processing;Feature extraction;Robustness;Generators;Surface texture;Surface treatment;Faces","","","","21","","17 Nov 2025","8-12 Sept. 2025","8-12 Sept. 2025","IEEE","IEEE Conferences"
"Partial Reconstruction Error for Deepfake Detection","Y. Zhang; Z. Meng; B. Peng; J. Dong; B. Chu; W. Wang","School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China; New Laboratory of Pattern Recognition (NLPR), Institute of Automation, Chinese Academy of Sciences, Beijing, China; New Laboratory of Pattern Recognition (NLPR), Institute of Automation, Chinese Academy of Sciences, Beijing, China; New Laboratory of Pattern Recognition (NLPR), Institute of Automation, Chinese Academy of Sciences, Beijing, China; School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China; New Laboratory of Pattern Recognition (NLPR), Institute of Automation, Chinese Academy of Sciences, Beijing, China","ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","7 Mar 2025","2025","","","1","5","The rapid development of deepfake technology poses a formidable challenge to personal privacy and security, underscoring the urgent need for deepfake detection. Recently, the methods based on the reconstruction error, such as DIRE and RECCE, achieve impressive performance in forgery detection. However, their performance on facial forgery datasets is relatively poor. The reconstruction process is performed on the whole images, neglecting contextual information for reconstruction. In this paper, we propose Partial Reconstruction Error to perform deepfake detection based on the reconstruction of masked regions in an image. In this way, contextual information helps to reveal the inconsistencies between the original and reconstructed regions thereby improving the detection performance. This method outperforms the best global reconstruction-based approaches on the FF++, Celeb-DF, and DiFF datasets by 4.00%, 2.83%, and 2.67%, respectively.","2379-190X","979-8-3503-6874-1","10.1109/ICASSP49660.2025.10889075","Research and Development; National Natural Science Foundation of China; Ministry of Justice; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10889075","Deepfake Detection;Masked Autoencoder;Partial Reconstruction","Deepfakes;Privacy;Signal processing;Reconstruction algorithms;Forgery;Security;Data mining;Speech processing;Image reconstruction;Faces","","1","","28","IEEE","7 Mar 2025","6-11 April 2025","6-11 April 2025","IEEE","IEEE Conferences"
"Domain Generalization for Face Forgery Detection by Style Transfer","T. Kim; J. Choi; H. Cho; H. Lim; J. Choi","Dept. of Advanced Imaging, Chung-Ang Univ., Seoul, South Korea; Dept. of Advanced Imaging, Chung-Ang Univ., Seoul, South Korea; Dept. of Advanced Imaging, Chung-Ang Univ., Seoul, South Korea; Dept. of Advanced Imaging, Chung-Ang Univ., Seoul, South Korea; Dept. of Advanced Imaging, Chung-Ang Univ., Seoul, South Korea",2024 IEEE International Conference on Consumer Electronics (ICCE),"28 Feb 2024","2024","","","1","5","Although deep fake detection models have made significant progress, the challenge of performance degradation remains yet for unseen datasets. To address this, we introduce a novel data generalization approach using style transfer to generate images in various domains. Utilizing style transfer, we create a new domain where domain-specific information is eliminated and subsequently train our model on the new domain. Our approach enhances the generalization performance of the detector by adding the style-transferred images to train the deepfake detector. Through the experiments, we confirm that the performance on the trained dataset remains unchanged while achieving an improvement of 8.8% on an unseen dataset. Therefore, We verify the effectiveness of the style-transferred images for generalizing the performance upon unseen datasets.","2158-4001","979-8-3503-2413-6","10.1109/ICCE59016.2024.10444215","Korea Creative Content Agency; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10444215","Deepfake detection;forgery detection;data augmentation;style transfer","Training;Degradation;Deepfakes;Detectors;Forgery;Faces;Consumer electronics","","2","","26","IEEE","28 Feb 2024","6-8 Jan. 2024","6-8 Jan. 2024","IEEE","IEEE Conferences"
"Swin-BiLSTM with Attention for Face Swap Detection in Deepfake Videos","N. F. Lukitania; V. Suryani","School of Computing, Telkom University, Bandung, Indonesia; School of Computing, Telkom University, Bandung, Indonesia",2025 International Conference on Information and Communication Technology (ICoICT),"14 Oct 2025","2025","","","1","6","Digital manipulation tools like deepfakes have advanced in sophistication because to the quick development of deep learning and artificial intelligence. Face swapping, in which one person’s face is swapped out for another, is one of the most alarming types of deepfakes. This technique produces incredibly lifelike movies that may deceive viewers. Detecting these manipulated videos is crucial to mitigating their negative impact on privacy and security. This paper proposes an ensemble approach to detecting face swap deepfakes by combining the Swin Transformer and Bidirectional Long Short-Term Memory (BiLSTM) with an attention mechanism. The Swin Transformer is employed for spatial feature extraction, while the BiLSTM captures temporal patterns between frames, and the attention mechanism focuses on the most relevant timesteps. The model is evaluated on the FaceForensics++ dataset, achieving a validation accuracy of 93.81% with a validation loss of 0.19, outperforming the Long Short-Term Memory (LSTM), Fully Convolutional Network (FCN), and Convolutional Neural Network - Bidi-rectional Long Short-Term Memory (CNN-BiLSTM) models. Experimental results demonstrate the superior ability of the Swin-BiLSTM With Attention model to accurately detect face swap manipulations, even under varying facial poses, lighting conditions, and motion variations. The proposed method shows promise in addressing the challenges of deepfake detection, offering potential applications in privacy protection, misinformation prevention, and security. Future work may explore the integration of additional data modalities or advanced techniques to further enhance detection accuracy and robustness.","","979-8-3315-0323-9","10.1109/ICoICT66265.2025.11192953","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11192953","Deepfake Detection;Face Swap;Swin Transformer;BiLSTM;Attention Mechanism","Deepfakes;Privacy;Attention mechanisms;Accuracy;Bidirectional long short term memory;Transformers;Robustness;Security;Convolutional neural networks;Faces","","","","18","IEEE","14 Oct 2025","30-31 July 2025","30-31 July 2025","IEEE","IEEE Conferences"
"A Comparative Study of EfficientNetB4 and VGG19 Models for Deepfake Detection","S. Shrestha; E. S. Park; S. Gautam; N. Mansoor","Computer Information Science, Minnesota State University, Mankato, Mankato, MN, United States; Computer Information Science, Minnesota State University, Mankato, Mankato, MN, United States; Computer Information Science, Minnesota State University, Mankato, Mankato, MN, United States; Computer Information Science, Minnesota State University, Mankato, Mankato, MN, United States",2025 International Conference on Advanced Machine Learning and Data Science (AMLDS),"2 Oct 2025","2025","","","276","281","With the increasing production of hyper-realistic altered images, the need for effective deepfake detection technology has become critical. These altered images pose significant threats to security, privacy, and the spread of misinformation, complicating the distinction between authentic and manipulated content. This challenge has far-reaching implications, from social media and politics to personal relationships. This study focuses on detecting deepfake human face images using a balanced dataset of 140,000 images, comprising 70,000 real faces sourced from Nvidia’s Flickr dataset and 70,000 fake faces generated by StyleGAN. In this research, we compare the performance of EfficientNetB4 and VGG19 models, to identify subtle manipulations in high-quality deepfake images. Our findings demonstrate that the EfficientNetB4 model achieves an accuracy of 98.54%, while the VGG19 model reaches 99.11% in the base model, highlighting the effectiveness of these models in advancing deepfake detection technology.","","979-8-3315-1099-2","10.1109/AMLDS63918.2025.11159417","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11159417","Deepfake Detection;GANs;Convolutional Neural Network;EfficientNetB4;VGG19","Training;Deepfakes;Analytical models;Accuracy;Social networking (online);Computational modeling;Convolutional neural networks;Web sites;Security;Faces","","","","14","IEEE","2 Oct 2025","19-21 July 2025","19-21 July 2025","IEEE","IEEE Conferences"
"GAN and ResNet based Combination Deep Learning Model for Recognizing Fake Faces","K. Gowsic; R. Hariprasath; M. Guruprasad; M. Kabirajan; J. K. Sojan","Department of Computer Science and Engineering, Mahendra Engineering College, Tamilnadu, India; Department of Computer Science and Engineering, Mahendra Engineering College, Tamilnadu, India; Department of Computer Science and Engineering, Mahendra Engineering College, Tamilnadu, India; Department of Computer Science and Engineering, Mahendra Engineering College, Tamilnadu, India; Department of Computer Science and Engineering, Mahendra Engineering College, Tamilnadu, India",2025 4th International Conference on Innovative Mechanisms for Industry Applications (ICIMIA),"20 Oct 2025","2025","","","1061","1068","AI-driven deepfake technology has grown and matured to the point of rendering it more difficult to distinguish between real and manipulated photos or videos (e.g., altered faces). Deepfakes are built using a highly advanced neural network and they often share hyper-realistic visual properties that evade human perception. This study presents a hybrid deep learning model for robust, reliable, and efficient fake face detection using GANs and ResNet. The hybrid deep learning model takes advantage of GANs to navigate the generative processes inherent in deepfakes and also utilizes ResNet to extract the fine visual features of faces. In addition, CNNs are used to address spatial inconsistencies such as lighting differences, symmetrical facial differences, and textural manipulations. The system was trained on both real and manipulated photos, and several preprocessing techniques (e.g., normalization, dimension reduction) to provide robustness. The experimental results found that this hybrid model demonstrated measureable improvements over traditional methods (i.e., standalone) in accuracy, precision, and sensitivity. This hybrid model brings forth a cost-effective and scalable method for real-time deepfake detection in digital media security and authentication.","","979-8-3315-5386-9","10.1109/ICIMIA67127.2025.11200763","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11200763","Convolutional Neural Networks;Deepfake Detection;Generative Adversarial Networks;Hybrid Model;Residual Networks;Visual Manipulation","Deep learning;Deepfakes;Visualization;Sensitivity;Generative adversarial networks;Feature extraction;Real-time systems;Hybrid power systems;Faces;Residual neural networks","","","","15","IEEE","20 Oct 2025","3-5 Sept. 2025","3-5 Sept. 2025","IEEE","IEEE Conferences"
"RE-Mark: An Identity-Recovery Watermarking Method for Undoing Deepfake Face-Swap","T. Walczyna; J. M. Zurada; Z. Piotrowski","Electronics and Telecommunications Faculty, Military University of Technology, Warsaw, Poland; Electrical and Computer Eng. Department, University of Louisville, 2301 S 3rd St, Louisville, KY, USA; Electronics and Telecommunications Faculty, Military University of Technology, Warsaw, Poland",IEEE Access,"","2025","PP","99","1","1","In response to the growing threat of face‑swap deepfakes, we introduced RE‑Mark. This active zero-bit watermark embeds a compact neural identity signature directly within a facial image and later reconstructs the pre-swap appearance from a single image. The scheme employs a pair of symmetric, attention-enhanced U-Nets acting as an embedder and extractor. It is trained with a specific training pipeline that mixes five different face-swap engines with classical degradations such as noise and blur. This diversity forces the network to learn robust, high-level cues rather than brittle artifact patterns, yielding transparent watermarks that remain visually imperceptible at a peak signal-to-noise ratio (PSNR) of approximately 36 dB. Unlike previous active defenses that only flag manipulations, RE-Mark hides enough semantic redundancy to recover an authentic face without any external reference gallery, closing the gap between fragile detectors and robust—but non-restorative—watermarks. Therefore, the method equips platforms and investigators with a practical tool for both tamper verification and post‑factum identity restoration.","2169-3536","","10.1109/ACCESS.2025.3638457","Wojskowa Akademia Techniczna(grant numbers:UGB 22-054/2025); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11271225","Deepfake detection;Face‑swap robustness;Identity recovery;Image watermarking;Neural networks","Deepfakes;Watermarking;Faces;Image reconstruction;Visualization;Image restoration;Feature extraction;Robustness;Pipelines;Engines","","","","","CCBY","28 Nov 2025","","","IEEE","IEEE Early Access Articles"
"Unmasking the Illusion: A Novel Approach for Detecting Deep Fakes using Video Vision Transformer Architecture","A. Jadhav; D. Narale; R. Kore; U. Shisode; A. Kulange","Dept. Information Technology, JSPM’s Rajarshi Shahu College Of Engineering, Tathawade, Pune, India; Dept. Information Technology, JSPM’s Rajarshi Shahu College Of Engineering, Tathawade, Pune, India; Dept. Information Technology, JSPM’s Rajarshi Shahu College Of Engineering, Tathawade, Pune, India; Dept. Information Technology, JSPM’s Rajarshi Shahu College Of Engineering, Tathawade, Pune, India; Dept. Information Technology, JSPM’s Rajarshi Shahu College Of Engineering, Tathawade, Pune, India",2024 Asian Conference on Intelligent Technologies (ACOIT),"2 Apr 2025","2024","","","1","5","Deepfakes are fake images, videos, audio, and text content that appear to be real. They are now easier than ever to create because of different AI tools. They aregenerally legal and have legitimate applications in many areas, but now a days they are commonly used for exploitation. Anyone can use deepfake tools to create fakevideos or images that spread misinformation, harass andintimidate others, and ultimately ruin people’s lives. Facial mapping technologies are used by Cyber criminals to create an accurate facial symmetry data set. They swapthe face of a person on to the face of another person. To tackle this problems, we propose this Deepfake Detection System. Key feature of our model is to classify the given input video into real or fake class. Our model will detect weather the given video is real one or is generated (manipulated) by deepfake generation techniques. Existing methodology related to deepfake detection involves various techniques. Currently, existing detection systems are using Convolutional Neural Networks (CNN) as a backbone, artificial neural networks (ANN), Recurrent Neural Network (RNN) algorithms. Each having its own benefits, drawbacks and related accuracy.We are trying to integrate two of these techniques i.e, Convolutional Neural Network and Vision Transformer. Basic aim to integrate or merge two techniques is to modify or increase the accuracy of model.","","979-8-3503-7495-7","10.1109/ACOIT62457.2024.10939366","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10939366","Video vision transformer;CNN;Deep-fake;Deepfake detection;DeepLearning","Surveys;Deepfakes;Computer vision;Recurrent neural networks;Accuracy;Transformers;Real-time systems;Convolutional neural networks;Artificial intelligence;Faces","","1","","11","IEEE","2 Apr 2025","6-7 Sept. 2024","6-7 Sept. 2024","IEEE","IEEE Conferences"
"Deepfake Detection Using Transfer Learning","S. A. Khan; D. Valles","Ingram School of Engineering, Texas State University, San Marcos, USA; Ingram School of Engineering, Texas State University, San Marcos, USA","2024 IEEE 15th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON)","20 Nov 2024","2024","","","556","562","Deepfake technology’s rise has led to a surge in false identities, creating a significant and present problem with broad societal ramifications. Concerns over identity theft, harassment, and the dissemination of false information have escalated due to the simplicity with which deepfaked facial images can now be produced and distributed thanks to the broad availability of generative AI tools like Generative Adversarial Networks (GANs). The availability of these tools has political ramifications since it can degrade public opinion and damage institutional trust. As such, the ability to identify deepfake face images has become essential. Ensuring a person’s identity is critical in preventing the dissemination of false information on social media. Detection of deepfake facial images is also necessary for identity verification in border control, law enforcement, and security applications. To effectively and precisely recognize deepfake face images, this study effort has focused on modifying transfer learning models, such as ResNet101V2, MobileNetV2, NASNetLarge, NASNetMobile, DenseNet121, DenseNet169, DenseNet201, and Xception.","","979-8-3315-4090-6","10.1109/UEMCON62879.2024.10754706","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10754706","deepfake detection;GANs;transfer learning;deep learning;identity verification","Training;Deepfakes;Social networking (online);Law enforcement;Face recognition;Computational modeling;Transfer learning;Mobile communication;Security;Surges","","","","26","IEEE","20 Nov 2024","17-19 Oct. 2024","17-19 Oct. 2024","IEEE","IEEE Conferences"
"Disruptive Attacks on Face Swapping via Low-Frequency Perceptual Perturbations","M. Huang; M. Shu; S. Zhou; Z. Liu","Department of Mathematics and Artificial Intelligence, Qilu University of Technology, Jinan, China; Department of Mathematics and Artificial Intelligence, Qilu University of Technology, Jinan, China; Department of Mathematics and Artificial Intelligence, Qilu University of Technology, Jinan, China; Department of Mathematics and Artificial Intelligence, Qilu University of Technology, Jinan, China",2025 International Joint Conference on Neural Networks (IJCNN),"14 Nov 2025","2025","","","1","9","Deepfake technology, driven by Generative Adversarial Networks (GANs), poses significant risks to privacy and societal security. Existing detection methods are predominantly passive, focusing on post-event analysis without preventing attacks. To address this, we propose an active defense method based on low-frequency perceptual perturbations to disrupt face-swapping manipulation, reducing the performance and naturalness of generated content. Unlike prior approaches that used low-frequency perturbations to impact classification accuracy, our method directly targets the generative process of deepfake techniques.We combine frequency and spatial domain features to strengthen defenses. By introducing artifacts through low-frequency perturbations while preserving high-frequency details, we ensure the output remains visually plausible. Additionally, we design a complete architecture featuring an encoder, a perturbation generator, and a decoder, leveraging discrete wavelet transform (DWT) to extract low-frequency components and generate perturbations that disrupt facial manipulation models. Experiments on CelebA-HQ and LFW demonstrate significant reductions in face-swapping effectiveness, improved defense success rates, and preservation of visual quality.","2161-4407","979-8-3315-1042-8","10.1109/IJCNN64981.2025.11228245","Shandong Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11228245","deepfake detection;privacy protection;adversarial defense;low-frequency perturbations","Deepfakes;Privacy;Visualization;Perturbation methods;Focusing;Feature extraction;Generators;Discrete wavelet transforms;Decoding;Faces","","","","42","IEEE","14 Nov 2025","30 June-5 July 2025","30 June-5 July 2025","IEEE","IEEE Conferences"
"Spotting fully-synthetic facial images via local camera surface frames","A. Ciamarra; R. Caldelli; A. D. Bimbo","Universitas Mercatorum, Rome, Italy; CNIT, Florence, Italy; University of Florence, Florence, Italy",2024 IEEE International Workshop on Information Forensics and Security (WIFS),"27 Dec 2024","2024","","","1","6","The actual capacity to AI-generate realistic fully synthetic images is day-by-day improving and this is particularly true for pictures representing human faces that appear indistinguishable from real people. This poses the crucial need to develop instruments able to discern between true and do not existing people by detecting some eventual inconsistencies embedded within the images during the generation process. The main difference between a pristine picture and a deepfake generated one is that, in the second case, there has not been an effective camera acquisition; so all the various interrelationships among the elements belonging to the scene (lights, reflectance, object respective positions in the 3D space) are not taken by the real world in that precise time instant but just artificially reproduced. According to such consideration, in this work, we introduce local camera surface frames as a possible mean to represent these specific environmental characteristics in order to highlight differences. The experimental analysis carried out has witnessed that this feature can grant a very high level of accuracy and a significant degree of generalization.","2157-4774","979-8-3503-6442-2","10.1109/WIFS61860.2024.10810698","Horizon Europe; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10810698","Deepfake;Deepfake detection;fully synthetic;facial images;local surface frames","Reflectivity;Deepfakes;Accuracy;Three-dimensional displays;Instruments;Forensics;Conferences;Cameras;Security;Faces","","2","","20","IEEE","27 Dec 2024","2-5 Dec. 2024","2-5 Dec. 2024","IEEE","IEEE Conferences"
"On the Generalisation Capability of Local Surface Frames in Detecting Diffusion-Based Facial Images","A. Ciamarra; R. Caldelli; A. Del Bimbo","University of Florence, Italy; CNIT, Florence, Italy; University of Florence, Italy",2025 IEEE/CVF Winter Conference on Applications of Computer Vision Workshops (WACVW),"29 Apr 2025","2025","","","1312","1321","Extraordinary unreal images can be realised with pow-erful AI techniques. Various tools available to everyone are able to recreate high quality contents, especially generating entire fully synthetic images. Among the existing architectures, diffusion-based models can easily produce any kind of images, including human facial images, by giving a prompt like a text. Such false contents are often used to spread dis-information and this raises concerns about people security. At the present, it is getting hard to develop reliable instruments to distinguish between real and generated (even non-existing) people. Moreover, the large amount of diffusion-based implementations poses the problem for such detectors to generalise on novel generative techniques. To address these issues, we propose to investigate the capacity of a distinctive feature, based on the image acquisition environment, to individuate diffusion-based face images from the pristine ones. In fact, generated images should not contain the characteristics that are proper of the acquisition phase performed through a real camera. Such inconsistencies can be highlighted by means of recently introduced local surface frames. This feature takes into account objects and surfaces involved in the scene, which all impact the camera acquisition process, along with further intrinsic information tied to the device, as well as lighting and reflections affecting the entire scenario. The paper explores the ability of this feature to generalise towards different datasets and new generative methods unknown during training. Experimental results highlight that such a feature still provides significant levels of detection accuracy also in these cases.","2690-621X","979-8-3315-3662-6","10.1109/WACVW65960.2025.00154","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10972530","deepfake detection;fully synthetic;facial images;local surface frames;diffusion models","Training;Performance evaluation;Cameras;Robustness;Reflection;Security;Surface treatment;Faces;Testing;Synthetic data","","","","34","IEEE","29 Apr 2025","28 Feb.-4 March 2025","28 Feb.-4 March 2025","IEEE","IEEE Conferences"
"DF-VLAD: Deepfake Video Detection based on Feature Aggregation","Y. Huang; Z. Luo; M. Zhang; W. Liu; S. Li","Department of Artificial Intelligence, Xiamen University, Xiamen, China; Department of Artificial Intelligence, Xiamen University, Xiamen, China; Institute of Energy Research, Jiangxi Academy of Sciences, Nanchang, China; School of Software, East China Jiaotong University, Nanchang, China; Department of Artificial Intelligence, Xiamen University, Xiamen, China",2021 11th International Conference on Information Technology in Medicine and Education (ITME),"15 Apr 2022","2021","","","91","95","With the rapid development of Deepfake technology, face video forgery can produce highly deceptive video content and bring serious security threats. The detection of this kind of fake video is more urgent and challenging. Most of the existing detection methods regard this problem as a common binary classification problem, and using a simple average or maximum as the prediction of video results can easily lead to missed detection or false detection. While the video-based detection work such as LSTM, in Deepfake detection, too much focus on timing modeling will affect the performance of Deepfake video detection to a certain extent. Based on this, this paper proposes a VLAD-based aggregation module DF-VLAD, which advances the aggregation of multiple frames from the output layer to the feature layer, which on the one hand makes the aggregation more flexible, on the other hand, it also uses the objective function of forgery detection to directly guide the learning of frame-level depth representation; On the other hand, this paper deals with this problem as a special fine-grained classification problem, because the difference between fake face and real face is very subtle. It is found that the existing face forgery methods such as Face2Face and NeuralTextures leave some common artifacts in the spatial domain. Different forgery methods produce different artifacts, while natural faces have more similar features. To make the model pay more attention to artifacts, a forgery trace capture model based on the fusion of self-attention mechanism and channel attention mechanism is proposed in this paper. Like other fine-grained classification methods, note intentions are used to guide the network to pay attention to key parts of the face. Experimental results on different public data sets show that the proposed method achieves the latest performance.","2474-3828","978-1-6654-0679-6","10.1109/ITME53901.2021.00029","National Nature Science Foundation of China(grant numbers:61876159,61806172,62076116,U1705286); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9750563","Deepfake detection;face manipulation;VLAD;attention","Education;Feature extraction;Linear programming;Forgery;Timing;Security;Face detection","","2","","26","IEEE","15 Apr 2022","19-21 Nov. 2021","19-21 Nov. 2021","IEEE","IEEE Conferences"
"AI-Powered Deepfake Detection in Biometric Systems","U. M. Atasoy; M. Altıntaş; T. İnan","Department of Artificial Intelligence Engineering, TOBB University of Economics and Technology, Ankara, Türkiye; Department of Artificial Intelligence Engineering, TOBB University of Economics and Technology, Ankara, Türkiye; Department of Artificial Intelligence Engineering, TOBB University of Economics and Technology, Ankara, Türkiye",2025 Innovations in Intelligent Systems and Applications Conference (ASYU),"30 Oct 2025","2025","","","1","6","Deepfake technologies pose a growing threat to biometric systems by enabling the creation of highly realistic forged facial content. This study proposes a deepfake detection framework based on the XceptionNet architecture, aiming to enhance detection robustness under both familiar and unseen conditions. To achieve this, we leverage two widely adopted datasets-Celeb-DF-v2 and FaceForensics++-and construct a hybrid dataset to improve domain generalization. The pipeline includes Dlib-based face detection and alignment, consistent preprocessing, and efficient feature extraction using XceptionNet. We evaluate the system across six test settings, including unseen samples from different videos, and report high accuracy and F1 scores, even under domain shifts. Our findings show that training on diverse datasets significantly boosts generalization, and the proposed system outperforms several existing baselines on unseen Celeb-DF-v2. This work demonstrates the potential of combining architectural efficiency with dataset diversity to build deployable deepfake detection models for biometric security applications.","2770-7946","979-8-3315-9727-6","10.1109/ASYU67174.2025.11208454","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11208454","Deepfake Detection;Biometric Security;Deep Neural Networks;Dataset Generalization;Face Manipulation Forensics","Biometrics;Training;Deepfakes;Technological innovation;Biological system modeling;Diversity reception;Pipelines;Robustness;Security;Standards","","","","15","IEEE","30 Oct 2025","10-12 Sept. 2025","10-12 Sept. 2025","IEEE","IEEE Conferences"
"Short And Low Resolution Deepfake Video Detection Using CNN","A. Rahman; N. Siddique; M. J. Moon; T. Tasnim; M. Islam; M. Shahiduzzaman; S. Ahmed","Dept. of CSE, BUBT, Dhaka, Bangladesh; Dept. of CSE, BUBT, Dhaka, Bangladesh; Dept. of CSE, BUBT, Dhaka, Bangladesh; Dept. of CSE, BUBT, Dhaka, Bangladesh; Dept. of CSE, BUBT, Dhaka, Bangladesh; Dept. of CSE, BUBT, Dhaka, Bangladesh; Dept. of CSE, BUBT, Dhaka, Bangladesh",2022 IEEE 10th Region 10 Humanitarian Technology Conference (R10-HTC),"3 Nov 2022","2022","","","259","264","Recently, convincing deepfake videos are growing very fast that can delude even the trained experts. These deepfake videos have huge impacts all over the world covering the political, social, and personal lives. The state-of-the-art machine learning studies are demonstrating noticeable success to detect fake videos in high resolution and long-time video data while the same performance is not observed in low resolution and short-time clips. In this work, we have trained a convolutional neural network (CNN) that demonstrates mentionable accuracy in detecting fake videos in low-resolution and short-time video data. We have exploited Kaggle Deepfake Detection Challenge (DFDC) and the Face Forensics++ datasets in our experiment. Our model shows 94.93% accuracy in detecting fake videos for the DFDC dataset while the same is 93.2% for FaceForensics++ Dataset. We evaluated our models by different performance metrics and compared the performance with state-of-the-art methods. Our model demonstrates comparable performance.","2572-7621","978-1-6654-0156-2","10.1109/R10-HTC54060.2022.9929719","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9929719","Deepfake Video;Machine-Learning;dlib;Convolutional Neural Network(CNN);Deepfake-Detection-Challenge(DFDC);FaceForensics++","Measurement;Deep learning;Deepfakes;Media;Convolutional neural networks;Faces;IEEE Regions","","13","","36","IEEE","3 Nov 2022","16-18 Sept. 2022","16-18 Sept. 2022","IEEE","IEEE Conferences"
"Deepfake Detection using EfficientNet: Working Towards Dense Sampling and Frames Selection","T. -A. To; H. -C. Luong; N. -T. Nguyen; T. -T. Nguyen; M. -T. Tran; T. -L. Do","Faculty of Information Technology and Software Engineering Laboratory, University of Science, VNUHCM, Ho Chi Minh City, Vietnam; Faculty of Information Technology and Software Engineering Laboratory, University of Science, VNUHCM, Ho Chi Minh City, Vietnam; Faculty of Information Technology and Software Engineering Laboratory, University of Science, VNUHCM, Ho Chi Minh City, Vietnam; Faculty of Information Technology and Software Engineering Laboratory, University of Science, VNUHCM, Ho Chi Minh City, Vietnam; Viet Nam National University, Ho Chi Minh City, Vietnam; Viet Nam National University, Ho Chi Minh City, Vietnam",2022 RIVF International Conference on Computing and Communication Technologies (RIVF),"18 Jan 2023","2022","","","612","617","Deepfake is a controversial technology that allows the automatic generation of video content through generative adversarial networks. The emergence of Deepfake technology is problematic and sophisticated, making it more difficult to detect. In our paper, we contribute a deep-learning method to resolve that problem. We use the MTCNN face detector to extract facial images and apply data augmentation and EfficientNet for real-fake classification. We apply frame selection with the raw label prediction to tackle the fault cases and receive the final label. With the approach above applied, we utilize training and evaluation datasets from FaceForensics++ and achieve an accuracy of 62.5%.","2162-786X","978-1-6654-6166-5","10.1109/RIVF55975.2022.10013900","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10013900","Deepfake Detection;Efficient Net;Dense Sampling;Frame Selection","Deep learning;Training;Learning systems;Deepfakes;Image resolution;Social networking (online);Computer architecture","","7","","26","IEEE","18 Jan 2023","20-22 Dec. 2022","20-22 Dec. 2022","IEEE","IEEE Conferences"
"Guardian AI: Synthetic Media Forensics through Multimodal Fusion and Advanced Machine Learning","K. K; S. R; D. S; D. S","Department of Computer Science and Business Systems, K.S.Rangasamy College of Technology, Namakkal, Tamil Nadu, India; Department of Computer Science and Business Systems, K.S.Rangasamy College of Technology, Namakkal, Tamil Nadu, India; Department of Computer Science and Business Systems, K.S.Rangasamy College of Technology, Namakkal, Tamil Nadu, India; Department of Computer Science and Business Systems, K.S.Rangasamy College of Technology, Namakkal, Tamil Nadu, India",2024 International Conference on Cognitive Robotics and Intelligent Systems (ICC - ROBINS),"21 May 2024","2024","","","226","232","The burgeoning spread of synthetic media disrupts content verification and threatens online trust. This research proposes Guardian AI, a robust deepfake detection system achieving 93% accuracy by harnessing the synergistic power of facial recognition, image forensics, and machine learning. Guardian AI extracts diverse features from videos: facial recognition models analyze landmarks, expressions, and lip-syncing for inconsistencies; image forensics algorithms detect manipulated pixels, lighting patterns, and compression artifacts; and temporal analysis captures unnatural head movements and frame-to-frame motion discrepancies. These multifaceted features are then fused and fed into a rigorously trained deep learning model on multi-modal datasets of real and deepfake videos. Guardian AI classifies video inputs as real or fake, providing a confidence score for its prediction. By leveraging facial recognition's subtle inconsistency detection, image forensics' manipulation artifact identification, and machine learning's robust multi-cue integration, Guardian AI achieves exceptional accuracy and generalizability, adapting to evolving deepfake creation techniques with its diverse training data. This study signifies a significant contribution to content verification by delivering a high accuracy deepfake detection system, paving the way for a more reliable and trustworthy online environment.","","979-8-3503-7274-8","10.1109/ICC-ROBINS60238.2024.10533980","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10533980","Deepfake Detection;Facial Recognition;Image Forensics;Machine Learning;Multimodal Fusion;Content Verification","Deepfakes;Image forensics;Ethics;Explainable AI;Face recognition;Feature extraction;Real-time systems","","1","","10","IEEE","21 May 2024","17-19 April 2024","17-19 April 2024","IEEE","IEEE Conferences"
"Facial Behavior Analysis-Based Deepfake Video Detection using GAN Discriminator","Q. Jaleel; I. H. Ali","Software Department, University of Babylon, Babylon, Iraq; Software Department, University of Babylon, Babylon, Iraq",2022 International Conference on Data Science and Intelligent Computing (ICDSIC),"27 Mar 2023","2022","","","36","40","Deepfake is an artificial intelligence-based method for making fake images of people. It works by putting the existing (source) images or videos on the final (destination) images or videos. But recent improvements in deep learning have made it much easier to make fake videos that look real and are convincing with a relatively small amount of data and computing power. As a result of the development of deep learning techniques such as Generative adversarial networks (GAN), Deepfake has become closer to the truth. Many researchers are based on discovering deep fakes that were created by traditional methods. Traditional methods of detection that look for artifacts and pixels that don't match up can't keep up. This paper can detect deepfakes that are perfectly created. It is detected by modifying the GAN algorithm and inverting its function. The discriminator model of a GAN network is used to analyze behavior, facial gestures, and the appearance of an object. The paper is divided into two stages. The first stage is to use a GAN discriminator that has been modified. It is then trained using a deepfake dataset. The second stage is to test the videos by extracting the faces. Next, run it through the GAN discriminator to see if it's a forgery. In comparison to other networks, the GAN discriminator has demonstrated its ability and accuracy in detecting fake videos. The network's accuracy in detecting and distinguishing between real and fake videos is %94.65.","","979-8-3503-3488-3","10.1109/ICDSIC56987.2022.10075660","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10075660","GAN;GAN discriminator;Media Forensics;DeepFake Detection;Face Detection","Deep learning;Training;Deepfakes;Analytical models;Image resolution;Network architecture;Generative adversarial networks","","8","","17","IEEE","27 Mar 2023","1-2 Nov. 2022","1-2 Nov. 2022","IEEE","IEEE Conferences"
"Towards Generic Deepfake Detection with Dynamic Curriculum","W. Song; Y. Lin; B. Li","Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen Key Laboratory of Media Security, Shenzhen University, Shenzhen, China; Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen Key Laboratory of Media Security, Shenzhen University, Shenzhen, China; Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen Key Laboratory of Media Security, Shenzhen University, Shenzhen, China","ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","18 Mar 2024","2024","","","4500","4504","Most previous deepfake detection methods bent their efforts to discriminate artifacts by end-to-end training. However, the learned networks often fail to mine the generic face forgery information efficiently due to ignoring data diversity. In this work, we propose to introduce sample hardness into the training of deepfake detectors via a curriculum learning paradigm. Specifically, we present a novel simple yet effective strategy, named Dynamic Facial Forensic Curriculum (DFFC), which makes the model gradually focus on hard samples during the training. To this end, we propose Dynamic Forensic Hardness (DFH) which integrates the facial quality score and instantaneous instance loss to dynamically measure sample hardness during training. Besides, we present a pacing function to construct data subsets from easy to hard throughout the training process based on DFH. Comprehensive experiments show that DFFC can improve both within- and cross-dataset performance of various kinds of end-to-end deepfake detectors in a plug-and-play manner. It indicates that DFFC can help deepfake detectors learn generic forgery discriminative features more efficiently by exploiting the information from hard samples.","2379-190X","979-8-3503-4485-1","10.1109/ICASSP48485.2024.10448345","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10448345","Deepfake detection;Curriculum learning;Face image quality","Training;Image quality;Deepfakes;Forensics;Detectors;Signal processing;Feature extraction","","4","","31","IEEE","18 Mar 2024","14-19 April 2024","14-19 April 2024","IEEE","IEEE Conferences"
"Model-Agnostic Method: Exposing Deepfake Using Pixel-Wise Spatial and Temporal Fingerprints","J. Yang; Y. Sun; M. Mao; L. Bai; S. Zhang; F. Wang","Department of Computer Science and Technology, Tongji University, Shanghai, China; Department of Computer Science and Technology, Tongji University, Shanghai, China; Department of Computer Science and Technology, Tongji University, Shanghai, China; Department of Computer Science and Technology, Tongji University, Shanghai, China; Department of Computer Science and Technology, Tongji University, Shanghai, China; Department of Computer Science, Brunel University, Uxbridge, U.K.",IEEE Transactions on Big Data,"10 Nov 2023","2023","9","6","1496","1509","Deepfake poses a serious threat to the reliability of judicial evidence and intellectual property protection. Existing detection methods either blindly utilize deep learning or use biosignal features, but neither considers spatial and temporal relevance of face features. These methods are increasingly unable to resist the growing realism of fake videos and lack generalization. In this paper, we identify a reliable fingerprint through the consistency of AR coefficients and extend the original PPG signal to 3-dimensional fingerprints to effectively detect fake content. Using these reliable fingerprints, we propose a novel model-agnostic method to expose Deepfake by analyzing temporal and spatial faint synthetic signals hidden in portrait videos. Specifically, our method extracts two types of faint information, i.e., PPG features and AR features, which are used as the basis for forensics in temporal and spatial domains, respectively. PPG allows remote estimation of the heart rate in face videos, and irregular heart rate fluctuations expose traces of tampering. AR coefficients reflect pixel-wise correlation and spatial traces of smoothing caused by up-sampling in the process of generating fake faces. Furthermore, we employ two ACBlock-based DenseNets as classifiers. Our method provides state-of-the-art performance on multiple deep forgery datasets and demonstrates better generalization.","2332-7790","","10.1109/TBDATA.2023.3284272","National Key R&D Program of China(grant numbers:2019YFC1906201); National Natural Science Foundation of China(grant numbers:91748122); Xianyang Key R&D Program(grant numbers:S2021ZDYF-SF-0739); China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10146470","Auto-regressive (AR);deep learning;deepfake detection;fingerprint;photoplethysmography (PPG);temporal and spatial","Fingerprint recognition;Feature extraction;Faces;Deepfakes;Heart rate;Biological system modeling;Skin","","9","","63","IEEE","8 Jun 2023","Dec. 2023","","IEEE","IEEE Journals"
"MMNet: Multi-Collaboration and Multi-Supervision Network for Sequential Deepfake Detection","R. Xia; D. Liu; J. Li; L. Yuan; N. Wang; X. Gao","State Key Laboratory of Integrated Services Networks, School of Electronic Engineering, Xidian University, Xi’an, Shaanxi, China; State Key Laboratory of Integrated Services Networks, School of Cyber Engineering, Xidian University, Xi’an, China; State Key Laboratory of Integrated Services Networks, School of Electronic Engineering, Xidian University, Xi’an, Shaanxi, China; Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing, China; State Key Laboratory of Integrated Services Networks, School of Telecommunications Engineering, Xidian University, Xi’an, Shaanxi, China; Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing, China",IEEE Transactions on Information Forensics and Security,"13 Feb 2024","2024","19","","3409","3422","Advanced manipulation techniques have provided criminals with opportunities to make social panic or gain illicit profits through the generation of deceptive media, such as forgery face images. In response, various deepfake detection methods have been proposed to assess image authenticity. Sequential deepfake detection, which is an extension of deepfake detection, aims to identify forged facial regions with the correct sequence for recovery. Nonetheless, due to the different combinations of spatial and sequential manipulations, forgery face images exhibit substantial discrepancies that severely impact detection performance. Additionally, the recovery of forged images requires knowledge of the manipulation model to implement inverse transformations, which is difficult to ascertain as relevant techniques are often concealed by attackers. To address these issues, we propose Multi-Collaboration and Multi-Supervision Network (MMNet) that handles various spatial scales and sequential permutations in forgery face images and achieve recovery without requiring knowledge of the corresponding manipulation method. Furthermore, existing evaluation metrics only consider detection accuracy at a single inferring step, without accounting for the matching degree with ground-truth under continuous multiple steps. To overcome this limitation, we propose a novel evaluation metric called Complete Sequence Matching (CSM), which considers the detection accuracy at multiple inferring steps, reflecting the ability to detect integrally forged sequences. Extensive experiments on several typical datasets demonstrate that MMNet achieves state-of-the-art detection performance and independent recovery performance. Code will be available at https://github.com/xarryon/MMNet","1556-6021","","10.1109/TIFS.2024.3361151","National Natural Science Foundation of China(grant numbers:U22A2096,62036007,U21A20514,62221005,62306227); Technology Innovation Leading Program of Shaanxi(grant numbers:2022QFY01-15); Natural Science Basic Research Plan in Shaanxi Province of China(grant numbers:2022JQ-696); Natural Science Foundation of Chongqing(grant numbers:CSTB2022NSCQ-MSX1265); Science and Technology Research Program of Chongqing Municipal Education Commission(grant numbers:KJQN202300606); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10418195","Deceptive media;sequential deepfake detection;face recovery","Faces;Deepfakes;Feature extraction;Forgery;Visualization;Measurement;Task analysis","","30","","62","IEEE","1 Feb 2024","2024","","IEEE","IEEE Journals"
"A Comprehensive Study on Mitigating Synthetic Identity Threats Using Deepfake Detection Mechanisms","S. Uppal; V. Banga; S. Neeraj; A. Singhal","Dept of CSE, ASET, Amity University Uttar Pradesh, Noida, India; Dept of CSE, ASET, Amity University Uttar Pradesh, Noida, India; Dept of CSE, ASET, Amity University Uttar Pradesh, Noida, India; Dept of CSE, ASET, Amity University Uttar Pradesh, Noida, India","2024 14th International Conference on Cloud Computing, Data Science & Engineering (Confluence)","21 Mar 2024","2024","","","750","755","Synthetic Identity Threats (SIT) present one of the greatest risks that could undermine the integrity and security of digital systems. These threats adapt Deepfake Technology through generation of new faces, modification of facial attributes or reenactment of fake emotions on human faces. This study is a full documentation of how Deepfake Detection mechanisms can be modelled to neutralize these SIT's using various Deep Learning architectures. We also explored applications of Deepfake beyond malicious intent into forms that are less nefarious like entertainment purposes. We utilized Generative Adversarial Networks to create Deepfakes and experimented with conducting face swaps between two distinct photos as well to assess the quality of Deepfake Technology. For detection of Deepfakes, Convolution Neural Network has shown the highest accuracy of 89.36%, Inception ResNet attained an accuracy of 82.978% while Visual Geometry Group and EfficientNet were at a score of 82.8% and 83% respectively. It is evident that although the current detecting methods are competent in their abilities, the SIT environment continues to develop. Through analyzing the nuances of producing Deepfakes and comparing current quality detection methods, we hope to offer useful information on how scholars and administrators can better protect the internet from deceitful attacks of Deepfakes.","2766-421X","979-8-3503-4483-7","10.1109/Confluence60223.2024.10463324","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10463324","Synthetic Identity Threats (SIT);Deepfake Detection Challenge Dataset (DFDC);Convolution Neural Network (CNN);Inception ResNet;Visual Geometry Group (VGG);EfficientNet;Generative Adversarial Networks (GAN);Deepfake Generation;Face Swapping","Geometry;Deepfakes;Visualization;Neural networks;Government;Virtual environments;Production","","2","","15","IEEE","21 Mar 2024","18-19 Jan. 2024","18-19 Jan. 2024","IEEE","IEEE Conferences"
"Fighting Deepfake by Exposing the Convolutional Traces on Images","L. Guarnera; O. Giudice; S. Battiato","Department of Mathematics and Computer Science, University of Catania, Catania, Italy; Department of Mathematics and Computer Science, University of Catania, Catania, Italy; Department of Mathematics and Computer Science, University of Catania, Catania, Italy",IEEE Access,"18 Sep 2020","2020","8","","165085","165098","Advances in Artificial Intelligence and Image Processing are changing the way people interacts with digital images and video. Widespread mobile apps like FACEAPP make use of the most advanced Generative Adversarial Networks (GAN) to produce extreme transformations on human face photos such gender swap, aging, etc. The results are utterly realistic and extremely easy to be exploited even for non-experienced users. This kind of media object took the name of Deepfake and raised a new challenge in the multimedia forensics field: the Deepfake detection challenge. Indeed, discriminating a Deepfake from a real image could be a difficult task even for human eyes but recent works are trying to apply the same technology used for generating images for discriminating them with preliminary good results but with many limitations: employed Convolutional Neural Networks are not so robust, demonstrate to be specific to the context and tend to extract semantics from images. In this paper, a new approach aimed to extract a Deepfake fingerprint from images is proposed. The method is based on the Expectation-Maximization algorithm trained to detect and extract a fingerprint that represents the Convolutional Traces (CT) left by GANs during image generation. The CT demonstrates to have high discriminative power achieving better results than state-of-the-art in the Deepfake detection task also proving to be robust to different attacks. Achieving an overall classification accuracy of over 98%, considering Deepfakes from 10 different GAN architectures not only involved in images of faces, the CT demonstrates to be reliable and without any dependence on image semantic. Finally, tests carried out on Deepfakes generated by FACEAPP achieving 93% of accuracy in the fake detection task, demonstrated the effectiveness of the proposed technique on a real-case scenario.","2169-3536","","10.1109/ACCESS.2020.3023037","iCTLab s.r.l. - Spin-off of University of Catania; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9189772","Deepfake detection;generative adversarial networks;multimedia forensics;image forensics","Information integrity;Videos;Generative adversarial networks;Faces;Task analysis;Computer architecture;Gallium nitride","","101","","31","CCBY","9 Sep 2020","2020","","IEEE","IEEE Journals"
"Deepfake Detection Fighting Against Noisy Label Attack","T. Qiao; S. Xie; Y. Chen; F. Retraint; R. Shi; X. Luo","School of Cyberspace, Hangzhou Dianzi University, Hangzhou, China; School of Cyberspace, Hangzhou Dianzi University, Hangzhou, China; Cyberspace Institute of Advanced Technology, Guangzhou University, Guangzhou, China; Laboratory of Computer Science and Digital Society, University of Technology of Troyes, Troyes, France; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; State Key Laboratory of Mathematical Engineering and Advanced Computing, Zhengzhou Science and Technology Institute, Zhengzhou, China",IEEE Transactions on Multimedia,"21 Aug 2024","2024","26","","9047","9059","The face manipulation technique such as Deepfake has been widely used to create realistic faces, which raises growing concerns in the community. Based on the correct labeled data, the current Deepfake detectors are mostly trained on the clean dataset, usually resulting in the reliable high detection accuracy. However, in the real-world scenario, labelers possibly mislabel the data or malicious attackers always intend to poison the training data with incorrect label, namely noisy label attack, leading to poor detection results. To overcome the tough issue, we propose a Deepfake detection framework fighting against noisy label attack. Specifically, a Negative Sample Generator (NSG) utilizes the possibly-poisoned samples to generate label-reliable negative samples through simulating blending artifacts caused by Deepfake. Next, a Noise-immune Contrastive Learner (NiCL) takes both positive and negative samples as training data, exploring blending artifacts and intrinsic forgery clues to filtrate the noisy samples out. Moreover, relying on label purification, the filtrated noisy samples are further purified, which then are fed back to the feature extractor for the following model training. Extensive experiments on the benchmark datasets demonstrate the superiority of our proposed Deepfake detector. In particular, when fighting against noisy label attack, the high performance of the proposed detector is remarkably better than its competitors.","1941-0077","","10.1109/TMM.2024.3385286","Zhejiang Provincial Natural Science Foundation of China(grant numbers:LZ23F020006,LTGG24F020008); National Key R&D Project(grant numbers:2022YFB3102900); National Natural Science Foundation of China(grant numbers:62172435,U23A20305); Henan Province Key R&D Project of China(grant numbers:221111321200); vigideo; UTT's AMI O-SPAR; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10491334","Deepfake detection;noisy label attack;contrastive learning","Noise measurement;Deepfakes;Training;Faces;Data models;Training data;Forensics","","7","","71","IEEE","4 Apr 2024","2024","","IEEE","IEEE Journals"
"AI-Powered Facial Analysis: Real or Fake Image Detection, Age Group Classification, Grooming Analysis and Emotion Recognition","P. G. Om Prakash; Y. S. S. Tadi; K. Karumajji","Dept. of Computational Intelligence, SRM Institute of Science & Technology, Kattankulathur, India; Dept. of Computational Intelligence, SRM Institute of Science & Technology, Kattankulathur, India; Dept. of Computational Intelligence, SRM Institute of Science & Technology, Kattankulathur, India","2025 2nd International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)","25 Jun 2025","2025","","","1","7","The development of deepfake technology has made it extremely difficult to tell the difference between real and altered facial photos, which presents significant privacy and security risks. This project offers a multifaceted deep learning-driven solution that can classify age, identify emotions, and conduct grooming analysis in addition to detecting deepfake photos. The method achieves 93.91% success rate in deepfake identification using a model built on CNN that was trained on datasets of real and fake faces. Furthermore, an OpenCV-Caffe model categorizes people into various age groups, a Vision Transformer (ViT)-based beard recognition model achieves 99.9% accuracy, and an Xception-based emotion detection method reaches 98.65% accuracy. Users can input photographs, evaluate several faces, and generate a detailed report on age distribution, feelings beard presence and real/fake categorization using the system's real-time Streamlit user interface. This AI-powered solution addresses the growing worries about digital verification of identity and distorted media by offering a safe, effective and automated method of facial analysis.","","979-8-3315-9848-8","10.1109/RMKMATE64874.2025.11042624","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11042624","Age Classification;Deepfake Detection;Emotion Recognition;Facial Analysis;Grooming Detection and Vision Transformer","Emotion recognition;Deepfakes;Computer vision;Accuracy;Streaming media;Transformers;Real-time systems;Security;Faces;Resilience","","","","20","IEEE","25 Jun 2025","7-8 May 2025","7-8 May 2025","IEEE","IEEE Conferences"
"Detection of Deepfake Video using Deep Learning and MesoNet","L. Rebello; L. Tuscano; Y. Shah; A. Solomon; V. Shrivastava","Computer Engineering Department, SFIT, Mumbai; Computer Engineering Department, SFIT, Mumbai; Computer Engineering Department, SFIT, Mumbai; Computer Engineering Department, SFIT, Mumbai; Computer Engineering Department, SFIT, Mumbai",2023 8th International Conference on Communication and Electronics Systems (ICCES),"1 Aug 2023","2023","","","1022","1026","Fraudsters are increasingly using evidence tampering to evade criminal charges and the acquisition of personal data for identity-related offenses. Deepfake is one of the most common strategies used today for identity theft and reputation defamation. To prevent the spread of these crimes, we need a system that can tell the difference between real and deep fake videos. Deep Neural Networks will be used in our system to identify and mark films as legitimate or manipulated, as well as the altered sections, by running the video through our trained Sequence Model, which can detect any discrepancies or alterations as a sequence of frames. LSTM will be used for temporal sequence analysis, and CNN will be employed for frame feature extraction. MesoNet is a neural network built primarily to identify deep fakes, but it would also be used for other purposes. MesoNet manages the noise produced by low-quality video processing, which impedes analysis. DeepFakes jeopardizes facial recognition and internet content. This deception is risky and can be exploited to impersonate a legitimate user. Our approach will propose a temporal-aware method for automatically detecting deepfake videos.","","979-8-3503-9663-8","10.1109/ICCES57224.2023.10192854","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10192854","DeepFake Detection;Deep Learning;Neural Networks;Convolution Neural Network;Recurrent Neural Network;Long Short-Term Memory;MesoNet","Deepfakes;Freeware;Sequences;Limiting;Social networking (online);Films;Face recognition","","4","","15","IEEE","1 Aug 2023","1-3 June 2023","1-3 June 2023","IEEE","IEEE Conferences"
"DeepMark: A Platform Ensuring Content Integrity","S. Chirakkarottu; A. M. S; A. Manoj; A. M. Nair; D. K. S","Dept. of CSE, FISAT, Cochin, Kerala, India; Dept. of CSE, FISAT, Cochin, Kerala, India; Dept. of CSE, FISAT, Cochin, Kerala, India; Dept. of CSE, FISAT, Cochin, Kerala, India; Dept. of CSE, FISAT, Cochin, Kerala, India",2025 Advanced Computing and Communication Technologies for High Performance Applications (ACCTHPA),"24 Sep 2025","2025","","","1","6","Social media content integrity evaluation is necessary to avoid unauthorized redistribution and alteration of multimedia content. The traditional approaches are primarily based on metadata or watermarking methods, which are easily tampered with or deleted, and thus are insufficient to guarantee long-term content authenticity. This renders it difficult to maintain ownership authentication and prevent content tampering. To counter these weaknesses, we suggest an improved system that employs DWT-based watermarking, facial feature hashing, and cryptographic metadata embedding to ensure content integrity. The system delves into the spatial coordinates of facial landmarks to generate unique hash values that are securely stored in a database to enable verification. The system, through the integration of multi-layer security techniques, manages to eliminate the risk of content re-posting and monitors unauthorized tampering, even when it is covert. Moreover, our method minimizes computational overhead while still being able to verify in real-time, thereby making the system scalable to mass use. The suggested architecture enhances the security and reliability of user-generated media on social networks, offering an end-to-end solution for preventing media forgery and abuse.","","979-8-3315-4437-9","10.1109/ACCTHPA65749.2025.11168595","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11168595","Deepfake Detection;Digital Watermarking;Media Integrity;Forensic Metadata Analysis;Multimodal Verification;Cryptographic Watermarking;Synthetic Media Manipulation","Social networking (online);Face recognition;Watermarking;Metadata;Real-time systems;Libraries;Discrete wavelet transforms;Reliability;Sustainable development;Facial features","","","","8","IEEE","24 Sep 2025","18-19 July 2025","18-19 July 2025","IEEE","IEEE Conferences"
"A CNN Algorithm Based DeepFake Detection System","S. M. Mangalampalli; M. J. Mistry; A. M. Pal; J. Pereira","Vidyavardhini's College of Engg. &Tech., Mumbai, India; Vidyavardhini's College of Engg. &Tech., Mumbai, India; Vidyavardhini's College of Engg. &Tech., Mumbai, India; Vidyavardhini's College of Engg. &Tech., Mumbai, India",2025 12th International Conference on Computing for Sustainable Global Development (INDIACom),"21 Aug 2025","2025","","","1","6","DeepFake is a technology that has garnered significant attention in the modern world and is often used for unlawful and immoral practices. The consequences and aftereffects of generation and publication of deepfakes in the public domain can tamper the social image of organizations or individuals. The objective of this study is to find a solution to this upcoming societal horror which can ruin lives and stigmatize the affected individuals. This project mainly concentrated on the development of a DeepFake Detection model that leverages a custom Convolutional Neural Network (CNN) to identify facemanipulated images or video content by extracting frames from images or videos. The model achieved high accuracy in demonstration of effectiveness of custom CNN architecture in identification of subtle facial inconsistencies and performed robustly across the dataset which highlighted the capability for generalization and detection of face-manipulated content in images and videos, alike. In essence, this CNN model stands out as a comprehensive solution not only addressing and amending the challenges faced by current systems but also enables people to be alert. This research serves as a foundational step towards the development of robust and scalable solutions to effectively counter DeepFake technology.","","978-93-80544-60-1","10.23919/INDIACom66777.2025.11115232","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11115232","Convolutional Neural Network;DeepFake Detection;face manipulation;visual features;video classification;frame extraction","Deepfakes;Visualization;Accuracy;Organizations;Computer architecture;Feature extraction;Classification algorithms;Convolutional neural networks;Faces","","","","23","","21 Aug 2025","2-4 April 2025","2-4 April 2025","IEEE","IEEE Conferences"
"Comparison of Deepfakes Detection Techniques","S. Salman; J. A. Shamsi","Dept.of Computer Science, National University of Computer and Emerging Sciences, Karachi, Pakistan; Dept.of Computer Science, National University of Computer and Emerging Sciences, Karachi, Pakistan",2023 3rd International Conference on Artificial Intelligence (ICAI),"1 Jun 2023","2023","","","227","232","Detection of fake audio and video is a challenging problem. Deepfake is popularly used for creating fake audio and video content using deep learning. Deepfakes, artificially created audiovisual interpretations can be used to degrade the reputation of a renowned person, hate-speech, or affect public belief. The development of novel methods for identifying various deep fake video types has received a significant amount of research throughout the years. In this research, we present a thorough comparative analysis of current state-of-the-art deepfake detection methods. The primary goal of our research is to identify the factors that contribute to the performance degradation of deepfake detection models currently being used when tested against a comprehensive dataset.","","979-8-3503-2212-5","10.1109/ICAI58407.2023.10136659","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10136659","deepfake detection;deep learning;comparative revicew","Degradation;Deep learning;Deepfakes;Artificial intelligence","","6","","21","IEEE","1 Jun 2023","22-23 Feb. 2023","22-23 Feb. 2023","IEEE","IEEE Conferences"
"It Wasn’t Me: Irregular Identity in Deepfake Videos","H. Liu; P. Bestagini; L. Huang; W. Zhou; S. Tubaro; W. Zhang; N. Yu","University of Science and Technology of China, Hefei, China; Politecnico di Milano, Milan, Italy; Politecnico di Milano, Milan, Italy; University of Science and Technology of China, Hefei, China; Politecnico di Milano, Milan, Italy; University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China",2023 IEEE International Conference on Image Processing (ICIP),"11 Sep 2023","2023","","","2770","2774","With the rapid development in media generation technologies, the creation of DeepFake videos is within everyone’s reach. As the widespread diffusion of DeepFakes can lead to severe consequences (e.g., defamation, fake news spreading, etc.), detecting DeepFakes is becoming a crucial task within the forensic community. However, most of the existing DeepFake detectors suffer from two issues: i) they are hardly explainable as they build upon black-box data-driven techniques rather than interpretable features; ii) they are often tailored to low-level texture features, failing to generalize on low-quality DeepFake videos. In this work we propose a video DeepFake detector that aims at solving these issues. The proposed detector relies on the fact that most DeepFake generators work on a frame-by-frame basis, thus breaking the temporal consistency of facial features across frames. In particular, we noticed that facial identity features tend to be less stable in time on DeepFake videos than original ones. We therefore propose a framework trained on time series of facial identity features. The use of high-level semantic features makes the detector interpretable and robust against low-quality DeepFake videos. Extensive experiments show that our method achieves outstanding performance on low-quality DeepFake video and obtains promising results on unseen dataset evaluation. The code is available at https://github.com/HongguLiu/Identity-Inconsistency-DeepFake-Detection","","978-1-7281-9835-4","10.1109/ICIP49359.2023.10222654","China Scholarship Council; University of Science and Technology of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10222654","DeepFake Detection;Identity Inconsistency;Interpretability;Robustness","Deepfakes;Image coding;Forensics;Semantics;Time series analysis;Detectors;Feature extraction","","4","","31","IEEE","11 Sep 2023","8-11 Oct. 2023","8-11 Oct. 2023","IEEE","IEEE Conferences"
"Comparative Analyais of CNN Architectures for Deep Fake Detection","P. Wani; S. Chavan; S. Paithankar; D. Ghusse; S. Barve","School of Computer Engineering, MIT Academy of Engineering, Pune, India; School of Computer Engineering, MIT Academy of Engineering, Pune, India; School of Computer Engineering, MIT Academy of Engineering, Pune, India; School of Computer Engineering, MIT Academy of Engineering, Pune, India; School of Computer Engineering, MIT Academy of Engineering, Pune, India","2025 3rd International Conference on Intelligent Systems, Advanced Computing and Communication (ISACC)","22 Apr 2025","2025","","","1119","1125","DeepFake technology, driven by advanced generative models, threatens online authenticity and privacy. This paper presents a comparative analysis of three convolutional neural network (CNN) architectures—VGGFace16, DenseNet-121, and a custom CNN model—for DeepFake image detection. The study utilizes the 140k Faces Dataset, comprising 70,000 real and 70,000 synthetic images, and the Real and Fake Face Detection Dataset from Yonsei University, ensuring a diverse and well-balanced training set while accounting for computational constraints. Feature extraction from the final convolutional layers, dimensionality reduction via Principal Component Analysis (PCA), and classification with a Support Vector Machine (SVM) using a polynomial kernel form the core methodology. DenseNet-121 achieved the highest accuracy (97%) on grayscaled images, while the augmented custom CNN balanced accuracy (86%) and interpretability, attaining a Receiver Operating Characteristic Area Under the Curve (ROC-AUC) score of 0.953. PCA visualizations confirmed the models’ ability to distinguish real from fake images. The findings underscore dataset selection’s role in model performance and the necessity of resource-efficient training. Future work will expand dataset diversity, explore cross-dataset validation, and leverage advanced computational resources to enhance generalization, contributing to more robust DeepFake detection systems.","","979-8-3315-2389-3","10.1109/ISACC65211.2025.10969171","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10969171","DeepFake detection;convolutional neural networks (CNN);VGGFace16;DenseNet-121;custom CNN;140k Faces Dataset;Real and Fake Face Detection Dataset;feature extraction;Principal Component Analysis (PCA);Support Vector Machine (SVM);polynomial kernel;ROC-AUC","Support vector machines;Training;Deepfakes;Accuracy;Computational modeling;Computer architecture;Feature extraction;Polynomials;Convolutional neural networks;Principal component analysis","","1","","20","IEEE","22 Apr 2025","27-28 Feb. 2025","27-28 Feb. 2025","IEEE","IEEE Conferences"
"Illumination Enlightened Spatial-temporal Inconsistency for Deepfake Video Detection","K. Tian; C. Chen; Y. Zhou; X. Hu","Nanjing University of Science and Technology, Nanjing, China; State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Nanjing University of Science and Technology, Nanjing, China; Nanjing University of Science and Technology, Nanjing, China",2024 IEEE International Conference on Multimedia and Expo (ICME),"30 Sep 2024","2024","","","1","6","The rapid advancement of facial manipulation techniques has greatly simplified the creation of deepfake videos, posing a major threat to social safety, public opinions and even political stability. Existing deepfake detection methods primarily concentrate on capturing spatial artifacts or extracting uniform temporal inconsistency, neglecting the potential of exploiting dynamic spatiotemporal inconsistency. To address these issues, this paper proposes a novel network that effectively leverages dynamic spatiotemporal inconsistency, termed DSTI, by integrating the sequential illumination features and intra/inter-frame clues. The proposed DSTI contains two branches: one branch employs a transformer encoder to perform inconsistency computation from sequential illumination representations derived from 3D facial models, including illumination coefficients, 3D normal vectors, and luminance values. The other branch utilizes a timesformer network to capture intra/inter-frame inconsistency from sampled videos. Extensive experimentation validates that the proposed method outperforms other competitive approaches.","1945-788X","979-8-3503-9015-5","10.1109/ICME57554.2024.10687905","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10687905","Deepfake detection;face forgery detection;illumination inconsistency;digital feature inconsistency","Deepfakes;Three-dimensional displays;Lighting;Streaming media;Feature extraction;Transformers;Forgery","","3","","29","IEEE","30 Sep 2024","15-19 July 2024","15-19 July 2024","IEEE","IEEE Conferences"
"Deepfake Detection using a Two-Stream Capsule Network","Z. Joseph; C. Nyirenda","Department of Computer Science, University of the Western Cape, Robert Sobukwe Road, Bellville, South Africa; Department of Computer Science, University of the Western Cape, Robert Sobukwe Road, Bellville, South Africa",2021 IST-Africa Conference (IST-Africa),"26 Oct 2021","2021","","","1","8","This paper aims to address the problem of Deepfake Detection using a Two-Stream Capsule Network. First we review methods used to create Deepfake content, as well as methods proposed in the literature to detect such Deepfake content. We then propose a novel architecture to detect Deepfakes, which consists of a two-stream Capsule network running in parallel that takes in both RGB images/frames as well as Error Level Analysis images. Results show that the proposed approach exhibits the detection accuracy of 73.39 % and 57.45 % for the Deepfake Detection Challenge (DFDC) and the Celeb-DF datasets respectively. These results are, however, from a preliminary implementation of the proposed approach. As part of future work, population-based optimization techniques such as Particle Swarm Optimization (PSO) will be used to tune the hyper parameters for better performance.","2576-8581","978-1-905824-67-0","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9577010","Deepfake;Deepfake detection;face tampering;deep learning;convolutional neural networks;Capsule networks;Error Level Analysis","Training;Analytical models;Computational modeling;Neural networks;Computer architecture;Particle swarm optimization;Optimization","","1","","21","","26 Oct 2021","10-14 May 2021","10-14 May 2021","IEEE","IEEE Conferences"
"A Heterogeneous Feature Ensemble Learning based Deepfake Detection Method","J. Zhang; K. Cheng; G. Sovernigo; X. Lin","School of Computer Science, Hubei University of Technology, China; School of Computer Science, Hubei University of Technology, China; School of Computer Science, University of Guelph, Canada; School of Computer Science, University of Guelph, Canada",ICC 2022 - IEEE International Conference on Communications,"11 Aug 2022","2022","","","2084","2089","The Deepfake technique can swap the face of a person with the face of another person in an image or a video which may cause a public security problem. Recently, researchers have focused on detecting deepfake images by deep learning. However some recent works have observed that detectors trained on images produced by one deepfake model perform poorly when tested on others. In this paper we propose to detect deepfake images through heterogeneous feature ensemble learning. We first extract gray gradient features, spectrum features and texture features from real and fake face images, then integrate them into an ensemble feature vector through a flatten process, and finally adopt a back-propagation neural network to train a deepfake detector with the feature vector. Experimental results show that our approach achieves better detection accuracy compared with several state-of-the-art deepfake detectors.","1938-1883","978-1-5386-8347-7","10.1109/ICC45855.2022.9838630","Hubei University of Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9838630","Deepfake detection;Ensemble Learning;Heterogeneous Feature;Neural Network","Deep learning;Deepfakes;Forensics;Conferences;Neural networks;Detectors;Feature extraction","","11","","23","IEEE","11 Aug 2022","16-20 May 2022","16-20 May 2022","IEEE","IEEE Conferences"
"Securing Phygital Gameplay: Strategies for Video-Replay Spoofing Detection","V. D. Huszár; V. K. Adhikarla","Computer Vision and Artificial Intelligence Team, International Federation of Teqball, Budapest, Hungary; Computer Vision and Artificial Intelligence Team, International Federation of Teqball, Budapest, Hungary",IEEE Access,"15 Apr 2024","2024","12","","52282","52301","Physical Virtual Sports (PVS) utilize digital technologies for the analysis and evaluation of sports performances. This research article addresses the challenge of detecting video-replay spoofing in PVS, with a specific focus on a digital football sport aimed at assessing and improving a player’s football juggling skills. In the context of the growing presence of digital coaches as well as PVS, accurate assessment of player performance and identification of deceptive practices in these applications are paramount. The proliferation of sophisticated technologies, such as deepfake algorithms and computer vision techniques, has facilitated the manipulation of video replays, deceiving both viewers and officials. To tackle the challenges associated with video-replay spoofing, this article introduces a meticulously curated dataset comprising 600 players engaged in the digital football sport. Additionally, the dataset includes video-replay spoofing videos captured on a wide range of display devices. A deep learning-based model is developed and trained on this dataset, achieving an accuracy rate of approximately 95%. Generalization studies were also conducted to assess the model’s ability to generalize to unseen scenarios and datasets. The ROC-AUC score highlighted the model’s discriminative power across different threshold values, validating its effectiveness in distinguishing between genuine and spoofed video replays. The results demonstrate that our trained model exhibited consistent performance across multiple public face biometric spoofing datasets, underscoring its robustness against sophisticated video-replay attacks in various domains. Additionally, ablation studies were carried out by systematically removing or modifying the model’s backbone architectures to analyze their effects on detection accuracy and reliability. Furthermore, computational complexity analysis was presented to evaluate the model’s efficiency in terms of time and space requirements. The findings underscore the scientific significance and relevance of video replay spoof detection in PVS. By presenting a novel dataset (https://www.fiteq.org/research) and employing an advanced deep learning approach, this article contributes to the scientific community’s understanding and progress in combating fraudulent practices, ultimately preserving the integrity and fairness of digital sports applications.","2169-3536","","10.1109/ACCESS.2024.3385373","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10491248","Active virtual sports;computer vision;dataset;deepfake detection;deep learning;deceptive practices;digital sports applications;fraudulent practices;integrity;video-replay spoofing","Games;Sports;Face recognition;Histograms;Biometrics (access control);Biological system modeling;Virtual reality;Deepfakes;Digital systems;Fraud;Videos","","4","","78","CCBYNCND","4 Apr 2024","2024","","IEEE","IEEE Journals"
"Security Strengthen and Detection of Deepfake Videos and Images Using Deep Learning Techniques","S. Talreja; A. Bindle; V. Kumar; I. Budhiraja; P. Bhattacharya","School of Computer Science Engineering and Technology, Bennett University, Greater Noida, India; Electronics and Communication Engineering, Maharishi Markandeswar University, Mullana-Ambala, Haryana; Computer Science and Engineering, Amity School of Engineering and Technology, Amity University, Kolkata, India; School of Computer Science Engineering and Technology, Bennett University, Greater Noida, India; Computer Science and Engineering, Amity School of Engineering and Technology, Amity University, Kolkata, India",2024 IEEE International Conference on Communications Workshops (ICC Workshops),"12 Aug 2024","2024","","","1834","1839","The identification of fraudulent movies or images created using deep learning algorithms is the subject of this research and attempts an in-depth investigation of Deepfake Detection. Deepfakes are created by manipulating or replacing certain parts of an original video or image using machine learning algorithms, usually concentrating on face features. Deepfake detection's main goal is to precisely recognize and distinguish these altered media from real movies and photos. This study looks at a number of deepfake detection techniques, including forensic methods, machine learning algorithms, and picture analysis. These approaches' efficiency and performance are assessed based on their capacity to accurately identify and categories deep-fakes. The paper also examines the difficulties and restrictions of deepfake detection, such as the development of more complex and convincing deepfakes. Further, prospective uses and future possibilities for deepfake detection research are examined, with an emphasis on improving detection skills and creating effective countermeasures. Overall, this research offers insightful information about cutting-edge methods and developments in Deepfake Detection, giving a greater comprehension of its importance in resolving the issues brought on by manipulated media in the current digital era.","2694-2941","979-8-3503-0405-3","10.1109/ICCWorkshops59551.2024.10615811","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10615811","DeepFake Detection;Deep Learning;Machine Learning","Deep learning;Deepfakes;Machine learning algorithms;Image resolution;Conferences;Forensics;Face recognition","","2","","20","IEEE","12 Aug 2024","9-13 June 2024","9-13 June 2024","IEEE","IEEE Conferences"
"Fighting Malicious Media Data: A Survey on Tampering Detection and Deepfake Detection","J. Wang; Z. Li; C. Zhang; J. Chen; Z. Wu; L. S. Davis; Y. -G. Jiang","Institute of Trustworthy Embodied AI, Fudan University, Shanghai, China; Institute of Trustworthy Embodied AI, Fudan University, Shanghai, China; Institute of Trustworthy Embodied AI, Fudan University, Shanghai, China; Institute of Trustworthy Embodied AI, Fudan University, Shanghai, China; Institute of Trustworthy Embodied AI, Fudan University, Shanghai, China; Center for Automation Research, University of Maryland, College Park, MD, USA; Institute of Trustworthy Embodied AI, Fudan University, Shanghai, China",Proceedings of the IEEE,"28 Jul 2025","2025","113","3","287","311","Online media data, in the form of images and videos, are becoming mainstream communication channels. However, recent advances in deep learning (DL), particularly deep generative models, open the doors for producing perceptually convincing images and videos at a low cost, which not only poses a serious threat to the trustworthiness of digital information but also has severe societal implications. This motivates a growing interest in research in media tampering detection (TD), i.e., using DL techniques to examine whether media data have been maliciously manipulated. Depending on the content of the targeted images, media forgery could be divided into image tampering and Deepfake techniques. The former typically moves or erases the visual elements in ordinary images, while the latter manipulates the expressions and even the identity of human faces. Accordingly, the means of defense include image TD and Deepfake detection (DFD), which share a wide variety of properties. In this article, we provide a comprehensive review of the current media TD approaches and discuss the challenges and trends in this field for future research.","1558-2256","","10.1109/JPROC.2025.3576367","National Natural Science Foundation of Project(grant numbers:62072116); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11048678","Deepfake detection (DFD);media forensics;tampering detection (TD)","Media;Deepfakes;Surveys;Forgery;Forensics;Visualization;Training;Fake news;Social networking (online);Information integrity","","","","384","IEEE","23 Jun 2025","March 2025","","IEEE","IEEE Journals"
"Deepfake Detection Using EfficientNet and XceptionNet","B. Yasser; J. Hani; S. El-Gayar; O. Amgad; N. Ahmed; H. M. Ebied; H. Amr; M. Salah","Software Engineering Faculty of Computer and Information Sciences, Ain Shams University, Cairo, Egypt; Software Engineering Faculty of Computer and Information Sciences, Ain Shams University, Cairo, Egypt; Computer Science Department, Faculty of Computer and Information Sciences, Ain Shams University, Cairo, Egypt; Software Engineering Faculty of Computer and Information Sciences, Ain Shams University, Cairo, Egypt; Software Engineering Faculty of Computer and Information Sciences, Ain Shams University, Cairo, Egypt; Scientific Computing Department, Faculty of Computer and Information Sciences, Ain Shams University, Cairo, Egypt; Software Engineering Faculty of Computer and Information Sciences, Ain Shams University, Cairo, Egypt; Software Engineering Faculty of Computer and Information Sciences, Ain Shams University, Cairo, Egypt",2023 Eleventh International Conference on Intelligent Computing and Information Systems (ICICIS),"18 Jan 2024","2023","","","598","603","The increasing prevalence of manipulated media, particularly deepfake videos, poses significant challenges in distinguishing real from fake content. This paper addresses the issue of detecting deepfake videos using advanced CNN architectures such as EfficientNet-B4 and XceptionNet. The FF++ and Celeb-DF (v2) datasets are used to compare real and fake videos. The methodology involves preprocessing the Celeb- DF dataset by extracting frames and isolating faces, training the models, and evaluating their performance using log loss and Area Under the Curve (AUC) metrics. The study shows that both models are effective in accurately classifying real and fake videos and highlights the importance of continuously updating deepfake detection algorithms in response to evolving deepfake generation techniques.","2831-5952","979-8-3503-2210-1","10.1109/ICICIS58388.2023.10391114","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10391114","Deepfake Detection;Extracting Frames;cropping faces;accuracy;XceptionNet;EfficientNet","Training;Measurement;Deepfakes;Computational modeling;Computer architecture;Detection algorithms;Faces","","6","","21","IEEE","18 Jan 2024","21-23 Nov. 2023","21-23 Nov. 2023","IEEE","IEEE Conferences"
"DeepFake Videos Detection Using Self-Supervised Decoupling Network","J. Zhang; J. Ni; H. Xie","School of Computer Science and Engineering, Sun Yat-sen University, China; School of Computer Science and Engineering, Sun Yat-sen University, China; School of Computer Science and Engineering, Sun Yat-sen University, China",2021 IEEE International Conference on Multimedia and Expo (ICME),"9 Jun 2021","2021","","","1","6","With wide applications of facial manipulation technology, fake images and videos are becoming a great public concern. Although existing methods for face forgery detection could achieve fairly good results on public database, most of them perform poorly when the fake images/videos are compressed as they are usually done in social networks. To tackle this issue, a self-supervised decoupling network (SSDN), that incorporates compression irrelevance, is proposed in this paper. The proposed model learns two separate feature representations for the suspect videos, i.e., authenticity and compression. A joint self-supervised strategy is then utilized for feature decoupling, in which, the similarity decoupling is carried out by similarity learning on authentic features, whereas for adversarial decoupling, the proposed SSDN model is trained in an adversarial manner for robust feature learning. Experimental results show that the SSDN outperforms the state-of-the-art methods for deepfake detection against compression attacks on public datasets, e.g., FaceForensics++.","1945-788X","978-1-6654-3864-3","10.1109/ICME51207.2021.9428368","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9428368","DeepFake detection;self-supervised decoupling;robustness","Image coding;Social networking (online);Databases;Conferences;Feature extraction;Forgery;Task analysis","","19","","24","IEEE","9 Jun 2021","5-9 July 2021","5-9 July 2021","IEEE","IEEE Conferences"
"DeePhyNet: Toward Detecting Phylogeny in Deepfakes","K. Thakral; H. Agarwal; K. Narayan; S. Mittal; M. Vatsa; R. Singh","Department of Computer Science and Engineering, Indian Institute of Technology Jodhpur, Jodhpur, India; Department of Electrical Engineering, Indian Institute of Technology Jodhpur, Jodhpur, India; Department of Computer Science and Engineering, Indian Institute of Technology Jodhpur, Jodhpur, India; Department of Computer Science and Engineering, Indian Institute of Technology Jodhpur, Jodhpur, India; Department of Computer Science and Engineering, Indian Institute of Technology Jodhpur, Jodhpur, India; Department of Computer Science and Engineering, Indian Institute of Technology Jodhpur, Jodhpur, India","IEEE Transactions on Biometrics, Behavior, and Identity Science","27 Dec 2024","2025","7","1","132","145","Deepfakes have rapidly evolved from their inception as a niche technology into a formidable tool for creating hyper-realistic manipulated content. With the ability to convincingly manipulate videos, images, and audio, deepfake technology can be used to create fake news, impersonate individuals, or even fabricate events, posing significant threats to public trust and societal stability. The technology has already been used to generate deepfakes for a number of the above-listed applications. Extending the complexities, this paper introduces the concept of deepfake phylogeny. Currently, multiple deepfake generation algorithms can also be used sequentially to create deepfakes in a phylogenetic manner. In such a scenario, deepfake detection, ingredient model signature detection, and phylogeny sequence detection performances have to be optimized. To address the challenge of detecting such deepfakes, we propose DeePhyNet, which performs three tasks: it first differentiates between real and fake content; it next determines the signature of the generative algorithm used for deepfake creation to determine which algorithm has been used for generation, and finally, it also predicts the phylogeny of algorithms used for generation. To the best of our knowledge, this is the first algorithm that performs all three tasks together for deepfake media analysis. Another contribution of this research is the DeePhyV2 database to incorporate multiple deepfake generation algorithms including recently proposed diffusion models and longer phylogenetic sequences. It consists of 8960 deepfake videos generated using four different generation techniques. The results on multiple protocols and comparisons with state-of-the-art algorithms demonstrate that the proposed algorithm yields the highest overall classification results across all three tasks.","2637-6407","","10.1109/TBIOM.2024.3487482","Ministry of Electronics and Information Technology, Government of India; Prime Ministers Research Fellowship; IBM PhD Fellowship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10737137","Deepfakes;phylogeny;deepfake detection","Deepfakes;Phylogeny;Faces;Face recognition;Feature extraction;Prediction algorithms;Generative adversarial networks;Forgery;Fingerprint recognition","","","","77","IEEE","28 Oct 2024","Jan. 2025","","IEEE","IEEE Journals"
"Deepfake Image Detection using Deep Learning","A. K. S; A. K. M; R. R. Vincent; U. U. Hegde; A. M. S; N. N. Pasha","Dept. of Computer Studies, Symbiosis Institute of Computer Studies and Research (SICSR), Pune, India; Dept. of Information Science and Engineering, Bio-Intelligence Lab, Presidency University, Bangaluru, India; Dept. of Computer Science and Engineering, Bio-Intelligence Lab, Presidency University, Bangaluru, India; Dept. of Computer Science and Engineering, Bio-Intelligence Lab, Presidency University, Bangaluru, India; Dept. of Computer Science and Engineering, Bio-Intelligence Lab, Presidency University, Bangaluru, India; Dept. of Computer Science and Engineering, Bio-Intelligence Lab, Presidency University, Bangaluru, India",2025 International Conference on Artificial Intelligence and Data Engineering (AIDE),"12 May 2025","2025","","","492","497","Deepfake images are generated by modifying existing visuals and are frequently exploited in harmful ways. When executed proficiently, these images can be almost indistinguishable from authentic ones. The increasing development of deep learning techniques has largely fueled the increase in deepfake content. While numerous techniques are available for creating deepfake images, the most commonly employed are GANs and autoencoders. This paper presents a way to make deepfake detection more accurate by using a combination of the YOLOv8 model and a Recurrent Neural Network (RNN). YOLOv8 extracts spatial details from the images, while the RNN identifies temporal patterns and subtle irregularities across image frames, signaling potential manipulation. This methodology presents an efficient solution for identifying deepfake images and reducing their misuse.","","979-8-3315-2751-8","10.1109/AIDE64228.2025.10987437","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10987437","Deepfake detection;Recurrent Neural Networks (RNN);YOLO v8;GANs","YOLO;Deep learning;Deepfakes;Adaptation models;Analytical models;Visualization;Recurrent neural networks;Accuracy;Computational modeling;Faces","","","","20","IEEE","12 May 2025","6-7 Feb. 2025","6-7 Feb. 2025","IEEE","IEEE Conferences"
"Generalized Deepfake Detection Using Identity, Behavioral, and Geometric Signatures","M. U. Farooq; A. Khan; I. U. Haq; K. M. Malik","College of Innovation and Technology, University of Michigan-Flint, Flint, USA; College of Innovation and Technology, University of Michigan-Flint, Flint, USA; College of Innovation and Technology, University of Michigan-Flint, Flint, USA; College of Innovation and Technology, University of Michigan-Flint, Flint, USA",IEEE Transactions on Computational Social Systems,"","2025","PP","99","1","15","Trust in online media is increasingly compromised by deepfake multimedia, which undermines the authenticity of shared content. Existing detection techniques often perform well only on specific types of deepfakes, limiting their generalization ability and making them vulnerable in real-world applications. To address this, we propose a novel deepfake detection framework featuring an effective feature descriptor that integrates deep identity, behavioral, and geometric (DBaG) signatures, along with a classifier named DBaGNet. The DBaGNet classifier utilizes the extracted DBaG signatures and applies a triplet loss objective to enhance generalized representation learning for improved classification. These comprehensive DBaG signatures capture both facial geometry inconsistencies and behavioral cues, improving the detection of diverse deepfake types and enhancing generalization. We evaluate our approach using six benchmark deepfake datasets: WLDR, CelebDF, DFDC, FaceForensics++, DFD, and NVFAIR. Cross-dataset evaluations demonstrate significant performance gains over several state-of-the-art methods.","2329-924X","","10.1109/TCSS.2025.3588348","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11107183","Behavioral biometrics;DBaG;deepfake detection;face forgery detection;multimedia forensics","Deepfakes;Feature extraction;Faces;Prototypes;Deep learning;Visualization;Streaming media;Forgery;Face recognition;Detectors","","","","","IEEE","1 Aug 2025","","","IEEE","IEEE Early Access Articles"
"AV-Lip-Sync+: Leveraging AV-HuBERT to Exploit Multimodal Inconsistency for Deepfake Detection of Frontal Face Videos","S. A. Shahzad; A. Hashmi; Y. -T. Peng; Y. Tsao; H. -M. Wang","Social Networks and Human-Centered Computing Program, Taiwan International Graduate Program, Academia Sinica, Taipei, Taiwan; Social Networks and Human-Centered Computing Program, Taiwan International Graduate Program, Academia Sinica, Taipei, Taiwan; Department of Computer Science, National Chengchi University, Taipei, Taiwan; Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan; Institute of Information Science, Academia Sinica, Taipei, Taiwan",IEEE Transactions on Human-Machine Systems,"2 Dec 2025","2025","55","6","973","982","Multimodal manipulations (also known as audio-visual deepfakes) make it difficult for unimodal deepfake detectors to detect forgeries in multimedia content. To avoid the spread of false propaganda and fake news, timely detection is crucial. The damage to either modality (i.e., visual or audio) can only be discovered through multimodal models that can exploit both pieces of information simultaneously. However, previous methods mainly adopt unimodal video forensics and use supervised pretraining for forgery detection. This study proposes a new method based on a multimodal self-supervised-learning (SSL) feature extractor to exploit inconsistency between audio and visual modalities for multimodal video forgery detection. We use the transformer-based SSL pretrained Audio-Visual HuBERT (AV-HuBERT) model as a visual and acoustic feature extractor and a multiscale temporal convolutional neural network to capture the temporal correlation between the audio and visual modalities. Since AV-HuBERT only extracts visual features from the lip region, we also adopt another transformer-based video model to exploit facial features and capture spatial and temporal artifacts caused during the deepfake generation process. Experimental results show that our model outperforms all existing models and achieves new state-of-the-art performance on the FakeAVCeleb and DeepfakeTIMIT datasets.","2168-2305","","10.1109/THMS.2025.3618409","National Science and Technology Council(grant numbers:NSTC 111-2221-E-001-002,NSTC 113-2221-E-004-001-MY3,NSTC 113-2221-E-004-006-MY2); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11214430","Audio-visual;audio-visual deepfake detection;deepfake detection;deepfakes;inconsistency;lip syn;multimedia forensics;multimodality;video forgery","Deepfakes;Visualization;Feature extraction;Forgery;Lips;Detectors;Forensics;Faces;Streaming media;Social networking (online);Audio-visual systems","","","","83","IEEE","22 Oct 2025","Dec. 2025","","IEEE","IEEE Journals"
"An Analysis of Recent Advances in Deepfake Image Detection in an Evolving Threat Landscape","S. M. Abdullah; A. Cheruvu; S. Kanchi; T. Chung; P. Gao; M. Jadliwala; B. Viswanath",Virginia Tech; Virginia Tech; Virginia Tech; Virginia Tech; Virginia Tech; Virginia Tech; Virginia Tech,2024 IEEE Symposium on Security and Privacy (SP),"5 Sep 2024","2024","","","91","109","Deepfake or synthetic images produced using deep generative models pose serious risks to online platforms. This has triggered several research efforts to accurately detect deepfake images, achieving excellent performance on publicly available deepfake datasets. In this work, we study 8 state-of-the-art detectors and argue that they are far from being ready for deployment due to two recent developments. First, the emergence of lightweight methods to customize large generative models, can enable an attacker to create many customized generators (to create deepfakes), thereby substantially increasing the threat surface. We show that existing defenses fail to generalize well to such user-customized generative models that are publicly available today. We discuss new machine learning approaches based on content-agnostic features, and ensemble modeling to improve generalization performance against user-customized models. Second, the emergence of vision foundation models—machine learning models trained on broad data that can be easily adapted to several downstream tasks—can be misused by attackers to craft adversarial deepfakes that can evade existing defenses. We propose a simple adversarial attack that leverages existing foundation models to craft adversarial samples without adding any adversarial noise, through careful semantic manipulation of the image content. We highlight the vulnerabilities of several defenses against our attack, and explore directions leveraging advanced foundation models and adversarial training to defend against this new threat.","2375-1207","979-8-3503-3130-1","10.1109/SP54263.2024.00194","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10646853","deepfake image;foundation models;generative models;deepfake detection","Training;Deepfakes;Adaptation models;Privacy;Noise;Semantics;Generators","","13","","80","IEEE","5 Sep 2024","19-23 May 2024","19-23 May 2024","IEEE","IEEE Conferences"
"A comprehensive study on multimedia DeepFakes","A. Boutadjine; F. Harrag; K. Shaalan; S. Karboua","Computer Science Departement, Ferhat Abbas University Setif 1, Setif, Algeria; Computer Science Departement, Ferhat Abbas University Setif 1, Setif, Algeria; Faculty of Engineering and IT, The British University in Dubai, Dubai, United Arab Emirates; Computer Science Departement, Ferhat Abbas University Setif 1, Setif, Algeria","2023 International Conference on Advances in Electronics, Control and Communication Systems (ICAECCS)","24 Apr 2023","2023","","","1","6","Since the entry of so-called DeepFakes in the development of fake multimedia, this late has marked a turning point and emerged as a major issue, although visual and aural media manipulations date back to the beginning of media itself. Thanks to this technology, the detection of altered and generated material has recently received more attention since the human ability to identify DeepFakes has significantly been far less effective than that of deep learning models. organizations need to be ready as there are countless ways to deceive using convincingly altered photos, videos, and audio, such as perpetrating fraud, damaging reputations, extorting money or influencing public opinion during elections, which undoubtedly impacts society. In this regard, there is a critical need for automated solutions that can identify fake multimedia material and prevent the spread of dangerous misinformation. This article aims to give a comprehensive review of DeepFakes and a summary of the technology that underpins it. We provide information on various DeepFake detection algorithms, identify potential dangers of this frightening modern phenomenon, and highlight future research challenges.","","978-1-6654-6310-2","10.1109/ICAECCS56710.2023.10104814","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10104814","DeepFake;artificial intelligence;deep learning;DeepFake detection.","Deepfakes;Visualization;Biological system modeling;Voting;Psychology;Streaming media;Turning","","7","","31","IEEE","24 Apr 2023","6-7 March 2023","6-7 March 2023","IEEE","IEEE Conferences"
"Training-Free Deepfake Detection: An Identity-Guided Approach Using Facial Embeddings","M. Aquilina; T. M. Wani; I. Amerini","Sapienza University of Rome, Italy; Sapienza University of Rome, Italy; Sapienza University of Rome, Italy",2025 International Joint Conference on Neural Networks (IJCNN),"14 Nov 2025","2025","","","1","7","Artificially generated images that exploit personal identity to undermine individual dignity present a significant challenge. Conventional detection methods, which rely on classifiers trained to recognize artifacts specific to known generators, often fail when confronted with forgeries from unknown sources. This paper introduces a training-free framework for deepfake detection that leverages pre-trained models and facial embeddings. Our approach, using models exclusively trained on authentic images, retrieves a set of genuine reference images corresponding to the target image’s identity and applies specialized operations on the resulting facial embeddings to assess authenticity. The technique achieves detection accuracies approaching 90%, underscoring its potential as a robust countermeasure against identity-based deepfake generation.","2161-4407","979-8-3315-1042-8","10.1109/IJCNN64981.2025.11228290","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11228290","deepfake detection;training-free;cosine similarity;sensitivity;ensemble","Deepfakes;Sensitivity;Accuracy;Neural networks;Generators;Forgery","","","","26","IEEE","14 Nov 2025","30 June-5 July 2025","30 June-5 July 2025","IEEE","IEEE Conferences"
"IDCNet: Image Decomposition and Cross-View Distillation for Generalizable Deepfake Detection","Z. Wang; Y. Chen; Y. Yao; M. Han; W. Xing; M. Li","School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China; Key Laboratory of Knowledge Engineering with Big Data, Ministry of Education, the School of Computer Science and Information Engineering, and the Intelligent Interconnected Systems Laboratory of Anhui Province, Hefei University of Technology, Hefei, China; Key Laboratory of Knowledge Engineering with Big Data, Ministry of Education, the School of Computer Science and Information Engineering, and the Intelligent Interconnected Systems Laboratory of Anhui Province, Hefei University of Technology, Hefei, China; Binjiang Institute of Zhejiang University, Hangzhou, China; Binjiang Institute of Zhejiang University, Hangzhou, China; Key Laboratory of Knowledge Engineering with Big Data, Ministry of Education, the School of Computer Science and Information Engineering, and the Intelligent Interconnected Systems Laboratory of Anhui Province, Hefei University of Technology, Hefei, China",IEEE Transactions on Information Forensics and Security,"11 Aug 2025","2025","20","","8373","8386","Existing deepfake detectors predominantly process entire facial images as input, which limits their sensitivity to local forgery cues due to representation bias and information loss through CNN feature aggregation. To address these limitations, we propose IDCNet, a novel deepfake detection framework based on image decomposition and cross-view distillation. Our key insight is that decomposing images into complementary views enables specialized processing of global and local forgery cues, while cross-view distillation facilitates their mutual enhancement. Specifically, the framework employs a lightweight U-Net generator with a dual-objective mechanism to decompose input images into global content and local detail views, optimized through reconstruction and classification losses. A cross-view distillation strategy is then applied to enhance complementary feature learning between views. Furthermore, to integrate local artifact information into existing detection models without architectural modifications, we propose a feature alignment method. Extensive experiments across 14 forgery methods demonstrate the effectiveness of our approach, achieving up to 4.4% AUC improvement on the CDFV2 dataset compared to state-of-the-art methods. The source code is available at: https://github.com/wangzhiyuan120/idcnet","1556-6021","","10.1109/TIFS.2025.3593353","National Natural Science Foundation of China (NSFC)(grant numbers:62372149,U23A20303); Key Laboratory of Knowledge Engineering with Big Data (the Ministry of Education of China)(grant numbers:BigKEOpen2025-04); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11098842","Face forgery detection;deepfake detection;multi-view learning;representation disentanglement;mutual information","Deepfakes;Forgery;Feature extraction;Faces;Image decomposition;Training;Generators;Facial animation;Detectors;Knowledge transfer","","1","","69","IEEE","28 Jul 2025","2025","","IEEE","IEEE Journals"
"Hybrid Federated Deepfake Detection via Residual-Aware Temporal Modeling and Privacy-Preserving Learning","A. Bhatnagar; R. C. Pandey; V. Vishal; A. Singh","Dept. of Information Technology, Rajkiya Engineering College, Ambedkar Nagar, India; Dept. of Information Technology, Rajkiya Engineering College, Ambedkar Nagar, India; Dept. of Information Technology, Rajkiya Engineering College, Ambedkar Nagar, India; Dept. of Information Technology, Rajkiya Engineering College, Ambedkar Nagar, India",2025 IEEE International Conference on Advances in Computing Research On Science Engineering and Technology (ACROSET),"16 Dec 2025","2025","","","1","6","The rapid advancement of deepfake technology has emerged as a significant challenge to the integrity of digital media, decreasing public trust along with compromising privacy and making forensic investigations complex. Current detection methods though effective in controlled settings, struggle to maintain accuracy under privacy-preserving requirements, evolving manipulation strategies or novel synthetic artifacts. To overcome these limitations this paper introduces an innovative detection architecture combining three core components: (A) Anomaly detection through variational autoencoder-derived residual analysis, (B) Sequential pattern recognition via bidirectional LSTM networks and (C) Decentralized model training through federated learning protocols. This multi-modal framework analyses visual inconsistencies and temporal irregularities while maintaining strict data confidentiality simultaneously. Rigorous testing across widely recognized dataset FaceForensics++(FF++) and some others reveal enhanced & effective adaptability to quality degradation, signal interference and domain-shift scenarios compared to conventional approaches. The proposed framework achieves 84.1% to 96.2% detection accuracy under cross- dataset evaluation demonstrating both technical efficacy and practical viability. These advancements address critical gaps in digital content authentication, offering a scalable solution for combating sophisticated synthetic media in real-world applications.","","978-1-6654-5810-8","10.1109/ACROSET66531.2025.11280626","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11280626","Deepfake Detection;Federated Learning;Residual Learning;BiLSTM;Privacy Preservation;Face Forgery;Temporal Modeling","Training;Deepfakes;Privacy;Visualization;Accuracy;Federated learning;Face recognition;Computational modeling;Bidirectional long short term memory;Media","","","","34","IEEE","16 Dec 2025","27-28 Sept. 2025","27-28 Sept. 2025","IEEE","IEEE Conferences"
"Capsule Networks and LSTM Models for Robust Deepfake Detection in Audio and Video","A. M. B.; J. W. Kathrine; S. Kushmitha","Department of Computer Science and Engineering, Karunya Institute of Technology and Sciences, Coimbatore, India; Department of Computer Science and Engineering, Karunya Institute of Technology and Sciences, Coimbatore, India; Department of Computer Science and Engineering, Karunya Institute of Technology and Sciences, Coimbatore, India",2024 International Conference on IoT Based Control Networks and Intelligent Systems (ICICNIS),"10 Jan 2025","2024","","","1569","1576","Due to the fast advancement of deepfakes, notable difficulties have been presented by deepfake innovation in confirming the believability of computerized content, especially on the audio and video front. This paper introduces a new hierarchical model that articulates Capsule Networks within LSTM for the effective and robust deepfake detection in both audio-video frameworks. It is argued that using Capsule Networks, spatial mindfulness capabilities enable the detection of subtle spatial objects in video outlines, whereas, LSTM models capture transient objects in audio arrangements and video frames over time. Thus, our approach implements two designs at once that reached progressed discovery accuracy, addressing spatial and temporary disorders, inherent in deepfake media. It is discovered from the outcomes that this model is very much effective on several datasets suggesting its better generalizing capability in different types of Deepfake media. In its current form, the design of this approach seems capable of being used for the real-time detection task. In this regard, this research provides practical insights into the development of media forensics offering an approach that can be more effective in the role of dissemination of fake news prevention, and fills the gap in the current literature, thus advancing the overall understanding of media forensics.","","979-8-3315-1809-7","10.1109/ICICNIS64247.2024.10823109","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10823109","Deepfake Detection;Capsule Networks;LSTM Networks;Audio Deepfake;Video Deepfake;Face-Swapping;Voice Synthesis;Data Pre-processing;Feature Extraction;Sequence Analysis;Audio Pre-processing;Video Frame Extraction;Digital Content Authenticity;Long-Term Memory;Face and Voice Manipulation","Deepfakes;Technological innovation;Social networking (online);Computational modeling;Forensics;Streaming media;Transformers;Real-time systems;Transient analysis;Long short term memory","","","","15","IEEE","10 Jan 2025","17-18 Dec. 2024","17-18 Dec. 2024","IEEE","IEEE Conferences"
"Xception Net & Vision Transformer: A comparative study for Deepfake Detection","D. Shah; D. Shah; D. Jodhawat; J. Parekh; K. Srivastava","Department of Computer Engineering, Dwarkadas J. Sanghvi College of Engineering, Mumbai, India; Department of Computer Engineering, Dwarkadas J. Sanghvi College of Engineering, Mumbai, India; Department of Computer Engineering, Dwarkadas J. Sanghvi College of Engineering, Mumbai, India; Department of Computer Engineering, Dwarkadas J. Sanghvi College of Engineering, Mumbai, India; Department of CSE - Data Science, Dwarkadas J. Sanghvi College of Engineering, Mumbai, India","2022 International Conference on Machine Learning, Computer Systems and Security (MLCSS)","28 Mar 2023","2022","","","393","398","Deepfakes are artificial media in which an existing image consisting of a person is replaced with someone else. The creation of fake content is not new, but deepfakes are more credible because it involves the use of advanced deep learning techniques to manipulate or generate audio and visual content. In the 21st century, there have been astonishing advancements in Generative Adversarial Networks (GANs) and the use of encoder and decoder architecture [1] which have resulted in various effective methods of deepfake creation such as face-swap, lip-syncing, puppet-master and many more [2]. These methods are not only easily accessible but also get more accurate with time. Earlier deepfakes were detected with deep convolutional neural networks such as EfficientNet B7 and Xception Net, but with further advancements in deepfake generation there comes a need for better deepfake detection methods. This paper analyses the performance of Xception Net which has historically performed well with deepfake detection [3]–[5], Vision transformer [6] which is a fairly new technology and a combination of the two models. The paper proposes a combination of Xception and Vision transformer such that Xception Net is used for feature extraction from the patches and the output is then fed as a sequence to a transformer. This work is expected to assist readers to understand when to use Xception Net, Vision transformer and a combination of the two.","","978-1-6654-5493-3","10.1109/MLCSS57186.2022.00077","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10076744","DFDC (DeepFake Detection Challenge);Deepfake;Xception;Vision Transformer;Deep Learning;Deepfake Detection","Training;Deepfakes;Analytical models;Visualization;Computational modeling;Neural networks;Transformers","","7","","23","IEEE","28 Mar 2023","5-6 Aug. 2022","5-6 Aug. 2022","IEEE","IEEE Conferences"
"Comparative Analysis on Different DeepFake Detection Methods and Semi Supervised GAN Architecture for DeepFake Detection","J. John; B. V. Sherif","Muthoot Institute Of Technology And Science, Kochi, India; Muthoot Institute Of Technology And Science, Kochi, India","2022 Sixth International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)","22 Dec 2022","2022","","","516","521","The use of deep learning results in solving a wide range of real-world problems and applications, but there are some drawbacks along with this positive side. One of the most recent and advanced problems among them is the wide use of deepfakes. Deepfakes are digital tampered images or videos created using different deep learning methods. In a deepfake, the face of a targeted person is superimposed on a source image so that this digital tampered data can be used for digital frauds, blackmailing, pornography etc. With the developments in the deep learning field, it is becoming challenging to distinguish between real and fake manually. So it is essential to do research and development in the area of deepfake detection. In this paper, an extensive discussion and timely overview on different deepfake detection methods are done under the classification of feature-based, temporal-based, and deep feature-based deepfake detection. The comparison study is mainly done based on the key features used, face detection architecture, deep learning architecture, video-based or image-based, the dataset used, frames size, and dataset size used. Along with the comparison, a semisupervised GAN architecture is also proposed and developed to detect the deepfake images.","2768-0673","978-1-6654-6941-8","10.1109/I-SMAC55078.2022.9987265","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9987265","DeepFake;SGAN;DeepFake Detection","Deep learning;Deepfakes;Publishing;Neural networks;Feature extraction;Generative adversarial networks;Fraud","","22","","20","IEEE","22 Dec 2022","10-12 Nov. 2022","10-12 Nov. 2022","IEEE","IEEE Conferences"
"Fine-Grained Open-Set Deepfake Detection via Unsupervised Domain Adaptation","X. Zhou; H. Han; S. Shan; X. Chen","Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China",IEEE Transactions on Information Forensics and Security,"16 Aug 2024","2024","19","","7536","7547","Deepfake represented by face swapping and face reenactment can transfer the appearance and behavioral expressions of a face in one video image to another face in a different video. In recent years, with the advancement of deep learning techniques, deepfake technology has developed rapidly, achieving increasingly realistic effects. Therefore, many researchers have begun to study deepfake detection research. However, most existing studies on deepfake detection are mainly limited to binary classification of real and fake images, rather than identifying different methods in an open-world scenario, leading to failures in dealing with unknown deepfake categories in practice. In this paper, we propose an unsupervised domain adaptation method for fine-grained open-set deepfake detection. Our method first uses labeled data from the source domain for model pre-training to establish the ability of recognizing different deepfake methods in the source domain. Then, the method uses a Network Memorization based Adaptive Clustering (NMAC) approach to cluster unlabeled images in the target domain and designs a Pseudo-Label Generation (PLG) to generate virtual class labels for unknown deepfake categories by matching the adaptive clustering results with the known deepfake categories in the source domain. Finally, we retrain the initial multi-class deepfake detection model using labeled data of the source domain and pseudo-labeled data of the target domain to improve its generalization ability to unknown deepfake classes presented in the target domain. We validate the effectiveness of the proposed method under multiple open-set fine-grained deepfake detection tasks based on three deepfake datasets (ForgerNet, FaceForensics++, and FakeAVCeleb). Experimental results show that our method has better domain generalization ability than the state-of-the-art methods, and achieves promising performance in fine-grained open-set deepfake detection.","1556-6021","","10.1109/TIFS.2024.3435440","National Key Research and Development Program of China(grant numbers:2021ZD0111901); National Natural Science Foundation of China(grant numbers:62176249); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10614208","Deepfake detection;domain adaptation;unsupervised learning;fine-grained classification","Deepfakes;Adaptation models;Feature extraction;Data models;Face recognition;Training;Faces","","6","","64","IEEE","29 Jul 2024","2024","","IEEE","IEEE Journals"
"GTA-Net: A Robust Method for Deepfake Face Image Detection","Q. Yu; X. Wang; M. Jia; N. Bai; J. Hou; D. Liu","Xi'an University of Technology, Xi'an, China; Xi'an University of Technology, Xi'an, China; Xi'an University of Technology, Xi'an, China; Xi'an University of Technology, Xi'an, China; Xi'an University of Technology, Xi'an, China; Xi'an University of Technology, Xi'an, China",2023 China Automation Congress (CAC),"19 Mar 2024","2023","","","4576","4581","The rapid advancement of artificial intelligence technology has resulted in the emergence of deepfake, which has had a significant impact on various fields due to its realistic effects. Addressing the challenges posed by deepfake has become a crucial area of research. In this study, we propose a two-stream network framework, GTA-Net, for the detection of deepfake face images. The framework comprises a Global Residual Attention module (GRA), a Texture Feature Saliency module (TFS), and an Attention Feature Fusion module (AFF). We incorporate Local Binary Patterns (LBP) features into the network input to guide the decision-making process of the model towards prominent texture features, thereby enhancing detection accuracy. Additionally, we employ a residual attention mechanism to focus on specific deepfake-generated features and improve robustness by avoiding interference from content-preserving manipulations. Experimen-tal results show that the proposed method has high detection accuracy and strong robustness against degraded datasets, and generalization for cross-dataset detection.","2688-0938","979-8-3503-0375-9","10.1109/CAC59555.2023.10451644","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10451644","deepfake detection;texture feature saliency;robustness;generalization","Deepfakes;Adaptation models;Decision making;Focusing;Interference;Feature extraction;Robustness","","1","","28","IEEE","19 Mar 2024","17-19 Nov. 2023","17-19 Nov. 2023","IEEE","IEEE Conferences"
"Lightweight detection method for deepfake face video","R. Yang; D. Xu; Y. Cheng","Shanghai Institute of Technology, Shanghai, China; Shanghai Institute of Technology, Shanghai, China; East China University of Political Science and Law, Shanghai, China",2023 8th International Conference on Intelligent Informatics and Biomedical Sciences (ICIIBMS),"14 Dec 2023","2023","8","","68","75","This paper proposes a lightweight fake facial video classification detection model to address the issues of insufficient accuracy, poor robustness, and excessive parameters in existing forgery face video detection models. The model utilizes an improved version of EfficientNetV2-S as the backbone network for feature extraction. The MTCNN algorithm is employed to extract the facial region and perform alignment, while data augmentation techniques are applied to enhance the model's robustness. The pre-processed data is then fed into the backbone network for classification detection. Furthermore, in order to improve the performance of the network model, reduce the influence of network parameters, and decrease model complexity, the structure of the backbone network is streamlined and the composition of the network is adjusted. Additionally, the CBAM attention module is introduced to enable the shallow model to capture more facial details. Experimental results demonstrate that compared to the original EfficientNetV2-S model, the proposed model achieves a 50% reduction in parameter count. Moreover, it achieves accuracy improvements of 1.1%, 2.8%, and 3.1% on the FaceForensice++, Celeb-DF-v1, and DFDC datasets, respectively. When compared with the Xception, CapsuleNet, and DefakeHop models in the field, varying degrees of improvement are also observed.","2189-8723","979-8-3503-6956-4","10.1109/ICIIBMS60103.2023.10347675","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10347675","Deepfake Detection;EfficientnetV2-S;MTCNN;CBAM;Lion Optimization","Training;Deepfakes;Feature extraction;Robustness;Forgery;Resource management;Informatics","","","","19","IEEE","14 Dec 2023","23-25 Nov. 2023","23-25 Nov. 2023","IEEE","IEEE Conferences"
"Texture, Shape and Order Matter: A New Transformer Design for Sequential DeepFake Detection","Y. Li; Y. Li; X. Wang; B. Wu; J. Zhou; J. Dong","School of Computer Science and Technology, Ocean University of China; School of Computer Science and Technology, Ocean University of China; University at Albany, SUNY; School of Data Science, The Chinese University of Hong Kong, Shenzhen, China; School of Computer Science and Technology, Ocean University of China; School of Computer Science and Technology, Ocean University of China",2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV),"8 Apr 2025","2025","","","202","211","Sequential DeepFake detection is an emerging task that predicts the manipulation sequence in order. Existing methods typically formulate it as an image-to-sequence problem, employing conventional Transformer architectures. However, these methods lack dedicated design and consequently result in limited performance. As such, this paper describes a new Transformer design, called TSOM, by exploring three perspectives: Texture, Shape, and Order of Manipulations. Our method features four major improvements: we describe a new texture-aware branch that effectively captures subtle manipulation traces with a Diversiform Pixel Difference Attention module. Then we introduce a Multi-source Cross-attention module to seek deep correlations among spatial and sequential features, enabling effective modeling of complex manipulation traces. To further enhance the cross-attention, we describe a Shape-guided Gaussian mapping strategy, providing initial priors of the manipulation shape. Finally, observing that the subsequent manipulation in a sequence may influence traces left in the preceding one, we intriguingly invert the prediction order from forward to backward, leading to notable gains as expected. Extensive experimental results demonstrate that our method outperforms others by a large margin, highlighting the superiority of our method.","2642-9381","979-8-3315-1083-1","10.1109/WACV61041.2025.00030","National Natural Science Foundation of China(grant numbers:62402464); Shandong Natural Science Foundation(grant numbers:ZR2024QF035); China Postdoctoral Science Foundation(grant numbers:2021TQ0314,2021M703036); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10943824","deepfake detection;multimedia forensics","Deepfakes;Computer vision;Correlation;Shape;Annotations;Design methodology;Transformers","","1","","40","IEEE","8 Apr 2025","26 Feb.-6 March 2025","26 Feb.-6 March 2025","IEEE","IEEE Conferences"
"Blockchain-Driven Defense Against Deepfakes on Social Media Platforms","A. Elgalaly; A. Fahmy; A. Ahmed; M. Youssif; M. Essam; S. A. E. Mohamed","Computer Science and Information Technology, Egypt-Japan University of Science and Technology (E-JUST), Alexandria, Egypt; Computer Science and Information Technology, Egypt-Japan University of Science and Technology (E-JUST), Alexandria, Egypt; Computer Science and Information Technology, Egypt-Japan University of Science and Technology (E-JUST), Alexandria, Egypt; Computer Science and Information Technology, Egypt-Japan University of Science and Technology (E-JUST), Alexandria, Egypt; Computer Science and Information Technology, Egypt-Japan University of Science and Technology (E-JUST), Alexandria, Egypt; Computer Science and Information Technology, Egypt-Japan University of Science and Technology (E-JUST), Alexandria, Egypt","2024 12th International Japan-Africa Conference on Electronics, Communications, and Computations (JAC-ECC)","9 Jul 2025","2024","","","170","175","The rapid advancement of Artificial Intelligence (AI) has driven a surge in the spread of falsified digital content, particularly through deepfake technologies that generate highly realistic but fake videos, images, and audio. Such manipulated media can distort reality, damage reputations, and erode public trust. To address these risks, this paper proposes a blockchainbased framework designed to protect the authenticity and integrity of user-generated video content on social media platforms. The framework integrates two AI models: Multi-task Cascaded Convolutional Neural Network (MTCNN) for facial verification and Artificial Neural Network (ANN) for voice recognition, ensuring that both visual and audio identities are authenticated before publication. Once verified, blockchain records consent immutably using smart contracts, creating a secure log of authorization for accountability and transparency. This paper also explores blockchain’s role as a decentralized verification tool, examining deepfake detection methods, benchmarks, and the application of blockchain to enhance media reliability within a landscape increasingly susceptible to sophisticated manipulation.","2690-3385","979-8-3315-3144-7","10.1109/JAC-ECC64419.2024.11061235","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11061235","Deepfake detection methods;Multi-task cascaded convolutional neural networks;Social Engineering;Social media platforms;Blockchain technology;Decentralized verification","Deepfakes;Visualization;Social networking (online);Surge protection;Multitasking;Blockchains;Convolutional neural networks;Artificial intelligence;Surges;Standards","","","","16","IEEE","9 Jul 2025","16-18 Dec. 2024","16-18 Dec. 2024","IEEE","IEEE Conferences"
"ResNeXt-50 and LSTM for Deepfake Detection","F. Kamil; E. M. Maharani; R. Rahmania","Computer Science Department, School of Computer Science, Bina Nusantara University, Bandung, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Bandung, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Bandung, Indonesia",2025 IEEE International Conference on Artificial Intelligence for Learning and Optimization (ICoAILO),"16 Sep 2025","2025","","","113","118","Deepfake technology presents a significant threat to digital security due to its increasing sophistication and potential for misuse. This research proposes a Deepfake detection model combining ResNeXt-50 32×4d for spatial feature extraction and Long Short-Term Memory (LSTM) networks for temporal analysis. A video processing pipeline was implemented to isolate and retain facial regions from each frame in the dataset. Videos were decomposed into frames, with faces detected using a pre-trained model of face recognition and frames containing faces were cropped, resized to 256×256 pixels, and saved. Only the first 150 frames per video were processed to maintain temporal order for sequential analysis, with the dataset split into training, validation, and test sets (70%, 20%, 10%). The processed frames were then passed through the ResNeXt-50 for spatial feature extraction and LSTM for temporal dependencies. Evaluated on the Celeb-DF and FaceForensics++ datasets, the model achieved peak accuracies of 99.90% and 99.13%, respectively. Future research will focus on integrating multimodal data and leveraging Explainable AI to further improve detection accuracy and interpretability.","","979-8-3315-6928-0","10.1109/ICoAILO66760.2025.11156046","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11156046","Deepfake Detection;ResNeXt-5032x4d;LSTM;Celeb-DF;FaceForensics++","Training;Deepfakes;Sequential analysis;Accuracy;Pipelines;Feature extraction;Security;Long short term memory;Faces;Optimization","","","","42","IEEE","16 Sep 2025","7-9 Aug. 2025","7-9 Aug. 2025","IEEE","IEEE Conferences"
"Comparative Evaluation of Xception and DenseNet121 for Robust Deepfake Detection","K. Yesugade; R. Jadhav","Department of Computer Engineering, Bharati Vidyapeeth (Deemed to be University), College of Engineering, Pune, India; Department of Computer Engineering, Bharati Vidyapeeth (Deemed to be University), College of Engineering, Pune, India",2025 12th International Conference on Computing for Sustainable Global Development (INDIACom),"21 Aug 2025","2025","","","1","5","Generative adversarial networks (GANs) have led to rapid advancement of deepfake technology, the authenticity of which poses a major challenge to digital media. In this study, two deep learning architectures, Xception and DenseNet121, are evaluated in terms of how well they can differentiate real and fake faces. The models were trained on normalized and augmented data using a curated dataset of $\mathbf{1 4 0, 0 0 0}$ images, half real faces from the Flickr dataset, the other half-synthetic faces generated by StyleGAN. With a training accuracy of 86.31 % and a test accuracy of 73.00 %, Xception model also shows strong feature extraction power. Validation accuracy (77.00 %) of DenseNet121 was slightly better than in validation accuracy (76.00 %) but more sensitive to dataset conditions. Performance graphs served to further illustrate the complementary strengths of the two models, lending support for the applicability of ensemble methods to improve detection robustness. This study highlights the benefits of advanced architectures, data preparation rigour, and ensemble approaches to combat deepfake. Future work should concentrate on improving generalization, interpretability, robustness to evolving challenges in the area of digital media authentication.","","978-93-80544-60-1","10.23919/INDIACom66777.2025.11115841","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11115841","Deepfake detection;Xception;DenseNet121;Deep learning;Digital media authenticity;GAN","Deep learning;Deepfakes;Accuracy;Media;Feature extraction;Data models;Robustness;Ensemble learning;Web sites;Faces","","","","23","","21 Aug 2025","2-4 April 2025","2-4 April 2025","IEEE","IEEE Conferences"
"AI/ML-Based Solution for Detecting Face-Swap Deepfakes","S. S. Patil; A. M; P. M; P. P. C","Dept. Of Computer Science And Engineering, Sri Venkateshwara College Of Engineering, Bengaluru; Dept. Of Computer Science And Engineering, Sri Venkateshwara College Of Engineering, Bengaluru; Dept. Of Computer Science And Engineering, Sri Venkateshwara College Of Engineering, Bengaluru; Dept. Of Computer Science And Engineering, Sri Venkateshwara College Of Engineering, Bengaluru",2025 International Conference on Emerging Trends in Industry 4.0 Technologies (ICETI4T),"26 Aug 2025","2025","","","1","7","The rapid advancement of deepfake technology, particularly in face-swap applications, poses significant challenges to the integrity of digital media and personal security. This research introduces a hybrid system using Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) to detect deepfakes. The model combines spatial and temporal feature analysis to spot inconsistencies in manipulated media. Facial landmarks are detected using the Dlib library, while classifiers like Support Vector Machines (SVM) and Artificial Neural Networks (ANN) enhance detection accuracy. Data augmentation and bidirectional LSTM processing improve the system’s robustness in real-world scenarios. By leveraging AI-driven techniques, the model offers a reliable solution to counter the growing misuse of deepfake technology, ensuring high precision and adaptability.","","979-8-3315-0696-4","10.1109/ICETI4T63625.2025.11132146","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11132146","deepfake detection;face-swap;Convolutional Neural Networks (CNNs);Recurrent Neural Networks (RNNs);Support Vector Machines (SVM);Artificial Neural Networks (ANN);AI/ML","Support vector machines;Deepfakes;Ethics;Adaptation models;Technological innovation;Computational modeling;Collaboration;Data augmentation;Convolutional neural networks;Security","","","","20","IEEE","26 Aug 2025","6-7 June 2025","6-7 June 2025","IEEE","IEEE Conferences"
"XWSB: A Blend System Utilizing XLS-R and Wavlm With SLS Classifier Detection System for SVDD 2024 Challenge","Q. Zhang; S. Wen; F. Yan; T. Hu; J. Li","College of Intelligent Systems Science and Engineering, Hubei Minzu University, Enshi, China; School of Mathematics and Statistics, Hubei Minzu University, Enshi, China; College of Intelligent Systems Science and Engineering, Hubei Minzu University, Enshi, China; College of Intelligent Systems Science and Engineering, Hubei Minzu University, Enshi, China; College of Intelligent Systems Science and Engineering, Hubei Minzu University, Enshi, China",2024 IEEE Spoken Language Technology Workshop (SLT),"16 Jan 2025","2024","","","788","794","This paper introduces the model structure used in the SVDD 2024 Challenge. The SVDD 2024 challenge has been introduced this year for the first time. Singing voice deepfake detection (SVDD) which faces complexities due to informal speech intonations and varying speech rates. In this paper, we propose the XWSB system, which achieved SOTA performance in the SVDD challenge. XWSB stands for XLS-R, WavLM, and SLS Blend, representing the integration of these technologies for the purpose of SVDD. Specifically, we used the best performing model structure XLS-R&SLS from the ASVspoof DF dataset, and applied SLS to WavLM to form the WavLM&SLS structure. Finally, we integrated two models to form the XWSB system. Experimental results show that our system demonstrates advanced recognition capabilities in the SVDD challenge, specifically achieving an EER of 2.32% in the CtrSVDD track. The code and data can be found at https://github.com/QiShanzhang/XWSB_for_ SVDD2024.","","979-8-3503-9225-8","10.1109/SLT61566.2024.10832183","Natural Science Foundation of Hubei Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10832183","Singing Voice Deepfake Detection;Audio deepfake detection;WavLM;XLS-R","Training;Adaptation models;Deepfakes;Codes;Conferences;Data models;Complexity theory;Faces","","2","","25","IEEE","16 Jan 2025","2-5 Dec. 2024","2-5 Dec. 2024","IEEE","IEEE Conferences"
"Deepfake Detection Using Graph Representation with Multi-dimensional Features","J. Chen; W. Lin; J. Xu","School of Computer and Cyber Sciences Communication University of China, Beijing, China; School of Computer and Cyber Sciences Communication University of China, Beijing, China; School of Computer and Cyber Sciences Communication University of China, Beijing, China",2023 IEEE Smart World Congress (SWC),"1 Mar 2024","2023","","","717","722","The proliferation of fake video poses a significant threat to the authority and authenticity of news across multiple domains. The most existing methods of deepfake detection primarily focus on identifying the face as a whole in a video, ignoring the correlation between the facial components. However, our investigation indicates that constituent potions of a face have different effects in deepfake detection. To address this issue, we divided the face in a video frame into several regions and explored the relationship between these regions. Our approach involves constructing a feature graph of this correlation, aiming to make use of the relationship and temporal characteristics between regions of a face in a deepfake video. To begin with, the features of each facial region are extracted through CNN. Subsequently, the feature graph of the entire video is constructed with these features being the vertices and the correlation being the edge. A graph neural network is finally utilized to determine whether the video has been tampered with. Our experiments on several publicly accessible datasets demonstrate that the proposed approach outperforms other state-of-the-art deepfake detection techniques in most scenarios.","","979-8-3503-1980-4","10.1109/SWC57546.2023.10449093","Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10449093","graph representation;deepfake detection;temporal characteristics","Deepfakes;Correlation;Image edge detection;Logic gates;Feature extraction;Graph neural networks;Faces","","3","","28","IEEE","1 Mar 2024","28-31 Aug. 2023","28-31 Aug. 2023","IEEE","IEEE Conferences"
"Masked Relation Learning for DeepFake Detection","Z. Yang; J. Liang; Y. Xu; X. -Y. Zhang; R. He","Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Center for Research on Intelligent Perception and Computing, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Center for Research on Intelligent Perception and Computing, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Center for Research on Intelligent Perception and Computing, Institute of Automation, Chinese Academy of Sciences, Beijing, China",IEEE Transactions on Information Forensics and Security,"6 Mar 2023","2023","18","","1696","1708","DeepFake detection aims to differentiate falsified faces from real ones. Most approaches formulate it as a binary classification problem by solely mining the local artifacts and inconsistencies of face forgery, which neglect the relation across local regions. Although several recent works explore local relation learning for DeepFake detection, they overlook the propagation of relational information and lead to limited performance gains. To address these issues, this paper provides a new perspective by formulating DeepFake detection as a graph classification problem, in which each facial region corresponds to a vertex. But relational information with large redundancy hinders the expressiveness of graphs. Inspired by the success of masked modeling, we propose Masked Relation Learning which decreases the redundancy to learn informative relational features. Specifically, a spatiotemporal attention module is exploited to learn the attention features of multiple facial regions. A relation learning module masks partial correlations between regions to reduce redundancy and then propagates the relational information across regions to capture the irregularity from a global view of the graph. We empirically discover that a moderate masking rate (e.g., 50%) brings the best performance gain. Experiments verify the effectiveness of Masked Relation Learning and demonstrate that our approach outperforms the state of the art by 2% AUC on the cross-dataset DeepFake video detection. Code will be available at https://github.com/zimyang/MaskRelation.","1556-6021","","10.1109/TIFS.2023.3249566","National Natural Science Foundation of China(grant numbers:U2003111,U21B2045,62276256); Beijing Nova Program(grant numbers:Z211100002121108); Chinese Association for Artificial Intelligence (CAAI)-Huawei MindSpore Open Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10054130","Multimedia forensics;DeepFake detection;masked learning;relation feature","Deepfakes;Faces;Feature extraction;Forgery;Image edge detection;Correlation;Visualization","","93","","94","IEEE","27 Feb 2023","2023","","IEEE","IEEE Journals"
"Learning Features of Intra-Consistency and Inter-Diversity: Keys Toward Generalizable Deepfake Detection","H. Chen; Y. Lin; B. Li; S. Tan","Guangdong Key Laboratory of Intelligent Information Processing, the Shenzhen Key Laboratory of Media Security, and the Guangdong Laboratory of Artificial Intelligence and Digital Economy (SZ), Shenzhen University, Shenzhen, China; Guangdong Key Laboratory of Intelligent Information Processing, the Shenzhen Key Laboratory of Media Security, and the Guangdong Laboratory of Artificial Intelligence and Digital Economy (SZ), Shenzhen University, Shenzhen, China; Guangdong Key Laboratory of Intelligent Information Processing, the Shenzhen Key Laboratory of Media Security, and the Guangdong Laboratory of Artificial Intelligence and Digital Economy (SZ), Shenzhen University, Shenzhen, China; Guangdong Key Laboratory of Intelligent Information Processing, the Shenzhen Key Laboratory of Media Security, and the Guangdong Laboratory of Artificial Intelligence and Digital Economy (SZ), Shenzhen University, Shenzhen, China",IEEE Transactions on Circuits and Systems for Video Technology,"7 Mar 2023","2023","33","3","1468","1480","Public concerns about deepfake face forgery are continually rising in recent years. Most deepfake detection approaches attempt to learn discriminative features between real and fake faces through end-to-end trained deep neural networks. However, the majorities of them suffer from the problem of poor generalization across different data sources, forgery methods, and/or post-processing operations. In this paper, following the simple but effective principle in discriminative representation learning, i.e., towards learning features of intra-consistency within classes and inter-diversity between classes, we leverage a novel transformer-based self-supervised learning method and an effective data augmentation strategy towards generalizable deepfake detection. Considering the differences between the real and fake images are often subtle and local, the proposed method firstly utilizes Self Prediction Learning (SPL) to learn rich hidden representations by predicting masked patches at a pre-training stage. Intra-class consistency clues in images can be mined without deepfake labels. After pre-training, the discrimination model is then fine-tuned via multi-task learning, including a deepfake classification task and a forgery mask estimation task. It is facilitated by our new data augmentation method called Adjustable Forgery Synthesizer (AFS), which can conveniently simulate the process of synthesizing deepfake images with various levels of visual reality in an explicit manner. AFS greatly prevents overfitting due to insufficient diversity in training data. Comprehensive experiments demonstrate that our method outperforms the state-of-the-art competitors on several popular benchmark datasets in terms of generalization to unseen forgery methods and untrained datasets.","1558-2205","","10.1109/TCSVT.2022.3209336","NSFC(grant numbers:61872244,62272314); Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2019B151502001); Shenzhen Research and Development Program(grant numbers:JCYJ20200109105008228); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9903059","Deepfake detection;self-supervised learning;masked image modeling;transformer;generalization","Deepfakes;Task analysis;Forgery;Faces;Feature extraction;Data models;Transformers","","62","","55","IEEE","26 Sep 2022","March 2023","","IEEE","IEEE Journals"
"MRE-Net: Multi-Rate Excitation Network for Deepfake Video Detection","G. Pang; B. Zhang; Z. Teng; Z. Qi; J. Fan","School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; AI Laboratory, Lenovo Research, Beijing, China",IEEE Transactions on Circuits and Systems for Video Technology,"3 Aug 2023","2023","33","8","3663","3676","The current social media is flooded with hyper realistic face-synthetic videos due to the explosion of DeepFake technology that has brought a serious impact on human society security, which calls for further exploring on deepfake video detection methods. Existing methods attempt to isolated capture spatial artifacts or extract the homogeneous temporal inconsistency to detect deepfake video, but little attention has been paid to the exploitation of dynamic spatial-temporal inconsistency. To mitigate this issue, in this paper, we propose a novel Multi-Rate Excitation Network (MRE-Net) to effectively excite dynamic spatial-temporal inconsistency from the perspective of multiple rates for deepfake video detection. The proposed MRE-Net is composed of two components: Bipartite Group Sampling (BGS) and multiple rate branches. The BGS draws the entire video into multiple bipartite groups with different rates to cover various face motion dynamic evolution. We further design multiple rate branches to capture both short-term and long-term spatial-temporal inconsistency from corresponding bipartite groups of BGS. Concretely, for the early stages of the multi-rate branches, Momentary Inconsistency Excitation (MIE) module is developed to encode the spatial artifacts and intra-group short-term temporal inconsistency. Meanwhile, for the last stages of the multi-rate branches, Longstanding Inconsistency Excitation (LIE) module is constructed to perceive inter-group long-term temporal dynamics. Extensive experiments and visualizations conducted on four popular datasets demonstrate the effectiveness of the proposed method against state-of-the-art deepfake detection methods.","1558-2205","","10.1109/TCSVT.2023.3239607","Fundamental Research Funds for the Central Universities of China(grant numbers:2022JBMC009); Natural Science Foundation of China(grant numbers:61972027); Beijing Municipal Natural Science Foundation(grant numbers:4212041); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10025759","Deepfake detection;momentary inconsistency;longstanding inconsistency","Deepfakes;Faces;Forgery;Feature extraction;Social networking (online);Three-dimensional displays;Frequency-domain analysis","","50","","60","IEEE","25 Jan 2023","Aug. 2023","","IEEE","IEEE Journals"
"Explainable AI-Driven Deepfake Detection Using Gradient-Weighted Class Activation Mapping","Gifariani; B. Soewito","Department of Computer Science, BINUS Graduate Program, Master of Computer Science, Bina Nusantara University, Jakarta, Indonesia; Department of Computer Science, BINUS Graduate Program, Master of Computer Science, Bina Nusantara University, Jakarta, Indonesia",2025 6th International Conference on Artificial Intelligence and Data Sciences (AiDAS),"5 Nov 2025","2025","","","374","379","The rapid rise of synthetic media technologies has made deepfake content a serious threat to digital security and authenticity. To address this challenge, this study proposes an integrated deepfake detection by combining YOLO for face detection, CNN-based classification, and XAI for interpretability. YOLO is utilized for rapid and precise localization of facial regions from video frames or images. These detected face regions are then classified as either real or deepfake using ResNet50V2, InceptionResNetV2, and Xception. To enhance transparency and trust in the model's decisions, Explainable AI (XAI) is integrated using Grad-CAM, providing visual insights into which regions influenced the classification. To improve demographic representation, we develop a custom dataset by combining CelebDFv2 with a primary dataset focused on Asian facial features. Experimental results show ResNet50V2 outperforms other models with 91.69% accuracy, 75.80% precision, and a 44.45% F1-score. The findings demonstrate the potential of integrating object detection, deep learning, and XAI to build interpretable and scalable deepfake detection systems.","","979-8-3315-8603-4","10.1109/AiDAS67696.2025.11213703","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11213703","Deepfake Detection;YOLO;CNN Models;Explainable AI;Grad-CAM","YOLO;Location awareness;Deep learning;Deepfakes;Visualization;Explainable AI;Media;Security;Facial features;Faces","","","","20","IEEE","5 Nov 2025","2-3 Sept. 2025","2-3 Sept. 2025","IEEE","IEEE Conferences"
"Smart Access: A Multi-Biometric System with Advanced Spoofing and Deepfake Detection for Secure Access Control","Y. Alkady; F. Amer; M. Abdelhady; A. Khaled","Faculty of Computer Sciences, Misr International University, Egypt; Faculty of Computer Sciences, Misr International University, Egypt; Faculty of Computer Sciences, Misr International University, Egypt; Faculty of Computer Sciences, Misr International University, Egypt","2025 International Mobile, Intelligent, and Ubiquitous Computing Conference (MIUCC)","21 Oct 2025","2025","","","325","331","Smart Access is a biometric access control system that leverages artificial intelligence to provide secure, contactless, and cost-effective authentication for physical environments such as offices, hotels, hospitals, and research facilities. Traditional access control systems that rely on keys, PINs, RFID cards, or dedicated biometric hardware often suffer from high costs, vulnerability to spoofing, and usability issues. Smart Access (SA) addresses these challenges by replacing physical tokens and sensors with advanced AI-powered multimodal biometric verification, using the user's smartphone as the interface. The system combines facial recognition, voice authentication, and deepfake detection to verify user identity. Facial authentication is implemented using the Deep Face framework with a VGG-Face model, enhanced by liveness detection to prevent spoofing through images or pre-recorded videos. Voice authentication includes three distinct layers: speaker verification using Speech Brain, transcript verification using Whisper ASR, and deepfake detection via a fine-tuned Wav2Vec2 model. This multi-layered approach effectively counters replay attacks and synthetic voice manipulation. The system architecture includes a mobile/web application, a secure backend for AI processing, and an ESP32 microcontroller that controls physical access points. Once authentication is successful, a secure command is issued to the ESP32 device to unlock the door. The system also includes a comprehensive admin dashboard for managing users, rooms, permissions, and access logs, supporting multi-tenant configurations to isolate organizational data. Evaluation results demonstrate a true acceptance rate of 97.4% for facial recognition and 94.6% detection accuracy for deepfake audio, with an average end-toend authentication time of 2.4 seconds. A user study with 30 participants showed that over 90% found the system intuitive and more secure than traditional methods.","","979-8-3315-3922-1","10.1109/MIUCC66482.2025.11196797","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11196797","Authentication;contactless access;deepfake detection;ESP32;facial recognition;liveness detection;multimodal verification;PINs;RFID cards;smartphone interface;speaker verification;spoofing prevention;system architecture;transcript verification;user identity verification;usability;voice authentication;Wav2Vec2;Whisper ASR","Access control;Deepfakes;Face recognition;Authentication;Systems architecture;Brain modeling;Pins;Usability;Artificial intelligence;Radiofrequency identification","","","","16","IEEE","21 Oct 2025","17-18 Sept. 2025","17-18 Sept. 2025","IEEE","IEEE Conferences"
"Exploiting spatiotemporal inconsistencies to detect deepfake videos in the wild","A. Khedkar; A. Peshkar; A. Nagdive; M. Gaikwad; S. Baudha","Dept. of Artificial Intelligence, G.H. Raisoni College of Engineering, Nagpur, India; Dept. of Information Technology, G.H. Raisoni College of Engineering, Nagpur, India; Dept. of Information Technology, G.H. Raisoni College of Engineering, Nagpur, India; Dept. of Information Technology, G.H. Raisoni College of Engineering, Nagpur, India; Dept. of Electronics & Electrical Engineering, BITS Pilani, Goa, India",2022 10th International Conference on Emerging Trends in Engineering and Technology - Signal and Information Processing (ICETET-SIP-22),"15 Jun 2022","2022","","","1","6","Cyberspace is an emerging battlefield and deepfakes are being constantly weaponized by malicious actors. With rapid advancements in media synthesis technologies, detecting deepfakes is becoming increasingly difficult. The following paper presents a unified approach focusing on the fusion of Convolutional Neural Networks and Long Short Term Memory Networks for spatial and temporal analysis of deepfake videos. This study compares the performance of the most prevalent and frequently used deepfake detection methods- convolutional neural networks (CNN) and convolutional neural networks combined with long-short term memory networks (CNN-LSTM) with our architecture on a combined dataset consisting of videos from Face Forensics++ and Deepfake Detection Challenge Dataset, which consists of multiple types of manipulated media- Deepfakes, Faceswaps, Neural Textures, Face Shifter and Face2Face. We find that our architecture provides a 2.5% increase in detection accuracy over the most frequently used current deepfake detection method (CNN-LSTM).","2157-0485","978-1-6654-6741-4","10.1109/ICETET-SIP-2254415.2022.9791719","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9791719","Deepfake Detection;Image Processing;Deep learning;GAN;Generalization;Interpretation","Weapons;Focusing;Cyberspace;Information processing;Media;Market research;Spatiotemporal phenomena","","2","","44","IEEE","15 Jun 2022","29-30 April 2022","29-30 April 2022","IEEE","IEEE Conferences"
"Meta-Learning With Relation Embedding for Few-Shot Deepfake Detection","X. Liu; P. Song; P. Lu; Y. Wang","College of Physics and Electronic Information Engineering, Guilin University of Technology, Guilin, China; Guangxi Key Laboratory of Embedded Technology and Intelligent System, Guilin University of Technology, Guilin, China; Guangxi Key Laboratory of Embedded Technology and Intelligent System, Guilin University of Technology, Guilin, China; Guangxi Key Laboratory of Embedded Technology and Intelligent System, Guilin University of Technology, Guilin, China",IEEE Access,"5 Dec 2024","2024","12","","180135","180145","The generation of facial images via generative models has gained significant popularity, while the task of discriminating between authentic and synthetic faces has proven to be increasingly challenging. This challenge is exacerbated when novel generative models emerge, as it is difficult to obtain a substantial number of images from these new models and the limited number of samples can undermine the accuracy of training. To tackle these issues, we introduce a few-shot deepfake detection approach based on meta-learning with relation embedding. Initially, we employ an embedding function to generate feature representations of the images. Subsequently, we convert the basic representations of feature maps into their corresponding self-correlation tensors, enabling us to learn the structural patterns inherent in these tensors. Finally, we utilize a learnable metric to classify the self-correlation tensors. Our model is trained using an initialization parameter meta-learning strategy, extracting generalizable knowledge through training on multiple interrelated tasks, thereby enhancing model performance. The effectiveness of our approach has been validated through experiments on the miniImageNet, Stanford-Dogs, and CUB-200-2011 datasets. Additionally, we conducted tests on a self-constructed deepfake face dataset, and the results indicated that the proposed method exhibits strong performance compared with other methods.","2169-3536","","10.1109/ACCESS.2024.3499353","National Natural Science Foundation of China(grant numbers:62066011); Natural Science Foundation of Guangxi Zhuang Autonomous Region(grant numbers:2022GXNSFAA035640,2023GXNSFAA026057); Guangxi Key Laboratory of Embedded Technology and Intelligent System Foundation(grant numbers:2019-2-4,2019-2-5); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10754643","Deepfake detection;diffusion model;few-shot learning;generative adversarial network;meta-learning;self-correlation","Feature extraction;Deepfakes;Correlation;Semantics;Metalearning;Measurement;Training;Vectors;Optimization;Forgery","","1","","45","CCBY","15 Nov 2024","2024","","IEEE","IEEE Journals"
"Hybrid Recurrent Deep Learning Model for DeepFake Video Detection","G. Jaiswal","ICT Research Lab, Department of Computer Science, University of Lucknow, Lucknow, India","2021 IEEE 8th Uttar Pradesh Section International Conference on Electrical, Electronics and Computer Engineering (UPCON)","10 Jan 2022","2021","","","1","5","Nowadays deepfake videos are concern with social ethics, privacy and security. Deepfake videos are synthetically generated videos that are generated by modifying the facial features and audio features to impose one person’s facial data and audio to other videos. These videos can be used for defaming and fraud. So, counter these types of manipulations and threats, detection of deepfake video is needed. This paper proposes multilayer hybrid recurrent deep learning models for deepfake video detection. Proposed models exploit the noise-based temporal facial convolutional features and temporal learning of hybrid recurrent deep learning models. Experiment results of these models demonstrate its performance over stacked recurrent deep learning models.","2687-7767","978-1-6654-0962-9","10.1109/UPCON52273.2021.9667632","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9667632","Deepfake detection;Hybrid Recurrent model;Deep learning;Deepfake video;video temporal feature","Deep learning;Privacy;Computational modeling;Stacking;Nonhomogeneous media;Security;Task analysis","","12","","32","IEEE","10 Jan 2022","11-13 Nov. 2021","11-13 Nov. 2021","IEEE","IEEE Conferences"
"Detection and Verification for Deepfake Bypassed Facial Feature Authentication","M. G. Sonkusare; H. A. Meshram; A. Sah; S. Prakash","Department of Embedded Technology, Vellore Institute of Technology, Vellore, India; Department of Embedded Technology, Vellore Institute of Technology, Vellore, India; Department of Embedded Technology, Vellore Institute of Technology, Vellore, India; Department of Electronics and Communication Engineering, Indian Institute of Information Technology, Allahabad, Prayagraj, India",2022 Second International Conference on Artificial Intelligence and Smart Energy (ICAIS),"30 Mar 2022","2022","","","646","649","Facial features have become one of the leading standards for biometric authentication. With the growing demand for the Internet of Things, it has become imperative to have systems to detect any data breach used for authentication. New deep fake technologies have made it possible to compromise the database, making real-time authentication inefficient. The counterfeit to the real-time data can be challenging to detect. We have developed a deep fake image detection utilizing ResNet50 and Spatial Pyramidal Pooling to tackle this problem. Our model detects manipulation in real-time data, irrespective of its size and background, at an accuracy of 94%. This model will allow us to detect bypass in the database for facial biometric authentication and improve the system’s security.","","978-1-6654-0052-7","10.1109/ICAIS53314.2022.9742980","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9742980","Authentication;Biometrics;Deepfake detection;ResNet50;Spatial pyramid pooling","Biometrics (access control);Databases;Biological system modeling;Authentication;Real-time systems;Data models;Internet of Things","","1","","25","IEEE","30 Mar 2022","23-25 Feb. 2022","23-25 Feb. 2022","IEEE","IEEE Conferences"
"Harmonizing Dynamic Frequency Analysis with Attention Mechanisms for Efficient Facial Image Authenticity Detection","Y. Zhao; J. Li; L. Wang","School of Computer and Information Engineering, Hefei University of Technology, Hefei, China; School of Computer and Information Engineering, Hefei University of Technology, Hefei, China; Anhui Communications Vocational and Technical College, Hefei, China",2023 International Conference on Computer Science and Automation Technology (CSAT),"25 Mar 2024","2023","","","348","352","Deepfake detection is increasingly critical in security and digital forensics. Our research presents a novel method that synergizes dynamic frequency domain analysis with attention mechanisms to discern Deepfakes more effectively. This approach is developed in response to the inadequacies of existing techniques when confronted with sophisticated image alterations. By leveraging frequency domain subtleties and an advanced attention mechanism, our model achieves heightened accuracy in identifying key facial anomalies. Our experimental results show that DFAM could yield 93.94% accuracy rate which is the best compared with state-of-the-arts on Deepfakes dataset.","","979-8-3503-7143-7","10.1109/CSAT61646.2023.00097","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10471603","deepfake detection;dynamic frequency domain analysis;attention mechanisms","Computer science;Deepfakes;Automation;Frequency-domain analysis;Digital forensics;Security","","1","","22","IEEE","25 Mar 2024","6-8 Oct. 2023","6-8 Oct. 2023","IEEE","IEEE Conferences"
"Wavelet-based GAN Fingerprint Detection using ResNet50","S. T. Erukude; S. Reddy Veluru; V. C. Marella","Department of Computer Science, Kansas State University, Manhattan, USA; College of Business Administration, Kansas State University, Manhattan, USA; College of Business Administration, Kansas State University, Manhattan, USA",2025 4th International Conference on Innovative Mechanisms for Industry Applications (ICIMIA),"20 Oct 2025","2025","","","382","387","Identifying images generated by Generative Adversarial Networks (GANs) has become a significant challenge in digital image forensics. This research presents a wavelet-based detection method that uses discrete wavelet transform (DWT) preprocessing and a ResNet50 classification layer to differentiate the StyleGAN-generated images from real ones. Haar and Daubechies wavelet filters are applied to convert the input images into multi-resolution representations, which will then be fed to a ResNet50 network for classification, capitalizing on subtle artifacts left by the generative process. Moreover, the wavelet-based models are compared to an identical ResNet50 model trained on spatial data. The Haar and Daubechies preprocessed models achieved a greater accuracy of 93.8 percent and 95.1 percent, much higher than the model developed in the spatial domain (accuracy rate of 81.5 percent). The Daubechies-based model outperforms Haar, showing that adding layers of descriptive frequency patterns can lead to even greater distinguishing power. These results indicate that the GAN-generated images have unique wavelet-domain artifacts or ""fingerprints."" The method proposed illustrates the effectiveness of wavelet-domain analysis to detect GAN images and emphasizes the potential of further developing the capabilities of future deepfake detection systems.","","979-8-3315-5386-9","10.1109/ICIMIA67127.2025.11200674","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11200674","Deepfake Detection;Wavelet-domain analysis;Image forensics;StyleGAN Fingerprints","Image forensics;Deepfakes;Accuracy;Digital images;Fingerprint recognition;Generative adversarial networks;Feature extraction;Wavelet analysis;Discrete wavelet transforms;Residual neural networks","","","","15","IEEE","20 Oct 2025","3-5 Sept. 2025","3-5 Sept. 2025","IEEE","IEEE Conferences"
"READFake: Reflection and Environment-Aware DeepFake Detection","M. Mohzary; E. Basunduwah; S. Song; B. -Y. Choi","Department of Computer Science, Jazan University, Jazan, Saudi Arabia; School of Science and Engineering, University of Missouri-Kansas City, MO, USA; School of Computer and Cyber Science, Augusta University, Augusta, GA, USA; School of Science and Engineering, University of Missouri-Kansas City, MO, USA",2024 IEEE International Conference on Visual Communications and Image Processing (VCIP),"27 Jan 2025","2024","","","1","5","This paper presents a novel Reflection and Environment-Aware DeepFake (READFake) detection technique. Using reflections on various body parts (e.g., eyes, nose, cheeks, etc.) and environmental factors, we validate the hypothesis that the existing DeepFake creation methods, including reenactment, replacement, and synthesis, fail to coordinate their counterfeits with the reflective components along with the given environmental mapping. We detect various features from the specular highlight images, including color components, shapes, and textures, to check the coordination with the surrounding environmental factors, such as indoor/outdoor, bright/dark backgrounds, and light strength. We have conducted extensive experiments to evaluate the performance of READFake using various input parameters and advanced Deep Neural Network (DNN) architectures on multiple public DeepFake datasets. The empirical results show that READFake achieves high accuracy (99.00%) in detecting sophisticated DeepFake images.","2642-9357","979-8-3315-2954-3","10.1109/VCIP63160.2024.10849940","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10849940","DeepFake Detection;Specular Highlights;DNN","Deepfakes;Accuracy;Shape;Image color analysis;Visual communication;Nose;Artificial neural networks;Feature extraction;Reflection;Environmental factors","","","","36","IEEE","27 Jan 2025","8-11 Dec. 2024","8-11 Dec. 2024","IEEE","IEEE Conferences"
"Fourier-Based GAN Fingerprint Detection Using ResNet50","S. T. Erukude; V. C. Marella; S. R. Veluru","Department of Computer Science, Kansas State University, Manhattan, USA; College of Business Administration, Kansas State University, Manhattan, USA; College of Business Administration, Kansas State University, Manhattan, USA",2025 9th International Conference on Inventive Systems and Control (ICISC),"13 Oct 2025","2025","","","971","976","The rapid rise of photorealistic images produced from Generative Adversarial Networks (GANs) poses a serious challenge for image forensics and industrial systems requiring reliable content authenticity. This paper uses frequency-domain analysis combined with deep learning to solve the problem of distinguishing StyleGAN-generated images from real ones. Specifically, a two-dimensional Discrete Fourier Transform (2D DFT) was applied to transform images into the Fourier domain, where subtle periodic artifacts become detectable. A ResNet50 neural network is trained on these transformed images to differentiate between real and synthetic ones. The experiments demonstrate that the frequency-domain model achieves a 92.8 percent and an AUC of 0.95, significantly outperforming the equivalent model trained on raw spatial-domain images. These results indicate that the GAN-generated images have unique frequency-domain signatures or “fingerprints”. The method proposed highlights the industrial potential of combining signal processing techniques and deep learning to enhance digital forensics and strengthen the trustworthiness of industrial AI systems.","","979-8-3315-1247-7","10.1109/ICISC65841.2025.11187724","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11187724","Deepfake Detection;Frequency-Domain Analysis;Image Forensics;StyleGAN Fingerprints;Trustworthy AI Systems","Deep learning;Image forensics;Deepfakes;Adaptation models;Frequency-domain analysis;Discrete Fourier transforms;Fingerprint recognition;Generative adversarial networks;Artificial intelligence;Residual neural networks","","","","15","IEEE","13 Oct 2025","12-13 Aug. 2025","12-13 Aug. 2025","IEEE","IEEE Conferences"
"Supervised Learning Techniques for Deepfake Detection: Integrating ResNet50 and LSTM","N. L. Mudegol; A. Urunkar","Department of Computer Science and Enginneering, Walchand College of Engineering Sangli, Sangli, India; Department of Computer Science and Enginneering, Walchand College of Engineering Sangli, Sangli, India",2025 1st International Conference on AIML-Applications for Engineering & Technology (ICAET),"26 Mar 2025","2025","","","1","6","Deepfake technology has garnered considerable scholarly interest owing to its capacity to generate exceptionally lifelike yet artificially constructed media artifacts, posing serious threats to various aspects of society, including privacy, security, and misinformation. In response to this growing concern, this project aims to develop an effective deepfake detection system using deep learning models. This paper focuses on leveraging supervised learning techniques to distinguish between authentic and deepfake videos. The proposed approach involves collecting a diverse dataset of both authentic and deepfake videos, covering various scenarios and manipulation techniques. Preprocessing techniques are applied to extract relevant features from the videos, preparing them for input to the deep learning models. Several neural network architectures, including Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and their combinations [13], are explored for their suitability in detecting deepfake content. Transfer learning methodologies are utilized to capitalize on models that have undergone prior training, such as those trained on ImageNet, as feature extractors or initializations for the network. The models are trained on the labeled dataset. The paper aims to detect deepfake in videos by using ResNet50 for feature extraction and training those features on the LSTM Model.","","979-8-3503-5561-1","10.1109/ICAET63349.2025.10932283","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10932283","Deepfake Detection;CNN;RNN;Transfer Learning;ResNet50-LSTM","Training;Deep learning;Deepfakes;Recurrent neural networks;Transfer learning;Supervised learning;Feature extraction;Convolutional neural networks;Long short term memory;Residual neural networks","","","","15","IEEE","26 Mar 2025","16-17 Jan. 2025","16-17 Jan. 2025","IEEE","IEEE Conferences"
"Deepfake Image Detection Using Yolov8","P. Sathe; V. Sabane; C. Undale; A. Uttarkar; V. Chavhan; N. P. Sable; A. Yenkikar","Department of CSE – Artificial Intelligence, Vishwakarma Institute of Information Technology, Pune, India; Department of CSE – Artificial Intelligence, Vishwakarma Institute of Information Technology, Pune, India; Department of CSE – Artificial Intelligence, Vishwakarma Institute of Information Technology, Pune, India; Department of CSE – Artificial Intelligence, Vishwakarma Institute of Information Technology, Pune, India; Department of CSE – Artificial Intelligence, Vishwakarma Institute of Information Technology, Pune, India; Department of CSE – Artificial Intelligence, Vishwakarma Institute of Information Technology, Pune, India; Department of CSE – Artificial Intelligence, Vishwakarma Institute of Information Technology, Pune, India",2024 IEEE Pune Section International Conference (PuneCon),"27 Feb 2025","2024","","","1","5","Due to growing number of fake media and the possible problems with misinformation and identity theft, deepfake image recognition has become a hot topic. In order to evaluate the efficacy of widely recognized deep learning models in detecting and classifying deepfake images, we compare and contrast YOLO (You Only Look Once) V8, CNN (Convolutional Neural Network), combination of LSTM (Long Short-Term Memory) with CNN and ResNet in this paper. The capacity to recognize photos that have been manipulated effectively is essential for maintaining trust regarding digital media and preventing the spread of deceptive data. The objective of our research is to explain each model's abilities, limitations and performance in the context of deepfake image recognition. We evaluated each model's accuracy, precision, and F1-scores using a dataset of 190402 images, half real and half fake that cover a wide spectrum of deep fake images. Based on the evaluation metrics, each model was ranked in terms of its ability to separately describe and determine original versus generated photos with focus on detecting subtle changes eluding human senses. The comparison research shows each model's nuanced capabilities, offering light on the implications for applications in the real world like detecting and controlling the spread of deep fake information across numerous internet platforms. Our findings help towards building deep fake detection systems, further understanding the comparative performance of state of the art deep architectures. This study shall inform more effective deep fake detection systems that can guarantee trust and security in digital media environments. Accuracy achieved by model is 96%, precision score was 94%, recall value is 0.98, F1 score has a value of 0.95.","2831-5022","979-8-3315-2782-2","10.1109/PuneCon63413.2024.10895706","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10895706","Deepfake detection;Image classification;YOLOV8;Long Short-Term Memory;Convolutional Neural Network;ResNet;Deep Learning","YOLO;Deepfakes;Accuracy;Image recognition;Computational modeling;Scalability;Computer architecture;Convolutional neural networks;Security;Long short term memory","","","","22","IEEE","27 Feb 2025","13-15 Dec. 2024","13-15 Dec. 2024","IEEE","IEEE Conferences"
"DeepFake Detection Using Error Level Analysis and Deep Learning","R. Rafique; M. Nawaz; H. Kibriya; M. Masood","Department of Computer Sciences, University of Engineering and Technology, Taxila; Department of Computer Sciences, University of Engineering and Technology, Taxila; Department of Computer Sciences, University of Engineering and Technology, Taxila; Department of Computer Sciences, University of Engineering and Technology, Taxila",2021 4th International Conference on Computing & Information Sciences (ICCIS),"19 Jan 2022","2021","","","1","4","The image recognition software is used in numerous distinctive industries that include entertainment and media. The deep learning (DL) algorithms have been of great help in the development of several techniques used for creating, altering, and locating any data. The deepfake method is a photo-faking technique that includes replacing two people's faces to an extent that it becomes very difficult to identify it with a naked eye. The convolution neural network (CNN) models including Alex Net and Shuffle Net are used to recognize genuine and counterfeit face images in this article. The technique analyzes the performance and working of all distinctive algorithms using the real/fake face recognition collection from Yonsei University's Computational Intelligence Photography Lab. The first step in the process starts by the normalizing of pictures then the Error Level Analysis is carried out before it is put into several difference CNN models. Then the in-depth features are extracted from the CNN models utilizing the Support Vector Machine and the K-nearest neighbor methods. The most perfect accuracy of 88.2% of Shuffle Net via KNN was analyzed while Alex Net's vector had the accuracy of 86.8%.","","978-1-6654-9441-0","10.1109/ICCIS54243.2021.9676375","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9676375","Deep Learning;Machine Learning;CNN;Deepfake Detection;SVM;KNN","Support vector machines;Deep learning;Image recognition;Computational modeling;Face recognition;Feature extraction;Convolutional neural networks","","42","","14","IEEE","19 Jan 2022","29-30 Nov. 2021","29-30 Nov. 2021","IEEE","IEEE Conferences"
"MesoNet-ViT: Meso Network and Vision Transformer for Deepfake Detection","I. Ilhan; M. Karaköse","Vocational School of Technical Sciences, Adıyaman University, Adıyaman, Turkey; Department of Computer Engineering, Fırat University, Elazığ, Turkey",2025 29th International Conference on Information Technology (IT),"21 Mar 2025","2025","","","1","4","Social media tools using deep learning technology are used for entertainment, but they can also pose a danger with forgery outside of their purpose. New solutions and detection methods are still needed in the challenge against forgery. In this study, the proposed MesoNet-ViT method was used to classify fake and real images. MesoNet-ViT is a combination of the Meso and Vision Transformer (ViT) methods used in deepfake detection. In this hybrid architecture, the face region is extracted from the input file with the BlazeFace method and given as input to the classification module. Feature maps extracted from the face image with the Meso method are fed to the ViT model, which detects whether the video is fake or real. When the experiments are analyzed, our method has shown that it can compete with other methods with an ACC value of 96.2 on the DeepFake Detection Challenge (DFDC) dataset and an ACC value of 98.1 on the DF-TIMIT dataset.","2836-3744","979-8-3315-1764-9","10.1109/IT64745.2025.10930249","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10930249","Deepfake detection;Meso network;Vision Transformers;MesoNet-Vit","Deep learning;Deepfakes;Computer vision;Social networking (online);Entertainment industry;Transformers;Feature extraction;Forgery;Information technology;Faces","","1","","23","IEEE","21 Mar 2025","19-22 Feb. 2025","19-22 Feb. 2025","IEEE","IEEE Conferences"
"Deepfake Video Detection Based on the Decomposition of Spatial-Temporal Attention Mechanism in ViViT","G. Sun; Z. Lian","School of Computer Science and Engineering, Nanjing University of Science and Technology; School of Cyber Science and Engineering, Nanjing University of Science and Technology, Nanjing, China",2024 IEEE International Symposium on Parallel and Distributed Processing with Applications (ISPA),"20 Feb 2025","2024","","","1629","1634","With the rapid development of Deepfake synthesis technology in recent years, our cybersecurity and individual privacy face challenges. In pursuit of robust Deepfake detection, researchers have tried to use temporal cues in videos, employing models such as RNNs and 3D convolutional networks. Despite these efforts, there remains ample opportunity for improvement within these models. In this paper, we introduced an approach utilizing the Video Vision Transformer, which is based on the decomposition of Spatial-Temporal attention mechanisms, for the detection of video face forgery. This method is designed to capture spatial artifacts and temporal inconsistencies. Besides, difference module is introduced to screen features and reduce the interference of natural factors on the model. To enable robust Deepfake detection. We have conducted extensive experiments across some datasets, including FaceForensics++, DFDC and WildDeepfake datasets. Which demonstrates the validity of the model.","2158-9208","979-8-3315-0971-2","10.1109/ISPA63168.2024.00221","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10885266","Deepfake detection;Spatial-Temporal Attention Mechanism;Difference module","Training;Deepfakes;Computer vision;Solid modeling;Privacy;Attention mechanisms;Three-dimensional displays;Transformers;Forgery;Faces","","","","34","IEEE","20 Feb 2025","30 Oct.-2 Nov. 2024","30 Oct.-2 Nov. 2024","IEEE","IEEE Conferences"
"Generalizable Deepfake Detection With Phase-Based Motion Analysis","E. Prashnani; M. Goebel; B. S. Manjunath","Department of Electrical and Computer Engineering, University of California at Santa Barbara, Santa Barbara, CA, USA; Department of Electrical and Computer Engineering, University of California at Santa Barbara, Santa Barbara, CA, USA; Department of Electrical and Computer Engineering, University of California at Santa Barbara, Santa Barbara, CA, USA",IEEE Transactions on Image Processing,"12 Dec 2024","2025","34","","100","112","We propose PhaseForensics, a DeepFake (DF) video detection method that uses a phase-based motion representation of facial temporal dynamics. Existing methods that rely on temporal information across video frames for DF detection have many advantages over the methods that only utilize the per-frame features. However, these temporal DF detection methods still show limited cross-dataset generalization and robustness to common distortions due to factors such as error-prone motion estimation, inaccurate landmark tracking, or the susceptibility of the pixel intensity-based features to adversarial distortions and the cross-dataset domain shifts. Our key insight to overcome these issues is to leverage the temporal phase variations in the band-pass frequency components of a face region across video frames. This not only enables a robust estimate of the temporal dynamics in the facial regions, but is also less prone to cross-dataset variations. Furthermore, we show that the band-pass filters used to compute the local per-frame phase form an effective defense against the perturbations commonly seen in gradient-based adversarial attacks. Overall, with PhaseForensics, we show improved distortion and adversarial robustness, and state-of-the-art cross-dataset generalization, with 92.4% video-level AUC on the challenging CelebDFv2 benchmark (a recent state of-the-art method, FTCN, compares at 86.9%).","1941-0042","","10.1109/TIP.2024.3441821","NSF(grant numbers:1664172); Computational Facilities Purchased under NSF(grant numbers:1925717); Dissertation Fellowship funded by the Department of Electrical and Computer Engineering at UC Santa Barbara; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10685029","Deepfake detection;deep learning;video analysis;video forensics","Feature extraction;Deepfakes;Faces;Robustness;Detectors;Dynamics;Generators","","12","","85","IEEE","20 Sep 2024","2025","","IEEE","IEEE Journals"
"Deepfake Detection using Multi-path CNN and Convolutional Attention Mechanism","R. B. P.; M. S. Nair","Department of Computer Science, Artificial Intelligence & Computer Vision Lab, Cochin University of Science and Technology, Kochi, Kerala, India; Department of Computer Science, Artificial Intelligence & Computer Vision Lab, Cochin University of Science and Technology, Kochi, Kerala, India",2022 IEEE 2nd Mysore Sub Section International Conference (MysuruCon),"13 Dec 2022","2022","","","1","6","Image and video forgery using cutting-edge deep learning techniques has become one of the major issues in the social networking era. Media manipulation in which one person’s face is swapped out for another’s or has additional features added is referred to as deepfakes. Despite the fact that it has many beneficial purposes, fraudsters generally utilise it to create celebrity porn, revenge porn, and fake news, among other things. One of the biggest risks that deepfake presents is that people’s belief in the reality of many things may decline. The motivation behind deepfake detection is the need to prove that the real thing is real and the fake thing is fake. In this paper a multi-CNN approach for detecting deepfakes is being proposed. Here, a multipath convolutional neural network (CNN) with three modules is used, each of which is stacked with a convolutional block attention mechanism. The first two modules in the dual-path paradigm are a Resnet module and a Densenet module. The Resnet component enables for feature reuse while Densenet allows for the investigation of new features. The parallel InceptionResnet module contains a one-dimensional feature reduction module with residual connections. When the performance of the proposed model is compared with that of four deep learning based approaches, it is found that the proposed method gave the best outcomes, with an accuracy and F1-score of 0.940 and 0.939, respectively.","","978-1-6654-9790-9","10.1109/MysuruCon55714.2022.9972657","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9972657","deepfake detection;deep learning;feature extraction;attention mechanism;classifier","Deep learning;Deepfakes;Social networking (online);Forgery;Convolutional neural networks;Faces;Residual neural networks","","5","","22","IEEE","13 Dec 2022","16-17 Oct. 2022","16-17 Oct. 2022","IEEE","IEEE Conferences"
"AdaForensics: Learning A Characteristic-aware Adaptive Deepfake Detector","X. Yang; H. Song; X. Lu; S. -L. Huang; Y. Duan","Tsinghua Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Tsinghua Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Department of Electronic Engineering, Tsinghua University, Beijing, China",2024 IEEE International Conference on Multimedia and Expo (ICME),"30 Sep 2024","2024","","","1","6","In this paper, we propose a characteristic-aware adaptive network named AdaForensics for deepfake detection. Most existing methods learn a fixed network to detect deepfakes based on carefully-designed network architectures. However, these methods employ the same deepfake detector for all the images despite of various facial characteristic, which fail to provide customized forgery detection for different individuals. To address this, our AdaForensics simultaneously learns characteristic-agnostic and characteristic-specific embeddings, where the detector dynamically adapts to varying faces with our designed hypernetwork on the fly. More specifically, our AdaForensics not only explores the shareable abstractions from various deepfake images, but also adapts the detector to the given characteristic at test time. To achieve this, we propose a two-branch HyperNetwork to learn an adaptive deepfake detector, which automatically adjusts the parameters based on characteristic of the input. Extensive experiments on widely-used datasets including FaceForensics, Celeb-DF and DFDC demonstrate our AdaForensics outperforms the state-of-the-art works.","1945-788X","979-8-3503-9015-5","10.1109/ICME57554.2024.10687869","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10687869","Deepfake detection;HyperNetwork;Characteristic-aware","Deepfakes;Adaptive systems;Detectors;Network architecture;Forgery;Faces","","4","","40","IEEE","30 Sep 2024","15-19 July 2024","15-19 July 2024","IEEE","IEEE Conferences"
"Evaluating Models for Deepfake Detection: A Comparative Study","V. Krishna; P. S. Neha; V. P; H. Vidyasekaran","Computer Science and Engineering, Amrita Vishwa Vidyapeetham, Chennai, India; Computer Science and Engineering, Amrita Vishwa Vidyapeetham, Chennai, India; Computer Science and Engineering, Amrita Vishwa Vidyapeetham, Chennai, India; Computer Science and Engineering, Amrita Vishwa Vidyapeetham, Chennai, India",2024 International Conference on IoT Based Control Networks and Intelligent Systems (ICICNIS),"10 Jan 2025","2024","","","1381","1388","Deepfake detection poses a significant challenge in digital forensics due to increasingly advanced AI-generated videos. This study evaluates three models using the FaceForensics++ and DeeperForensics-1.0 datasets. The preprocessing involved video encoding, renaming, trimming, frame extraction, face detection, and data loading. The first model, a Convolutional Neural Network (CNN), achieved 84% accuracy. The second model, Xception, an efficient CNN with depth-wise separable convolutions and residual connections, attained 89% accuracy. The third model, combining CNN with a Recurrent Neural Network (RNN) and LSTM layers, significantly improved detection accuracy to 97%. This hybrid model highlights the importance of capturing spatial and temporal features in deepfake detection, demonstrating the efficacy of advanced deep learning techniques in addressing the deepfake threat.","","979-8-3315-1809-7","10.1109/ICICNIS64247.2024.10823264","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10823264","Deepfake detection;CNN;Xception;hybrid model;CNN+RNN;classification","Deepfakes;Accuracy;Recurrent neural networks;Loading;Feature extraction;Convolutional neural networks;Face detection;Intelligent systems;Long short term memory;Load modeling","","2","","17","IEEE","10 Jan 2025","17-18 Dec. 2024","17-18 Dec. 2024","IEEE","IEEE Conferences"
"DeepFake Detection for Military Security: A Deep Learning Approach Using TensorFlow and CNN Architecture","M. K. Shashank; H. Y. Patil; D. Saxena","Faculty of Communication Engineering(FCE), Military College of Telecommunication Engineering, Mhow, MP, India; Faculty of Communication Engineering(FCE), Military College of Telecommunication Engineering, Mhow, MP, India; Department of Computer Science and Engineering, Chandigarh University, Mohali, Punjab, India","2025 IEEE International Conference on Computer, Electronics, Electrical Engineering & their Applications (IC2E3)","24 Sep 2025","2025","","","1","6","Military security faces considerable danger from DeepFake technology because adversaries can use its capabilities to modify visual media alongside the dissemination of fake information and the execution of cyber-psychological warfare. A deep learning artificial intelligence model for military DeepFake detection uses Convolutional Neural Networks (CNNs) combined with EfficientNetB4 architecture. Our model succeeds in differentiating between genuine images and deepfakes using TensorFlow on physical and simulated images obtained from the DeepFake Detection Challenge while achieving elevated accuracy numbers during training. The model benefits from transfer learning as well as data augmentation and advanced feature extraction mechanisms to detect a wide range of DeepFake generation approaches. The test datasets yield an accuracy of 89.36% which proves that CNN-based models have strong capabilities to detect altered media content. The integrated military intelligence systems will deploy this approach to perform instant authentication of digital images and strategic communications thus reducing the dangers from DeepFake-based deception operations. Researchers will enact two goals: they will work on strengthening adversarial attack resilience and create light-weight systems for resource-limited applications. DeepFake threats to national security require immediate protection which can be achieved through AI-armed countermeasures.","","979-8-3315-2439-5","10.1109/IC2E365635.2025.11167802","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11167802","Deepfake Detection;Military Security;Artificial Intelligence;CNN;Tensorflow;Misinformation;Adversarial AI","Training;Deep learning;Deepfakes;Visualization;Accuracy;Military computing;Authentication;Convolutional neural networks;Artificial intelligence;Faces","","","","16","IEEE","24 Sep 2025","15-16 May 2025","15-16 May 2025","IEEE","IEEE Conferences"
"GrDT: Towards Robust Deepfake Detection Using Geometric Representation Distribution and Texture","H. Xie; H. He; B. Fu; V. Sanchez","Department of Computer Science, University of Warwick, UK; Department of Computer Science, University of Warwick, UK; Department of Computer Science, University of Warwick, UK; Department of Computer Science, University of Warwick, UK",2025 IEEE/CVF Winter Conference on Applications of Computer Vision Workshops (WACVW),"29 Apr 2025","2025","","","686","696","In recent years, deepfake images and videos have rapidly spread across social media platforms. This poses signifi-cant threats to public privacy, property, and safety. Several detection methods have been proposed, with the most common approaches being those based on deep learning and the analysis of biometric signals. However, these methods generally suffer from poor generalization capa-bilities, struggle to detect high-quality deepfakes, and de-pend on high-resolution training data. Based on these observations, we propose a detection method based on a Graph Attention Network (GAT) and biometric features, referred to as GrDT. The core idea of GrDT is to iden-tify deepfake face images by leveraging facial texture representations and the geometric relationships of key facial points. Cross-validation on the DF40 and ForgeryNet datasets shows that GrDT outperforms other methods in terms of the AP and AUC metrics. The code is available at https://github.com/SIPLab24IGrDT.","2690-621X","979-8-3315-3662-6","10.1109/WACVW65960.2025.00083","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10972515","deepfake detection;graph attention network;facial texture","Biometrics;Training;Measurement;Deepfakes;Privacy;Social networking (online);Training data;Feature extraction;Safety;Faces","","","","72","IEEE","29 Apr 2025","28 Feb.-4 March 2025","28 Feb.-4 March 2025","IEEE","IEEE Conferences"
"Robust Deepfake Detection via Synthetic Domain Alignment","I. Yee; A. Huang; S. Hu",Pennsylvania State University; Stanford University; Purdue University,2025 IEEE 22nd International Conference on Mobile Ad-Hoc and Smart Systems (MASS),"4 Nov 2025","2025","","","694","699","Deepfake technology has advanced rapidly in recent years, enabling the creation of hyper-realistic manipulated media that can be weaponized for misinformation, fraud, and identity abuse. While generative models for face swapping and reenactment have improved, deepfake detection models often struggle in real-world deployments due to a multitude of problems. Some of them are due to constant advancements in attacks, domain shifts from generation, and more. This work explores Synthetic Domain Alignment (SDA) as a strategy for improving deepfake detection robustness. SDA leverages an unconditional generative model to synthesize new samples in both the source and target domains, then uses these synthetic datasets to retrain the detector with better domain alignment. This synthetic-to-synthetic alignment process helps bridge the gap between domains without requiring direct access to the original source data, making it suitable for privacy-sensitive or streaming applications. We evaluate our approach against a strong static baseline trained on FaceForensics++ under both in-domain and cross-dataset settings, including compressed, degraded, and unseen manipulation types. Experimental results demonstrate that SDA can significantly improve detection accuracy under severe domain shifts, highlighting its potential for practical deployment.","2155-6814","979-8-3315-6599-2","10.1109/MASS66014.2025.00113","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11206208","Deepfake Detection;Synthetic Domain Alignment;Domain Shift;Robust AI;Multimedia Forensics","Deepfakes;Accuracy;Forensics;Weapons;Transfer learning;Detectors;Feature extraction;Robustness;Faces;Synthetic data","","","","8","USGov","4 Nov 2025","6-8 Oct. 2025","6-8 Oct. 2025","IEEE","IEEE Conferences"
"Detecting Deepfakes using Temporal Consistency of Facial Expression Transitions","R. E. Chacko; G. Bajwa","Department of Computer Science, Lakehead University, Thunder Bay, Ontario, Canada; Department of Computer Science, Lakehead University, Thunder Bay, Ontario, Canada","2025 22nd Annual International Conference on Privacy, Security, and Trust (PST)","3 Dec 2025","2025","","","1","7","Deepfake generation techniques have developed at a rapid rate, making it possible to generate highly realistic yet misleading videos with potentially far-reaching implications for privacy, security, and public confidence. This paper presents a study on the detection of deepfakes using the temporal consistency of facial expression transitions. Our method captures and integrates significant spatial and temporal information, facial edges, and dense optical flow with an Xception-based CNN and a bidirectional LSTM (BiLSTM) with an attention mechanism. We evaluated the approach on a multi-expression dataset obtained from DeeperForensics-1.0, comparing performance systematically across a range of expressions from Angry to Neutral. The experiments demonstrate a detection rate of up to $98.38 \%$ on the combined multi-expressions and point to the unique challenge of less expressive emotions. The findings affirm that face expression continuity examination plays an important part in enhancing the robustness of deepfake detection, achieving a scalable and adaptive approach to verifying the integrity of real-world media.","2643-4202","979-8-3315-0343-7","10.1109/PST65910.2025.11268852","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11268852","Deepfake detection;temporal consistency;facial expression analysis;optical flow;edges;Xception;bidirectional LSTM;attention mechanism;video forensics;spatio-temporal modeling","Deepfakes;Privacy;Attention mechanisms;Image edge detection;Bidirectional long short term memory;Media;Robustness;Security;Optical flow;Faces","","","","34","IEEE","3 Dec 2025","26-28 Aug. 2025","26-28 Aug. 2025","IEEE","IEEE Conferences"
"Context-Aware Deepfake Detection for Securing AI-Driven Financial Transactions","C. Liu; G. Zhang; S. Guo; Q. Li; G. Jeon; M. Gao","School of Electrical and Electronic Engineering, Shandong University of Technology, Zibo, China; School of Electrical and Electronic Engineering, Shandong University of Technology, Zibo, China; School of Electrical and Electronic Engineering, Shandong University of Technology, Zibo, China; School of Electronic Engineering and Computer Science, Queen Mary University of London, London, U.K.; Department of Embedded Systems Engineering, Incheon National University, Incheon, South Korea; School of Electrical and Electronic Engineering, Shandong University of Technology, Zibo, China",IEEE Transactions on Computational Social Systems,"2 Dec 2025","2025","12","6","5342","5349","The rapid advancement of deepfake technology has threatened the community’s sense of security, particularly in the context of face-based payment systems. Thus, deepfake detection has emerged as a critical issue demanding immediate attention. However, the generalization performance of existing detection models is limited as they are overly reliant on specific forged features while ignoring the common forged features. To address this problem, we introduce the context-aware decoupling network (CADNet) for deepfake detection. Specifically, a context self-calibration (CSC) module is constructed to guide the network to focus on local forged regions. It enlarges possible regions to increase the likelihood of forgery cues. Meanwhile, a frequency domain decoupling (FDD) module is introduced to extract and fuse different frequency components. It realizes the collaborative representation optimization of global semantics and local details. The experimental results prove that the proposed model exhibits strong generalization capability across multiple standard datasets. It achieves average area under the curve (AUC) values of 98.64% for in-domain evaluation and 75.52% for cross-dataset generalization.","2329-924X","","10.1109/TCSS.2025.3577753","Shandong Province Undergraduate Teaching Reform Project(grant numbers:Z2024184); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11073561","Context self-calibration (CSC);deepfake detection;facial payment;frequency domain decoupling (FDD);generalization","Deepfakes;Feature extraction;Forgery;Frequency-domain analysis;Image reconstruction;Wavelet transforms;Faces;Convolution;Fuses;Finance","","","","43","IEEE","8 Jul 2025","Dec. 2025","","IEEE","IEEE Journals"
"Deepfake Detection on Videos Based on Ratio Images","R. L. Testa; A. Machado-Lima; F. L. S. Nunes","School of Arts, Sciences and Humanities University of São Paulo, São Paulo, Brazil; School of Arts, Sciences and Humanities University of São Paulo, São Paulo, Brazil; School of Arts, Sciences and Humanities University of São Paulo, São Paulo, Brazil",2022 12th International Congress on Advanced Applied Informatics (IIAI-AAI),"23 Sep 2022","2022","","","403","408","Deepfake detection comes as a countermeasure to identify fake media content to reduce its harmful implications. Most detection approaches rely on identifying specific artifacts that can quickly become obsolete due to the fast advance in facial forgery methods. Some facial manipulation detection methods use temporal information to classify the video as real or fake. These methods mainly rely on 3D CNN architectures or two-stream networks using frame and video features. Our method not only considers temporal aspects, but it comes from a different perspective: extracting features that can account for inter-frame changes on a video. Inspired by the concept of ratio images, we extract features based on the ratio between adjacent frames for the face and its background. The experimental evaluation showed better results in intra- and cross-dataset tests on FaceForensics++ (FF++) and CelebDF datasets compared to the state-of-the-art deepfake detection approaches in the assessment with seen and unseen facial manipulation methods, as well as in seen and unseen video settings. In the intra-dataset experiment, the model resulted in an AUC of 100% for both CelebDF and FF++ datasets. In the cross dataset experiment, the model resulted in an AUC of 98% when trained with CelebDF and tested with FF++ and 86% when trained with FF++ and tested with CelebDF.","2472-0070","978-1-6654-9755-8","10.1109/IIAIAAI55812.2022.00086","Coordenação de Aperfeiçoamento de Pessoal de Nível Superior; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9894567","Deepfake detection;facial forgery;facial manipulation;Expression Ratio Image;spatial-temporal;video","Deepfakes;Three-dimensional displays;Media;Feature extraction;Forgery;Informatics;Faces","","","","30","IEEE","23 Sep 2022","2-8 July 2022","2-8 July 2022","IEEE","IEEE Conferences"
"SWYNT: Swin Y-Net Transformers for Deepfake Detection","F. Khalid; M. H. Akbar; S. Gul","Department of Computer Science, University of Engineering and Technology (UET), Taxila, Pakistan; Department of Computer Science, University of Engineering and Technology (UET), Taxila, Pakistan; Department of Computer Science, University of Engineering and Technology (UET), Taxila, Pakistan",2023 International Conference on Robotics and Automation in Industry (ICRAI),"6 Apr 2023","2023","","","1","6","Nowadays, less technical individuals can create false videos by only source and target images, using deepfakes generation tools and methodologies. Distributing false information on social media and other concerns related to the deepfakes have thus significantly increased. To deal with the challenges posed by incorrect details, efficient Deepfakes detection algorithms must be developed considering the tremendous advancement in deepfakes generating techniques. Existing techniques are not reliable enough to find deepfakes, especially when the videos are made with various deepfakes generation methods. The Swin Y-Net Transformers (SWYNT) architecture we created in this paper can visually discriminate between natural and artificial faces. The architecture uses a Swin transformer, encoder, and decoder in a U -Net architecture with a classification branch to build a model that can classify and segment deepfakes. The segmentation process creates segmentation masks and helps train the classifier. We have evaluated our suggested method using the extensive, standard, and diverse FaceForensics++ (FF++) and the Celeb-DF dataset. The generalizability evaluation of our process, which is part of the performance evaluation, reveals the model's promising performance in identifying deepfakes videos generated using various methodologies on both large-scale datasets.","2831-3313","978-1-6654-6472-7","10.1109/ICRAI57502.2023.10089585","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10089585","Celeb-DF;Deepfake;Deepfake Detection;FaceForensics++;Swin Transformer;Swim Y-Net;U-Net","Performance evaluation;Industries;Deepfakes;Social networking (online);Transformers;Decoding;Reliability","","7","","26","IEEE","6 Apr 2023","3-5 March 2023","3-5 March 2023","IEEE","IEEE Conferences"
"Deepfake Detection using Multi-Stream Convolutional Neural Networks with Attention-based Fusion","M. Sankaran; M. Alwbaidy; L. K. R; S. D. Govardhan; P. P. Selvam","USA; Department of Computers Techniques Engineering, College of Technical Engineering, The Islamic University, Najaf, Iraq; Department of Electronics and Communication Engineering, Nitte Meenakshi Institute of Technology, Nitte (Deemed to be University), Bengaluru, India; Department of Electronics and Communication Engineering, Dhanalakshmi Srinivasan College of Engineering and Technology, Mamallapuram, India; Doctoral Studies and Intellectual Property Rights, Meenakshi Academy of Higher Education & Research (Deemed to be University), Chennai, India",2025 International Conference on Intelligent Communication Networks and Computational Techniques (ICICNCT),"18 Nov 2025","2025","","","1","6","In recent years, DeepFake technology has rapidly evolved by enabling the development of highly realistic forged facial videos that pose serious threats to digital trust and security. Traditional deep learning approaches, although effective in image classification, usually struggle to generalize against subtle manipulation artifacts, compression noise, and temporal inconsistencies. To address these challenges, a MultiStream Convolutional Neural Network (MS-CNN) framework is proposed for robust deepfake detection. Initially, utilizes the FaceForensics++ dataset which is a widely recognized benchmark containing authentic and manipulated facial videos. Preprocessing incorporates face detection, alignment, and the generation of complementary modalities, which include frequency-domain representations, residual noise maps, and temporal signals, such as rPPG and optical flow. These multimodal inputs were passed through parallel CNN streams for feature extraction to capture spatial, spectral, and temporal inconsistencies. The extracted features are combined using an attention-based adaptive fusion mechanism that dynamically learns the relative importance of each modality. Finally, a fully connected softmax classifier produces end-to-end predictions that differentiate between real and fake videos. The experimental results show that the MS-CNN obtains higher accuracy (99.77 %), precision (98.95 %), recall (98.45 %), and F1score (98.76 %) when compared with the existing CNN model, which improves detection robustness and generalization in different manipulation techniques.","","979-8-3315-8623-2","10.1109/ICICNCT66124.2025.11232837","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11232837","deepfake detection;multi-stream convolutional neural networks;residual noise maps;softmax classifier;temporal signals","Training;Deepfakes;Accuracy;Computational modeling;Noise;Feature extraction;Transformers;Robustness;Convolutional neural networks;Security","","","","15","IEEE","18 Nov 2025","5-6 Sept. 2025","5-6 Sept. 2025","IEEE","IEEE Conferences"
"Aggregated Distinguishable Feature Learning for Generalized Deepfake Detection","B. Yan; C. Xu; C. -T. Li","School of Information Technology, Deakin University, Melbourne, Australia; Institute for Sustainable Industries Liveable Cities, Victoria University, Melbourne, Australia; School of Information Technology, Deakin University, Geelong, Australia",2025 International Joint Conference on Neural Networks (IJCNN),"14 Nov 2025","2025","","","1","8","Deepfake detection is essential for mitigating the growing risks associated with the misuse of AI in video manipulation. While existing deep learning-based methods excel in intra-dataset settings, their performance often deteriorates significantly when applied to unseen datasets, underscoring the pressing challenge of improving generalization capability. To tackle this challenge, we focus on identitying discriminative regions by applying the principle of object detection, which locating forged clues. In this paper, we propose an aggregated distinguishable feature learning framework that innovatively incorporates object detector with a graph claasifier. Specifically, the proposed framework consists of three main components: 1) We employ a DEtection TRansformer (DETR) to learn intrinsic feature differences for capturing different discriminative regions. 2) To better utilize distinguishable features in these regions, we treat each local feature vector of the regions as node and design a node correlation generation module (NCGM) to establish the connections between the nodes by integrating the feature similarity and spatial location relationship. 3) we employ graph convolutional neural networks to aggregate the distinguishable features and learn the global connectivity pattern of the nodes for face forgery detection. Comprehensive experimental results on four benchmark datasets demonstrate that our method effectively improves generalization capability and outperforms other state-of-the-art approaches.","2161-4407","979-8-3315-1042-8","10.1109/IJCNN64981.2025.11228889","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11228889","Deepfake detection;graph neural classifier;object detection;structural similarity;forgery localization","Representation learning;Deepfakes;Correlation;Object detection;Detectors;Pressing;Feature extraction;Transformers;Forgery;Vectors","","","","43","IEEE","14 Nov 2025","30 June-5 July 2025","30 June-5 July 2025","IEEE","IEEE Conferences"
"Hierarchical Multi-Branch Deepfake Detection Network (HMBDDN)","A. M. Mohammadi; N. Ratha","Department of Computer Science and Engineering, State University of New York at Buffalo, United States; Department of Computer Science and Engineering, State University of New York at Buffalo, United States",2024 IEEE Western New York Image and Signal Processing Workshop (WNYISPW),"11 Dec 2024","2024","","","1","6","Deepfake technology, which manipulates visual media, poses significant threats to content authenticity and security. This paper addresses these challenges by presenting a novel deepfake detection system designed to enhance detection accuracy, mitigate data imbalance, and improve generalization capabilities. Our approach encompasses multiple stages, including robust face detection, comprehensive feature extraction, effective data balancing, and precise classification, providing a holistic solution. Specifically, the system extracts intricate features from facial data and employs an advanced data balancing strategy to ensure equitable training across classes. A sophisticated discriminator model is then utilized to perform the final classification. The proposed method achieves high accuracy on the Celeb-DF v2 dataset, outperforming existing state-of-the-art (SOTA) deepfake detection models. These results demonstrate the robustness and effectiveness of our approach, contributing to more reliable detection of manipulated media and enhancing the integrity of digital content.","2471-9242","979-8-3315-0555-4","10.1109/WNYISPW63690.2024.10786607","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10786607","Deepfake Detection;Multi-Branch Discriminator;Feature Learning;Data Balancing;SMOTE","Deepfakes;Adaptation models;Visualization;Accuracy;Computational modeling;Media;Feature extraction;Robustness;Data models;Computational efficiency","","","","33","IEEE","11 Dec 2024","8-8 Nov. 2024","8-8 Nov. 2024","IEEE","IEEE Conferences"
"AI vs. AI: Deep Learning Approaches for Detecting Deepfake Content","S. Kulkarni; D. K. Vishwakarma; V. Ranga","Department of Information Technology, Delhi Technological University, New Delhi, India; Department of Information Technology, Delhi Technological University, New Delhi, India; Department of Information Technology, Delhi Technological University, New Delhi, India","2024 1st International Conference on Advances in Computing, Communication and Networking (ICAC2N)","28 Feb 2025","2024","","","1075","1080","The proliferation of deepfake content has raised significant concerns due to its potential for misuse in spreading misinformation and undermining trust in digital media. This review paper explores the implementation of deep learning techniques during deepfake detection regarding the effectiveness of different algorithms and models regarding synthetic media generation using advanced AI methods. The paper is an in-depth analysis of some key benchmark datasets among the likes of FakeAVCeleb, FaceForensics++, DFDC, FaceForensics, and LAV-DF, essential for training and evaluation of deepfake detection techniques. This paper compares the strengths and weaknesses of these models differently in different scenarios using FACTOR, EfficientNetB4 + EfficientNetB4ST + B4Att + B4AttST, Cross-Efficient Vision Transformation, XceptionNet, BA-TFD deep learning models over these datasets. However, it deals directly with the current improvements in the field that tackle the varying and growing challenges we face due to increasingly sophisticated generative technologies. It is through this comprehensive review that this paper will provide better insights into deepfake detection mechanisms and the contributions made toward the development of further robust and scalable solutions toward the threats imparted by deepfake content.","","979-8-3503-5681-6","10.1109/ICAC2N63387.2024.10895362","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10895362","Deepfake Detection;Vision Transformer;Ensemble of CNN;Deep Learning;Neural Networks","Deep learning;Training;Measurement;Deepfakes;Attention mechanisms;Reviews;Transformers;Robustness;Artificial intelligence;Standards","","","","19","IEEE","28 Feb 2025","16-17 Dec. 2024","16-17 Dec. 2024","IEEE","IEEE Conferences"
"Deepfake Detection via a Progressive Attention Network","S. Guo; M. Gao; Q. Li; G. Jeon; D. Camacho","Shandong University of Technology, Zibo, China; Shandong University of Technology, Zibo, China; Queen Mary University of London, London, United Kingdom; Incheon National University, Incheon, South Korea; Universidad Politécnica de Madrid (UPM), Madrid, Spain",2024 International Joint Conference on Neural Networks (IJCNN),"9 Sep 2024","2024","","","1","6","The rapid advancement of deepfake technology has enabled the creation of highly realistic forged face images or videos. While deepfake technology adds entertainment to people’s lives, it also poses a potential threat to social security. Deepfake detection is a crucial technology for identifying forged images. However, existing deep learning-based models for deepfake detection often overlook subtle forged traces. To solve this problem, we propose a Progressive Attention Network (PANet). The PANet incorporates two attention modules, namely the Efficient Multi-Scale Attention Module (EMAM) and the Spatial and Channel Attention Module (SCAM), in a progressive manner. The EMAM focuses on crucial facial regions, such as the eyes, nose, and mouth, rather than the entire face. The SCAM facilitates fine-grained feature extraction. Experimental results demonstrate that the proposed method achieves state-of-the-art results on deepfake detection datasets.","2161-4407","979-8-3503-5931-2","10.1109/IJCNN60899.2024.10650463","EMI; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10650463","Deepfake Detection;Efficient Multi-Scale Attention;Feature Extraction;Information Disorder;Forged Traces","Deepfakes;Neural networks;Nose;Mouth;Focusing;Entertainment industry;Feature extraction","","2","","31","IEEE","9 Sep 2024","30 June-5 July 2024","30 June-5 July 2024","IEEE","IEEE Conferences"
"Deepfake Detection with Clustering-based Embedding Regularization","K. Zhu; B. Wu; B. Wang","School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China; School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China; School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China",2020 IEEE Fifth International Conference on Data Science in Cyberspace (DSC),"21 Aug 2020","2020","","","257","264","In recent months, AI-synthesized face swapping videos referred to as deepfake have become an emerging problem. False video is becoming more and more difficult to distinguish, which brings a series of challenges to social security. Some scholars are devoted to studying how to improve the detection accuracy of deepfake video. At the same time, in order to conduct better research, some datasets for deepfake detection are made. Companies such as Google and Facebook have also spent huge sums of money to produce datasets for deepfake video detection, as well as holding deepfake detection competitions. The continuous advancement of video tampering technology and the improvement of video quality have also brought great challenges to deepfake detection. Some scholars have achieved certain results on existing datasets, while the results on some high-quality datasets are not as good as expected. In this paper, we propose new method with clustering-based embedding regularization for deepfake detection. We use open source algorithms to generate videos which can simulate distinctive artifacts in the deepfake videos. To improve the local smoothness of the representation space, we integrate a clustering-based embedding regularization term into the classification objective, so that the obtained model learns to resist adversarial examples. We evaluate our method on three latest deepfake datasets. Experimental results demonstrate the effectiveness of our method.","","978-1-7281-9558-2","10.1109/DSC50466.2020.00046","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9172873","face swapping;deepfake detection;clustering-based;regularization","Deepfakes;Social networking (online);Resists;Data science;Forgery;Data models;Quality assessment;Internet;Security;Faces","","14","","38","IEEE","21 Aug 2020","27-30 July 2020","27-30 July 2020","IEEE","IEEE Conferences"
"Fixing Domain Bias for Generalized Deepfake Detection","Y. Mao; W. You; L. Zhou; Z. Lu","School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China; School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China; School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China; School of Cyber Science and Engineering, University of International Relations, Beijing, China",2023 IEEE International Conference on Multimedia and Expo (ICME),"25 Aug 2023","2023","","","2225","2230","Generalizing deepfake detection has posed a great challenge to digital media forensics, as inferior performance is obtained when training sets and testing sets are domain-mismatched. In this paper, we show that a CNN-based detection model can significantly improve performance by fixing domain bias. Specifically, we propose a novel Fixing Domain Bias network (FDBN). FDBN does not rely on manual features, but is based on three core designs. Firstly, a domain-invariant network based on randomly stylized normalization is devised to constrain the domain discrepancy in the feature space. Then, through adversarial learning, a generalizing representation in the stylized distribution is learned to enhance the shared feature bias among manipulation methods in the domain-specific network. Finally, to encourage equality of biases among different domains, we utilize the bias extrapolation penalty strategy by suppressing the expected bias on the extremely-performing domains. Extensive experiments demonstrate that our framework achieves effectiveness and generalization towards unseen face forgeries.","1945-788X","978-1-6654-6891-6","10.1109/ICME55011.2023.00380","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10219848","deepfake detection;face forgery detection;domain bias;domain generalization","Training;Deepfakes;Extrapolation;Correlation;Forensics;Manuals;Media","","","","33","IEEE","25 Aug 2023","10-14 July 2023","10-14 July 2023","IEEE","IEEE Conferences"
"AVT$^{2}$-DWF: Improving Deepfake Detection With Audio-Visual Fusion and Dynamic Weighting Strategies","R. Wang; D. Ye; L. Tang; Y. Zhang; J. Deng","Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, Wuhan, China; Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, Wuhan, China; Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, Wuhan, China; Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, Wuhan, China; Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, Wuhan, China",IEEE Signal Processing Letters,"2 Aug 2024","2024","31","","1960","1964","With the continuous improvements of deepfake methods, forgery messages have transitioned from single-modality to multi-modal fusion, posing new challenges for existing forgery detection algorithms. In this letter, we propose AVT$^{2}$-DWF, the Audio-Visual dual Transformers grounded in Dynamic Weight Fusion, which aims to amplify both intra- and cross-modal forgery cues, thereby enhancing detection capabilities. AVT$^{2}$-DWF adopts a dual-stage approach to capture both spatial characteristics and temporal dynamics of facial expressions. This is achieved through a face transformer with an $n$-frame-wise tokenization strategy encoder and an audio transformer encoder. Subsequently, it uses multi-modal conversion with dynamic weight fusion to address the challenge of heterogeneous information fusion between audio and visual modalities. Experiments on DeepfakeTIMIT, FakeAVCeleb, and DFDC datasets indicate that AVT$^{2}$-DWF achieves state-of-the-art performance intra- and cross-dataset Deepfake detection.","1558-2361","","10.1109/LSP.2024.3433596","National Natural Science Foundation of China(grant numbers:62072343,61932011); Fundamental Research Funds for the Central Universities(grant numbers:2042023kf0228); National Key Research and Development Program of China(grant numbers:2019QY(Y)0206); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10609529","Audio-visual;deepfake detection;dynamic weight fusion","Feature extraction;Transformers;Visualization;Training;Faces;Deepfakes;Forgery","","18","","22","IEEE","25 Jul 2024","2024","","IEEE","IEEE Journals"
"DeepFake-o-meter: An Open Platform for DeepFake Detection","Y. Li; C. Zhang; P. Sun; L. Ke; Y. Ju; H. Qi; S. Lyu","Ocean University of China, China; University of Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China; University at Buffalo State University of New York, USA; University at Buffalo State University of New York, USA; University of Chinese Academy of Sciences, China; University at Buffalo State University of New York, USA",2021 IEEE Security and Privacy Workshops (SPW),"8 Jul 2021","2021","","","277","281","In recent years, the advent of deep learning-based techniques and the significant reduction in the cost of computation resulted in the feasibility of creating realistic videos of human faces, commonly known as DeepFakes. The availability of open-source tools to create DeepFakes poses as a threat to the trustworthiness of the online media. In this work, we develop an open-source online platform, known as DeepFake-o-meter, that integrates state-of-the-art DeepFake detection methods and provide a convenient interface for the users. We describe the design and function of DeepFake-o-meter in this work.","","978-1-6654-3732-5","10.1109/SPW53761.2021.00047","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9474270","Multimedia Forensics;DeepFake Detection;Software Engineering","Privacy;Conferences;Media;Tools;Security;Open source software;Faces","","11","","20","IEEE","8 Jul 2021","27-27 May 2021","27-27 May 2021","IEEE","IEEE Conferences"
"A Hybrid Xception-LSTM Model with Channel and Spatial Attention Mechanism for Deepfake Video Detection","D. Dagar; D. K. Vishwakarma","Dept. of Information Technolgy, Delhi Technological University (DTU), Delhi, India; Dept. of Information Technolgy, Delhi Technological University (DTU), Delhi, India",2023 3rd International Conference on Mobile Networks and Wireless Communications (ICMNWC),"22 Feb 2024","2023","","","1","5","The great strides taken in recent times in image and video manipulation have raised serious concerns. Deepfake technology uses deep learning approaches to create highly realistic, astonishing content. Detecting such videos is the only promising defense against such fraudulent data. To counter the malicious intent of the user, a deepfake detection model is proposed that employs channel and spatial attention mechanisms(CBAM) along with Xception and LSTM pretrained models. Xception uses depthwise separable convolution to capture the latent spatial artifacts. LSTM captures the discrepancies among the manipulated sequences; hence, this hybrid ensembling of models allows the learning of powerful features. The evaluation is performed on the recently proposed Div-DF dataset consisting of varied video manipulation like face swap, facial reenactment, and lip-sync. It shows that the model works well (Accuracy~ 93 % & AUC ~ 0.98) on the diversified dataset and easily beats the score of various state-of-the-art deepfake detection and image classification models.","","979-8-3503-1702-2","10.1109/ICMNWC60182.2023.10435983","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10435983","deepfake detection;deepfake dataset;video manipulation detection;channel attention;spatial attention","Wireless communication;Deep learning;Deepfakes;Image coding;Convolution;Faces;Image classification","","7","","31","IEEE","22 Feb 2024","4-5 Dec. 2023","4-5 Dec. 2023","IEEE","IEEE Conferences"
"A Deepfake detection technique using Recurrent Neural Network and EfficientNet","S. P. Koritala; M. Chimata; S. N. Polavarapu; B. S. Vangapandu; T. K. Gogineni; V. M. Manikandan","Department of Computer Science and Engineering, SRM University Mangalagiri, Andhra Pradesh, India; Department of Computer Science and Engineering, SRM University Mangalagiri, Andhra Pradesh, India; Department of Computer Science and Engineering, SRM University Mangalagiri, Andhra Pradesh, India; Department of Computer Science and Engineering, SRM University Mangalagiri, Andhra Pradesh, India; Department of Computer Science and Engineering, SRM University Mangalagiri, Andhra Pradesh, India; Department of Computer Science and Engineering, SRM University Mangalagiri, Andhra Pradesh, India",2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT),"4 Nov 2024","2024","","","1","6","A deepfake is a computer-generated image or video that appears to be real but is a fabricated representation created to make an individual appear to be saying or doing something that did not occur. Deepfakes generate misleading or deceptive information by manipulating and superimposing faces onto pre-existing footage using artificial intelligence. This paper introduces a novel approach for deepfake detection through a combination of EfficientNet and Recurrent Neural Networks (RNNs). This method enhances detection efficiency by leveraging the hierarchical features acquired by EfficientNet and employing RNNs, specifically Long Short-Term Memory (LSTM) networks, to capture temporal dependencies. Application of this approach to the Celeb-DF dataset resulted in an accuracy of $\mathbf{9 9. 9 8 \%}$.","2473-7674","979-8-3503-7024-9","10.1109/ICCCNT61001.2024.10723875","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10723875","EfficientNet;Recurrent Neural Network(RNN);LSTM;Deepfake detection","Deepfakes;Accuracy;Recurrent neural networks;Scalability;Feature extraction;Real-time systems;Artificial intelligence;Long short term memory;Faces","","4","","20","IEEE","4 Nov 2024","24-28 June 2024","24-28 June 2024","IEEE","IEEE Conferences"
"A Study on Effective Use of BPM Information in Deepfake Detection","S. -H. Lee; G. -E. Yun; M. Y. Lim; Y. K. Lee","Department of Information Security, Seoul Women's University, Seoul, Republic of Korea; Department of Information Security, Seoul Women's University, Seoul, Republic of Korea; Department of Information Security, Seoul Women's University, Seoul, Republic of Korea; Department of Information Security, Seoul Women's University, Seoul, Republic of Korea",2021 International Conference on Information and Communication Technology Convergence (ICTC),"7 Dec 2021","2021","","","425","427","Recent developments in deepfake technology are increasing new security threats. To solve these issues, various detection methods have been proposed including the methods utilizing biological signals captured by R-PPG. However, existing methods have limitations in terms of detection accuracy and generalized performance. In this paper, we present our approach for R-PPG-based BPM (Beats Per Minute) analysis for effective deepfake detection. With the selected deepfake datasets, we performed (a) comparison and analysis of conditions for BPM processing, and (b) BPM extraction by dividing the face into 16 regions and comparison of BPM in each region. The results showed that our proposed BPM-related properties are effective in deepfake detection.","2162-1233","978-1-6654-2383-0","10.1109/ICTC52510.2021.9621186","IITP(Institute of Information & communications Technology Planning & Evaluation) in 2021(grant numbers:2016-0-00022); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9621186","deepfake;deepfake detection;R-PPG;security","Feature extraction;Biology;Information and communication technology;Security;Faces;Videos;Information integrity","","3","","21","IEEE","7 Dec 2021","20-22 Oct. 2021","20-22 Oct. 2021","IEEE","IEEE Conferences"
"Implementation of Deep Learning Techniques for Deepfake Classification: A comparative study using ResNet-50 and VGG16","K. Yesugade; R. Jadhav","Department of Computer Engineering, Bharati Vidyapeeth (Deemed to be University) College of Engineering, Pune, India; Department of Information Technology, Bharati Vidyapeeth (Deemed to be University) College of Engineering, Pune, India",2024 IEEE Pune Section International Conference (PuneCon),"27 Feb 2025","2024","","","1","5","This work investigates the use and assessment of ResNet-50 and VGG16 deep learning models for detecting deepfake images using the Labelled Faces in the Wild (LFW) dataset. The methodology encompassed thorough preparation of the dataset and the utilisation of both models to differentiate between authentic and altered facial photos. The models' performance was evaluated using fundamental criteria including accuracy, precision, recall, and F1 score. VGG16 demonstrated superior performance compared to ResNet-50, achieving an accuracy of 93.87%, recall of 96.23%, and an F1 score of 94.41%, while ResNet-50 achieved a precision of 92.54%, recall of 95.26%, and F1 score of 93.88%. Although both models achieved good accuracy, VGG16 had superior stability and generalization across the whole dataset. The study determines that VGG16 is the more dependable model for detecting deepfakes on the LFW dataset. It suggests that future efforts should concentrate on enhancing ResNet-50 or creating ensemble methods to enhance detection capabilities.","2831-5022","979-8-3315-2782-2","10.1109/PuneCon63413.2024.10894868","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10894868","Deepfake Detection;VGG16;ResNet50;Image Classification;Deep Learning","Training;Deep learning;Hands;Deepfakes;Accuracy;Stability criteria;Feature extraction;Ensemble learning;Faces;Optimization","","1","","18","IEEE","27 Feb 2025","13-15 Dec. 2024","13-15 Dec. 2024","IEEE","IEEE Conferences"
"Advancing Digital Forensics: Comparative Analysis of Deep Learning Models for Deepfake Detection","M. Chakarverti; A. Goswami; A. Yadav","SCSET, Bennett University, Greater Noida, India; SCSET, Bennett University, Greater Noida, India; SCSET, Bennett University, Greater Noida, India","2024 International Conference on Modeling, Simulation & Intelligent Computing (MoSICom)","18 Feb 2025","2024","","","564","569","Deepfake has significantly advanced the generation of synthetic media capabilities, allowing for the creation of significantly promising fake visual and audio content. This technology manipulates existing media to replace a person’s face and voice, posing severe ethical and security concerns. Deepfakes are increasingly exploited in various cybercrimes, including identity theft, cyber extortion, and the spread of fake news, with over 95% involving obscene content highlighting the growing threat. Hence, the detection of deepfake content is a growing field among researchers. Moving on the same lines, our study compared the six well-known models (i.e., MesoNet, Xception, VGG19, ResNet101, NAS-Net, and MobileNet). A dataset was used that has both real and fake images which was employed for all models to assess their performance. Our results showed that the VGG19 was the most effective model with 83.84% among all six. The results can be used to further push the development of tools and techniques to fight against the digital media tampering that may be helpful for the cybersecurity industry.","","979-8-3315-3331-1","10.1109/MoSICom63082.2024.10881081","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10881081","Cybersecurity;Deepfake Detection;Image Manipulation;Neural Networks","Industries;Deep learning;Deepfakes;Visualization;Ethics;Computational modeling;Identity theft;Digital forensics;Computer crime;Faces","","","","25","IEEE","18 Feb 2025","9-11 Dec. 2024","9-11 Dec. 2024","IEEE","IEEE Conferences"
"Deepfake Detection with NAND Logic Using Two Region Watermarking","S. Kuwahara; S. Arai; Y. Kawachi; H. Kang","Advanced Course of Electrical and Electronic Engineering, National Institute of Technology, Tokyo College, NITTC, Hachioji, Japan; Advanced Course of Electrical and Electronic Engineering, National Institute of Technology, Tokyo College, NITTC, Hachioji, Japan; Department of Electronic Engineering, National Institute of Technology, Tokyo College, NITTC, Hachioji, Japan; Department of Electronic Engineering, National Institute of Technology, Tokyo College, NITTC, Hachioji, Japan",2024 IEEE 13th Global Conference on Consumer Electronics (GCCE),"28 Nov 2024","2024","","","1308","1312","In this paper, we propose a novel method for detecting Deepfakes in video content such as news broadcasts. Deepfake is the techniques to replace parts of images and audio to a high degree using deep learning, and its quality is improving as computing power increases. It can be used to create malicious videos, such as replacing the faces of politicians or company CEOs to instruct fraudulent transactions, raising concerns about the risk of propaganda and fraud, and measures are needed. Previous research has mainly implemented Deepfake content detection using machine learning, but challenges remain, such as low accuracy and difficulty in quickly responding to new Deepfake techniques. In this study, we propose a method that embeds a watermark resistant to linear processing, image processing, and collusion attacks into both the facial and background regions of a single frame in the video. The results of applying our proposed method to 1,000 facial images showed that we could detect Deepfake videos with 100 % accuracy.","2693-0854","979-8-3503-5507-9","10.1109/GCCE62371.2024.10760958","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10760958","Watermarking;Deepfake detection","Resistance;Deep learning;Deepfakes;Accuracy;Image processing;Watermarking;Robustness;Fraud;Logic;Faces","","","","18","IEEE","28 Nov 2024","29 Oct.-1 Nov. 2024","29 Oct.-1 Nov. 2024","IEEE","IEEE Conferences"
"Robust Deepfake Detection via Perturbation Domain Alignment","L. Lu; Y. Wang; L. Zhang; Y. Guo","School of Computer Science and Engineering, Beihang University, Beijing, China; School of Computer Science and Engineering, Beihang University, Beijing, China; Freelancer, Beijing, China; School of Computer Science and Engineering, Beihang University, Beijing, China","ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","7 Mar 2025","2025","","","1","5","Deepfake detection becomes vital in distinguishing the real image/videos from the fake ones, which are produced via advanced deep learning based face manipulation techniques. Although existing approaches exhibit decent generalization, they struggle to maintain good robustness against diverse perturbations in practical scenarios. Perturbations, which can induce distortions on the original image/video, such as compression, Gaussian noise, blur, etc., tend to introduce negative impacts on the performance of deepfake detection models. Therefore, in this paper, we propose a novel deepfake detection method, named Robust Deepfake Detection via Perturbation Domain Alignment (PDA-RDD), by exploiting the mechanism of domain alignment. Our approach consider different perturbations as distinct domains, and proposes a paired instance momentum whitening (PIMW) module to align these domains, to effectively remove the sensitive information associated with these perturbations. To further enhance PIMW, we construct an MLP projector (MLPP) to project the encoded feature into a more optimal latent vector. Extensive experiments demonstrate the effectiveness of our method on multiple widely used datasets.","2379-190X","979-8-3503-6874-1","10.1109/ICASSP49660.2025.10890870","National Natural Science Foundation of China; State Key Laboratory of Software Development Environment; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10890870","deepfake detection;robustness;domain alignment","Deep learning;Deepfakes;Image coding;Perturbation methods;Gaussian noise;Robustness;Vectors;Acoustics;Speech processing;Faces","","","","40","IEEE","7 Mar 2025","6-11 April 2025","6-11 April 2025","IEEE","IEEE Conferences"
"AI-Powered Deepfake Detection Using CNN and Vision Transformer Architectures","M. S. Sheikh; U. Kirtonia; N. T. Arthi; M. Al-Imran","Department of Computer Science and Engineering, East West University, Dhaka, Bangladesh; Department of Computer Science and Engineering, East West University, Dhaka, Bangladesh; Department of Computer Science and Engineering, East West University, Dhaka, Bangladesh; Department of Computer Science and Engineering, East West University, Dhaka, Bangladesh",2025 6th International Conference on Big Data Analytics and Practices (IBDAP),"4 Sep 2025","2025","","","179","184","The increasing use of artificial intelligence-generated deepfakes creates major challenges in maintaining digital authenticity. Four AI-based models, consisting of three CNNs and one Vision Transformer, were evaluated using large face image datasets. Data preprocessing and augmentation techniques improved model performance across different scenarios. VFDNET demonstrated superior accuracy with MobileNetV3, showing efficient performance, thereby demonstrating AI's capabilities for dependable deepfake detection.","","979-8-3315-9474-9","10.1109/IBDAP65587.2025.11145852","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11145852","Deepfake Detection;DFCNET;VFDNET;MobileNetV3;ResNet50","Deepfakes;Computer vision;Accuracy;Data preprocessing;Big Data;Transformers;Robustness;Data models;Faces;Residual neural networks","","","","15","IEEE","4 Sep 2025","1-3 Aug. 2025","1-3 Aug. 2025","IEEE","IEEE Conferences"
"A Comparative Analysis of Machine Learning and Deep Learning Approaches in Deepfake Detection","M. Vashistha; S. Jain; S. Pandey; A. Pradhan; S. Tarwani","Artificial Intelligence and Data Science, Vivekananda Institute of Professional Studies - Technical Campus, Delhi, India; Artificial Intelligence and Data Science, Vivekananda Institute of Professional Studies - Technical Campus, Delhi, India; Artificial Intelligence and Data Science, Vivekananda Institute of Professional Studies - Technical Campus, Delhi, India; Artificial Intelligence and Data Science, Vivekananda Institute of Professional Studies - Technical Campus, Delhi, India; Artificial Intelligence and Data Science, Vivekananda Institute of Professional Studies - Technical Campus, Delhi, India",2024 IEEE Region 10 Symposium (TENSYMP),"19 Nov 2024","2024","","","1","8","Deepfakes refer to the visual media where the faces, bodily movements have been digitally altered using some software or program, this has proven to be more of a double edged sword as it also contributes towards content creation and media creation that may be used for positive purposes. To combat this situation, measures to detect deep fake in the media is a credible approach. This work showcases a comparative analysis among 3 Deep Learning as well as 3 Machine Learning algorithms in order to reach a conclusive state of determining the best algorithms that can be implemented for Deepfake detection. For the machine learning algorithms, KNN, SVM and Logistic Regression have been used whereas CNN, TCN and CNN + LSTM have been used for the Deep Learning Algorithm. Detection of deepfakes through these algorithms works by sequentially processing, analyzing and classifying the features on the basis of the dataset fed for the algorithms. The chosen metrics for performing a comparison between each of the algorithms are Accuracy and F1 Score. The development, implementation and comparison of the algorithms was carried out on Google Collab and Jupyter Notebook. Upon comparative analysis of the algorithms between each other, it was found that CNN had the highest accuracy and Fl-score of 0.9409 and 0.7225 respectively with KNN being the worst-performing algorithm with an accuracy 0.5770 and F1 score of 0.4088 respectively.","2642-6102","979-8-3503-6486-6","10.1109/TENSYMP61132.2024.10752209","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10752209","Deepfake Detection;Face Morphing;Convolutional Neural Networks;Machine Learning;Deep Learning;Support Vector Machine;K-Nearest Neighbour;Face Recognition","Deep learning;Deepfakes;Visualization;Machine learning algorithms;Accuracy;Nearest neighbor methods;Media;Prediction algorithms;Feature extraction;Classification algorithms","","1","","21","IEEE","19 Nov 2024","27-29 Sept. 2024","27-29 Sept. 2024","IEEE","IEEE Conferences"
"CDNet: Cluster Decision for Deepfake Detection Generalization","Z. Hou; Z. Hua; K. Zhang; Y. Zhang","Harbin Institute of Technology, Shenzhen, China; Harbin Institute of Technology, Shenzhen, China; Harbin Institute of Technology, Shenzhen, China; Nanjing University of Aeronautics and Astronautics, Nanjing, China",2023 IEEE International Conference on Image Processing (ICIP),"11 Sep 2023","2023","","","3010","3014","The fast development of deepfake generation technology has caused serious security threats to human society. Many deep-fake detection methods have been proposed recently, but most of them can only show high detection performance for the deepfakes generated by the similar techniques with the training dataset. To improve the ability of detecting unseen types of deepfakes, some deepfake detection methods have constructed self-generated datasets to train their models. However, the artifacts on these self-generated datasets are usually caused by some specific face-blending algorithms and lack of generality. In this paper, we propose cluster decision network (CDNet) to improve the deepfake detection generalizability. We design a selective attention module that decides the attention areas by manually cropping the facial areas (e.g., eyes, nose, and lips), which greatly reduce the model size and ensure a small model size. Inspired by the contrastive learning, we also propose a cluster classifier to equally utilize the feature representation. Extensive experiments show that our method outperforms existing state-of-the-art methods in deepfake detection generalizability and has the minimum model size.","","978-1-7281-9835-4","10.1109/ICIP49359.2023.10223180","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10223180","Deepfake detection;Generalizability;Contrastive learning","Training;Deepfakes;Lips;Image processing;Decision making;Nose;Clustering algorithms","","3","","21","IEEE","11 Sep 2023","8-11 Oct. 2023","8-11 Oct. 2023","IEEE","IEEE Conferences"
"Metamorphic Testing for the Deepfake Detection Model","C. Pang; Y. Pan; H. Bai","Southwest University of Science and Technology, Mianyang, Sichuan, China; Southwest University of Science and Technology, Mianyang, Sichuan, China; China Aerodynamics Research and Development Center, Mianyang, Sichuan, China","2023 IEEE 23rd International Conference on Software Quality, Reliability, and Security Companion (QRS-C)","19 Feb 2024","2023","","","1","8","Technological advancements in Deepfake enhance its quality and continuously reduce the application threshold. But the illicit utilization of Deepfake brings potential threats to individuals and the country. For safeguarding facial information security, it is crucial to detect the manipulated images and videos through deepfake detection models. It is an important topic of how to guarantee the accuracy, generalization, and significance of these models. Nevertheless, it is hard to obtain test predictions for deepfake detection models which present a notable testing challenge due to their extensive editing capabilities and uncertainties. In order to alleviate test oracle problem in this field, this paper general metamorphic relations based on the practice application scenario from three categories including image post-processing, image inpainting, and modifying the faces using textual prompts. This study founded the highest inconsistency percentage reaching up to 18.77% and the highest AUC percentage decreased by 12.9%. This paper assesses the effectiveness of these six metamorphic relations by employing five Deepfake detection models and evaluating the models' generalization based on result discrepancies. Experimental results show that metamorphic relations constructed can automatically generate high-quality follow-up test cases for identifying inconsistencies and assessing the models' generalization.","2693-9371","979-8-3503-5939-8","10.1109/QRS-C60940.2023.00012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10429947","deepfake detection;metamorphic testing;metamorphic relations;generalization","Deepfakes;Uncertainty;Information security;Software quality;Predictive models;Software reliability;Testing","","1","","25","IEEE","19 Feb 2024","22-26 Oct. 2023","22-26 Oct. 2023","IEEE","IEEE Conferences"
"A New Approach to Detect Deepfake Video using Multi-Input Convolutional Neural Network","M. A. Rahman; M. Ehsan Shahmi Chowdhury","Department of Computer Science and Engineering, Green University of Bangladesh, Dhaka, Bangladesh; Department of Computer Science and Engineering, Green University of Bangladesh, Dhaka, Bangladesh",2022 4th International Conference on Sustainable Technologies for Industry 4.0 (STI),"24 Apr 2023","2022","","","1","6","In this modern age, Deepfake videos are spreading around, having a severe impact on the social and personal lives of the general public. Efficient techniques, operating better than others, is hence in the requirement. In this research, combination of many objects like left eye, right eye and mouth shapes from image frames of videos are taken into consideration, thus achieving better accuracy than other detection techniques. In this proposal, deep learning techniques, specially the multi-input Convolution Neural Network, are executed. The proposal firstly detects the face, followed by specific objects such as left eye, right eye and mouth. Then multi-input CNN is applied that classifies the data based on eyes and mouth. After applying multi-input CNN, the accuracy increases impressively. Novel techniques are used to extract specific features like eyes, mouth. Memory storage was a concern for the proposal. Despite this, comparison with other relevant research works proved better accuracy and data analysis.","","978-1-6654-9045-0","10.1109/STI56238.2022.10103229","Green University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10103229","Convolutional Neural Network;DeepFake Detection;Deep Learning;Image Frames;Video Detection","Training;Deep learning;Deepfakes;Shape;Scalability;Mouth;Training data","","","","15","IEEE","24 Apr 2023","17-18 Dec. 2022","17-18 Dec. 2022","IEEE","IEEE Conferences"
"Hybrid Deep Learning-Based Deepfake Detection Using VGG19 and InceptionV3","H. S. Shreyas; A. A. Choudhari; T. Arvind; R. Ugarakhod","Dept. of Electronics and Communication Engineering, PES University, Bengaluru, India; Dept. of Electronics and Communication Engineering, PES University, Bengaluru, India; Dept. of Electronics and Communication Engineering, PES University, Bengaluru, India; Dept. of Electronics and Communication Engineering, PES University, Bengaluru, India",2025 6th International Conference on Data Intelligence and Cognitive Informatics (ICDICI),"2 Sep 2025","2025","","","1672","1677","Deepfake technology has become a significant threat to the authenticity of digital media, cybersecurity and public trust, as it uses AI and machine learning-specifically Generative Adversarial Networks (GANs)-to produce highly realistic fake videos that are increasingly difficult to detect using traditional methods. In response to this growing challenge, this paper proposes a hybrid deep learning model that combines the strengths of two powerful convolutional neural networks: VGG19 and InceptionV3. VGG19 is effective at extracting finegrained texture features, while InceptionV3 excels at capturing complex patterns at multiple scales. The model also incorporates a Multi-Task Cascaded Convolutional Network (MTCNN) for face detection and alignment from video frames. Experimental results on benchmark datasets demonstrate that this hybrid model outperforms the individual models in terms of accuracy, precision, and stability. This research makes valuable contributions to the development of scalable, intelligent systems for multimedia forensics and AI-based digital security.","","979-8-3315-0313-0","10.1109/ICDICI66477.2025.11134949","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11134949","Deepfake Detection;Deep Learning;Hybrid model;VGG19;InceptionV3","Deep learning;Deepfakes;Adaptation models;Accuracy;Forensics;Media;Feature extraction;Transformers;Data models;Convolutional neural networks","","","","13","IEEE","2 Sep 2025","9-11 July 2025","9-11 July 2025","IEEE","IEEE Conferences"
"Visual Deepfake Detection: Review of Techniques, Tools, Limitations, and Future Prospects","N. Ur Rehman Ahmed; A. Badshah; H. Adeel; A. Tajammul; A. Daud; T. Alsahfi","Department of Computing, Hamdard University, Islamabad Campus, Islamabad, Pakistan; Department of Software Engineering, University of Sargodha, Sargodha, Pakistan; Department of Computing, Hamdard University, Islamabad Campus, Islamabad, Pakistan; U.S.-Pakistan Center for Advanced Studies in Water, Mehran University of Engineering and Technology, Jamshoro, Sindh, Pakistan; Faculty of Resilience, Rabdan Academy, Abu Dhabi, United Arab Emirates; Department of Information Systems and Technology, College of Computer Science and Engineering, University of Jeddah, Jeddah, Saudi Arabia",IEEE Access,"3 Jan 2025","2025","13","","1923","1961","In recent years, rapid advancements in deepfakes (incorporating Artificial Intelligence (AI), machine, and deep learning) have updated tools and techniques for manipulating multimedia. Though technology has primarily been utilized for beneficial purposes, such as education and entertainment, it is also used for malicious or unethical tasks to spread disinformation or ruin someone’s dignity, even if it encompasses harassing and blackmailing victims. Deepfakes refer to high-quality and realistic multimedia-manipulated content that has been digitally modified or synthetically generated. We conducted a systematic literature review of deepfake detection to offer an updated overview of existing research work that initially describes the widely accessible deepfake generation tools, classifications, and detection process. We highlighted recent techniques in visual deepfake detection based on the feature representations, grouped into four domains: spatial, temporal, frequency, and spatio-temporal, including their key features and limitations by providing details of existing datasets, together with the potentials of deepfake and its future directions. This study tried to add an updated repository of technological change in deepfake, which could help researchers to develop robust deepfake models.","2169-3536","","10.1109/ACCESS.2024.3523288","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10816641","Deepfake detection;machine learning;deep learning;deepfake applications;deepfake datasets;deepfake generation tools","Deepfakes;Face recognition;Deep learning;Faces;Training;Generators;Decoding;Social networking (online);Generative adversarial networks;Feature extraction","","9","","282","CCBY","27 Dec 2024","2025","","IEEE","IEEE Journals"
"Deepfake Detection through Deep Learning","D. Pan; L. Sun; R. Wang; X. Zhang; R. O. Sinnott","School of Computing and Information Systems, The University of Melbourne, Melbourne, Australia; School of Computing and Information Systems, The University of Melbourne, Melbourne, Australia; School of Computing and Information Systems, The University of Melbourne, Melbourne, Australia; School of Computing and Information Systems, The University of Melbourne, Melbourne, Australia; School of Computing and Information Systems, The University of Melbourne, Melbourne, Australia","2020 IEEE/ACM International Conference on Big Data Computing, Applications and Technologies (BDCAT)","28 Dec 2020","2020","","","134","143","Deepfakes allow for the automatic generation and creation of (fake) video content, e.g. through generative adversarial networks. Deepfake technology is a controversial technology with many wide reaching issues impacting society, e.g. election biasing. Much research has been devoted to developing detection methods to reduce the potential negative impact of deepfakes. Application of neural networks and deep learning is one approach. In this paper, we consider the deepfake detection technologies Xception and MobileNet as two approaches for classification tasks to automatically detect deepfake videos. We utilise training and evaluation datasets from FaceForensics++ comprising four datasets generated using four different and popular deepfake technologies. The results show high accuracy over all datasets with an accuracy varying between 91–98% depending on the deepfake technologies applied. We also developed a voting mechanism that can detect fake videos using the aggregation of all four methods instead of only one.","","978-0-7381-2396-7","10.1109/BDCAT50828.2020.00001","Australian Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9302547","DeepFake Detection;Xception;MobileNet;FaceForenscis++;Keras;TensorFlow","Videos;Information integrity;Faces;Convolution;Training;Deep learning;Voting","","120","","24","IEEE","28 Dec 2020","7-10 Dec. 2020","7-10 Dec. 2020","IEEE","IEEE Conferences"
"AVoiD-DF: Audio-Visual Joint Learning for Detecting Deepfake","W. Yang; X. Zhou; Z. Chen; B. Guo; Z. Ba; Z. Xia; X. Cao; K. Ren","School of Cyber Science and Technology, Sun Yat-sen University, Shenzhen Campus, Shenzhen, China; School of Software Engineering, University of Electronic Science and Technology of China, Chengdu, China; Zhuque Laboratory, Tencent Security, Shenzhen, China; School of Electronic and Computer Engineering, Peking University, Shenzhen, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; College of Cyber Security, Jinan University, Guangzhou, China; School of Cyber Science and Technology, Sun Yat-sen University, Shenzhen Campus, Shenzhen, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China",IEEE Transactions on Information Forensics and Security,"4 Apr 2023","2023","18","","2015","2029","Recently, deepfakes have raised severe concerns about the authenticity of online media. Prior works for deepfake detection have made many efforts to capture the intra-modal artifacts. However, deepfake videos in real-world scenarios often consist of a combination of audio and visual. In this paper, we propose an Audio-Visual Joint Learning for Detecting Deepfake (AVoiD-DF), which exploits audio-visual inconsistency for multi-modal forgery detection. Specifically, AVoiD-DF begins by embedding temporal-spatial information in Temporal-Spatial Encoder. A Multi-Modal Joint-Decoder is then designed to fuse multi-modal features and jointly learn inherent relationships. Afterward, a Cross-Modal Classifier is devised to detect manipulation with inter-modal and intra-modal disharmony. Since existing datasets for deepfake detection mainly focus on one modality and only cover a few forgery methods, we build a novel benchmark DefakeAVMiT for multi-modal deepfake detection. DefakeAVMiT contains sufficient visuals with corresponding audios, where any one of the modalities may be maliciously modified by multiple deepfake methods. The experimental results on DefakeAVMiT, FakeAVCeleb, and DFDC demonstrate that the AVoiD-DF outperforms many state-of-the-arts in deepfake detection. Our proposed method also yields superior generalization on various forgery techniques.","1556-6021","","10.1109/TIFS.2023.3262148","National Key Research and Development Program of China(grant numbers:2022YFB3103504); Shenzhen Science and Technology Program(grant numbers:20220016); National Natural Science Foundation of China(grant numbers:62261160653,62122032,62172359); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10081373","Deepfake detection;multi-modal;audio-visual;joint learning","Deepfakes;Visualization;Forgery;Detectors;Feature extraction;Faces;Electronic mail","","110","","67","IEEE","27 Mar 2023","2023","","IEEE","IEEE Journals"
"MSVT: Multiple Spatiotemporal Views Transformer for DeepFake Video Detection","Y. Yu; R. Ni; Y. Zhao; S. Yang; F. Xia; N. Jiang; G. Zhao","Institute of Information Science, Beijing Jiaotong University, Beijing, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China; Rapid-Rich Object Search Laboratory, Interdisciplinary Graduate Program, Nanyang Technological University, Jurong West, Singapore; Mashang Consumer Finance Company Ltd., Chongqing, China; Mashang Consumer Finance Company Ltd., Chongqing, China; Mashang Consumer Finance Company Ltd., Chongqing, China",IEEE Transactions on Circuits and Systems for Video Technology,"5 Sep 2023","2023","33","9","4462","4471","Recently, DeepFake videos have developed rapidly, causing new security issues in society. Due to the rough spatiotemporal view, existing video-based detection methods struggle to capture fine-grained spatiotemporal information, resulting in limited generalization ability. In addition, although the transformer has achieved great success in the past few years, the application of transformer on deepfake video detection still needs to be studied. To solve this problem, in this paper, we propose a novel Multiple Spatiotemporal Views Transformer (MSVT) with Local Spatiotemporal View (LSV) and Global Spatiotemporal View (GSV), to mine more detailed spatiotemporal information. Firstly, for establishing the LSV, different from existing works that sparsely sample a single frame to build the input sequence, we employ the local-consecutive temporal view to capture vital dynamic inconsistency. Furthermore, the extracted frame features within each group are fed to the temporal transformer followed by the feature fusion module, to generate group-level spatiotemporal features. Then, we further establish Global Spatiotemporal View (GSV) by feeding all the frame features within the whole video to the temporal transformer followed by the feature fusion module. Finally, we propose a novel global-local transformer (GLT) to effectively integrate these multi-level features for mining more subtle and comprehensive features. Extensive experiments on six large datasets demonstrate that our MSVT outperforms state-of-the-art detection methods.","1558-2205","","10.1109/TCSVT.2023.3281448","National Key Research and Development Program of China(grant numbers:2021ZD0112100); National NSF of China(grant numbers:U1936212,62120106009); Beijing NSF(grant numbers:4222014); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10138555","Generalized DeepFake detection;multiple spatiotemporal views;global-local transformer","Transformers;Feature extraction;Spatiotemporal phenomena;Deepfakes;Feeds;Faces;Task analysis","","36","","78","IEEE","30 May 2023","Sept. 2023","","IEEE","IEEE Journals"
"Constructing New Backbone Networks via Space-Frequency Interactive Convolution for Deepfake Detection","Z. Guo; Z. Jia; L. Wang; D. Wang; G. Yang; N. Kasabov","School of Computer Science and Technology, Xinjiang University, Urumqi, China; School of Computer Science and Technology, Xinjiang University, Urumqi, China; School of Computer Science and Technology, Xinjiang University, Urumqi, China; College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; School of Engineering, Computing and Mathematical Sciences, Auckland University of Technology, Auckland, New Zealand",IEEE Transactions on Information Forensics and Security,"21 Nov 2023","2024","19","","401","413","The serious concerns over the negative impacts of Deepfakes have attracted wide attentions in the community of multimedia forensics. The existing detection works achieve deepfake detection by improving the traditional backbone networks to capture subtle manipulation traces. However, there is no attempt to construct new backbone networks with different structures for Deepfake detection by improving the internal feature representation of convolution. In this work, we propose a novel Space-Frequency Interactive Convolution (SFIConv) to efficiently model the manipulation clues left by Deepfake. To obtain high-frequency features from tampering traces, a Multichannel Constrained Separable Convolution (MCSConv) is designed as the component of the proposed SFIConv, which learns space-frequency features via three stages, namely generation, interaction and fusion. In addition, SFIConv can replace the vanilla convolution in any backbone networks without changing the network structure. Extensive experimental results show that seamlessly equipping SFIConv into the backbone network greatly improves the accuracy for Deepfake detection. In addition, the space-frequency interaction mechanism does benefit to capturing common artifact features, thus achieving better results in cross-dataset evaluation. Our code will be available at https://github.com/EricGzq/SFIConv.","1556-6021","","10.1109/TIFS.2023.3324739","Xinjiang Uygur Autonomous Region Tianshan Excellence Project(grant numbers:2022TSYCLJ0036); Scientific and Technological Innovation 2030 Major Project(grant numbers:2022ZD0115800); National Natural Science Foundation of China(grant numbers:62302427,62261053,61972143,61972142,62372164,U1903213); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10286083","Deepfake detection;space-frequency interactive convolution;backbone network;manipulation traces","Deepfakes;Convolution;Faces;Feature extraction;Forgery;Deep learning;Task analysis","","33","","52","IEEE","16 Oct 2023","2024","","IEEE","IEEE Journals"
"Efficient Deepfake Detection via Layer-Frozen Assisted Dual Attention Network for Consumer Imaging Devices","M. Talha Usman; H. Khan; S. Kumar Singh; M. Young Lee; J. Koo","School of Computing, Gachon University, Seongnam, South Korea; School of Computing, Gachon University, Seongnam, South Korea; Department of Computer Engineering, Marwadi University, Rajkot, India; School of Computing, Chung-Ang University, Seoul, South Korea; School of Computing, Gachon University, Seongnam, South Korea",IEEE Transactions on Consumer Electronics,"18 Jun 2025","2025","71","1","281","291","The advancement of open-source frameworks and user-friendly manipulation applications has accelerated the spread of deep fakes. In this study, we proposed optimal features assisted with a dual attention (DA) network strategy to combat this proliferation in consumer imaging devices. We employed EfficientNetV2 (ENV2) as the primary feature extractor, initially utilizing its pre-trained weights from the ImageNet dataset while keeping its layers frozen to leverage their rich feature extraction capabilities. We enhance this base model with a DA module that integrates the Convolutional Block Attention Module (CBAM), which utilizes both channel attention (CA) and spatial attention (SA) mechanisms to improve feature representation. CA dynamically adjusts channel-wise feature responses to capture interdependencies between channels, thereby improving feature discrimination. SA allows the network to focus on important regions within feature maps, enhancing localization and reducing noise. The features are assisted in multi-stages of the network with residual fashion to focus on discriminative visual information. During fine-tuning, we unfreeze the deeper layers of ENV2 for further refinement of learned features to better suit the deepfake dataset. We employed a targeted fine-tuning approach, unfreezing specific layers and applying iterative adjustments to optimize performance, providing valuable insights into countering the growing use of synthetic media in consumer imaging. To validate our network, we conducted comprehensive experiments on four benchmark datasets: FaceForensics++, the World Leaders, Celeb-DF, and DFDC. As a result, our network achieved superior performance compared to existing benchmarks and state-of-the-art approaches, offering a promising solution for robust deepfake detection (DD) in consumer imaging technologies.","1558-4127","","10.1109/TCE.2024.3476477","National Research Foundation of Korea (NRF) Grant; Korea Government (MSIT)(grant numbers:RS-2023-00240740); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10711866","Deepfake detection;consumer imaging technologies;attention mechanisms;model optimization;progressive fusion;fine-tuning","Feature extraction;Deepfakes;Training;Imaging;Visualization;Face recognition;Consumer electronics;Computer architecture;Benchmark testing;Accuracy","","32","","53","IEEE","9 Oct 2024","Feb. 2025","","IEEE","IEEE Journals"
"Improving Video Vision Transformer for Deepfake Video Detection Using Facial Landmark, Depthwise Separable Convolution and Self Attention","K. N. Ramadhani; R. Munir; N. P. Utama","Bandung Institute of Technology, Bandung, Indonesia; Bandung Institute of Technology, Bandung, Indonesia; Bandung Institute of Technology, Bandung, Indonesia",IEEE Access,"19 Jan 2024","2024","12","","8932","8939","In this paper, we present our result of research in video deepfake detection. We built a deepfake detection system to detect whether a video is a deepfake or real. The deepfake detection algorithm still struggle in providing a sufficient accuracy values, especially in challenging deepfake dataset. Our deepfake detection system utilized spatiotemporal feature that extracted using Video Vision Transformer (ViViT). The main contribution of our research is providing a deepfake detection system that based on ViViT architecture and using landmark area images for the input of the system. Our system extracted the feature from a number of spatial features. The spatial feature was extracted using Depthwise Separable Convolution (DSC) block combined with Convolution Block Attention Module (CBAM) from tubelet. The tubelet was a representation of facial landmark area that was extracted from the input video. In our system, we used 25 facial landmark area for an input video. In our experiment we used Celeb-DF version 2 dataset because it is considered to be a challenging deepfake dataset. We conducted augmentation to the dataset, so we obtained 8335 videos for training set, 390 videos for validation set, and 1123 videos for testing set. We trained our deepfake detection system using Adam optimizer, with learning rate of 10–4 and 100 epoch. From the experiment, we obtained the accuracy score of 87.18% and F1 score of 92.52%. We also conducted the ablation study to display the effect of each part of our model to the overall system performance. From this research, we obtained that by using landmark area images, our ViViT based deepfake detection system had a good performance in detecting deepfake videos.","2169-3536","","10.1109/ACCESS.2024.3352890","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10388363","Deepfake detection;facial landmark;depthwise separable convolution;convolution block attention module;video vision transformer","Deepfakes;Feature extraction;Visualization;Face recognition;Convolutional neural networks;Head;Transformers","","28","","28","CCBYNCND","11 Jan 2024","2024","","IEEE","IEEE Journals"
"MeDiFakeD: Medical Deepfake Detection using Convolutional Reservoir Networks","R. Budhiraja; M. Kumar; M. K. Das; A. S. Bafila; S. Singh","Institute of Informatics and Communication University of Delhi South Campus, New Delhi, India; School of Computer and Information Sciences Indira Gandhi National Open University, New Delhi, India; Institute of Informatics and Communication University of Delhi South Campus, New Delhi, India; Institute of Informatics and Communication University of Delhi South Campus, New Delhi, India; Institute of Informatics and Communication University of Delhi South Campus, New Delhi, India","2022 IEEE Global Conference on Computing, Power and Communication Technologies (GlobConPT)","14 Nov 2022","2022","","","1","6","Generation of photo-realistic fake content using Artificial Intelligence (AI)-based Generative Adversarial Networks has not only engulfed media, facial recognition or social networks, but is now rapidly surging ahead in the realm of medical imaging and is further facilitated by worldwide Covid-19 outbreak. Medical Deepfake pertains to application of AI-triggered deepfake technology on to medical modalities like Computed Tomography (CT) scan, X-Ray, Ultrasound etc. Owing to its high degree of privacy and sensitivity, any threats originating from exposed vulnerabilities, or, attacks on patients medical imagery takes an extremely threatening stance, either devastating the patients remaining lifespan, or resulting in grave financial frauds while satiating corrupt business motives. These tampering attacks, involve either insertion or removal of certain disease conditions, tumors in/from the modality under analysis. This paper implements and demonstrates a practical, lightweight technique which aims to accelerate deepfake detection for biomedical imagery by detecting malignant tumors injected in modalities of healthy patients. The developed technique makes use of convolutional reservoir networks (CoRN), which enable ensemble feature extraction and results in improved classification metrics. We further corroborate its effectiveness while working with a miniscule (< 100) set of images and illustrate the extent of generalization attained with different forms of the same medical imagery.","","978-1-6654-9365-9","10.1109/GlobConPT57482.2022.9938172","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9938172","Medical Image Tampering;Medical Deepfake Detection;Convolutional Reservoir Network;Convolution Neural Networks;Reservoir Computing;Computed Tomography","Deepfakes;Ultrasonic imaging;Computed tomography;Face recognition;Computer architecture;Reservoirs;Feature extraction","","9","","9","IEEE","14 Nov 2022","23-25 Sept. 2022","23-25 Sept. 2022","IEEE","IEEE Conferences"
"Empirical Assessment of Deepfake Detection: Advancing Judicial Evidence Verification Through Artificial Intelligence","E. Hydara; M. Kikuchi; T. Ozono","Department of Computerf Science, Nagoya Institute of Technology, Nagoya, Aichi, Japan; Department of Computerf Science, Nagoya Institute of Technology, Nagoya, Aichi, Japan; Department of Computerf Science, Nagoya Institute of Technology, Nagoya, Aichi, Japan",IEEE Access,"22 Oct 2024","2024","12","","151188","151203","Deepfake technology poses a profound challenge to the integrity of facial evidence in criminal justice, threatening the authenticity and admissibility of such evidence in the courtroom. In this research, a specialized deepfake detection system tailored for facial evidence verification was developed, aiming to counteract the influence of deepfake technology. The proposed system integrates a unique combination of video-frame selection, confidence thresholds, prediction timestamps, and heat maps for individual frames of suspect videos. This methodological fusion is designed to support forensic analysts by enhancing the reliability and trustworthiness of video evidence used in judicial settings. Our comprehensive evaluation involved diverse user groups participating in experimental scenarios to assess the effectiveness of the system. The results indicated that the combined features of the system significantly enhanced the detection of fabricated evidence, fostering high levels of confidence and trust among users. Moreover, this study delves into the legal and ethical considerations surrounding the deployment of deep fake-detection technologies, underscoring the necessity for legal frameworks to evolve in response to emerging digital threats. By addressing both the technical and jurisprudential challenges, this research contributes to safeguarding the evidential value of facial recognition in the judicial process against the disruptive potential of deepfake technologies.","2169-3536","","10.1109/ACCESS.2024.3480320","Japan Society for the Promotion of Science (JSPS) KAKENHI(grant numbers:JP24K03052,JP22K18006); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10716657","Artificial intelligence;criminal justice;deepfake detection;evidence verification;facial evidence","Deepfakes;Forensics;Artificial intelligence;Media;Feature extraction;Face recognition;Law enforcement;Ethics;Termination of employment","","4","","32","CCBYNCND","14 Oct 2024","2024","","IEEE","IEEE Journals"
"Space–Frequency and Global–Local Attentive Networks for Sequential Deepfake Detection","G. Zhang; Q. Li; M. Gao; S. Guo; G. Jeon; A. M. Abdelmoniem","School of Electrical and Electronic Engineering, Shandong University of Technology, Zibo, China; School of Electronic Engineering and Computer Science, Queen Mary University of London, London, U.K.; School of Electrical and Electronic Engineering, Shandong University of Technology, Zibo, China; School of Electrical and Electronic Engineering, Shandong University of Technology, Zibo, China; Department of Embedded Systems Engineering, Incheon National University, Incheon, South Korea; School of Electronic Engineering and Computer Science, Queen Mary University of London, London, U.K.",IEEE Transactions on Computational Social Systems,"6 Oct 2025","2025","12","5","2940","2948","The widespread misinformation generated by deepfake systems has emerged as a significant challenge in the dynamic realm of digital media. It poses threats to credibility, privacy, and security of information in daily life. Moreover, the increasing accessibility to facial editing tools further enables users to alter facial characteristics subtly through a series of intricate steps. To address the issue, we introduce a space–frequency and global–local attentive network (SFGLA-Net) for sequential deepfake detection. This method is designed to identify and analyze the sophisticated manipulated attributes of deepfake images. Specifically, we introduce a space–frequency fusion module to leverage the deep feature extracted in spatial and frequency domains, so as to exploit subtle inconsistencies and artifacts that are not perceptible in the spatial domain alone. Additionally, we design a global–local attention module to pinpoint the manipulated areas more accurately. Extensive experiments demonstrate the superior performance of the proposed method by significantly outperforming existing techniques in sequential deepfake detection. The code is available at https://github.com/guishengzhanga/SFGLA.","2329-924X","","10.1109/TCSS.2025.3541346","National Natural Science Foundation of Shandong Province(grant numbers:ZR2022MF307); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10904029","Deepfake;global–local consistency;sequential deepfake detection;space–frequency fusion","Deepfakes;Feature extraction;Frequency-domain analysis;Forgery;Data mining;Transformers;Attention mechanisms;Kernel;Faces;Accuracy","","3","","33","IEEE","25 Feb 2025","Oct. 2025","","IEEE","IEEE Journals"
"Leveraging Pixel Difference Feature for Deepfake Detection","M. Mao; C. Yan; J. Wang; J. Yang","Key Laboratory of the Ministry of Education for Embedded System and Service Computing, and National (Province Ministry Joint) Collaborative Innovation Center for Financial Network Security, Tongji University, Shanghai, China; Key Laboratory of the Ministry of Education for Embedded System and Service Computing, and National (Province Ministry Joint) Collaborative Innovation Center for Financial Network Security, Tongji University, Shanghai, China; Key Laboratory of the Ministry of Education for Embedded System and Service Computing, and National (Province Ministry Joint) Collaborative Innovation Center for Financial Network Security, Tongji University, Shanghai, China; Department of Computer Science and Technology, Tongji University, Shanghai, China",IEEE Transactions on Emerging Topics in Computational Intelligence,"23 Jul 2025","2025","9","4","3178","3188","The rise of Deepfake technology poses a formidable threat to the credibility of both judicial evidence and intellectual property safeguards. Current methods lack the ability to integrate the texture information of facial features into CNNs, despite the fact that fake contents are subtle and pixel-level. Due to the fixed grid kernel structure, CNNs are limited in their ability to describe detailed fine-grained information, making it challenging to achieve accurate image detection through pixel-level fine-grained features. To mitigate this problem, we propose a Pixel Difference Convolution (PDC) to capture local intrinsic detailed patterns via aggregating both intensity and gradient information. To avoid the redundant feature computations generated by PDC and explicitly enhance the representational power of a standard convolutional kernel, we separate PDC into vertical/horizontal and diagonal parts. Furthermore, we propose an Ensemble Dilated Convolution (EDC) to explore long-range contextual dependencies and further boost performance. We introduce a novel network, Pixel Difference Convolutional Network (PDCNet), which is built with PDC and EDC to expose Deepfake by capturing faint traces of tampering hidden in portrait images. By leveraging PDC and EDC in the information propagation process, PDCNet seamlessly incorporates both local and global pixel differences. Comprehensive experiments are performed on three databases, FF++, Celeb-DF, and DFDC to confirm that our PDCNet outperforms existing approaches. Our approach achieves accuracies of 0.9634, 0.9614, and 0.8819 in FF++, Celeb-DF, and DFDC, respectively.","2471-285X","","10.1109/TETCI.2025.3548803","China Scholarship Council CSC(grant numbers:202206260081); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10937061","Deepfake detection;pixel difference feature;ensemble dilated convolution","Faces;Deepfakes;Feature extraction;Convolution;Frequency-domain analysis;Forgery;Convolutional neural networks;Accuracy;Kernel;Biomedical monitoring","","1","","79","IEEE","21 Mar 2025","Aug. 2025","","IEEE","IEEE Journals"
"Learning Generalizable Representations for Deepfake Detection with Realistic Sample Generation and Dual Augmentation","Z. Gao; X. Zhu; H. Jia; Y. Zhao; C. Ma; C. Li","Key Laboratory of Computer Vision and System, Ministry of Education, Tianjin University of Technology, Tianjin, P.R China; Key Laboratory of Computer Vision and System, Ministry of Education, Tianjin University of Technology, Tianjin, P.R China; Key Laboratory of Computer Vision and System, Ministry of Education, Tianjin University of Technology, Tianjin, P.R China; Key Laboratory of Computer Vision and System, Ministry of Education, Tianjin University of Technology, Tianjin, P.R China; Shandong Artificial Intelligence Institute, Qilu University of Technology (Shandong Academy of Sciences), Jinan, P.R China; Key Laboratory of Computer Vision and System, Ministry of Education, Tianjin University of Technology, Tianjin, P.R China",IEEE Transactions on Dependable and Secure Computing,"","2025","PP","99","1","13","Deepfake detection aims to identify manipulated content generated by generative models such as GANs and diffusion models. Although many detection methods have been proposed in recent years, their performance often degrades significantly when the test data includes unknown images or novel forgery types. To address this challenge, we propose a Realistic Sample Generation and Dual Augmentation framework, abbreviated as RSG-DA, to enhance generalization in deepfake detection. The key idea is to explore and expand the forgery feature space in order to learn decision boundaries that can capture diverse forgery patterns. Specifically, we introduce a Dynamic Landmark Diffusion Generator (DLDG) that synthesizes hybrid forgery samples with high visual realism and structural diversity. Additionally, we design a Dual Data Augmentation (DDA) strategy composed of DW-Augmentation and Class-Augmentation, where DW-Augmentation strengthens the representation of authentic image features through multi-scale transformations, while Class-Augmentation enriches the forgery distribution by expanding it with varied manipulations. Finally, we present a Lightweight Generic Forgery Distillation (LGFD) module that integrates the above components into a unified encoder, enabling the learning of robust and transferable forgery representations. Extensive experiments show that our method consistently outperforms state-of-the-art approaches in both intra-dataset and cross-dataset evaluations.","1941-0018","","10.1109/TDSC.2025.3642980","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11297777","Deepfake Detection;Dynamic Landmark Diffusion Generator;Dual Data Augmentation;Lightweight Generic Forgery Distillation","Forgery;Deepfakes;Data augmentation;Visualization;Generators;Face recognition;Diffusion models;Robustness;Noise reduction;Feature extraction","","","","","IEEE","11 Dec 2025","","","IEEE","IEEE Early Access Articles"
"Synthetic Realities: A Critical Review of Deepfake Techniques","M. Yadav; S. K. Sheoran; G. Singh","Department of CSE, Indira Gandhi University, Meerpur, Rewari, Haryana, India; Department of ECE, National Institute of Technology, Kurukshetra, Haryana, India; Department of ECE, National Institute of Technology, Kurukshetra, Haryana, India","2025 International Conference on Cognitive Computing in Engineering, Communications, Sciences and Biomedical Health Informatics (IC3ECSBHI)","20 May 2025","2025","","","1094","1098","Deepfakes involve the manipulation of visual content using various techniques, initially intended for enjoyment, but potentially resulting in detrimental effects for economic, political, and societal objectives, including money fraud and identity fraud. Deepfakes, or hyper-realistic generated pictures and videos, are now feasible due to the fusion of deep learning and computer vision methodologies such as Generative Adversarial Networks (GANs) and autoencoders. Individuals with malicious intent or even non-technical users of machine learning can manipulate a photograph or video by modifying the data, resulting in a new image or video that is undetectable to both humans and machines. Public trust in digital media material has decreased due to deepfakes, since individuals can no longer believe the authenticity of the images they see. Research on deepfake detection is essential to maintain public trust in digital multimedia. This article explores multiple deepfake detection strategies to deal with deepfake and present a literature analysis to give an up to date summery of research activities in the field of deepfake detection. This paper provides a thorough examination of deep-fake phenomena and emphasizes several methods for creating and identifying deepfakes.","","979-8-3315-1852-3","10.1109/IC3ECSBHI63591.2025.10991244","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10991244","Deep Fakes;Artificial intelligence (AI);Deepfake detection;video or image manipulation","Deep learning;Economics;Deepfakes;Visualization;Reviews;Media;Streaming media;Generative adversarial networks;Fraud;Faces","","","","31","IEEE","20 May 2025","16-18 Jan. 2025","16-18 Jan. 2025","IEEE","IEEE Conferences"
"ADT: Anti-Deepfake Transformer","P. Wang; K. Liu; W. Zhou; H. Zhou; H. Liu; W. Zhang; N. Yu",University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China; Simon Fraser University; University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China,"ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","2899","2903","Recently almost all the mainstream deepfake detection methods use Convolutional Neural Networks (CNN) as their backbone. However, due to the overreliance on local texture information which is usually determined by forgery methods of training data, these CNN-based methods cannot generalize well to unseen data. To get out of the predicament of prior methods, in this paper, we propose a novel transformer-based framework to model both global and local information and analyze anomalies of face images. In particular, we design attention leading module, multi-forensics module and variant residual connections for deepfake detection, and leverage token-level contrast loss for more detailed supervision. Experiments on almost all popular public deepfake datasets demonstrate that our method achieves state-of-the-art performance in cross-dataset evaluation and comparable performance in intra-dataset evaluation.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9746888","University of Science and Technology of China; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9746888","Deepfake Detection;Transferability;Face Forensics;Vision Transformer","Analytical models;Conferences;Training data;Signal processing;Transformers;Forgery;Acoustics","","14","","34","IEEE","27 Apr 2022","23-27 May 2022","23-27 May 2022","IEEE","IEEE Conferences"
"Can ChatGPT Detect DeepFakes? A Study of Using Multimodal Large Language Models for Media Forensics","S. Jia; R. Lyu; K. Zhao; Y. Chen; Z. Yan; Y. Ju; C. Hu; X. Li; B. Wu; S. Lyu","University at Buffalo, State University of New York, Buffalo, USA; Williamsville East High School, Buffalo, USA; The Chinese University of Hong Kong, Shenzhen, China; The Chinese University of Hong Kong, Shenzhen, China; The Chinese University of Hong Kong, Shenzhen, China; University at Buffalo, State University of New York, Buffalo, USA; University at Albany, State University of New York, Albany, USA; University at Albany, State University of New York, Albany, USA; The Chinese University of Hong Kong, Shenzhen, China; University at Buffalo, State University of New York, Buffalo, USA",2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW),"27 Sep 2024","2024","","","4324","4333","DeepFakes, which refer to AI-generated media content, have become an increasing concern due to their use as a means for disinformation. Detecting DeepFakes is currently solved with programmed machine learning algorithms. In this work, we investigate the capabilities of multimodal large language models (LLMs) in DeepFake detection. We conducted qualitative and quantitative experiments to demonstrate multimodal LLMs and show that they can expose AI-generated images through careful experimental design and prompt engineering. This is interesting, considering that LLMs are not inherently tailored for media forensic tasks, and the process does not require programming. We discuss the limitations of multimodal LLMs for these tasks and suggest possible improvements.","2160-7516","979-8-3503-6547-4","10.1109/CVPRW63382.2024.00436","National Science Foundation; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10677972","Deepfake Detection;Multimodal Large Language Models;Media Forensics;GPT4V","Deepfakes;Machine learning algorithms;Forensics;Large language models;Conferences;Training data;Focusing","","22","","42","IEEE","27 Sep 2024","17-18 June 2024","17-18 June 2024","IEEE","IEEE Conferences"
"Deepfake Detection using GAN Discriminators","S. A. Aduwala; M. Arigala; S. Desai; H. J. Quan; M. Eirinaki","Computer Engineering Department, San José State University (SJSU), San José, CA, USA; Computer Engineering Department, San José State University (SJSU), San José, CA, USA; Computer Engineering Department, San José State University (SJSU), San José, CA, USA; Computer Engineering Department, San José State University (SJSU), San José, CA, USA; Computer Engineering Department, San José State University (SJSU), San José, CA, USA",2021 IEEE Seventh International Conference on Big Data Computing Service and Applications (BigDataService),"18 Oct 2021","2021","","","69","77","Deepfake videos are videos where the features of a person are replaced with the features of another person. Videos can be manipulated using powerful Deep Learning techniques. This technology may be used maliciously as a means of misinformation, manipulation, and persuasion. There are currently not many solutions to identify products of Deepfake technology, although there is significant research being conducted to tackle this problem. One often researched deep learning technology is the Generative Adversarial Network (GAN). These networks are commonly used to generate Deepfake videos but not used for their detection. In this work, we explore solutions based on GAN discriminators as a means to detect Deepfake videos. Using MesoNet as a baseline, we train a GAN and extract the discriminator as a dedicated module to detect Deepfakes. We test several discriminator architectures using multiple datasets to explore how the efficacy of the discriminator varies with different setups and training methods. Finally, we propose a model to boost the efficacy of a group of GAN discriminators using ensemble methods. Our results show that GAN discriminators, even augmented by ensemble methods, do not perform well on videos from unknown sources.","","978-1-6654-3483-6","10.1109/BigDataService52369.2021.00014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9564096","Deepfake Detection;Generative Adversarial Networks;GAN;Discriminator;Deepfake Videos;Deep Learning;Image Processing;Feature Recognition","Training;Deep learning;Conferences;Detectors;Computer architecture;Big Data;Generative adversarial networks","","10","","25","IEEE","18 Oct 2021","23-26 Aug. 2021","23-26 Aug. 2021","IEEE","IEEE Conferences"
"Abbreviated View of Deepfake Videos Detection Techniques","M. A. Younus; T. M. Hasan","Department of Computer Science, College of Science, University of Diyala, Diyala, Iraq; Department of Computer Science, College of Science, University of Diyala, Diyala, Iraq","2020 6th International Engineering Conference “Sustainable Technology and Development"" (IEC)","23 Jun 2020","2020","","","115","120","In the era of technological advances and a qualitative breakthrough in the artificial intelligence field and deep neural networks, a new age of hyper-realistic digital videos forgery called DeepFake has been born, with that new technology, it is difficult to distinguish between real videos and fake ones which are uploaded daily on various websites across the Internet. Many open-source DeepFake creation methods have risen, leading to a growing number of synthesized media clips over the internet. There are many efficient fast methods and techniques which have been designed to detect and spot such phenomenon. Background Comparison, Temporal Pattern Analysis, Eye blinking, Facial Artifacts, Mesoscopic Analysis, and Pose Estimation are some of those techniques. Some of these approaches designed to detect and identify the video forgery without any prior enlightenment concerning the videos under analysis. The primary scope of this study is to provide an abbreviate review of these methodologies of a method-comparison study that has been presented to assist the researcher's evaluation of such studies.","","978-1-7281-5910-2","10.1109/IEC49899.2020.9122916","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9122916","Digital videos forgery;Deepfake Detection techniques;Mesoscopic;Facial Artifacts","Training;Deepfakes;Reviews;Pose estimation;Pipelines;Symbols;Programming;Transformers;Forgery;Artificial intelligence","","9","","26","IEEE","23 Jun 2020","26-27 Feb. 2020","26-27 Feb. 2020","IEEE","IEEE Conferences"
"A Residual Fingerprint-Based Defense Against Adversarial Deepfakes","J. Jiang; B. Li; S. Yu; C. Liu; S. An; M. Liu; M. Yu","Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China","2021 IEEE 23rd Int Conf on High Performance Computing & Communications; 7th Int Conf on Data Science & Systems; 19th Int Conf on Smart City; 7th Int Conf on Dependability in Sensor, Cloud & Big Data Systems & Application (HPCC/DSS/SmartCity/DependSys)","30 May 2022","2021","","","797","804","The authenticity and integrity of digital visual media have always been a crucial branch in the domain of multimedia forensics and information security. Currently, the emerging Deepfakes destroy the authenticity and integrity as well as trump up a person's behaviors that do not exist in reality, which pose potential threats to individual, social and even national security. Although multiple well-designed deep neural networks have achieved satisfactory performance on Deepfake detection, by adding imperceptible but purposeful adversarial perturbations to fake images or videos, the crafted adversarial Deepfakes are demonstrated to cause the malfunction of detectors. In response to such threats, little recent research attempts to take defensive measures but shows scarce applicability, and the effective conventional defenses are insufficient to protect the particular Deepfake detectors. Therefore, to defend against adversarial Deepfakes, we propose a residual fingerprint-based defense customized for Deepfake detectors. By analyzing the impacts of adversarial perturbations on detectors, we construct a reconstruction network, and propose novel strategies to degrade the adversarial efficacy as well as extract discriminative residual fingerprints. Ultimately, we transform the extracted residual fingerprints for Deepfake detection. The evaluation results indicate the performance of compromised detectors is regained by our proposed defense, which is qualified for enhancing the security and reliability of multiple Deepfake detectors.","","978-1-6654-9457-1","10.1109/HPCC-DSS-SmartCity-DependSys53884.2021.00129","Youth Innovation Promotion Association CAS(grant numbers:2021155); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9781144","multimedia forensics and information security;Deepfake detection;adversarial Deepfakes;residual fingerprints","Visualization;Smart cities;Perturbation methods;Forensics;Neural networks;Detectors;Transforms","","4","","26","IEEE","30 May 2022","20-22 Dec. 2021","20-22 Dec. 2021","IEEE","IEEE Conferences"
"You’re not acting like yourself: Deepfake Detection Based on Facial Behavior","A. Libourel; J. -L. Dugelay","Digital Security, Eurecom, Biot, France; Digital Security, Eurecom, Biot, France","2025 IEEE 6th International Conference on Image Processing, Applications and Systems (IPAS)","21 Mar 2025","2025","CFP2540Z-ART","","1","6","Politicians and government leaders are critical targets for deepfake attacks. A single deepfake involving these individuals can severely damage their careers or, in extreme cases, pose a national security threat. Attackers can leverage vast amounts of publicly available audio and video recordings to train their models, making this threat even more pressing. In response, specialized deepfake detectors have been developed to focus on detecting deepfakes targeting a specific Person of Interest (POI). By learning facial expressions and movements unique to the POI, these detectors can identify inconsistencies in deepfakes where these authentic attributes are absent. However, previous methods relied on Facial Action Units, which offer an incomplete representation of the POI’s behavior. In this paper, we propose a novel approach to learning POI-specific movements without requiring deepfake samples during training, making it independent of any deepfake generation methods. Although our technique is speaker-dependent, it provides a robust solution for protecting high-profile individuals who are particularly exposed to deepfake threats.","","979-8-3315-0652-0","10.1109/IPAS63548.2025.10924537","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10924537","deepfake detection;biometrics;media forensics;behavioral analysis;POI recognition","Training;Deepfakes;Image recognition;Forensics;Government;Detectors;Pressing;Media;National security;Video recording","","1","","24","IEEE","21 Mar 2025","9-11 Jan. 2025","9-11 Jan. 2025","IEEE","IEEE Conferences"
"An Innovative Method for Identifying Deepfake Videos Through Ensemble Learning","S. Keerthika; S. Santhiya; P. Jayadharshini; J. Ruthranayaki; R. Hariarasu; M. Naveenan","Department of Artificial Intelligence, Kongu engineering College, Perundurai, India; Department of Artificial Intelligence, Kongu engineering College, Perundurai, India; Department of Artificial Intelligence, Kongu engineering College, Perundurai, India; Artificial Intelligence and Data Science, Kongu engineering College, Perundurai, India; Artificial Intelligence and Data Science, Kongu engineering College, Perundurai, India; Artificial Intelligence and Data Science, Kongu engineering College, Perundurai, India",2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT),"4 Nov 2024","2024","","","1","10","The detection of deepfake videos is essential due to the significant potential harm posed by manipulated media. Various deep learning techniques, including customized convolutional neural networks (CNNs), MobileNet, and DenseNet, have demonstrated promise in this domain. This study introduces a system for detecting deepfake videos by leveraging tooth and mouth movements, which are notably difficult to replicate accurately. The proposed methodology utilizes multiple transfer learning algorithms such as InceptionV3, MobileNet, VGG16, VGG19, Xception, and DenseNet121 to enhance the algorithm’s capability to detect and classify deepfake videos based on biological signal attributes derived from jaw and tooth frames. The study specifically targets the identification of deepfake videos by extracting and cropping frames from the input video to emphasize the mouth and nose regions. These preprocessed frames are subsequently fed into a customized CNN trained to classify videos as real or fake, achieving an accuracy of $91.7 \%$. Additionally, pre-trained CNN models DenseNet121 and MobileNetV2 further improve accuracy, attaining $88.4 \%$ and $90.9 \%$, respectively. An ensemble approach that combines the predictions of these models results in an overall accuracy of $93.2\%$.","2473-7674","979-8-3503-7024-9","10.1109/ICCCNT61001.2024.10724453","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10724453","Deepfake detection;deep learning;convolutional neural networks;multi-transfer learning;video classification","Deepfakes;Accuracy;Transfer learning;Nose;Teeth;Computer architecture;Robustness;Classification algorithms;Convolutional neural networks;Ensemble learning","","1","","16","IEEE","4 Nov 2024","24-28 June 2024","24-28 June 2024","IEEE","IEEE Conferences"
"DeepFakeGuard: Real-Time Deepfake Video Detection Leveraging Celeb-DF Dataset and CNN-LSTM Framework","V. S R; P. K. M; A. S. V N G; S. G","Department of Information Technology, Velammal College of Engineering and Technology, Madurai, Tamilnadu; Department of Information Technology, Velammal College of Engineering and Technology, Madurai, Tamilnadu; Department of Information Technology, Velammal College of Engineering and Technology, Madurai, Tamilnadu; Department of Information Technology, Velammal College of Engineering and Technology, Madurai, Tamilnadu",2025 5th International Conference on Expert Clouds and Applications (ICOECA),"13 Aug 2025","2025","","","744","750","Deepfake technology has significantly eroded the veracity of digital media across the world, raising concerns of misinformation and media manipulation. To counteract this, we have developed DeepFakeGuard, a powerful deepfake detection system with robust deep learning algorithms present on the web. The system works to identify deepfake videos by checking each subsequent frame for irregularities, for instance, unbalanced lip movements, abrupt light changes, or unnatural cuts. DeepFakeGuard has been pre-trained on a wide variety of datasets primarily focused on the Celeb-DF dataset with high-quality and challenging-to-detect deepfake content. This provides the system with flexibility and precision for multiple applications such as short-form broadcast, high-definition video streams, and live streams. The initial step was preprocessing of data meticulously with focus on neatness and elimination of data noise to ensure the model works at its best. We then employed the latest deep learning architectures, a combination of Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs), to detect the slightest disparities between subsequent frames. Our models have been exhaustively tested to identify tampered content from real media at high accuracy levels. The web-based system provides real-time detection of deepfake, with the ability to upload media files to be detected in real-time. In addition, its robust backend infrastructure for processing video prevents disruption in smooth processing, making DeepFakeGuard deployable on a wide variety of environments such as content moderation, digital forensics, and media verification. The result of our work is evidence of how DeepFakeGuard can enhance digital media security through effective deepfake content detection.","","979-8-3315-2447-0","10.1109/ICOECA66273.2025.00133","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11113856","Deepfake detection;Deep learning algorithms;Celeb-DF dataset;Real-time detection;Convolutional Neural Networks (CNNs);Recurrent Neural Networks (RNNs)","Deep learning;Deepfakes;Recurrent neural networks;Accuracy;Lips;Media;Real-time systems;Robustness;Convolutional neural networks;Long short term memory","","","","15","IEEE","13 Aug 2025","6-7 March 2025","6-7 March 2025","IEEE","IEEE Conferences"
"Leveraging Swin Transformer for Robust Deepfake Detection","A. Verma; A. Yadav","School of Computer Science and Engineering Technology, Bennett University Greater, Noida, Uttar Pradesh, India; School of Computer Science and Engineering Technology, Bennett University Greater, Noida, Uttar Pradesh, India","2024 International Conference on Communication, Control, and Intelligent Systems (CCIS)","26 Mar 2025","2024","","","1","6","The massive deployment of deepfake technology has underlined the critical urgency of appropriate detection mechanisms to mitigate its potential harms. Proper motivation emanates from the perceived increasing threat of misinformation dissemination, accompanied by the harmful impacts of its content on society. Based on the Swin Transformer model, this work presented a deepfake detection solution for addressing the challenge of achieving detection accuracy and being resilient to new sophisticated manipulation techniques. The research problem revolves around the existing inadequacy in the available detection techniques and how to fight against the rapid evolution of deepfake techniques. Our model was trained using LCC-FASD and CASIA datasets combined, which provide large data of real and fake images from various resources. When training the model, several batches of training samples are fed to the system and processed over several epochs depending on each class of the samples to improve the accuracy of the classification that is performed using the Label Smoothing Cross entropy Loss Function. The model undergoes great pre-processing and a high level of training to effectively differentiate between real and fake content. The results are promising, with an overall accuracy of 95.4%, while it was approximately 81% for real images and 94.1% for fake ones. These findings underline the robustness of the Swin Transformer model in reliably detecting deep-fakes, adding confidence and integrity in digital media to counteract adverse effects due to synthetic media manipulations.","","979-8-3315-2820-1","10.1109/CCIS63231.2024.10932042","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10932042","Deep Learning;Deepfake Technology;Deepfake Detection","Training;Deep learning;Measurement;Deepfakes;Adaptation models;Accuracy;Smoothing methods;Transformers;Data models;Robustness","","","","16","IEEE","26 Mar 2025","6-7 Dec. 2024","6-7 Dec. 2024","IEEE","IEEE Conferences"
"Spatial Vision Transformer: A Novel Approach to Deepfake Video Detection","P. M. Thuan; B. T. Lam; P. D. Trung","Center for Information Technology and Cyber Security Monitoring, Government Cipher Committee, Ha Noi, Viet Nam; Government Cipher Committee, Academy of Cryptography Techniques, Ha Noi, Viet Nam; Government Cipher Committee, Academy of Cryptography Techniques, Ha Noi, Viet Nam",2024 1st International Conference On Cryptography And Information Security (VCRIS),"27 Dec 2024","2024","","","1","6","Deepfake, a technology that leverages artificial intelligence to create manipulated videos, has emerged as a significant threat to security and privacy. In recent years, Transformer-based models, such as Vision Transformer (ViT) and Convolution Vision Transformer (CViT), have demonstrated high efficacy in detecting deepfake videos. However, optimizing the Convolutional blocks in CViT remains a challenge. This paper proposes an enhanced CViT model by replacing the traditional ConvBlocks and incorporating Spatial and Channel Reconstruction Convolution (SCConv) blocks. Experiments conducted on the Deepfake Detection Challenge (DFDC) dataset indicate that the new model not only improves detection accuracy but also reduces false detection rates, underscoring its potential in deepfake detection.","","979-8-3315-2994-9","10.1109/VCRIS63677.2024.10813391","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10813391","deepfake detection;SViT;CViT;DSViT;SCConv deepfake","Deepfakes;Computer vision;Privacy;Accuracy;Convolution;Refining;Redundancy;Transformers;Data models;Robustness","","","","14","IEEE","27 Dec 2024","3-4 Dec. 2024","3-4 Dec. 2024","IEEE","IEEE Conferences"
"Enhanced Attribution Algorithms for Deepfake Image Detection","P. B. G; R. H. R","Siddaganga Institute of Technology, Tumkur, India; Siddaganga Institute of Technology, Tumkur, India",2025 3rd International Conference on Smart Systems for applications in Electrical Sciences (ICSSES),"2 Jun 2025","2025","","","1","8","Deepfakes are artificially generated images pose significant risks to media authenticity and security. Traditional detection methods often lack transparency, making it difficult to understand their decision-making processes. This work introduces a novel detection system that enhances interpretability by utilizing advanced attribution techniques. The system employs the InSwapper model to generate Deepfake images, combined with a fine-tuned Residual Networks(ResNet101) for classification. Key attribution methods Integrated Gradients, Guided Integrated Gradients, Adversarial Gradient Integration, and Integrated Decision Gradients are integrated to produce saliency maps that identify the most influential regions in the images affecting Deepfake detection. Developed using Python and PyTorch, this approach significantly improves interpretability. Results indicate that all attribution methods can be successfully employed for detecting Deepfakes, providing clearer insights into the detection process. This advancement paves the way for future developments in real-time detection and broader accessibility in addressing manipulated content.","","979-8-3315-0767-1","10.1109/ICSSES64899.2025.11009947","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11009947","Deepfake Detection;Attribution Techniques;Saliency Maps","Deepfakes;Adaptation models;Predictive models;Media;Feature extraction;Smart systems;Real-time systems;Security;Reliability;Image classification","","","","18","IEEE","2 Jun 2025","21-22 March 2025","21-22 March 2025","IEEE","IEEE Conferences"
"DeepViT-Detect: A Deep Vision Transformer-Based Approach for Robust Deepfake Video Detection","V. K. R. Mannepalli; V. K. Kondra; J. P. Gourabathuni","Dept. of Computer Science & Enigineering, VNR Vignana Jyothi Institute of Engineering & Technology, Hyderabad, India; Dept. of Computer Science & Engineering (Software Engineering), VNR Vignana Jyothi Institute of Engineering & Technology, Hyderabad, India; Dept. of Computer Science, Northern Arizona University, Flagstaff, Arizona, United States",2025 4th International Conference on Innovative Mechanisms for Industry Applications (ICIMIA),"20 Oct 2025","2025","","","1118","1125","Deepfake videos are all over the place now, and it's getting tough to know what's real online. The ways we try to spot them now often miss the little things that show they're fake. So, we made something new called DeepViT-Detect that uses Vision Transformers (ViT) to find deepfakes. ViT is good at spotting both the big picture and tiny details because it uses self-attention, so it can see even the smallest weird things in video frames. Our model looks at frames from real and fake videos and learns to tell the difference between what's real and what's been messed with. We trained it a lot using all sorts of videos. Testing shows that DeepViT-Detect does much better than other methods at being accurate and strong, so it's a good step in the fight against deepfakes. This shows that using transformers could be a great way to find tricky fakes and keep visual media trustworthy.","","979-8-3315-5386-9","10.1109/ICIMIA67127.2025.11200731","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11200731","Deepfake Detection;Vision Transformer(ViT);Self-Attention;Frame-Based Analysis;Digital media security","Deepfakes;Computer vision;Visualization;Accuracy;Forensics;Media;Transformers;Long short term memory;Standards;Testing","","","","15","IEEE","20 Oct 2025","3-5 Sept. 2025","3-5 Sept. 2025","IEEE","IEEE Conferences"
"RoGA: Towards Generalizable Deepfake Detection through Robust Gradient Alignment","L. Qiu; K. Jiang; X. Tan","College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics",2025 IEEE International Conference on Multimedia and Expo (ICME),"30 Oct 2025","2025","","","1","6","Recent advancements in domain generalization for deepfake detection have attracted significant attention, with previous methods often incorporating additional modules to prevent overfitting to domain-specific patterns. However, such regularization can hinder the optimization of the empirical risk minimization (ERM) objective, ultimately degrading model performance. In this paper, we propose a novel learning objective that aligns generalization gradient updates with ERM gradient updates. The key innovation is the application of perturbations to model parameters, aligning the ascending points across domains, which specifically enhances the robustness of deepfake detection models to domain shifts. This approach effectively preserves domain-invariant features while managing domain-specific characteristics, without introducing additional regularization. Experimental results on multiple challenging deepfake detection datasets demonstrate that our gradient alignment strategy outperforms state-of-the-art domain generalization techniques, confirming the efficacy of our method. The code is available at https://github.com/Lynn0925/RoGA.","1945-788X","979-8-3315-9495-4","10.1109/ICME59968.2025.11209067","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11209067","Deepfake Detection;Face Forgery Detection","Deepfakes;Technological innovation;Risk minimization;Codes;Perturbation methods;Robustness;Forgery;Optimization;Faces;Overfitting","","","","39","IEEE","30 Oct 2025","30 June-4 July 2025","30 June-4 July 2025","IEEE","IEEE Conferences"
"Focus by Prior: Deepfake Detection Based on Prior-Attention","C. Yu; P. Chen; J. Dai; X. Wang; W. Zhang; J. Liu; J. Han","Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China",2022 IEEE International Conference on Multimedia and Expo (ICME),"26 Aug 2022","2022","","","1","6","Nowadays advanced facial manipulation techniques produce deepfake videos more realistically, which makes deepfake detection more difficult. To capture subtle and intricate artifacts, recent works attempt to enhance low-level textural information by attention-based framework. However, these methods require complex simulated data or extra supervision. Highly dependent on training settings, these methods not only have high training costs but also are prone to overfitting. To address this issue, we propose a novel perspective of deepfake detection via so-called prior-attention. Specifically, we introduce prior textural information, such as edge and noise, to model the attention maps explicitly. Benefiting from these natural “attention maps”, our model significantly enhances discriminative information without additional supervision. Furthermore, we design a Feature Abstraction Block (FAB) to facilitate cross-layer features interaction and insert it into distinct layers of CNN to detect the inconsistencies at multiple spatial levels. Extensive experiments demonstrate that our method achieves performance comparable to state-of-the-art methods.","1945-788X","978-1-6654-8563-0","10.1109/ICME52920.2022.9859897","National Key Research and Development Program of China(grant numbers:2020AAA0140000); National Natural Science Foundation of China(grant numbers:61702502); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9859897","Deepfake Detection;Face Forensics;Attention Mechanism","Training;Deepfakes;Cross layer design;Costs;Fuses;Image edge detection;Decision making","","5","","34","IEEE","26 Aug 2022","18-22 July 2022","18-22 July 2022","IEEE","IEEE Conferences"
"Enhanced Deepfake Detection with LSTM and ResNeXt Integration","H. Singh; R. Kumar; M. Gupta; N. Y. Joshi","Department of CSE, Chandigarh University, Mohali, India; Department of CSE, Chandigarh University, Mohali, India; Department of CSE, Chandigarh University, Mohali, India; Fiserv, Atlanta, Georgia, USA",2025 3rd International Conference on Disruptive Technologies (ICDT),"13 May 2025","2025","","","783","787","Created from advanced artificial intelligence (AI), Deepfakes are privacy, security, and trust shattering to digital media needs. In this work, we propose a novel deepfake detection model based on ResNext followed by Long Short Term Memory (LSTM) networks to achieve extraction of spatial features and temporal sequence analysis, respectively. Our approach combines the strengths of the two architectures and minimizes the investment in model size by retaining only a small portion of that which is accurate. On the Celeb-DF (v2) dataset, our model reached a detection accuracy of 93.59%, beating baseline methods. The demonstrated robustness and reliability of the proposed method make it a promising method to fight deepfakes in real world situations.","","979-8-3315-1958-2","10.1109/ICDT63985.2025.10986702","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10986702","Deepfake Detection;Convolutional Neural Network (CNN);Digital Deception;Image Manipulation;Artificial Intelligence (AI);Machine Learning;Multimedia Forensics;Video Analysis;Face Recognition;Image Authentication","Deepfakes;Analytical models;Adaptation models;Accuracy;Computational modeling;Computer architecture;Feature extraction;Transformers;Convolutional neural networks;Long short term memory","","","","28","IEEE","13 May 2025","7-8 March 2025","7-8 March 2025","IEEE","IEEE Conferences"
"Dual-Task Mutual Learning With QPHFM Watermarking for Deepfake Detection","C. Wang; C. Shi; S. Wang; Z. Xia; B. Ma","Key Laboratory of Computing Power Network and Information Security, Ministry of Education, Shandong Computer Science Center, Qilu University of Technology (Shandong Academy of Sciences), Jinan, China; Key Laboratory of Computing Power Network and Information Security, Ministry of Education, Shandong Computer Science Center, Qilu University of Technology (Shandong Academy of Sciences), Jinan, China; College of Artificial Intelligence, Dalian Maritime University, Dalian, China; Key Laboratory of Computing Power Network and Information Security, Ministry of Education, Shandong Computer Science Center, Qilu University of Technology (Shandong Academy of Sciences), Jinan, China; Key Laboratory of Computing Power Network and Information Security, Ministry of Education, Shandong Computer Science Center, Qilu University of Technology (Shandong Academy of Sciences), Jinan, China",IEEE Signal Processing Letters,"10 Oct 2024","2024","31","","2740","2744","Deepfake technology has rapidly evolved and emerged in recent years, posing significant threats to individuals' reputations and security. Although passive detection methods can achieve reasonable accuracy, they still lack proactive defense mechanisms. To address this issue, this letter proposes a proactive detection framework that combines Quaternion Polar Harmonic Fourier Moments (QPHFMs) with Dual-Task Mutual Learning (DTML) framework. Firstly, watermark information is embedded into QPHFMs, ensuring high imperceptibility while enhancing robustness against common attacks. Secondly, DTML is introduced, where the knowledge distilled from watermark detection can facilitate more accurate deepfake detection. Experimental results on benchmark datasets demonstrate that our method surpasses state-of-the-art techniques, delivering exceptional performance in watermark robustness and imperceptibility while simultaneously accomplishing accurate deepfake detection.","1558-2361","","10.1109/LSP.2024.3438101","Taishan Scholar(grant numbers:tsqn202306251); Open Foundation of Key Laboratory of Computing Power Network and Information Security(grant numbers:SKLCN-2023-08); National Natural Science Foundation of China(grant numbers:62302249,62272255,62406051,62372077); Young Talent of Lifting Engineering for Science and Technology in Shandong(grant numbers:SDAST2024QTA001); QiLu Research Projects(grant numbers:2023PY060,2023PX071); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10623297","Dual-task mutual learning;image watermarking;quaternion polar harmonic Fourier moments;proactive deepfake detection","Watermarking;Deepfakes;Forgery;Image reconstruction;Accuracy;Signal processing algorithms;Faces","","8","","35","IEEE","5 Aug 2024","2024","","IEEE","IEEE Journals"
"Unmasking the Imposter: Detecting Fake Media with Generative Adversarial Networks","S. Kapoor","Lab126, Amazon, Arlington, Virginia, USA",2025 IEEE 15th Annual Computing and Communication Workshop and Conference (CCWC),"5 Mar 2025","2025","","","00396","00400","The advancement of deepfake technology presents a serious challenge to the authenticity and reliability of digital content. This research paper presents a novel Generative Adversarial Network (GAN) based framework for reliably detecting deepfakes across various media formats, including images, videos, and audio. The proposed model distinguishes genuine media from fake media by training a discriminator network to identify subtle inconsistencies in synthetic content while simultaneously training a generator network to produce increasingly realistic forgeries. The results demonstrate the proposed approach outperforms existing top deepfake detection methods. This work highlights the potential of adversarial training to stay ahead of evolving deepfake threats and plays a crucial role in protecting the digital environment against the growing misinformation risk.","","979-8-3315-0769-5","10.1109/CCWC62904.2025.10903800","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10903800","Machine Learning for Misinformation;Generative Adversarial Networks;Adversarial Training;Synthetic Media;Deepfake Detection","Training;Deepfakes;Technological innovation;Instruments;Machine learning;Generative adversarial networks;Generators;Forgery;Reliability;Faces","","","","11","IEEE","5 Mar 2025","6-8 Jan. 2025","6-8 Jan. 2025","IEEE","IEEE Conferences"
"XLSR-Mamba: A Dual-Column Bidirectional State Space Model for Spoofing Attack Detection","Y. Xiao; R. K. Das","Fortemedia, Singapore; Fortemedia, Singapore",IEEE Signal Processing Letters,"26 Mar 2025","2025","32","","1276","1280","Transformers and their variants have achieved great success in speech processing. However, their multi-head self-attention mechanism is computationally expensive. Therefore, one novel selective state space model, Mamba, has been proposed as an alternative. Building on its success in automatic speech recognition, we apply Mamba for spoofing attack detection. Mamba is well-suited for this task as it can capture the artifacts in spoofed speech signals by handling long-length sequences. However, Mamba's performance may suffer when it is trained with limited labeled data. To mitigate this, we propose combining a new structure of Mamba based on a dual-column architecture with self-supervised learning, using the pre-trained wav2vec 2.0 model. The experiments show that our proposed approach achieves competitive results and faster inference on the ASVspoof 2021 LA and DF datasets, and on the more challenging In-the-Wild dataset, it emerges as the strongest candidate for spoofing attack detection.","1558-2361","","10.1109/LSP.2025.3547861","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10909468","Mamba;state space model;anti-spoofing;spoofing attack detection;deepfake detection","Computational modeling;Training;Transformers;Convolution;Feature extraction;Predictive models;Measurement;Attention mechanisms;Speech recognition;Speech enhancement","","12","","37","IEEE","4 Mar 2025","2025","","IEEE","IEEE Journals"
"A Contrario Detection of H.264 Video Double Compression","Y. Li; M. Gardella; Q. Bammey; T. Nikoukhah; J. -M. Morel; M. Colom; R. G. von Gioi","Centre Borelli, ENS Paris-Saclay, Université Paris-Saclay, CNRS, France; Centre Borelli, ENS Paris-Saclay, Université Paris-Saclay, CNRS, France; Centre Borelli, ENS Paris-Saclay, Université Paris-Saclay, CNRS, France; Centre Borelli, ENS Paris-Saclay, Université Paris-Saclay, CNRS, France; Department of Mathematics, City University of Hong Kong, Kowloon, Hong Kong; Centre Borelli, ENS Paris-Saclay, Université Paris-Saclay, CNRS, France; Centre Borelli, ENS Paris-Saclay, Université Paris-Saclay, CNRS, France",2023 IEEE International Conference on Image Processing (ICIP),"11 Sep 2023","2023","","","1765","1769","Video manipulation detection plays a vital role in modern multimedia forensics. In particular, double compression detection provides significant clues leading to the video edition history and hinting at potential malevolent manipulation. While such an analysis is well-understood on images, the research on this subject remains lacking in videos and existing methods are not yet able to reliably detect double-compressed videos. This work presents a novel method for identifying double compression in H.264 codec videos. Our technique exploits the periodicity of frame residuals caused by fixed Group of Pictures in the initial compression, and employs an a contrario framework to minimize and control false detections. The proposed method can reliably detect double compression in videos. It does not require threshold tuning, thus enabling automatic detection. The code is available at https://github.com/li-yanhao/gop_detection.","","978-1-7281-9835-4","10.1109/ICIP49359.2023.10222775","Horizon Europe; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10222775","Video double compression;video forensics;group of pictures;a contrario;deepfake detection","Learning systems;Image coding;Forensics;Streaming media;Feature extraction;Forgery;Reliability","","7","","32","EU","11 Sep 2023","8-11 Oct. 2023","8-11 Oct. 2023","IEEE","IEEE Conferences"
"Implementation of Deep Learning Method for Forgery Detection on Social Media","A. Kohapare; K. Dhongade; R. Sukare; P. Maidamwar","Department of Computer Science and Engineering, G H Raisoni College of Engineering, Nagpur, India; Department of Computer Science and Engineering, G H Raisoni College of Engineering, Nagpur, India; Department of Computer Science and Engineering, G H Raisoni College of Engineering, Nagpur, India; Department of Computer Science and Engineering, G H Raisoni College of Engineering, Nagpur, India",2024 2nd International Conference on Intelligent Data Communication Technologies and Internet of Things (IDCIoT),"22 Mar 2024","2024","","","1579","1583","In recent years, the surge in misinformation and rapid technological advancements has significantly increased the prevalence of media manipulation. The advent of AI-altered videos and sophisticated news content poses a serious threat to media integrity, particularly as these manipulations proliferate on social media platforms, creating challenges in discerning authenticity. The accessibility and user-friendliness of deepfake technology have compounded the issue, making the distinction between genuine and fabricated content increasingly challenging. This presents substantial risks, ranging from the dissemination of false information to fostering a general sense of scepticism toward online visuals. This research aims to comprehensively analyze the process of creating deepfakes and assess their broader societal impact, while also proposing potential solutions to mitigate this problem. The methodology employed has achieved accuracy of 87% that involves utilizing ResN ext, a CNN architecture with LS TM, to analyse fake videos, and error level analysis followed by CNN algorithm to analyse fake images, this research outlines the specific steps and procedures involved in this analytical process.","","979-8-3503-2753-3","10.1109/IDCIoT59759.2024.10467237","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10467237","Convolutional Neural Network;Deepfake Detection;Erroe Level Analysis;ResNext","Deepfakes;Visualization;Technological innovation;Social networking (online);Clustering algorithms;Classification algorithms;Convolutional neural networks","","6","","23","IEEE","22 Mar 2024","4-6 Jan. 2024","4-6 Jan. 2024","IEEE","IEEE Conferences"
"Review: DeepFake Detection Techniques using Deep Neural Networks (DNN)","H. Chotaliya; M. A. Khatri; S. Kanojiya; M. Bivalkar","Department of Computer Engineering, K J Somaiya Institute of Technology, Mumbai, Mumbai, India; Department of Computer Engineering, K J Somaiya Institute of Technology, Mumbai, Mumbai, India; Department of Computer Engineering, K J Somaiya Institute of Technology, Mumbai, Mumbai, India; Department of Computer Engineering, K J Somaiya Institute of Technology, Mumbai, Mumbai, India",2023 6th International Conference on Advances in Science and Technology (ICAST),"4 Mar 2024","2023","","","480","484","In the age of advanced digital manipulation, deepfake videos pose a significant threat to society by allowing the creation of highly convincing counterfeit footage. The application of deep learning has proven instrumental in tackling an extensive array of practical issues and real-world applications. However, alongside its substantial benefits, there exist certain disadvantages. Deepfake videos involve the substitution of one person's characteristics with those of another, achieved through the application of advanced Deep Learning techniques. This technology can be exploited with harmful intentions, leading to the dissemination of misinformation, manipulation, and persuasive content. This paper explores multiple deep learning techniques designed for detecting deep fake images and videos. It conducts a comparative analysis of these techniques, including CNN models like ResNet, VGG16, and Efficient Net, along with RNN models like LSTM, to assess their effectiveness in deepfake video detection.","","979-8-3503-5981-7","10.1109/ICAST59062.2023.10454938","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10454938","DeepFake detection;CNN;GAN;RNN;LSTM","Deep learning;Training;Deepfakes;Analytical models;Reviews;Motion pictures;Long short term memory","","6","","13","IEEE","4 Mar 2024","8-9 Dec. 2023","8-9 Dec. 2023","IEEE","IEEE Conferences"
"Spatio-Temporal Convolutional Neural Networks for Deepfake Detection: An Empirical Study","V. K. Sharma; R. Garg; Q. Caudron","Amity University, Noida, Uttar Pradesh, India; Amity University, Noida, Uttar Pradesh, India; Sound Agriculture, Emeryville, CA, United States",2023 Second International Conference on Informatics (ICI),"8 Feb 2024","2023","","","1","7","As the creation of deepfakes becomes more prevalent and sophisticated, the need for accurate and robust detection methods intensifies. This paper presents a comprehensive empirical study on the efficacy of S patio-Temporal Convolutional Neural Networks (ST-CNNs) for deepfake detection. It explores how the rich spatio-temporal information contained within video frames can be exploited by ST-CNNs to distinguish between genuine and manipulated content. The study is underpinned by a robust testing framework, wherein a range of deepfake generation techniques are used to evaluate the detection model. It further investigates the effect of various layers and architectural elements on detection performance. The results demonstrate that ST-CNNs, by leveraging spatio-temporal correlations, can offer superior deepfake detection performance compared to the conventional CNN models. This work can guide the development of more efficient and effective deepfake detection strategies by providing empirical insights into the utilization of ST-CNNs.","","979-8-3503-4383-0","10.1109/ICI60088.2023.10420892","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10420892","deepfake detection;spatio temporal;video forgery;convolutional neural network;synthetic media","Deepfakes;Correlation;Media;Convolutional neural networks;Informatics;Testing","","6","","31","IEEE","8 Feb 2024","23-25 Nov. 2023","23-25 Nov. 2023","IEEE","IEEE Conferences"
"Exposing Lip-syncing Deepfakes from Mouth Inconsistencies","S. K. Datta; S. Jia; S. Lyu","University at Buffalo, State University of New York; University at Buffalo, State University of New York; University at Buffalo, State University of New York",2024 IEEE International Conference on Multimedia and Expo (ICME),"30 Sep 2024","2024","","","1","6","A lip-syncing deepfake is a digitally manipulated video in which a person’s lip movements are created convincingly using AI models to match altered or entirely new audio. Lipsyncing deepfakes are a dangerous type of deepfakes as the artifacts are limited to the lip region and more difficult to discern. In this paper, we describe a novel approach, LIP-syncing detection based on mouth INConsistency (LIPINC), for lip-syncing deepfake detection by identifying temporal inconsistencies in the mouth region. These inconsistencies are seen in the adjacent frames and throughout the video. Our model can successfully capture these irregularities and outperforms the state-of-the-art methods on several benchmark deepfake datasets. Code is available at https://github.com/skrantidatta/LIPINC.","1945-788X","979-8-3503-9015-5","10.1109/ICME57554.2024.10687902","Defense Advanced Research Projects Agency; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10687902","DeepFake detection;Lip-syncing deepfakes;Spatial-temporal inconsistency","Deepfakes;Codes;Lips;Mouth;Benchmark testing;Artificial intelligence","","6","","35","IEEE","30 Sep 2024","15-19 July 2024","15-19 July 2024","IEEE","IEEE Conferences"
"Custom Attribution Loss for Improving Generalization and Interpretability of Deepfake Detection","P. Korshunov; A. Jain; S. Marcel","Idiap Research Institute, Martigny, Switzerland; Idiap Research Institute, Martigny, Switzerland; Idiap Research Institute, Martigny, Switzerland","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","8972","8976","The simplicity and accessibility of tools for generating deepfakes pose a significant technical challenge for their detection and filtering. Many of the recently proposed methods for deeptake detection focus on a ‘blackbox’ approach and therefore suffer from the lack of any additional information about the nature of fake videos beyond the fake or not fake labels. In this paper, we approach deepfake detection by solving the related problem of attribution, where the goal is to distinguish each separate type of a deepfake attack. We design a training approach with customized Triplet and ArcFace losses that allow to improve the accuracy of deepfake detection on several publicly available datasets, including Google and Jigsaw, FaceForensics++, HifiFace, DeeperForensics, Celeb-DF, DeepfakeTIMIT, and DF-Mobio. Using an example of Xception net as an underlying architecture, we also demonstrate that when trained for attribution, the model can be used as a tool to analyze the deepfake space and to compare it with the space of original videos.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9747628","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9747628","Deepfake attribution;deepfake detection;cross-database evaluations;ArcFace loss;Triplet loss","Training;Analytical models;Filtering;Forensics;Conferences;Neural networks;Signal processing","","5","","24","IEEE","27 Apr 2022","23-27 May 2022","23-27 May 2022","IEEE","IEEE Conferences"
"Robust and Generalized DeepFake Detection","S. Yadav; S. Bommareddy; D. K. Vishwakarma","Department of Applied Mathematics, Delhi Technological University, New Delhi, India; Department of Software Engineering, Delhi Technological University, New Delhi, India; Department of Information Technology, Delhi Technological University, New Delhi, India",2022 13th International Conference on Computing Communication and Networking Technologies (ICCCNT),"26 Dec 2022","2022","","","1","6","Images that are manipulated are prevalent and are on the spike because of the advancement in deep convolutional neural networks (CNNs) techniques. There have been several concerns regarding the advent spread of false information. There exists a need for a reliable and robust method to detect such fake images. In this paper, analysis was done using the architecture SlowFast in detecting manipulated videos. This paper focuses on detecting DeepFake videos under three distinct scenarios, which are (i) all manipulation detection, (ii) single manipulation detection, and then (iii) cross manipulation detection used to test the veracity of the videos. The manipulation methods and designing algorithms to categorize such unknown manipulation techniques were used.","","978-1-6654-5262-5","10.1109/ICCCNT54827.2022.9984553","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9984553","Deepfakes;Deepfake Detection;Media forensics;Computer Vision;SOTA(State-Of-The-Art);Facial Manipulation Detection","Knowledge engineering;Deepfakes;Databases;Machine learning;Forgery;Behavioral sciences;Reliability","","5","","25","IEEE","26 Dec 2022","3-5 Oct. 2022","3-5 Oct. 2022","IEEE","IEEE Conferences"
"Deepfake Detection Based on Incompatibility Between Multiple Modes","Y. Zhang; J. Zhan; W. Jiang; Z. Fan","School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, China",2021 International Conference on Intelligent Technology and Embedded Systems (ICITES),"20 Dec 2021","2021","","","1","7","We propose a multi-modal detection for deepfake videos, called the Incompatibility Between Multiple Modes (IBMM) detection. The detection algorithm can detect whether the video is real or fake, and may be embedded in the monitoring equipment in the future. The model adopts EfficientNet and simple 3D-CNN, and it identifies deepfake videos through three modes. In the facial motion mode and lip motion mode, we use the EfficientNet for feature learning. This network uses a series of fixed scaling coefficients to scale the dimensions of the network uniformly and achieves good results in learning image features. In the audio mode, we adopt 3D-CNN network to train the hot coding diagram of audio data. Besides, for a single mode, we use the cross-entropy loss to calculate the irrationality of the mode. For different modes, the contrastive loss is used to calculate the incongruity between the modes, such as incompatibility between lips and voice. Experimental results show that, compared with other existing fake detection methods, the method presented in this paper has higher accuracy (95.87%) on DFDC datasets. And compared with the existing methods, the accuracy increases by 5.21%.","","978-1-6654-2755-5","10.1109/ICITES53477.2021.9637096","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9637096","Deepfake detection;Efficientnet_b3;multimodal learning","Training;Representation learning;Statistical analysis;Lips;Market research;Synchronization;Indexes","","4","","29","IEEE","20 Dec 2021","31 Oct.-2 Nov. 2021","31 Oct.-2 Nov. 2021","IEEE","IEEE Conferences"
"Image Feature Detectors for Deepfake Image Detection Using Transfer Learning","K. M. A. Alheeti; S. S. Al-Rawi; H. A. Khalaf; D. Al Dosary","Computer Networking Systems Dept., College of Computer Sciences & Information Technology, University of Anbar, Ramadi, Iraq; Information Systems Dept., College of Computer and Information Technology, University of Anbar, Anbar, -Iraq; The University of al-Anbar -college of Medicine; College of Computer Sciences & Information Technology, University of Anbar, Ramadi, Iraq",2021 14th International Conference on Developments in eSystems Engineering (DeSE),"1 Mar 2022","2021","","","499","502","Deepfake is heavily based on artificial intelligence and machine learning to generate audio content and visuals with an extremely high potential to deceive. In this paper, a new detection system to identify any deepfake for audio or images. In other words, transfer learning techniques are used to present an intelligent detection system of deepfake videos. In this work, a support vector machine is employed for the detection process. Outstanding results are obtained from the train and test this system with various types of images that are real or fake.","2161-1351","978-1-6654-0888-2","10.1109/DeSE54285.2021.9719332","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9719332","AI;deepfake;detection;machine learning","Support vector machines;Visualization;Transfer learning;Detectors;Feature extraction;Videos;Information integrity","","4","","30","IEEE","1 Mar 2022","7-10 Dec. 2021","7-10 Dec. 2021","IEEE","IEEE Conferences"
"AdvShadow: Evading DeepFake Detection via Adversarial Shadow Attack","J. Liu; M. Zhang; J. Ke; L. Wang","Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, Wuhan, China; Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, Wuhan, China; Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, Wuhan, China; Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, Wuhan, China","ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","18 Mar 2024","2024","","","4640","4644","With the emergence of techniques called DeepFakes, there has been a notable proliferation of DeepFake detectors rooted in deep learning. These detectors aim to expose subtle distinctions between genuine and counterfeit facial images across spatial, frequency, and physiological domains. Unfortunately, these detectors are susceptible to adversarial attacks. In this study, we introduce a novel transferable adversarial attack named AdvShadow, designed to attack DeepFake detectors by leveraging natural shadows in real-life. The proposed AdvShadow comprises three components: random shadow generator, shadow overlay network, and adversarial shadow generation. Initially, we construct a random shadowed facial dataset, utilizing additional shadow overlay network to produce adversarial samples for training. Then we generate adversarial shadows for DeepFake datasets, mitigating the disparities of luminance between real and synthesized images. Through extensive experiments, we demonstrate the effectiveness and transferability of AdvShadow for attacking under black-box settings.","2379-190X","979-8-3503-4485-1","10.1109/ICASSP48485.2024.10448251","National Natural Science Foundation of China; Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10448251","DeepFakes;DeepFake detection;transferable adversarial shadows","Training;Deepfakes;Overlay networks;Perturbation methods;Closed box;Lighting;Detectors","","4","","25","IEEE","18 Mar 2024","14-19 April 2024","14-19 April 2024","IEEE","IEEE Conferences"
"GPT-4 versus Bard and Bing: LLMs for Fake Image Detection","O. M. Al-Janabi; O. M. Alyasiri; E. A. Jebur","College of Medicine, University of Baghdad, Baghdad, Iraq; Karbala Technical Institute, Al-Furat Al-Awsat Technical University, Karbala, Iraq; College of Medicine, University of Baghdad, Baghdad, Iraq",2023 3rd International Conference on Intelligent Cybernetics Technology & Applications (ICICyTA),"13 Feb 2024","2023","","","249","254","The recent emergence of sophisticated Large Language Models (LLMs) such as GPT-4, Bard, and Bing has revolutionized the domain of scientific inquiry, particularly in the realm of large pre-trained vision-language models. This pivotal transformation is driving new frontiers in various fields, including image processing and digital media verification. In the heart of this evolution, our research focuses on the rapidly growing area of image authenticity verification, a field gaining immense relevance in the digital era. The study is specifically geared towards addressing the emerging challenge of distinguishing between authentic images and deepfakes – a task that has become critically important in a world increasingly reliant on digital media. Our investigation rigorously assesses the capabilities of these advanced LLMs in identifying and differentiating manipulated imagery. We explore how these models process visual data, their effectiveness in recognizing subtle alterations, and their potential in safeguarding against misleading representations. The implications of our findings are far-reaching, impacting areas such as security, media integrity, and the trustworthiness of information in digital platforms. Moreover, the study sheds light on the limitations and strengths of current LLMs in handling complex tasks like image verification, thereby contributing valuable insights to the ongoing discourse on AI ethics and digital media reliability.","","979-8-3503-9455-9","10.1109/ICICyTA60173.2023.10429022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10429022","deepfake detection;large language models (LLMs);GPT-4;bard;bing chat","Deepfakes;Visualization;Image processing;Media;Security;Reliability;Task analysis","","3","","26","IEEE","13 Feb 2024","13-15 Dec. 2023","13-15 Dec. 2023","IEEE","IEEE Conferences"
"A New Approach to in Ensemble Method for Deepfake Detection","S. Atas; M. Karakose","Computer Engineering Department, University of Fırat (FU), Elazig, Turkey; Computer Engineering Department, University of Fırat (FU), Elazig, Turkey",2023 4th International Conference on Data Analytics for Business and Industry (ICDABI),"15 Aug 2024","2023","","","201","204","With the great development of technology and deep learning gaining competence in many areas, recently forgery of images has started to pose great threats and become the main topic of most technology companies. But here, with the ongoing race between good and evil, new approaches have emerged in fraud detection. Since this technological development is bilateral, fraud detection is constantly trying to be developed and trying to catch fraud. In this regard, various approaches have emerged by many different companies and people to contribute to society. In the method we have proposed to contribute to these detection processes and to detect forgery, feature extraction is provided on images using the D-CNN model, and with these features, SVM, Estimation is done on features with Random Forest and Logistic Regression. Finally, using the Ensemble method, an estimation process is performed by taking all the estimates together with the sampling on the images. Thanks to this proposed method, the determinations made are supported in a layered way and precision is ensured at the accuracy rate.","","979-8-3503-6978-6","10.1109/ICDABI60145.2023.10629338","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10629338","Deepfake Detection;Ensemble Method;D-CNN","Support vector machines;Deepfakes;Accuracy;Estimation;Companies;Feature extraction;Forgery","","2","","22","IEEE","15 Aug 2024","25-26 Oct. 2023","25-26 Oct. 2023","IEEE","IEEE Conferences"
"Robust Audio Anti-Spoofing System Based on Low-Frequency Sub-Band Information","M. Li; X. -P. Zhang","Department of Electrical, Computer and Biomedical Engineering, Toronto Metropolitan University, Toronto, ON, Canada; Department of Electrical, Computer and Biomedical Engineering, Toronto Metropolitan University, Toronto, ON, Canada",2023 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA),"15 Sep 2023","2023","","","1","5","The current audio anti-spoofing systems usually have a computationally complex architecture without providing the fundamental discriminative factors for the detection judgments. The state-of-the-arts also highly depend on voice information to develop detector systems, which may become vulnerable when the spoofing algorithms have further improved the quality of fake speech. Therefore, we conduct a series of experiments on different frequency sub-bands to investigate the underlying discriminative features. We find the lowest frequency sub-band in the range from 0 to 1600Hz contains the most critical features that distinguish between Deepfake and real speech. We also focus on forensic evidence and identify that the basis of detectors’ judgment exists in non-speech parts in audio samples. Based on the findings, our single detection system, with only 57K parameters and utilizing a one-tenth segment of the entire spectrogram as input, demonstrates its robustness by outperforming all official baselines of the ASVspoof2021 DF track. Our lightweight system can be easily applied in practical use cases, such as automated Deepfake screening or protecting voice-able devices.","1947-1629","979-8-3503-2372-6","10.1109/WASPAA58266.2023.10248132","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10248132","Deepfake Detection;Subband Frequency;Speech Anti-Spoofing;ASVspoof2021;Robustness","Deepfakes;Forensics;Conferences;Detectors;Computer architecture;Feature extraction;Robustness","","2","","22","IEEE","15 Sep 2023","22-25 Oct. 2023","22-25 Oct. 2023","IEEE","IEEE Conferences"
"RAW Data: A Key Component for Effective Deepfake Detection","S. Husseinil; J. -L. Dugelay","Department of Digital Security, EURECOM, Biot, France; Department of Digital Security, EURECOM, Biot, France","ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","7 Mar 2025","2025","","","1","5","Current deepfake detection methods are prone to overfitting to specific deepfake artifacts and often struggle with genuine images that have undergone compression and other image processing operations. These processes can obscure indicators of forgery, leading to inaccurate decisions. This paper aims to redefine the boundary between real and fake images by narrowing the definition of authentic samples to a stage closer to the radiance of the scene as captured by the sensor, prior to any transformations by an Image Signal Processor (ISP). Our proposed method bypasses ISP processing steps, such as denoising, white balance, and demosaicing, which are embedded in camera hardware. This unaltered preservation makes raw data an ideal starting point for deepfake detection. Given the scarcity of large-scale datasets designed for training on raw images, we propose a methodological approach to train our model on raw image data. Our method demonstrated state-of-the-art performance on the CDF dataset and showed competitive results across other RGB domain deepfake detection datasets. The model developed in this study is available at https://github.com/DeepFaux/Deepfake-Detection-with-RAW-Data.","2379-190X","979-8-3503-6874-1","10.1109/ICASSP49660.2025.10887800","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10887800","deepfake detection;image manipulation;ISP","Training;Deepfakes;Image coding;Noise reduction;Signal processing;Hardware;Forgery;Data models;Speech processing;Overfitting","","1","","38","IEEE","7 Mar 2025","6-11 April 2025","6-11 April 2025","IEEE","IEEE Conferences"
"MMDF-Net: A Multimodal Framework for Real-Time Deepfake Detection Using Visual and Audio Features","M. Javed; F. H. Dahri; A. A. Laghari; J. A. Bhutto; S. H. Bhutto; N. A. Dahri","Department of Computer Science and Technology, College of Computer Science, Donghua University, Shanghai, China; School of Computer Science and Engineering, Southeast University, Nanjing, China; Department of Computer Science, Sindh Madressutal Islam University, Sindh, Pakistan; College of Computer Science, Huanggang Normal University, Huanggang, China; Shanghai Dianji University, Shanghai, China; Faculty of Language Studies, Sohar University Oman","2025 IEEE 2nd International Conference on Electronics, Communications and Intelligent Science (ECIS)","28 Jul 2025","2025","","","1","5","The rapid evolution of deepfake technology necessitates detection frameworks capable of leveraging diverse modalities to ensure robust and real-time performance. This research introduces MMDF-Net, a novel multimodal framework for deepfake detection that integrates visual and audio features. MMDF-Net employs MobileNetV2 for lightweight local facial feature extraction and the Swin Transformer to capture global facial relationships, ensuring comprehensive visual representation. The Wav2vec model is used for audio feature extraction to balance visual data, enabling a holistic approach to detection and using the multimodal fusion mechanism to integrate these features, facilitating an accurate and reliable real-time deepfake framework. The proposed MMDF-Net framework achieves impressive performance on the LAV-DF and TVIL datasets, with LAV-DF yielding an accuracy of 97.0% and TVIL achieving 95.5%. Both datasets demonstrate robust detection capabilities, with the model maintaining high precision, recall, and F1-score while processing samples in less than 100ms, explaining the significance of combining visual and audio modalities for efficient and effective deepfake detection.","","979-8-3315-1358-0","10.1109/ECIS65594.2025.11086877","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11086877","Deepfake Detection;Multimodal Framework;MMDF-Net;Audio-Visual Integration;Swin Transformer","Training;Visualization;Deepfakes;Accuracy;Feature extraction;Transformers;Real-time systems;Reliability;Standards;Testing","","1","","17","IEEE","28 Jul 2025","23-25 May 2025","23-25 May 2025","IEEE","IEEE Conferences"
"Multi-Definition Video Deepfake Detection via Semantics Reduction and Cross-Domain Training","C. Wang; C. Zhao; G. Hu","College of Electronic and Information Engineering, Tongji University, Shanghai, China; College of Electronic and Information Engineering, Tongji University, Shanghai, China; Oosto, Belfast, U.K",2022 IEEE International Conference on Multimedia and Expo (ICME),"26 Aug 2022","2022","","","1","6","The recent development of Deepfake videos directly threatens our information security and personal privacy. Although lots of previous works have made much progress on the Deepfake detection, we empirically find that the existing approaches do not perform well on the low definition (LD) and crossdefinition (high and low) videos. To address this problem, in this paper, we follow two motivations: (1) high-level semantics reduction and (2) cross-domain training. For (1), we propose the Facial Structure Destruction and Adversarial Jigsaw Loss to reduce our model to learn high-level semantics and focus on learning low-level discriminative information; For (2), we propose a domain generalization method based on adversarial learning. We conduct extensive experiments on the FaceForensics++ dataset. Results show the great effectiveness of our method and we also achieve very competitive performance against state-of-the-art methods.","1945-788X","978-1-6654-8563-0","10.1109/ICME52920.2022.9859736","Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9859736","Deep Learning;Deepfake Detection","Training;Deepfakes;Privacy;Semantics;Information security;Detectors;Video compression","","1","","21","IEEE","26 Aug 2022","18-22 July 2022","18-22 July 2022","IEEE","IEEE Conferences"
"Advancements in Deepfake Detection: Leveraging Bi-LSTM-CNN Architecture for Robust Identification","O. Tantawy; A. Elshafee","Faculty of Computer Science October, University for Modern Sciences and Arts (MSA); University for Modern Sciences and Arts (MSA)",2024 6th Novel Intelligent and Leading Emerging Sciences Conference (NILES),"22 Nov 2024","2024","","","525","528","In our modern era, the saying “visual evidence is conclusive” no longer holds true, presenting significant implications across various spheres of our lives. With the rapid advancement of technology, the creation of synthetic media, particularly deepfakes, has become remarkably facile. Some applications even facilitate the creation of deepfakes directly on handheld devices. The identification of deepfakes poses a formidable challenge as they can be imperceptible to the human eye. Nevertheless, researchers are actively engaged in developing methodologies to discern deepfakes. Deepfakes constitute media generated through AI algorithms. These algorithms assimilate attributes from a reference image and overlay them onto a source image. In our pursuit of identifying video deepfakes, we employ deep learning architectures such as Bi-LSTM integrated with CNN. Our approach capitalizes on 50 epochs of training to attain a remarkable accuracy of up to 98.7%. We leverage transfer learning to construct a robust deepfake detection model. Initially, we utilize a pretrained CNN, dubbed Bi-LSTM-CNN, to extract salient features and construct feature vectors. Subsequently, the Bi-LSTM layer is trained using these feature vectors. The resulting confusion matrix substantiates the efficacy of our model, with validation and testing accuracies reaching an impressive level.","","979-8-3503-7851-1","10.1109/NILES63360.2024.10753235","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10753235","Advancements in Deepfake Detection;Leveraging Bi-LSTM-CNN Architecture for Robust Identification","Training;Deepfakes;Visualization;Accuracy;Scalability;Transfer learning;Media;Feature extraction;Vectors;Testing","","1","","18","IEEE","22 Nov 2024","19-21 Oct. 2024","19-21 Oct. 2024","IEEE","IEEE Conferences"
"A Deepfake Detection Method Based on Transformer Transformer Spatiotemporal Modeling","C. Meng; Y. Guo","School of Computer Science and Technology, Xi'an University of Posts and Telecommunications, Xi'an, China; School of Computer Science and Technology, Xi'an University of Posts and Telecommunications, Xi'an, China",2025 7th International Conference on Natural Language Processing (ICNLP),"19 Aug 2025","2025","","","325","329","This study proposes a novel spatiotemporal feature modeling model based on the Transformer architecture–STFormer–for deepfake detection tasks in videos. The model design features a four-stage pyramid structure, each incorporating a Spatiotemporal Embedding Layer (STEL) and multiple Transformer Encoder blocks. STEL extracts spatial features using multi-scale convolutional kernels and employs a Gate Recurrent Unit (GRU) to model inter-frame dynamic changes, ultimately fusing spatiotemporal features to form embedded representations. Furthermore, the model progressively reduces the number of embedding tokens at each stage while increasing the feature dimensions, thus efficiently extracting spatiotemporal features while maintaining information integrity and effectively managing computational budgets. Experimental validation on the FaceForensics++ and Celeb-DF datasets demonstrates that the STFormer model performs exceptionally well in detecting various forgery methods, substantiating its outstanding performance and broad applicability in deepfake detection.","","979-8-3315-2187-5","10.1109/ICNLP65360.2025.11108429","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11108429","deepfake detection;STFormer;spatiotemporal embedding Layer(STEL);spatiotemporal features","Deepfakes;Computational modeling;Logic gates;Feature extraction;Transformers;Forgery;Robustness;Spatiotemporal phenomena;Computational efficiency;Kernel","","","","23","IEEE","19 Aug 2025","21-23 March 2025","21-23 March 2025","IEEE","IEEE Conferences"
"Digital Mirage: The Paradox of Virtuality and Reality","S. Barde; A. Karan; Aman","Department of Computer Science and Engineering-Cyber Security, Parul University, Vadodara, India; Department of Computer Science and Engineering-Cyber Security, Parul University, Vadodara, India; Department of Computer Science and Engineering-Cyber Security, Parul University, Vadodara, India",2025 12th International Conference on Computing for Sustainable Global Development (INDIACom),"21 Aug 2025","2025","","","1","5","In this digital age, the rampancy of cyberattacks, ranging from hacking and identity theft to various other more pernicious kinds of cybercrime, has already become a growing concern for the world. Sadly, deepfake technology-one of the most recent developments in this area-is an advanced method of generating hyper-realistic fake videos and images by way of artificial intelligence. It is fast gaining grounds as a powerful tool for misinformation and manipulation of people's view to deceive individuals and corporations. Digital Mirage, is our project that aimed to detection and analysis deepfake video using the latest in AI methods combined with Python-based libraries. This initiative is devised to minimize the unwanted effects of digital deception on society for this we selected the Deepfake Detection Challenge (DFDC) dataset-a publicly available pool of authentic and manipulated media created by Facebook. To evaluate the efficacy of detection framework. At last, our system achieved 86% accuracy, which shows that traditional computer vision techniques can be merged with AI-driven approaches to achieve successful deepfake detection. Though it has progressed significantly, it represents a call to further research and development of more sophisticated tools toward countering the continuing threat that deepfake technologies and digital integrity.","","978-93-80544-60-1","10.23919/INDIACom66777.2025.11115608","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11115608","Deepfake Detection;Digital Mirage;Cyber Security;Artificial Intelligence","Deepfakes;Accuracy;Social networking (online);Nose;Feature extraction;Libraries;Real-time systems;Computer crime;Artificial intelligence;Research and development","","","","21","","21 Aug 2025","2-4 April 2025","2-4 April 2025","IEEE","IEEE Conferences"
"Exploring Active Data Selection Strategies for Continuous Training in Deepfake Detection","Y. Furuhashi; J. Yamagishi; X. Wang; H. H. Nguyen; I. Echizen","National Institute of Informatics 2-1-2 Hitotsubashi, Tokyo, Japan; National Institute of Informatics 2-1-2 Hitotsubashi, Tokyo, Japan; National Institute of Informatics 2-1-2 Hitotsubashi, Tokyo, Japan; National Institute of Informatics 2-1-2 Hitotsubashi, Tokyo, Japan; National Institute of Informatics 2-1-2 Hitotsubashi, Tokyo, Japan",2024 International Conference of the Biometrics Special Interest Group (BIOSIG),"11 Dec 2024","2024","","","1","5","In deepfake detection, it is essential to maintain high performance by adjusting the parameters of the detector as new deepfake methods emerge. In this paper, we propose a method to automatically and actively select the small amount of additional data required for the continuous training of deepfake detection models in situations where deepfake detection models are regularly updated. The proposed method automatically selects new training data from a redundant pool set containing a large number of images generated by new deepfake methods and real images, using the confidence score of the deepfake detection model as a metric. Experimental results show that the deepfake detection model, continuously trained with a small amount of additional data automatically selected and added to the original training set, significantly and efficiently improved the detection performance, achieving an EER of 2.5% with only 15% of the amount of data in the pool set.","1617-5468","979-8-3503-7371-4","10.1109/BIOSIG61931.2024.10786748","Ministry of Internal Affairs and Communications; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10786748","deepfake detection;active learning;continuous training;data selection;certainty scoring","Training;Measurement;Biometrics;Deepfakes;System performance;Training data;Detectors;Data models;Internet;Testing","","","","23","IEEE","11 Dec 2024","25-27 Sept. 2024","25-27 Sept. 2024","IEEE","IEEE Conferences"
"Deep Fake Detection Using CNN","A. Manisha; S. R. Sri; V. L. Vinya","Department of Computer Science and Engineering, Vardhaman College of Engineering, Telangana; Department of Computer Science and Engineering, Vardhaman College of Engineering, Telangana; Department of Computer Science and Engineering, Vardhaman College of Engineering, Telangana",2024 2nd International Conference on Artificial Intelligence Trends and Pattern Recognition (ICAITPR),"15 Apr 2025","2024","","","1","6","Advancing deep learning has brought great challenges toward the verification of authenticity in deepfake media, especially about security, privacy, and misinformation. This paper aims to provide a dependable method for detecting synthetic media: via a CNN-based approach named ResNet-50 that deals with a large dataset related to real and deepfake content, capturing subtle anomalies in the model. With further preprocessing, facial alignment, and feature extraction, enhanced accuracy is achieved. Empirical evaluations that demonstrate strong performance against manipulation and varied adversarial attacks underline the need for advance detection technology.","","979-8-3503-6800-0","10.1109/ICAITPR63242.2024.10960037","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10960037","Deepfake detection;CNNs;ResNet-50;synthetic media;adversarial robustness;feature extraction","Deepfakes;Privacy;Accuracy;Weapons;Transfer learning;Streaming media;Feature extraction;Robustness;Real-time systems;Security","","","","10","IEEE","15 Apr 2025","6-8 Dec. 2024","6-8 Dec. 2024","IEEE","IEEE Conferences"
"DeepFake Detection Using DenseNet-121","A. S. Menon; R. Raju; K. S. Lakshmi Varma; A. G. S","Department of Computer Science and IT, School of Computing, Amrita Vishwa Vidyapeetham, Kochi, India; Department of Computer Science and IT, School of Computing, Amrita Vishwa Vidyapeetham, Kochi, India; Department of Computer Science and IT, School of Computing, Amrita Vishwa Vidyapeetham, Kochi, India; Department of Computer Science and IT, School of Computing, Amrita Vishwa Vidyapeetham, Kochi, India","2025 4th International Conference on Advances in Computing, Communication, Embedded and Secure Systems (ACCESS)","29 Aug 2025","2025","","","656","661","In today’s world, image manipulations using advanced tools have become a significant concern. This paper introduces DenseNet-121 for distinguishing between real and fake images. The approach involves data preprocessing, organizing the dataset using CSV metadata, applying data augmentation, and training a fine-tuned convolutional neural network (CNN) to ensure high classification accuracy. Our implementation achieved a test accuracy of 97.00%.","","979-8-3315-3623-7","10.1109/ACCESS65134.2025.11135521","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11135521","DeepFake Detection;DenseNet-121;Real Image;Fake Image;Image Classification","Training;Deepfakes;Accuracy;Data preprocessing;Metadata;Data augmentation;Convolutional neural networks;Image classification","","","","11","IEEE","29 Aug 2025","11-13 June 2025","11-13 June 2025","IEEE","IEEE Conferences"
"Localization of Deepfake Facial Images Through U-NET Architecture","K. K. Sheelavantmath; V. Isloor; B. Sheetal; N. Bhuvisha; B. J. Sandesh","Dept. of CSE, PES University, Bangalore, Karnataka, India; Dept. of CSE, PES University, Bangalore, Karnataka, India; Dept. of CSE, PES University, Bangalore, Karnataka, India; Dept. of CSE, PES University, Bangalore, Karnataka, India; Dept. of CSE, PES University, Bangalore, Karnataka, India",2025 11th International Conference on Computing and Artificial Intelligence (ICCAI),"11 Aug 2025","2025","","","102","107","Traditional deep fake detection methods predominantly rely on binary classification, categorizing images as either real or fake, which often limits their transparency and interpretability for real-world applications. To address this, we propose a novel approach that integrates Histogram of Oriented Gradients (HOG) features into a U-Net architecture, enabling the capture of both fine-grained texture patterns and highlevel contextual information in deep fake regions. For enhanced interpretability, Class Activation Maps (CAM) are transformed into the HSV color space, facilitating intuitive color-based analysis. Contour detection is then employed to localize manipulated regions, and bounding boxes are generated using Dlib to precisely identify these features. By iterating through 68 facial landmarks, textual descriptions are generated to highlight alterations in facial features, providing a detailed understanding of the modifications. To further quantify the extent of manipulation, the resulting feature map undergoes a quantitative assessment by calculating the percentage of contour-detected areas. This method offers a comprehensive framework for identifying and analyzing subtle differences between genuine and modified images, advancing the transparency and accuracy of deep fake detection.","","979-8-3315-2491-3","10.1109/ICCAI66501.2025.00023","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11106172","Deepfake Detection;Histogram of Oriented Gradients (HOG);U-Net Architecture;Class Activation Maps (CAM);HSV Color Space;Contour Detection;Dlib;Facial Landmark Analysis","Location awareness;Deepfakes;Histograms;Attention mechanisms;Image color analysis;Data visualization;Computer architecture;Feature extraction;Real-time systems;Facial features","","","","14","IEEE","11 Aug 2025","28-31 March 2025","28-31 March 2025","IEEE","IEEE Conferences"
"A Spatial Adaptive Transformer Network for Sequential Deepfake Detection","C. Liu; G. Zhang; S. Sun; S. Guo; M. Gao; X. Xing","School of Electrical and Electronic Engineering, Shandong University of Technology, Zibo, China; School of Electrical and Electronic Engineering, Shandong University of Technology, Zibo, China; School of Electrical and Electronic Engineering, Shandong University of Technology, Zibo, China; School of Electrical and Electronic Engineering, Shandong University of Technology, Zibo, China; School of Electrical and Electronic Engineering, Shandong University of Technology, Zibo, China; College of Intelligent Systems Science and Engineering, Harbin Engineering University",2025 International Symposium on Intelligent Robotics and Systems (ISoIRS),"26 Sep 2025","2025","","","1","6","With the development of Artificial Intelligence Generated Content (AIGC) technology, deepfakes present a considerable threat to personal privacy and property security. Current deepfake detection methods are constrained by static feature extraction and limited multi-scale analysis and fail to localize subtle sequential artifacts. To detect the sequential deepfake, a dual-modality framework termed SATNet (Spatial Adaptive Transformer Network) is proposed. It consists of two main modules, namely Spatial Adaptation (SA) module and Global-Local Attention (GLA) module. The SA module is built to extract multi-scale feature and GLA module is designed to capture the hierarchical spatiotemporal dependencies. Experimental results demonstrate the effectiveness of SATNet in decoding sequences for adaptive multi-scale reasoning.","","979-8-3315-4359-4","10.1109/ISoIRS65690.2025.11167900","National Natural Science Foundation of China(grant numbers:62076078); Fundamental Research Funds for the Central Universities(grant numbers:CAAIXSJLJJ-2020-033A); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11167900","Deepfake Detection;Sequential Manipulations;Spatial Adaptation Module;Global-Local Attention Module","Deepfakes;Adaptation models;Adaptive systems;Accuracy;Transformer cores;Feature extraction;Transformers;Spatiotemporal phenomena;Security;Robots","","","","22","IEEE","26 Sep 2025","13-15 June 2025","13-15 June 2025","IEEE","IEEE Conferences"
"MaskGAN: A Facial Fusion Algorithm for Deepfake Image Detection","D. Liu; Z. Yang; R. Zhang; J. Liu","School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China; School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China; School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China; School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China",2022 International Conference on Computers and Artificial Intelligence Technologies (CAIT),"23 Mar 2023","2022","","","71","78","The rapid development of deepfakes has caused serious harm to social cognition. However, the current deepfake detection algorithms generally have the problem of poor generalization, and the accuracy rate drops sharply on datasets with unknown deepfake methods. In this paper, we propose a facial fusion algorithm called MaskGAN to enable more generalized deepfake detection. The generator of MaskGAN uses U-Net and SSE to extract the features of face images, and realizes mask generation and face fusion, The discriminator of MaskGAN uses the convolution layer to discriminate the face-swaping images generated by MaskGAN. Then, the obtained face-swaping images are used as training sets and input into an improved Deeplab V3+for training, so that the network can extract the fusion feature circle generated during the face-swaping process from the face-swaping images, so as to identify the authenticity of the face-swaping images. We achieve accurate face swapping with only fused features introduced, generating a face swapping dataset with fused labels. It solves the common problems of over-fitting and poor generalization of existing algorithms. Through a large number of experiments, it is proved that MaskGAN enabled Deeplab V3+detection model can perform well in the case of unknown tampering methods, which achieved 23.02% and 6.9% cross-domain AUC performance improvement.","","979-8-3503-9617-1","10.1109/CAIT56099.2022.10072275","National Key R&D Program of China(grant numbers:2019QY2202); National Natural Science Foundation of China(grant numbers:1936216,U21B2020,62002197); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10072275","generative adversarial network;deepfake detection;fusion feature;faceswap detection","Training;Deepfakes;Image color analysis;Convolution;Feature extraction;Generative adversarial networks;Generators","","1","","17","IEEE","23 Mar 2023","4-6 Nov. 2022","4-6 Nov. 2022","IEEE","IEEE Conferences"
"Comparative Analysis of Machine Learning and Deep Learning Models for Deepfake Detection: Insights from the Celeb-DF Dataset","Y. A. Chouhan; C. Chudasama; D. K. Verma; M. Lunagaria","Computer Engineering, Marwadi University, Rajkot, India; Computer Engineering, Marwadi University, Rajkot, India; Computer Engineering, Marwadi University, Rajkot, India; Computer Engineering, Marwadi University, Rajkot, India",TENCON 2024 - 2024 IEEE Region 10 Conference (TENCON),"5 Mar 2025","2024","","","314","318","We live in a digital age where reality is a maze of mirrors, where manipulation of data is at the tip of our fingers. The spread of misinformation and the unwanted spread of deepfakes have become prevalent. In times like these, there is a dire need to create a foundation of security that can be generated by accurate deepfake detection models. In order to conduct this research, we train 12 deepfake detection models using the Celeb-DF dataset, which consists of real and artificial celebrity videos. We then evaluate the results using five metrics: Accuracy, Precision, Recall, F1 Score, and ROC AUC Score. Among all the models the highest accuracy score of 94% was achieved by ResNet50. The AUC score of the models were impressive ranging from 89% -98%. The main objective of this paper is to use a thorough comparative study of a blend of deep learning and machine learning models in order to address privacy and confidentiality issues in the era of digital deception and build confidence in visual media.","2159-3450","979-8-3503-5082-1","10.1109/TENCON61640.2024.10902703","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10902703","Celeb-DF;Deepfake Detection;Face forging;Machine learning;Deep learning","Deep learning;Training;Deepfakes;Visualization;Accuracy;Nearest neighbor methods;Distance measurement;Security;Random forests;Residual neural networks","","","","13","IEEE","5 Mar 2025","1-4 Dec. 2024","1-4 Dec. 2024","IEEE","IEEE Conferences"
"Unsupervised Learning-Based Framework for Deepfake Video Detection","L. Zhang; T. Qiao; M. Xu; N. Zheng; S. Xie","School of Cyberspace, Hangzhou Dianzi University, Hangzhou, China; School of Cyberspace, Hangzhou Dianzi University, Hangzhou, China; School of Cyberspace, Hangzhou Dianzi University, Hangzhou, China; School of Cyberspace, Hangzhou Dianzi University, Hangzhou, China; School of Cyberspace, Hangzhou Dianzi University, Hangzhou, China",IEEE Transactions on Multimedia,"31 Oct 2023","2023","25","","4785","4799","With the continuous development of computer hardware equipment and deep learning technology, it is easier for people to swap faces in videos by currently-emerging multimedia tampering tools, such as the most popular deepfake. It would bring a series of new threats of security. Although many forensic researches have focused on this new type of manipulation and achieved high detection accuracy, most of which are based on supervised learning mechanism with requiring a large number of labeled samples for training. In this paper, we first develop a novel unsupervised detection manner for identifying deepfake videos. The main fundamental behind our proposed method is that the face region in the real video is taken by the camera while its counterpart in the deepfake video is usually generated by the computer; the provenance of two videos is totally different. Specifically, our method includes two clustering stages based on Photo-Response Non-Uniformity (PRNU) and noiseprint feature. Firstly, the PRNU fingerprint of each video frame is extracted, which is used to cluster the full-size identical source video (regardless of its real or fake). Secondly, we extract the noiseprint from the face region of the video, which is used to identify (re-cluster for the task of binary classification) the deepfake sample in each cluster. Numerical experiments verify our proposed unsupervised method performs very well on our own dataset and the benchmark FF++ dataset. More importantly, its performance rivals that of the supervised-based state-of-the-art detectors.","1941-0077","","10.1109/TMM.2022.3182509","Fundamental Research Funds for the Provincial Universities of Zhejiang(grant numbers:GK219909299001-007); Open Projects Program of National Laboratory of Pattern Recognition; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9795231","Deepfake detection;unsupervised learning;video clustering;PRNU;noiseprint","Faces;Streaming media;Cameras;Feature extraction;Forensics;Cyberspace;Training","","41","","62","IEEE","13 Jun 2022","2023","","IEEE","IEEE Journals"
"DDL: Effective and Comprehensible Interpretation Framework for Diverse Deepfake Detectors","Z. Sun; N. Ruan; J. Li","Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China",IEEE Transactions on Information Forensics and Security,"2 Apr 2025","2025","20","","3601","3615","In the context of escalating advancements in AI generative technologies, Deepfakes, the sophisticated face forgeries created using deep learning methods, have emerged as a significant security threat. The predominant countermeasures are Deepfake detectors based on deep learning (DL). However, due to the opaque nature of DL-model, they struggle to offer understandable explanations for their predictive decisions, which undermines their reliability and effectiveness in real-world applications. Existing mainstream DL-oriented interpretation approaches, the feature attribution methods, struggle to work on Deepfake detectors due to issues of low interpretation fidelity, poor intelligibility, and limited applicability across different types of detectors. This paper addresses these critical challenges by proposing the Deepfake Detector Lens (DDL), a novel framework designed to enhance the interpretability of diverse architectural Deepfake detectors, encompassing those based on image, frequency domain, and video. DDL employs a heuristic algorithm to enhance interpretation efficacy and incorporates image segmentation and face parsing techniques to bridge the gap between the machine-generated interpretation saliency map and human understanding. Comprehensive evaluations of DDL demonstrate its superiority over existing feature attribution methods in terms of fidelity, intelligibility, and applicability. The proposed DDL significantly advances the interpretability of Deepfake detection technology, offering a more reliable and understandable tool for combating AI-generated face forgeries.","1556-6021","","10.1109/TIFS.2025.3553803","National Key Research and Development Program of China(grant numbers:2023YFB2704700); National Natural Science Foundation of China(grant numbers:62472276); Shanghai Committee of Science and Technology, China(grant numbers:23511101000,24BC3200400); Science and Technology Project of State Grid Corporation of China(grant numbers:5700-202321603A-3-2-ZN); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10937201","Interpretable deepfake detection;feature attribution","Detectors;Deepfakes;Faces;Frequency-domain analysis;Security;Feature extraction;Deep learning;Lenses;Data mining;Training","","4","","52","IEEE","21 Mar 2025","2025","","IEEE","IEEE Journals"
"LGDF-Net: Local and Global Feature-Based Dual-Branch Fusion Networks for Deepfake Detection","M. Long; Z. Liu; L. -B. Zhang; F. Peng","School of Electronics and Communication Engineering, Guangzhou University, Guangzhou, Guangdong, China; School of Computer and Communication Engineering, Changsha University of Science and Technology, Changsha, China; School of Computer and Artificial Intelligence, Huaihua University, Huaihua, China; School of Artificial Intelligence, Guangzhou University, Guangzhou, Guangdong, China",IEEE Transactions on Circuits and Systems for Video Technology,"9 Jun 2025","2025","35","6","5489","5500","With the rapid development of Deepfake technology, social security is facing great challenges. Although numerous Deepfake detection algorithms based on traditional CNN frameworks perform well on specific datasets, they still suffer from overfitting due to an over-reliance on localized artifact information. This limitation leads to degraded detection performance across diverse datasets. To address this issue, this study proposes a dual-branch fusion network called LGDF-Net. LGDF-Net uses a dual-branch structure to process the local artifact features and global texture features generated by Deepfake separately, preserving their unique characteristics. Specifically, the local compression branch utilizes a specially designed local compression module (LCM) that allows the network to focus more accurately on key regions of localized artifacts in Deepfake faces. The global expansion branch enhances the analysis of the global facial context through a global expansion module (GEM), which captures image context information and subtle texture features more comprehensively. Additionally, the proposed multi-scale feature extraction module (MSFE) delves into image features at various scales, enriching the extraction of detailed information. Finally, the multi-level feature fusion strategy (MLFF) improves the integration of local and global features through multiple layers, enabling the network to learn the intrinsic connections between these two types of features. A series of experimental validations demonstrate that the proposed scheme outperforms many existing detection networks in terms of accuracy and generalization ability.","1558-2205","","10.1109/TCSVT.2025.3530402","Guangzhou Municipal Science and Technology Project(grant numbers:2025A03J3122); National Natural Science Foundation of China(grant numbers:62072055); Key Laboratory of Intelligent Control Technology for Wuling-Mountain Ecological Agriculture(grant numbers:ZNKZD2024-5); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10843307","Deepfake detection;dual-branching framework;multi-scale feature extraction;multi-level feature fusion","Feature extraction;Deepfakes;Forgery;Faces;Accuracy;Image color analysis;Electronic mail;Data mining;Visualization;Facial features","","4","","54","IEEE","16 Jan 2025","June 2025","","IEEE","IEEE Journals"
"Image Search Engine with Recognition","J. R. Kumar; B. Dheeraj; G. Gowtham; D. V. Babu; B. A. Kiran; M. Srikanth","Department of Information Technology, SRKR Engineering College, Bhimavaram, Andhra Pradesh, India; Department of Information Technology, SRKR Engineering College, Bhimavaram, Andhra Pradesh, India; Department of Information Technology, SRKR Engineering College, Bhimavaram, Andhra Pradesh, India; Department of Information Technology, SRKR Engineering College, Bhimavaram, Andhra Pradesh, India; Department of Information Technology, SRKR Engineering College, Bhimavaram, Andhra Pradesh, India; Department of Information Technology, SRKR Engineering College, Bhimavaram, Andhra Pradesh, India",2025 4th International Conference on Sentiment Analysis and Deep Learning (ICSADL),"27 Mar 2025","2025","","","1217","1223","The Image Recognition Search Engine is one of the modern advances in artificial intelligence and image analysis and processing. This advanced system surpasses typical functionalities in image identification as it captures features to solve new problems faced in existing systems of digital media authentication, content designing, and improvement of images. The system core relies on advanced AI algorithms that can rasterically recognize and analyze various forms of image objects ranging from objects, faces, scenes, and brand logos converting what appears to be simple images into indexical, analyzable data. One feature is that the system can integrate deepfake detection technology, which is relevant in the context of increasing the amount of manipulated content in the media space. Using special algorithms to learn even the least detectable abnormality in images including the presence of unnatural distinctive facial characteristics and changes in lighting conditions, we obtain a highly effective tool for improving the reliability of image identification. Furthermore, the platform allows for new features to convert an image into a video by implementing frame interpolation and motion estimation through animating the images to allow users to create interesting clips for applications regarding marketing or any personal use.","","979-8-3315-2392-3","10.1109/ICSADL65848.2025.10933116","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10933116","Image Recognition;Deepfake Detection;Image Processing;AI Algorithms;Content Analysis;object detection","Deepfakes;Visualization;Sentiment analysis;Image recognition;Face recognition;Search engines;Feature extraction;User experience;Artificial intelligence;Usability","","2","","11","IEEE","27 Mar 2025","18-20 Feb. 2025","18-20 Feb. 2025","IEEE","IEEE Conferences"
"WaveGuard: Robust Deepfake Detection and Source Tracing via Dual-Tree Complex Wavelet and Graph Neural Networks","Z. He; Z. Guo; L. Wang; G. Yang; Y. Diao; D. Ma","College of Computer Science and Technology, Xinjiang University, Urumqi, China; College of Computer Science and Technology, Xinjiang University, Urumqi, China; College of Computer Science and Technology, Xinjiang University, Urumqi, China; College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; School of Computer Science, Hefei University of Technology, Hefei, China; College of Computer Science and Technology, Xinjiang University, Urumqi, China",IEEE Transactions on Circuits and Systems for Video Technology,"","2025","PP","99","1","1","Deepfake technology has great potential in the field of media and entertainment, but it also brings serious risks, including privacy disclosure and identity fraud. To counter these threats, proactive forensic methods have become a research hotspot by embedding invisible watermark signals to build active protection schemes. However, existing methods are vulnerable to watermark destruction under malicious distortions, which leads to insufficient robustness. Moreover, embedding strong signals may degrade image quality, making it challenging to balance robustness and imperceptibility. Although watermarked images look natural, their underlying structures are often different from the original images, which is ignored by traditional watermarking methods. To address these issues, this paper proposes a proactive watermarking framework called WaveGuard, which explores frequency domain embedding and graph-based structural consistency optimization. In this framework, the watermark is embedded into the high-frequency sub-bands by dual-tree complex wavelet transform (DT-CWT) to enhance the robustness against distortions and deepfake forgeries. By leveraging joint sub-band correlations and selected sub-band combinations, the framework enables robust source tracing and semi-robust deepfake detection. To enhance imperceptibility, we propose a Structural Consistency Graph Neural Network (SC-GNN) that constructs graph representations of the original and watermarked images to ensure structural consistency and reduce perceptual artifacts. Experimental results show that the proposed method performs exceptionally well in face swap and face replay tasks. The code has been published at https://github.com/vpsg-research/WaveGuard.","1558-2205","","10.1109/TCSVT.2025.3628951","National Natural Science Foundation of China(grant numbers:62302427,62462060); Natural Science Foundation of Xinjiang Uygur Autonomous Region(grant numbers:2023D01C175); Tianshan Talent Training Program(grant numbers:2022TSYCLJ0036); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11224900","Deepfake Detection;Source Tracing;Frequency-domain Embedding;Graph Neural Network (GNN)","Watermarking;Deepfakes;Robustness;Distortion;Faces;Feature extraction;Perturbation methods;Graph neural networks;Training;Frequency-domain analysis","","1","","","IEEE","4 Nov 2025","","","IEEE","IEEE Early Access Articles"
"Unlocking A New Paradigm In Robustness For Multi-Step Facial Forgery Detection","S. Luo; W. Guan; L. Zhou; J. Dong","Beijing University of Posts and Telecommunications, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China",2025 IEEE International Conference on Image Processing (ICIP),"18 Aug 2025","2025","","","779","784","With the rapid advancement of face forgery technologies, the quality of manipulated images has significantly improved, posing a severe threat to information security. In response, deepfake detection has emerged as an effective countermeasure against the misuse of these technologies. Sequential deepfake detection,as a specialized extension, targets face images with multi-step manipulation. However, a key challenge in this task is defending against unknown image degradation that occurs during transformation, which is not widely addressed in previous research. This paper introduces a robust detection framework named RSFDF, aimed at enhancing detection capabilities when images are subjected to degradation operations. RSFDF incorporates two critical modules:ATEM and ESCM. ATEM assists the network in focusing on important features while suppressing irrelevant information; ESCM refines the attention mechanism to increase the model’s focus on edge contours, aiding in the judgment of sequential forgeries. Experiments show that RSFDF exhibits significant improvements in robustness against unknown image degradations.","2381-8549","979-8-3315-2379-4","10.1109/ICIP55913.2025.11084694","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11084694","Multi-step Manipulation;Sequential Deepfake Detection;Robustness","Degradation;Deepfakes;Sensitivity;Image edge detection;Image processing;Information security;Robustness;Forgery;Stability analysis;Faces","","","","29","IEEE","18 Aug 2025","14-17 Sept. 2025","14-17 Sept. 2025","IEEE","IEEE Conferences"
"AIM-Bone: Texture Discrepancy Generation and Localization for Generalized Deepfake Detection","B. Liu; X. Zhang; H. Ling; Z. Li; R. Wang; H. Zhang; P. Li","School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China","IEEE Transactions on Biometrics, Behavior, and Identity Science","26 Jun 2025","2025","7","3","422","431","Deep synthesis multimedia content, especially human face manipulation poses a risk of visual and auditory confusion, highlighting the call for generalized face forgery detection methods. In this paper, we propose a novel method for fake sample synthesis, along with a dual auto-encoder network for generalized deepfake detection. First, we delve into the texture discrepancy between tampered and unperturbed regions within forged images and impose models to learn such features by adopting Augmentation Inside Masks (AIM). It is capable of sabotaging the texture consistency within a single real image and generating textures that are commonly seen in fake images. It is realized by exhibiting forgery clues of discrepancy in noise patterns, colors, resolutions, and especially the existence of GAN (Generative Adversarial Network) features, including GAN textures, deconvolution traces, GAN distribution, etc. To the best of our knowledge, this work is the first to incorporate GAN features in fake sample synthesizing. The second is that we design a Bone-shaped dual auto-encoder with a powerful image texture filter bridged in between to aid forgery detection and localization in two streams. Reconstruction learning in the color stream avoids over-fitting in specific textures and imposes learning color-related features. Moreover, the GAN fingerprints harbored within the output image can be in furtherance of AIM and produce texture-discrepant samples for further training. The noise stream takes input processed by the proposed texture filter to focus on noise perspective and predict forgery region localization, subjecting to the constraint of mask label produced by AIM. We conduct extensive experiments on multiple benchmark datasets and the superior performance has proven the effectiveness of AIM-Bone and its advantage against current state-of-the-art methods. Our source code is available at https://github.com/heart74/AIM-Bone.git.","2637-6407","","10.1109/TBIOM.2025.3526655","National Natural Science Foundation of China(grant numbers:62372203,62302186); Major Scientific and Technological Project of Shenzhen(grant numbers:202316021); National Key Research and Development Program of China(grant numbers:2022YFB2601802); Major Scientific and Technological Project of Hubei Province(grant numbers:2022BAA046,2022BAA042); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10829837","Deepfake detection;forgery detection generalization;fake textures;adversarial learning;data augmentation","Forgery;Generative adversarial networks;Faces;Deepfakes;Training;Image color analysis;Image reconstruction;Feature extraction;Adversarial machine learning;Data augmentation","","","","60","IEEE","6 Jan 2025","July 2025","","IEEE","IEEE Journals"
"Masked Conditional Diffusion Model for Enhancing Deepfake Detection","T. Chen; S. Yang; S. Hu; Z. Fang; Y. Fu; X. Wu; X. Wang","Chengdu University of Information Technology; Chengdu University of Information Technology; Purdue University in Indianapolis; Johns Hopkins University; Chengdu University of Information Technology; Chengdu University of Information Technology; University at Albany, State University of New York (SUNY)",2024 International Joint Conference on Neural Networks (IJCNN),"9 Sep 2024","2024","","","1","7","Recent studies on deepfake detection have achieved promising results when training and testing faces are from the same dataset. However, their results severely degrade when confronted with forged samples that the model has not yet seen during training. In this paper, deepfake data to help detect deepfakes. this paper present we put a new insight into diffusion model-based data augmentation, and propose a Masked Conditional Diffusion Model (MCDM) for enhancing deepfake detection. It generates a variety of forged faces from a masked pristine one, encouraging the deepfake detection model to learn generic and robust representations without overfitting to special artifacts. Extensive experiments demonstrate that forgery images generated with our method are of high quality and helpful to improve the performance of deepfake detection models.","2161-4407","979-8-3503-5931-2","10.1109/IJCNN60899.2024.10651330","China Meteorological Administration; Chengdu University of Information Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10651330","Conditional Diffusion Model;Deepfake Detection;Data Augmentation","Training;Deepfakes;Neural networks;Diffusion models;Data augmentation;Data models;Forgery","","5","","51","IEEE","9 Sep 2024","30 June-5 July 2024","30 June-5 July 2024","IEEE","IEEE Conferences"
"Enhancing Deepfake Detection: An Ensemble Deep Learning Approach for Efficient Attribute Manipulation Identification","S. P P; R. R R; D. A; G. R; A. R; G. B. P","Department of CSE, Kongu Engineering College, Perundurai, India; Department of CSE, Kongu Engineering College, Perundurai, India; Department of CSE, Kongu Engineering College, Perundurai, India; Department of CSE, Kongu Engineering College, Perundurai, India; Department of CSE, Kongu Engineering College, Perundurai, India; Computer Technology-UG, Kongu Engineering College, Perundurai, India",2024 International Conference on Cognitive Robotics and Intelligent Systems (ICC - ROBINS),"21 May 2024","2024","","","352","359","The increasing use of deepfake technology by incorporating Artificial Intelligence (AI) to seamlessly replace faces in videos, poses a significant threat to individuals, societies, and national security. This research study addresses this growing concern by detecting deepfake classification with the integration of two powerful Convolutional Neural Network (CNN) models: InceptionV3 and EfficientNetB0. The existing deepfake detection systems predominantly rely on facial feature analysis, analyzing subtle inconsistencies; however, these methods are susceptible to evolving deepfake techniques. In response, the proposed ensemble model exploits the advantages of InceptionV3 and EfficientNetB0 models to capture intricate features and computational efficiency. The synergy between these models significantly enhances the accuracy upto 93% and adaptability of the proposed deepfake detection system. When compared with conventional facial feature analysis, this approach establishes a resilient defense against emerging deepfake threats. As deepfake technology continues to advance, necessitating continual research in face-based detection systems, this study proposes a cutting-edge ensemble approach that not only mitigates the risks associated with social media manipulation but also serves as a proactive measure against potential challenges in future.","","979-8-3503-7274-8","10.1109/ICC-ROBINS60238.2024.10533994","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10533994","Deepfake Detection;Ensemble Learning;Facial Feature Analysis;Attribute Manipulation;Efficient Net;Inception Net","Training;Deepfakes;Analytical models;Adaptation models;Sensitivity;Computational modeling;Predictive models","","1","","15","IEEE","21 May 2024","17-19 April 2024","17-19 April 2024","IEEE","IEEE Conferences"
"Improving DeepFake Video Detection Performance with a Noval Deep Learning Approach","M. A. Fouda; W. El-Shafai; E. -S. M. El-Rabaie","Department of Electronics and Electrical Communications Engineering, Faculty of Electronic Engineering, Menoufia University, Menouf, Egypt; Department of Electronics and Electrical Communications Engineering, Faculty of Electronic Engineering, Menoufia University, Menouf, Egypt; Department of Electronics and Electrical Communications Engineering, Faculty of Electronic Engineering, Menoufia University, Menouf, Egypt",2023 3rd International Conference on Electronic Engineering (ICEEM),"21 Nov 2023","2023","","","1","8","With the rise in both the quantity and sophistication of deepfake videos, the need for robust detection systems to identify potentially misleading content on social media and the internet has become paramount. However, current automated face forgery detection systems still face limitations, often demonstrating bias towards the training dataset. This research paper addresses this issue by proposing a novel approach for detecting deepfake media. We introduce a custom Visual Geometry Group (VGG16) deepfake detection method that leverages convolutional neural network architectures. To evaluate the effectiveness of our approach, we utilize the deepfake detection challenge (DFDC) dataset on Kaggle to build network models and compare the performance of our custom VGG16 method against the standard VGG16. Additionally, we investigate the impact of data augmentation techniques on the performance of Convolutional Neural Network (CNN)-based deepfake detectors, examining their effect on both VGG16 and our custom VGG16 approach using the DFDC dataset. Our results demonstrate a high level of accuracy, with precision, recall, and f1-score values of 0.983, 0.975, and 0.979, respectively, and an overall accuracy of 0.986 for deepfake detection. This study presents a promising approach to enhance the accuracy of deepfake video detection, representing a crucial step towards mitigating the potential negative impacts of deepfake technology.","","979-8-3503-2351-1","10.1109/ICEEM58740.2023.10319524","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10319524","Deepfake;Deep learning;CNN;Data Augmentation;Deepfake Detection;and VGG16","Training;Geometry;Deepfakes;Visualization;Social networking (online);Media;Forgery","","1","","23","IEEE","21 Nov 2023","7-8 Oct. 2023","7-8 Oct. 2023","IEEE","IEEE Conferences"
"Promoting Racial Fairness in Deepfake Face Detection","Z. Lei; R. Wang","School of Computer Science, Wuhan University, Wuhan, China; School of Computing and Information, University of Pittsburgh, Pittsburgh, USA",2025 International Joint Conference on Neural Networks (IJCNN),"14 Nov 2025","2025","","","1","7","Despite the development of efficient deepfake detection models for facial images in recent years, recent studies have shown that these models may exhibit significant performance differences across different racial groups. This unfairness can lead to misidentification of specific groups in deepfake detection, thereby affecting the overall reliability of the model. Existing methods mostly rely on designing fair loss functions, which can improve fairness under certain conditions. However, these methods often struggle to ensure consistent fairness across different groups, especially when dealing with sensitive factors such as race. To address this issue, this paper proposes a novel approach aimed at solving the generalization of fairness in deepfake detection, particularly focusing on racial fairness issues. Our method first preprocesses the original dataset by removing samples from minority racial groups to create a dataset without minority races. Based on this, we design an improved deepfake detection model. In particular, we introduce a racial classifier to extract race-related features. By integrating these race-related features with the original model, we guide the model to ignore race-sensitive features, thereby making it more focused on extracting general deepfake features and avoiding the impact of racial bias on detection performance. Extensive experimental results show that the optimized model demonstrates superior fairness generalization capabilities in cross-domain deepfake detection compared to existing methods, effectively reducing performance disparities among different racial groups.","2161-4407","979-8-3315-1042-8","10.1109/IJCNN64981.2025.11227218","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11227218","Deepfake detection;Racial bias;Fair detection","Deepfakes;Neural networks;Focusing;Interference;Feature extraction;Data models;Forgery;Quality assessment;Reliability;Video recording","","","","35","IEEE","14 Nov 2025","30 June-5 July 2025","30 June-5 July 2025","IEEE","IEEE Conferences"
"PViT: A Hybrid Model for Deepfake Face Detection using Patch Vision Transformers and Deep Learning","I. Ambreen; M. Aatif; Z. Jalil; F. Iqbal; A. Marrington","National Cyber Forensics Lab (NCFL), Air University, Islamabad, Pakistan; National Cyber Forensics Lab (NCFL), Air University, Islamabad, Pakistan; National Cyber Forensics Lab (NCFL), Air University, Islamabad, Pakistan; College of Technological Innovation, Zayed University, United Arab Emirates; College of Technological Innovation, Zayed University, United Arab Emirates","2025 12th IFIP International Conference on New Technologies, Mobility and Security (NTMS)","18 Jul 2025","2025","","","58","66","The proliferation of AI-generated deepfakes, particularly facial image forgeries, poses a significant threat to digital security by facilitating misinformation, identity theft, and privacy breaches. Traditional detection approaches, primarily based on Convolutional Neural Networks (CNNs), often exhibit limited effectiveness when confronted with highly refined or subtle manipulations, leading to compromised detection performance. To address this challenge, this study explores the application of Vision Transformers (ViTs), which leverage selfattention mechanisms to capture fine-grained inconsistencies in visual patterns. This research proposed a hybrid deepfake detection model that integrates patch-oriented ViTs with CNN architectures to improve discriminative feature extraction. Experimental evaluation on benchmark datasets demonstrates that the proposed model achieved a detection accuracy 99%, precision $\mathbf{9 9 \%}$, recall $\mathbf{9 9\%}$, F1-Score $\mathbf{9 9\%}$ on a validation set comprising 76,161 facial images, outperforming conventional CNN-based methods. These results highlight the potential of transformerbased architectures in advancing the robustness and reliability of deepfake detection systems, thereby contributing to the protection of digital authenticity and information integrity.","2157-4960","979-8-3315-5276-3","10.1109/NTMS65597.2025.11076897","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11076897","Deepfake Detection;Vision Transformer (ViT);Deep Learning;CNN;Image Manipulation;Generative Adversarial Networks (GANs);Patches","Deep learning;Deepfakes;Visualization;Accuracy;Computational modeling;Computer architecture;Streaming media;Transformers;Convolutional neural networks;Security","","","","53","IEEE","18 Jul 2025","18-20 June 2025","18-20 June 2025","IEEE","IEEE Conferences"
"Detecting Digital Deception: A CNN-RNN hybrid Approach of Deepfake Detection","H. Singh; R. Kumar; M. Gupta; V. S. Babu Chilluri","Department of CSE, Chandigarh University, Mohali, India; Department of CSE, Chandigarh University, Mohali, India; Department of CSE, Chandigarh University, Mohali, India; Intuit Inc., Mountain View, CA, USA",2025 International Conference on Pervasive Computational Technologies (ICPCT),"1 Apr 2025","2025","","","667","672","Deepfake technology has forced digital deception to create high demand for detection tools. This paper presents an approach for deepfake video detection using Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) architecture that targets the artifacts present in the output from the generative models including Generative adversarial network (GAN). This approach looks at many strategies in terms of frames, among them for frame comparison, feature extraction based on CNNs, and for the purpose of temporal analysis CNN with long-short-term memory (LSTM) networks. The described model is trained on the set of the genuine vs. forged images and videos and demonstrates quite stable results with respect to digital forging detection. It is discovered that this proposed model achieves higher accuracy than previously used detection approaches in addressing face-swapping and face-reenactment deepfakes. The findings of this research demonstrate that CNN & RNN based deepfake detection is promising for media forensics, as it advances multimedia security and digital media credibility. This proposed method shows an accuracy of 81% in the Deepfake Detection Dataset (DFDS), respectively, with a very reduced number of sample size of ⩽ 100 samples(frames). This promises early detection of fake contents compared to existing modalities.","","979-8-3315-0868-5","10.1109/ICPCT64145.2025.10940830","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10940830","Deepfake Detection;Convolutional Neural Network (CNN);Digital Deception;Image Manipulation;Artificial Intelligence (AI);Machine Learning;Multimedia Forensics;Video Analysis;Face Recognition;Image Authentication","Deepfakes;Recurrent neural networks;Accuracy;Forensics;Machine learning;Streaming media;Generative adversarial networks;Convolutional neural networks;Security;Long short term memory","","11","","21","IEEE","1 Apr 2025","8-9 Feb. 2025","8-9 Feb. 2025","IEEE","IEEE Conferences"
"Sparse Prototype-Based Framework for Deepfake Detection Using Class-Specific Dictionary Learning","F. Khalid; U. Haider; M. Hanif; A. Rashid; A. Khalil","Faculty of Computer Science and Engineering, GIK Institute of Engineering Sciences and Technology, Topi, Pakistan; School of Computer Science, University of Galway, Galway, Ireland; Faculty of Computer Science and Engineering, GIK Institute of Engineering Sciences and Technology, Topi, Pakistan; Faculty of Computer Science and Engineering, GIK Institute of Engineering Sciences and Technology, Topi, Pakistan; Faculty of Computer Information Science, Higher Colleges of Technology, Al Ain, United Arab Emirates",IEEE Access,"9 Dec 2025","2025","13","","204402","204415","Deepfake detection remains a pressing challenge due to the rapid evolution of forgery techniques and the demand for robust, generalizable, and interpretable solutions. We present a sparse prototype-based framework for deepfake detection that integrates class-specific dictionary learning with high-capacity face embeddings from the InceptionResNetV2 backbone. Discriminative dictionaries for real and manipulated faces are learned, and Orthogonal Matching Pursuit is employed to encode sparse representations. Classification decisions are derived from reconstruction residuals and sparse coefficient patterns, enabling transparent, traceable predictions. The proposed method is evaluated on Celeb-DF and five FaceForensics++ manipulation subsets, including FaceShifter, NeuralTexture, DeepFakes, FaceSwap, and Face2Face. It achieves up to 98.21% accuracy on FaceSwap and 92.05% on Celeb-DF, demonstrating competitive performance with state-of-the-art deep architectures while maintaining moderate computational cost. Beyond accuracy, the framework offers intrinsic interpretability by linking predictions to semantically meaningful prototypes, making it particularly suitable for forensic and high-stakes verification scenarios.","2169-3536","","10.1109/ACCESS.2025.3636276","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11264592","Deepfake detection;dictionary learning;face forensics;interpretable AI;prototype networks;and sparse coding","Deepfakes;Prototypes;Dictionaries;Machine learning;Computational modeling;Encoding;Forensics;Accuracy;Transformers;Detectors","","","","26","CCBY","24 Nov 2025","2025","","IEEE","IEEE Journals"
"Interactive Two-Stream Network Across Modalities for Deepfake Detection","J. Wu; B. Zhang; Z. Li; G. Pang; Z. Teng; J. Fan","School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; AI Laboratory, Lenovo Research, Beijing, China",IEEE Transactions on Circuits and Systems for Video Technology,"26 Oct 2023","2023","33","11","6418","6430","As face forgery techniques have become more mature, the proliferation of deepfakes may threaten the security of human society. Although existing deepfake detection methods achieve good performance for in-dataset evaluation, it remains to be improved in the generalization ability, where the representation of the imperceptible artifacts plays a significant role. In this paper, we propose an Interactive Two-Stream Network (ITSNet) to explore the discriminant inconsistency representation from the perspective of cross-modality. In particular, the patch-wise Decomposable Discrete Cosine Transform (DDCT) is adopted to extract fine-grained high-frequency clues, and information from different modalities communicates with each other via a designed interaction module. To perceive the temporal inconsistency, we first develop a Short-term Embedding Module (SEM) to refine subtle local inconsistency representation between adjacent frames, and then a Long-term Embedding Module (LEM) is designed to further refine the erratic temporal inconsistency representation from the long-range perspective. Extensive experimental results conducted on three public datasets show that ITSNet outperforms the state-of-the-art methods both in terms of in-dataset and cross-dataset evaluations.","1558-2205","","10.1109/TCSVT.2023.3269841","Fundamental Research Funds for the Central Universities of China(grant numbers:2022JBMC009); National Natural Science Foundation of China(grant numbers:61972027); Beijing Municipal Natural Science Foundation(grant numbers:42120411); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10107603","Deepfake detection;inconsistency representation;cross-modality learning","Forgery;Faces;Frequency-domain analysis;Feature extraction;Deepfakes;Convolution;Discrete cosine transforms","","22","","53","IEEE","24 Apr 2023","Nov. 2023","","IEEE","IEEE Journals"
"Improving Deepfake Detection Generalization by Invariant Risk Minimization","Z. Yin; J. Wang; Y. Xiao; H. Zhao; T. Li; W. Zhou; A. Liu; X. Liu","State Key Lab of Software Development Environment, Beihang University, Beijing, China; Zhongguancun Laboratory, Beijing, China; State Key Lab of Software Development Environment, Beihang University, Beijing, China; School of Cyberspace Security, University of Science and Technology of China, Hefei, China; Nanyang Technological University, Singapore; School of Cyberspace Security, University of Science and Technology of China, Hefei, China; State Key Lab of Software Development Environment, Beihang University, Beijing, China; State Key Lab of Software Development Environment, Beihang University, Beijing, China",IEEE Transactions on Multimedia,"10 Apr 2024","2024","26","","6785","6798","The abuse of deepfake techniques has raised serious concerns about social security and ethical problems, which motivates the development of deepfake detection. However, without fully addressing the domain gap issue, existing deepfake detection methods still show weak generalization ability among datasets belonging to different domains with domain-specific characteristics like identities and generation methods, limiting their practical applications. In this article, we propose the Invariant Domain-oriented Deepfake Detection method (ID$_{3}$), which improves the generalization of deepfake detection on multiple domains through invariant risk minimization, a novel learning paradigm that addresses the domain gap problem by jointly training a purified invariant predictor and learning an aligned invariant representation. To train a purified invariant predictor, we design the Domain Refinement Data Augmentation strategy with self-face-swapping and region-erasing approaches, which suppresses domain-specific features and encourages the models to focus on critical domain-invariant characteristics. To learn an aligned invariant representation, we propose the Domain Calibration Batch Normalization approach with multiple BN branches, which normalizes input features from different domains into aligned representations during both training and testing. Extensive experiments on multiple datasets demonstrate that our framework can boost the deepfake detection generalization ability and outperform other baselines by large margins. Our codes can be found here.","1941-0077","","10.1109/TMM.2024.3355651","KZ46009501; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10409578","Deepfake detection;invariant risk minimization;model generalization","Deepfakes;Risk minimization;Faces;Training;Predictive models;Forgery;Feature extraction","","21","","67","IEEE","19 Jan 2024","2024","","IEEE","IEEE Journals"
"Improving Generalization of Deepfake Detectors by Imposing Gradient Regularization","W. Guan; W. Wang; J. Dong; B. Peng","School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Multimodal Artificial Intelligence Systems (MAIS), Center for Research on Intelligent Perception and Computing (CRIPAC), Institute of Automation, Chinese Academy of Sciences (CASIA), Beijing, China; State Key Laboratory of Multimodal Artificial Intelligence Systems (MAIS), Center for Research on Intelligent Perception and Computing (CRIPAC), Institute of Automation, Chinese Academy of Sciences (CASIA), Beijing, China; State Key Laboratory of Multimodal Artificial Intelligence Systems (MAIS), Center for Research on Intelligent Perception and Computing (CRIPAC), Institute of Automation, Chinese Academy of Sciences (CASIA), Beijing, China",IEEE Transactions on Information Forensics and Security,"10 May 2024","2024","19","","5345","5356","The rapid development of face forgery technology has posed a significant threat to information security. While deepfake detection has proven to be an effective countermeasure, it often struggles to detect fake images generated by unknown forgery methods. Thus, the generalization ability of deepfake detectors to unseen forgery data is a critical concern. Despite many efforts aimed at discovering new forgery artifacts, they often fail to generalize to new manipulation technologies. In this paper, we tackle this challenge by focusing on the difference in texture patterns between training forgeries and unseen forgeries, which can lead to a degradation of generalization. Based on this principle, we propose a new conjecture that encourages deepfake detectors to reduce their sensitivity to forgery texture patterns, thereby improving the detection performance. To this end, we introduce an additional gradient regularization term to the original empirical loss during training. However, computing the Hessian matrix in the gradient calculation process of the regularization term poses a computational complexity. In order to overcome this issue, we optimize the formulation of the gradient regularization term using a first-order approximation method based on Taylor expansion and design a Perturbation Injection Module (PIM) to simplify the implementation process. Additionally, we provide a theoretical analysis from an optimization perspective and explore an interesting aspect of our method. Extensive experiments demonstrate the effectiveness of our approach in improving the generalization ability of deepfake detectors. Importantly, our method is orthogonal to recent advancements in powerful backbones and training data augmentation techniques. When combined with other effective techniques, our method achieves state-of-the-art experimental results.","1556-6021","","10.1109/TIFS.2024.3396064","National Key Research and Development Program of China(grant numbers:2021YFC3320103); National Natural Science Foundation of China (NSFC)(grant numbers:62372452,62272460); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10516609","Deepfake detection;forgery texture patterns","Deepfakes;Forgery;Faces;Detectors;Training;Feature extraction;Data models","","15","","80","IEEE","2 May 2024","2024","","IEEE","IEEE Journals"
"Preserving Visual Authenticity: Block chain-Augmented AI Frameworks for Advanced Digital Deception Recognition and Mitigation","M. Priya; J. Murugesan; P. Bhuvaneswari; M. Rubigha; S. Lalithambikai; B. Mohanraj","Department of Information Technology, Knowledge Institute of Technology, Salem, India; Department of Information Technology, Knowledge Institute of Technology, Salem, India; Department of Computer Science and Engineering, Sona College of Technology, Salem, India; Department of Information Technology, Knowledge Institute of Technology, Salem, India; Department of Information Technology, Knowledge Institute of Technology, Salem, India; Department of Information Technology, Sona College of Technology, Salem, India",2024 5th International Conference on Smart Electronics and Communication (ICOSEC),"24 Oct 2024","2024","","","707","713","The rapid advancements in deep learning have given rise to sophisticated DeepFake technologies, posing significant threats to visual integrity and authenticity in digital media. This paper presents an innovative approach to DeepFake detection and mitigation by integrating blockchain technology with artificial intelligence frameworks. The proposed Blockchain-Augmented AI (BAAI) framework utilizes the immutability and decentralized nature of block chain to enhance the security and reliability of the detection process. Our method involves the development of advanced AI models for detecting DeepFakes, which are then integrated with a blockchain-based ledger to ensure the verifiability and traceability of detection results. In this proposed work, a novel integration of blockchain technology and AI designed to enhance DeepFake detection capabilities. The framework achieves a $97 \%$ accuracy rate, ensuring reliable identification of manipulated media, while maintaining a low false positive rate of 3%. These results highlight the BAAI framework’s effectiveness in minimizing erroneous detections and its robustness in safeguarding digital visual content. In the face of increasingly sophisticated DeepFake technologies, this framework offers a crucial advancement in combating digital deception.","","979-8-3315-0440-3","10.1109/ICOSEC61587.2024.10722740","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10722740","DeepFake Detection;Visual Integrity;Blockchain-Augmented AI (BAAI);Detection Accuracy;False Positives;Detection Precision;Media Authenticity","Deep learning;Deepfakes;Visualization;Prevention and mitigation;Face recognition;Media;Robustness;Blockchains;Security;Artificial intelligence","","2","","20","IEEE","24 Oct 2024","18-20 Sept. 2024","18-20 Sept. 2024","IEEE","IEEE Conferences"
"SFSimNet: An Efficient Spatial-Frequency Multi-Scale Intra-Feature Similarity Measurement Network for Deepfake Detection","J. Fang; X. Ding; J. Feng; Y. Yu; L. He","Shenzhen Research Institute of Northwestern Polytechnical University, Shenzhen, Guangdong; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, Hubei, China; Shenzhen Research Institute of Northwestern Polytechnical University, Shenzhen, Guangdong; College of Artificial Intelligence, Nanjing University of Aeronautics and Astronautics, Nanjing, Jiangsu; School of Software, Northwestern Polytechnical University, Xi’an, Shaanxi, China",IEEE Transactions on Consumer Electronics,"","2025","PP","99","1","1","The rapid evolution of face synthesis technology, powered by AIGC (AI-generated content), has facilitated its widespread misuse, posing substantial security risks in consumer electronics applications. The core principle of deepfake technology involves manipulating or forgery of facial data using advanced AI/ML algorithms. However, such tampered or forged content inherently exhibits discrepancies from the original, creating opportunities for detection. In this paper, we exploit these discrepancies by employing intra-feature similarity measurements to distinguish between content for deepfake detection. We introduce a computationally efficient and low-complexity deepfake detection framework based on a multi-scale similarity measurement mechanism that operates in both the spatial and frequency domains. This approach effectively captures subtle traces of manipulation across diverse feature scales and domains. Comprehensive experimental results demonstrate our method’s exceptional performance, surpassing state-of-the-art deepfake detection techniques while requiring fewer parameters and lower computational costs (FLOPs), making it suitable for real-time consumer electronics applications. The code is available at.","1558-4127","","10.1109/TCE.2025.3580624","National Natural Science Foundation of China(grant numbers:62202387); the Guangdong Basic and Applied Basic Research Foundation(grant numbers:2025A1515011112); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11039045","Deepfake detection;multi-domain feature extraction;deep learning;intra-feature similarity","Deepfakes;Faces;Feature extraction;Accuracy;Frequency-domain analysis;Forgery;Computational efficiency;Computational modeling;Transformers;Training","","1","","","IEEE","17 Jun 2025","","","IEEE","IEEE Early Access Articles"
"Enhancing Deepfake Detection with Explainable AI","S. Karne; S. Kotwal; A. Tamboli; D. Ghusse; S. Barve","Dept. of Computer Engineering, MIT Academy of Engineering, Alandi, Pune; Dept. of Computer Engineering, MIT Academy of Engineering, Alandi, Pune; Dept. of Computer Engineering, MIT Academy of Engineering, Alandi, Pune; Dept. of Computer Engineering, MIT Academy of Engineering, Alandi, Pune; Dept. of Computer Engineering, MIT Academy of Engineering, Alandi, Pune","2025 Third International Conference on Networks, Multimedia and Information Technology (NMITCON)","10 Oct 2025","2025","","","1","6","The proliferation of synthetic media, popularly known as deepfakes, posed a significant threat to digital trust, media authenticity, and individual privacy. While prior deepfake detection methods relied heavily on deep neural networks for classification, they often lacked interpretability-leaving analysts with limited insight into why the model predicted an image as real or fake. This paper proposed a deepfake detection framework built on a DenseNet121 convolutional backbone, augmented with LIME and Grad-CAM for visual interpretability. The publicly available 140k Real-vs-Fake Faces dataset was employed to train the proposed model, which attained a classification accuracy of 99.69 %. Unlike traditional approaches, the proposed method combines high-performance detection with dual-model visual explanation, offering both model-agnostic and class-discriminative interpretability in a unified pipeline. This dual-level explanation enhances both the reliability of deepfake detection and user trust in AI-driven decisions. This paper outlined the methodology, presented empirical results, and positioned the approach as a step toward transparent, trustworthy deepfake detection systems.","","979-8-3315-1308-5","10.1109/NMITCON65824.2025.11187467","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11187467","Deepfake detection;convolutional neural networks;DenseNet121;explainable AI;LIME;Grad-CAM;visual explanations","Deepfakes;Visualization;Privacy;Explainable AI;Pipelines;Media;Predictive models;Reliability;Information technology;Faces","","","","16","IEEE","10 Oct 2025","1-2 Aug. 2025","1-2 Aug. 2025","IEEE","IEEE Conferences"
"GGMDDC: An Audio Deepfake Detection Multilingual Dataset","R. M. Purohit; A. J. Shah; H. A. Patil","Speech Research Lab, DA-IICT, Gandhinagar, India; Speech Research Lab, DA-IICT, Gandhinagar, India; Speech Research Lab, DA-IICT, Gandhinagar, India",2024 Asia Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC),"27 Jan 2025","2024","","","1","6","Audio Deepfake Detection (ADD) is of critical concern due to its social relevance. The development of ADD solution faces the limitation of the low diversity of language resources and is restricted to a limited number of speakers. However, there is a need for a more reliable ADD system due to advancements in deepfake audio generation by the attackers. Most of the existing datasets for ADD task are limited to a language count, so their usage remains limited to restricted number of speakers. Also, in most of the existing datasets for ADD, the number of issue of some speakers’ real and deepfake exists, and others are unavailable. In this study, we implemented a configuring version of Generative Adversarial Networks (GANs), namely, High Fidelity-GAN, to create dataset, GAN-Guideded Multilingual Deepfake Detection Corpus(GGMDDC). We achieved Mean Openion Score (MOS) of 4.52 for the proposed system, which proved to be better than MOS of the existing systems.","2640-0103","979-8-3503-6733-1","10.1109/APSIPAASC63619.2025.10848580","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10848580","HiFi-GAN;Mel Spectrogram;Multilingual Deepfakes;Audio Deepfake Detection","Deepfakes;Asia;Information processing;Generative adversarial networks;Multilingual;Reliability;Cultural differences;Faces","","","","30","IEEE","27 Jan 2025","3-6 Dec. 2024","3-6 Dec. 2024","IEEE","IEEE Conferences"
"Deepfake Video Detection Based on Spatial, Spectral, and Temporal Inconsistencies Using Multimodal Deep Learning","J. K. Lewis; I. E. Toubal; H. Chen; V. Sandesera; M. Lomnitz; Z. Hampel-Arias; C. Prasad; K. Palaniappan","Florida Southern College; University of Missouri; University of Maryland, College Park; IQT Labs; IQT Labs; IQT Labs; University of Missouri; University of Missouri",2020 IEEE Applied Imagery Pattern Recognition Workshop (AIPR),"10 May 2021","2020","","","1","9","Authentication of digital media has become an ever-pressing necessity for modern society. Since the introduction of Generative Adversarial Networks (GANs), synthetic media has become increasingly difficult to identify. Synthetic videos that contain altered faces and/or voices of a person are known as deepfakes and threaten trust and privacy in digital media. Deep-fakes can be weaponized for political advantage, slander, and to undermine the reputation of public figures. Despite imperfections of deepfakes, people struggle to distinguish between authentic and manipulated images and videos. Consequently, it is important to have automated systems that accurately and efficiently classify the validity of digital content. Many recent deepfake detection methods use single frames of video and focus on the spatial information in the image to infer the authenticity of the video. Some promising approaches exploit the temporal inconsistencies of manipulated videos; however, research primarily focuses on spatial features. We propose a hybrid deep learning approach that uses spatial, spectral, and temporal content that is coupled in a consistent way to differentiate real and fake videos. We show that the Discrete Cosine transform can improve deepfake detection by capturing spectral features of individual frames. In this work, we build a multimodal network that explores new features to detect deepfake videos, achieving 61.95% accuracy on the Facebook Deepfake Detection Challenge (DFDC) dataset.","2332-5615","978-1-7281-8243-8","10.1109/AIPR50011.2020.9425167","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9425167","deepfake detection;deep learning;multi-modal;computer vision","Visualization;Pipelines;Mouth;Nose;Predictive models;Media;Feature extraction","","40","","50","IEEE","10 May 2021","13-15 Oct. 2020","13-15 Oct. 2020","IEEE","IEEE Conferences"
"Fully Unsupervised Deepfake Video Detection Via Enhanced Contrastive Learning","T. Qiao; S. Xie; Y. Chen; F. Retraint; X. Luo","School of Cyberspace, Hangzhou Dianzi University, Hangzhou, China; School of Cyberspace, Hangzhou Dianzi University, Hangzhou, China; School of Cyberspace, Hangzhou Dianzi University, Hangzhou, China; Laboratory of Computer Science and Digital Society, University of Technology of Troyes, Troyes, France; State Key Laboratory of Mathematical Engineering and Advanced Computing, Zhengzhou Science and Technology Institute, Zhengzhou, China",IEEE Transactions on Pattern Analysis and Machine Intelligence,"5 Jun 2024","2024","46","7","4654","4668","Nowadays, Deepfake videos are widely spread over the Internet, which severely impairs the public trustworthiness and social security. Although more and more reliable detectors have recently sprung up for resisting against that new-emerging tampering technique, some challengeable issues still need to be addressed, such that most of Deepfake video detectors under the framework of the supervised mechanism require a large scale of samples with accurate labels for training. When the amount of the training samples with the true labels are not enough or the training data are maliciously poisoned by adversaries, the supervised classifier is probably not reliable for detection. To tackle that tough issue, it is proposed to design a fully unsupervised Deepfake detector. In particular, in the whole procedure of training or testing, we have no idea of any information about the true labels of samples. First, we novelly design a pseudo-label generator for labeling the training samples, where the traditional hand-crafted features are used to characterize both types of samples. Second, the training samples with the pseudo-labels are fed into the proposed enhanced contrastive learner, in which the discriminative features are further extracted and continually refined by iteration on the guidance of the contrastive loss. Last, relying on the inter-frame correlation, we complete the final binary classification between real and fake videos. A large scale of experimental results empirically verify the effectiveness of our proposed unsupervised Deepfake detector on the benchmark datasets including FF++, Celeb-DF, DFD, DFDC, and UADFV. Furthermore, our proposed well-performed detector is superior to the current unsupervised method, and comparable to the baseline supervised methods. More importantly, when facing the problem of the labeled data poisoned by malicious adversaries or insufficient data for training, our proposed unsupervised Deepfake detector performs its powerful superiority.","1939-3539","","10.1109/TPAMI.2024.3356814","Zhejiang Provincial Natural Science Foundation of China(grant numbers:LZ23F020006,LTGG24F020008); National Natural Science Foundation of China(grant numbers:U23A20305,62172435); National Key Research and Development Program of China(grant numbers:2022YFB3102900.e); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10411047","Contrastive learning;data augmentation;Deepfake detection;pseudo-label","Deepfakes;Feature extraction;Detectors;Training;Self-supervised learning;Generators;Forgery","","19","","59","IEEE","22 Jan 2024","July 2024","","IEEE","IEEE Journals"
"A Review of Deepfake Techniques: Architecture, Detection, and Datasets","P. Edwards; J. -C. Nebel; D. Greenhill; X. Liang","School of Computer Science and Mathematics, Kingston University, London, U.K.; School of Computer Science and Mathematics, Kingston University, London, U.K.; School of Computer Science and Mathematics, Kingston University, London, U.K.; School of Computer Science and Mathematics, Kingston University, London, U.K.",IEEE Access,"28 Oct 2024","2024","12","","154718","154742","Driven by continuous advancements in artificial intelligence, especially deep learning, the level of realism associated with deepfake technology continues to improve year after year, which poses unprecedented challenges to the field of deepfake detection. The boundary between what we as humans can detect as real or fake becomes evermore blurred as new generations of algorithms such as Dall-E 3 and Stable Diffusion are released. This paper provides a comprehensive study into the landscape of deepfake detection, exploring in-depth the key challenges, recognising recent successes, and suggesting promising avenues for future research. A meta-literature review is conducted to identify the current challenges and future directions, which form the foundation of this work. They are investigated by analysing state-of-the-art research with a focus on the key components that are crucial to the design of a deepfake detector, i.e., the architecture, detection methods and datasets. A major challenge identified by this study is the lack of dataset diversity leading to unfair attribute representation. This must be addressed by improving standardisation on dataset ethics and privacy. This is one of the main reasons for the insufficient generalisation capability of current deepfake detectors as demonstrated by their unsatisfactory performance when faced with unseen data or data in the wild. This literature review provides deepfake detection researchers and practitioners with the latest information that will serve as a vital resource for their continued and important activity, now and in the future.","2169-3536","","10.1109/ACCESS.2024.3477257","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10711187","Deepfakes;deepfake detection;generative AI;deep learning;machine learning;artificial intelligence;datasets;survey","Deepfakes;Reviews;Bibliographies;Computer architecture;Scalability;Deep learning;Data models;Object recognition;Lighting;Feature extraction;Generative AI;Artificial intelligence;Machine learning","","17","","106","CCBY","9 Oct 2024","2024","","IEEE","IEEE Journals"
"A Threat of Deepfakes as a Weapon on Digital Platform and their Detection Methods","M. Khichi; R. Kumar Yadav","Department of Computer Science and Engineering, Delhi Technological University, NEW DELHI, INDIA; Department of Computer Science and Engineering, Delhi Technological University, NEW DELHI, INDIA",2021 12th International Conference on Computing Communication and Networking Technologies (ICCCNT),"3 Nov 2021","2021","","","01","08","Advances in machine learning, deep learning, and Artificial Intelligence(AI) allows people to exchange other people's faces and voices in videos to make it look like what they did or say whatever you want to say. These videos and photos are called “deepfake” and are getting more complicated every day and this has lawmakers worried. This technology uses machine learning technology to provide computers with real data about images, so that we can make forgeries. The creators of Deepfake use artificial intelligence and machine learning algorithms to mimic the work and characteristics of real humans. It differs from counterfeit traditional media because it is difficult to identify. As In the 2020 elections loomed, AI-generated deepfakes were hit the news cycle. DeepFakes threatens facial recognition and online content. This deception can be dangerous, because if used incorrectly, this technique can be abused. Fake video, voice, and audio clips can do enormous damage. This paper examines the algorithms used to generate deepfakes as well as the methods proposed to detect them. We go through the threats, research patterns, and future directions for deepfake technologies in detail. This research provides a detailed description of deep imitation technology and encourages the creation of new and more powerful methods to deal with increasingly severe deep imitation by studying the history of deep imitation.","","978-1-7281-8595-8","10.1109/ICCCNT51525.2021.9580031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9580031","Deepfake;Convolutional Neural Networks(CNNs);Deep Neural Networks(DNNs);Recurrent Neural Networks(RNNs);Generative Adversarial Networks(GANs);Deepfake Detection Challenge(DFDC)","Machine learning algorithms;Weapons;Voting;Neural networks;Media;Forgery;History","","10","","66","IEEE","3 Nov 2021","6-8 July 2021","6-8 July 2021","IEEE","IEEE Conferences"
"Deepfake Video Detection Methods using Deep Neural Networks","M. Kshirsagar; S. Suratkar; F. Kazi","CoE-CNDS, VJTI, Mumbai, India; CoE-CNDS, VJTI, Mumbai, India; CoE-CNDS, VJTI, Mumbai, India",2022 Third International Conference on Intelligent Computing Instrumentation and Control Technologies (ICICICT),"18 Oct 2022","2022","","","27","34","Nowadays, humans are dealing with incipient trouble known as deepfake videos, advanced with the usage of deep learning. Due to freely accessible deep fake technology equipment and inexpensive computational power, internet is flooded with fake media like fake images, videos, audios etc. Fake images and videos are causing threats to privacy, reputation and the very identity of common people. Researchers are taking efforts to develop tools using various Convolutional Neural Networks (CNNs) to automatically detect this fake media however the existing tools are not able to cope with the evolution of deep fakes. In this paper, 26 unique deep convolutional models are utilised for the task of deepfake video detection. The models can natively classify objects like table, face, humans, cars etc. However, the paper highlights the use of these models in detection of deepfake/manipulated images and videos by changing the top layer of the model with sigmoid layer hence, detecting artifacts in an image produced by Generative Adversarial Networks (GANs)[11]. Once the models are trained, the paper demonstrates the usefulness of model ensemble to improve the accuracy of proposed system and thereby making the system more reliable.","","978-1-6654-1005-2","10.1109/ICICICT54557.2022.9917701","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9917701","Deep learning;deepfake detection;ensemble learning;autoencoders","Deep learning;Deepfakes;Visualization;Computational modeling;Neural networks;Predictive models;Media","","4","","35","IEEE","18 Oct 2022","11-12 Aug. 2022","11-12 Aug. 2022","IEEE","IEEE Conferences"
"Deepfake Detection and Mitigation Using Advanced CNN: Ensuring Digital Content Integrity","P. Sharma; S. Gupta; M. Sharma; N. Gupta","Dept. of CSE, Model Institute of Engineering & Technology, Jammu, India; Dept. of CSE, Model Institute of Engineering & Technology, Jammu, India; Valley Health System, Winchester, Virginia; School of Computer Science and Engineering, Geeta University",2025 3rd International Conference on Advancement in Computation & Computer Technologies (InCACCT),"28 May 2025","2025","","","661","665","Deepfake technology, with its hyper-realistic fake content and backed by AI technologies, presents a serious threat to the authenticity and security of digital content. The study deployed three different machine learning-based models: Support Vector Machine (SVM), Convolutional Neural Network (CNN), and Vision Transformers (ViT) for discrimination of real and fake faces. The model leverages the capabilities of CNN for automatic spatial feature learning from raw data, giving it exceptional performance in the discrimination between real and fake content. Performance measures were made in terms of accuracy, precision, recall, and F1 score and compared against traditional methods; the model remains a trustworthy contribution towards deepfake detection. Findings indicate that the CNN exceeded others with the highest precisions of up to 92.21%, recall of 90%, F1 score of 93%, and perfect accuracy of 97.25%. The paper further discusses the future developments, for instance, architectural improvements and real-time applications and expanding detection capacity outside visual data for a more formidable approach towards new deepfake formats, such as audio and text. This endeavor lays the groundwork for viable and scalable roads against the rising onslaught on digital media manipulation, ensuring content integrity in an AI-driven world.","","979-8-3315-4389-1","10.1109/InCACCT65424.2025.11011286","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11011286","Deepfake detection;digital media;ML;CNN;image and video analysis;AI","Support vector machines;Representation learning;Deepfakes;Visualization;Accuracy;Roads;Transformers;Convolutional neural networks;Security;Artificial intelligence","","1","","24","IEEE","28 May 2025","17-18 April 2025","17-18 April 2025","IEEE","IEEE Conferences"
"DST-FRD: A Distillation Method of Swin Transformer for Facial Reenactment Detection","H. Wu; Y. Chen; X. Wang; L. Wang; J. Xiang; L. Ren","Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Beijing Digital Education Center, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China",2024 27th International Conference on Computer Supported Cooperative Work in Design (CSCWD),"10 Jul 2024","2024","","","2010","2015","In recent times, transformer-based deepfake detection networks have exhibited remarkable performance. However, the computational complexity and the number of parameters have constrained the practical application of these networks. To address these issues, we propose a knowledge distillation method for the Swin Transformer network. Specifically, this method utilizes the region prediction results of face images to distill the knowledge of the Swin Transformer in subregions, compensating for the deficiency of the small window size of the Swin Transformer in the early stage. Extensive experiments have demonstrated that our proposed distillation method not only reduces the parameters and computational effort of the model but also surpasses the teacher network in accuracy on low-resolution images. Our student network exhibits significantly lower computational complexity and fewer parameters than the teacher network, with reductions of only 17.96% and 20.44%, respectively. Despite this reduction in complexity and parameters, our student network has achieved state-of-the-art results on the FaceForensics++ dataset, surpassing the teacher network by 0.071%, 0.86%, and 8.339% on Raw/Raw, Raw/C23, and Raw/C40, respectively.","2768-1904","979-8-3503-4918-4","10.1109/CSCWD61410.2024.10580515","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10580515","Knowledge distillation;Adversarial detection;Deepfake detection","Knowledge engineering;Deepfakes;Accuracy;Federated learning;Computational modeling;Transformers;Solids","","","","19","IEEE","10 Jul 2024","8-10 May 2024","8-10 May 2024","IEEE","IEEE Conferences"
"Deepfake detection based on Spatio-Temporal Fusion","T. Chen; J. Hu; S. Yang","College of Computer Science & Technology, Chengdu University of Information Technology, Chengdu, China; College of Computer Science & Technology, Chengdu University of Information Technology, Chengdu, China; College of Computer Science & Technology, Chengdu University of Information Technology, Chengdu, China",2025 International Conference on Information Management and Computing Technology (ICIMCT),"8 Oct 2025","2025","","","77","82","To address the limitations of existing detection algorithms that utilize temporal information but are weak in extracting local information of forged traces, this paper introduces a detection algorithm for forged faces which based on spatiotemporal feature fusion. The algorithm comprises a spatial-frequency domain hybrid feature enhancement module and a frequency-aware dynamic gating unit module. Through the frequency domain, the high-frequency components of forged traces are enhanced to capture the global spatial and local frequency-domain cues. Subsequently, the frequency-aware dynamic gating unit is employed to amplify subtle cues in the temporal dimension that are difficult to discern. These cues from both dimensions are then integrated through an information fusion module to obtain a more comprehensive feature representation. Experimental results demonstrate that the proposed algorithm exhibits superior generalization performance on datasets in the forged domain.","","979-8-3315-8501-3","10.1109/ICIMCT.2025.00024","China Meteorological Administration; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11185707","deepfake detection;Feature Enhancement;Spatiotemporal Feature Fusion","Deepfakes;Heuristic algorithms;Frequency-domain analysis;Computational modeling;Logic gates;Feature extraction;Robustness;Spatiotemporal phenomena;Information management;Detection algorithms","","","","46","IEEE","8 Oct 2025","9-11 May 2025","9-11 May 2025","IEEE","IEEE Conferences"
"CIPHER: Counterfeit Image Pattern High-level Examination via Representation for GAN and Diffusion Discriminator Learning","K. Kim; Y. Han; S. Ju; Y. Jean; Y. Kim; M. Choi; S. Lim; K. Park; S. Baek; S. Hyeon; N. -J. Kim; H. -J. Lee",OUTTA; OUTTA; OUTTA; OUTTA; OUTTA; OUTTA; OUTTA; OUTTA; OUTTA; OUTTA; Seoul National University; Seoul National University,2025 IEEE/IEIE International Conference on Consumer Electronics-Asia (ICCE-Asia),"4 Dec 2025","2025","","","1","6","The rapid progress of generative adversarial networks (GANs) and diffusion models has enabled the creation of synthetic faces that are increasingly difficult to distinguish from real images. This progress, however, has also amplified the risks of misinformation, fraud, and identity abuse, underscoring the urgent need for detectors that remain robust across diverse generative models. In this work, we introduce Counterfeit Image Pattern High-level Examination via Representation(CIPHER), a deepfake detection framework that systematically reuses and fine-tunes discriminators originally trained for image generation. By extracting scale-adaptive features from ProGAN discriminators and temporal-consistency features from diffusion models, CIPHER captures generation-agnostic artifacts that conventional detectors often overlook. Through extensive experiments across nine state-of-the-art generative models, CIPHER demonstrates superior cross-model detection performance, achieving up to 74.33% F1-score and outperforming existing ViT-based detectors by over 30% in F1-score on average. Notably, our approach maintains robust performance on challenging datasets where baseline methods fail, with up to 88% F1-score on CIFAKE compared to near-zero performance from conventional detectors. These results validate the effectiveness of discriminator reuse and cross-model fine-tuning, establishing CIPHER as a promising approach toward building more generalizable and robust deep-fake detection systems in an era of rapidly evolving generative technologies.","","979-8-3315-7402-4","10.1109/ICCE-Asia67487.2025.11263770","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11263770","Deepfake detection;GAN;Diffusion;Discriminator learning;Representation learning","Representation learning;Ciphers;Deepfakes;Social networking (online);Image synthesis;Detectors;Feature extraction;Diffusion models;Generative adversarial networks;Robustness","","","","48","IEEE","4 Dec 2025","27-29 Oct. 2025","27-29 Oct. 2025","IEEE","IEEE Conferences"
"WaViT-CDC: Wavelet Vision Transformer With Central Difference Convolutions for Spatial-Frequency Deepfake Detection","N. E. A. Badr; J. -C. Nebel; D. Greenhill; X. Liang","School of Computer Science and Mathematics, Kingston University London, London, U.K.; School of Computer Science and Mathematics, Kingston University London, London, U.K.; School of Computer Science and Mathematics, Kingston University London, London, U.K.; School of Computer Science and Mathematics, Kingston University London, London, U.K.",IEEE Open Journal of Signal Processing,"16 Jun 2025","2025","6","","621","630","The increasing popularity of generative AI has led to a significant rise in deepfake content, creating an urgent need for generalized and reliable deepfake detection methods. Since existing approaches rely on either spatial-domain features or frequency-domain features, they struggle to generalize across unseen datasets, especially those with subtle manipulations. To address these challenges, a novel end-to-end Wavelet Central Difference Convolutional Vision Transformer framework is designed to enhance spatial-frequency deepfake detection. Unlike previous methods, this approach applies the Discrete Wavelet Transform for multi-level frequency decomposition and Central Difference Convolution to capture local fine-grained discrepancies and focus on texture variances, while also incorporating Vision Transformers for global contextual understanding. The Frequency-Spatial Feature Fusion Attention module integrates these features, enabling the effective detection of fake artifacts. Moreover, in contrast to earlier work, subtle perturbations to both spatial and frequency domains are introduced to further improve generalization. Generalization cross-dataset evaluations demonstrate that WaViT-CDC outperforms state-of-the-art methods, when trained on both low-quality and high-quality face images, achieving an average performance increase of 2.5% and 4.5% on challenging high-resolution, real-world datasets such as Celeb-DF and WildDeepfake.","2644-1322","","10.1109/OJSP.2025.3571679","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11007485","Deepfake detection;central difference convolutions;vision transformer;spatial-frequency analysis;discrete wavelet transform;subtle perturbations;cross-dataset generalization","Feature extraction;Deepfakes;Frequency-domain analysis;Discrete wavelet transforms;Perturbation methods;Computer vision;Transformers;Convolution;Computational modeling;Wavelet analysis","","","","57","CCBY","20 May 2025","2025","","IEEE","IEEE Journals"
"A Robust Framework for Deepfake Detection Using Advanced Neural Architectures and Generalization Techniques","N. Chandrasekaran; Q. M. U. Haq; F. U. Islam","Dept. of Computer Science and Engineering, Yuan Ze University, Taoyuan city, Taiwan; Dept. of CSE & IBPI, Yuan Ze University, Taoyuan city, Taiwan; Dept. of Information Security, Military College of Signals, National University of Sciences and Technology, Islamabad, Pakistan",2025 International Conference on Communication Technologies (ComTech),"19 Jun 2025","2025","","","1","6","The emergence of deepfake technology has created major obstacles to the quality of digital media and presented major hazards to privacy, security, and public trust. To achieve high speed and scalability, we present a robust deepfake detection system in this paper that blends lightweight Convolutional Neural Network (CNN) architecture with effective preprocessing. Using MTCNN-based face identification, the system accurately isolates and aligns facial regions from video frames, reducing noise while improving feature extraction. To improve model generalization, preprocessing techniques include dynamic frame sampling and data augmentation techniques like color correction and geometric adjustments. The proposed CNN architecture, consisting of three convolutional blocks, dropout regularization, and fully linked layers, enables efficient feature extraction and the identification of genuine or fake facial images. For experimental evaluations, the Deepfake Detection Challenge dataset was utilized. The model achieved 93.5% accuracy and 0.38 validation loss, surpassing state-of-the-art methods like XceptionNet and MesoNet. These results show how the proposed method can detect deepfake changes in various video scenarios while preserving computational efficiency.","2996-3621","979-8-3315-1533-1","10.1109/ComTech65062.2025.11034556","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11034556","Deepfake Detection;MTCNN;CNN;DFDC dataset","Deepfakes;Privacy;Image color analysis;Scalability;Computer architecture;Media;Feature extraction;Hazards;Convolutional neural networks;Security","","","","27","IEEE","19 Jun 2025","23-24 April 2025","23-24 April 2025","IEEE","IEEE Conferences"
"AST: Generalization of Deepfake Detection with Attention Siamese Training","T. Peng; T. Wang; D. Liu; J. Wang; Y. Fu; H. Snoussi","School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; SKLSDE, Institute of Artificial Intelligence, Beihang University; Zhongguancun Laboratory, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; School of Computer Science, Wuhan University, Wuhan, China; Changchun Institute of Optics, Fine Mechanics and Physics, Chinese Academy of Sciences, Changchun, China; Laboratory of Computer Science and Digital Society, University of Technology of Troyes, Troyes, France",2023 China Automation Congress (CAC),"19 Mar 2024","2023","","","3945","3950","Recently deepfake detection research focused on distinguishing fake faces from real ones when they are evaluated on test datasets similar to the training set. However, these approaches are proved to fail once test sets are different from training sets, such as forgeries created from unseen generation methods. Due to the distributional differences brought about by various forgery methods. It is challenging for current deepfake detectors to have the ability to perform well on cross-domain forgeries. In this paper, we introduce a generalized method designed for the cross-domain deep fake detection task. Our key idea is modifying Efficient-Net with cross-attention block and Siamese training to improve the generalization of detectors in cross-domain datasets. We investigate how the triple loss function effect model's generalization ability on a theoretical level. The AST network can balance the model's generalizability across domains. The detection ability of the network is improved by an intra-class compact loss.","2688-0938","979-8-3503-0375-9","10.1109/CAC59555.2023.10451796","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10451796","Deepfake detection;Cross-domain;Siamese training","Training;Deepfakes;Detectors;Feature extraction;Data models;Forgery;Robustness","","","","23","IEEE","19 Mar 2024","17-19 Nov. 2023","17-19 Nov. 2023","IEEE","IEEE Conferences"
"Representation Alignment For Deepfake Detection","Z. Li; W. Tang; S. Gao; Y. Wang; S. Wang","School of Computer Science & Engineering, Beihang University, Beijing, China; School of Computer Science & Engineering, Beihang University, Beijing, China; School of Computer Science & Engineering, Beihang University, Beijing, China; School of Aeronautic Science & Engineering, Beihang University, Beijing, China; School of Computer Science & Engineering, Beihang University, Beijing, China",2025 11th International Conference on Computing and Artificial Intelligence (ICCAI),"11 Aug 2025","2025","","","677","686","DeepFake detection faces growing challenges with the rapid advancement of generative models, enabling the creation of increasingly sophisticated forgeries. Existing methods often rely on heuristic features from spatial or frequency domains without effectively integrating them into backbone architectures to capture general forgery representations. To address this, we propose the Representation Alignment (RA) technique to enhance backbone design by incorporating high-quality external semantic features. By aligning intermediate representations, RA enables the detector to capture robust spatial attributes and discriminative frequency features, improving its ability to generalize across diverse forgery types. The proposed RA-enhanced Xception detector demonstrates superior performance in both within-domain and cross-domain evaluations. These results validate the effectiveness of RA in enhancing generalization and robustness, offering a lightweight and efficient approach for advancing DeepFake detection.","","979-8-3315-2491-3","10.1109/ICCAI66501.2025.00109","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11105862","DeepFake Detection;Representation Alignment;Forgery generalization;Xception detector","Training;Deepfakes;Adaptation models;Frequency-domain analysis;Semantics;Detectors;Self-supervised learning;Feature extraction;Forgery;Robustness","","","","79","IEEE","11 Aug 2025","28-31 March 2025","28-31 March 2025","IEEE","IEEE Conferences"
"A Hybrid Deep Learning Framework for Deepfake Detection Using Temporal and Spatial Features","F. Zafar; T. A. Khan; S. Akbar; M. T. Ubaid; S. Javaid; K. A. Kadir","Department of Computer Sciences, School of Engineering and Applied Sciences, Bahria University, Karachi Campus, Karachi, Pakistan; Cybersecurity and Technological Convergence (CTC) Section, Malaysian Institute of Information Technology, Universiti Kuala Lumpur, Kuala Lumpur, Malaysia; Department of Computer Sciences, School of Engineering and Applied Sciences, Bahria University, Karachi Campus, Karachi, Pakistan; Department of Information Technology, University of Central Punjab, Lahore, Pakistan; Department of Computer Sciences, School of Engineering and Applied Sciences, Bahria University, Karachi Campus, Karachi, Pakistan; British Malaysian Institute, Universiti Kuala Lumpur, Kuala Lumpur, Malaysia",IEEE Access,"8 May 2025","2025","13","","79560","79570","The rise of deep-fake technology has sparked concerns as it blurs the distinction between fake media by harnessing Generative Adversarial Networks (GANs). This has raised issues surrounding privacy and security in the realm. This has led to a decrease in trust during online interactions; thus, emphasizing the importance of creating reliable methods for detection purposes. Our research introduces a model for detecting deepfakes by utilizing an Enhanced EfficientNet B0 structure in conjunction with Temporal Convolutional Neural Networks (TempCNNs). This approach aims to tackle the challenges presented by the evolving sophistication of deep-fake techniques. The system dissects video inputs into frames to extract features comprehensively by using Multi Test Convolutional Networks (MTCNN). This method ensures face detection and alignment by focusing on facial regions. To enhance the model’s adaptability, to different scenarios and datasets we implement data augmentation techniques such as CutMix, MixUp and Random Erasing. These strategies help the model maintain its strength, against distortions found in deepfake content. The backbone of EfficientNet B0 utilizes Mobile Inverted Bottleneck Convolutions (MBConv) and Squeeze and Excitation (SE) blocks to enhance feature extraction by adjusting channels to highlight details effectively. A Feature Pyramid Network (FPN) facilitates the fusion of scale features capturing intricate details as well, as broader context. When tested on the FFIW 10 K dataset, which comprises 10,000 videos evenly split between manipulated content, the model attained a training accuracy of 91.5 % and a testing accuracy of 92.45 %, after 40 epochs. The findings showcase the model’s proficiency, in identifying videos with precision and tackling the issue of class imbalances found in datasets – a valuable contribution, to advancing dependable deepfake detection solutions. Furthermore, the model achieves an impressive balance between accuracy and computational efficiency, attaining 92.45% testing accuracy with a lightweight computational cost of 0.45 GFLOPs, making it a highly practical choice for real-world deployment.","2169-3536","","10.1109/ACCESS.2025.3566008","Universiti Kuala Lumpur, Kuala Lumpur, Malaysia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10981422","Deepfake detection;face detection and alignment;EfficientNet B0;temporal convolutional networks (TCNs);multi-task convolutional neural network (MTCNN);feature pyramid network (FPN);mobile inverted bottleneck convolutions (MBConv)","Accuracy;Deepfakes;Computational modeling;Computational efficiency;Media;Feature extraction;Convolutional neural networks;Principal component analysis;Support vector machines;Generative adversarial networks","","5","","28","CCBY","30 Apr 2025","2025","","IEEE","IEEE Journals"
"Quality-based Artifact Modeling for Facial Deepfake Detection in Videos","S. Concas; S. M. La Cava; R. Casula; G. Orrù; G. Puglisi; G. L. Marcialis","University of Cagliari, Cagliari, Italy; University of Cagliari, Cagliari, Italy; University of Cagliari, Cagliari, Italy; University of Cagliari, Cagliari, Italy; University of Cagliari, Cagliari, Italy; University of Cagliari, Cagliari, Italy",2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW),"27 Sep 2024","2024","","","3845","3854","Facial deepfakes are becoming more and more realistic, to the point that it is often difficult for humans to distinguish between a fake and a real video. However, it is acknowledged that deepfakes contain artifacts at different levels; we hypothesize a connection between manipulations and visible or non-visible artifacts, especially where the subject’s movements are difficult to reproduce in detail. Accordingly, our approach relies on different quality measures, No-Reference (NR) and Full-Reference (FR), over the detected faces in the video. The measurements allow us to adopt a frame-by-frame approach to build an effective matrix-based representation of a video sequence. We show that the results obtained by this basic feature set for a neural network architecture constitute the first step that encourages the empowerment of this representation, aimed to extend our investigation to further deepfake classes. The FaceForensics++ dataset is chosen for experiments, which allows the evaluation of the proposed approach over different deepfake generation algorithms.","2160-7516","979-8-3503-6547-4","10.1109/CVPRW63382.2024.00389","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10678493","Deepfakes;deepfake detection;quality;quality measures;face patches","Deepfakes;Computer vision;Conferences;Video sequences;Neural networks;Computer architecture;Benchmark testing","","4","","38","IEEE","27 Sep 2024","17-18 June 2024","17-18 June 2024","IEEE","IEEE Conferences"
"Enhancing Deepfake Detection using SE Block Attention with CNN","S. Dasgupta; J. Mason; X. Yuan; O. Odeyomi; K. Roy","Department of Computer Science, North Carolina A&T State University, Greensboro, USA; Department of Computer Science, North Carolina A&T State University, Greensboro, USA; Department of Computer Science, North Carolina A&T State University, Greensboro, USA; Department of Computer Science, North Carolina A&T State University, Greensboro, USA; Department of Computer Science, North Carolina A&T State University, Greensboro, USA","2024 International Conference on Artificial Intelligence, Big Data, Computing and Data Communication Systems (icABCD)","29 Aug 2024","2024","","","1","6","In the digital age, Deepfake present a formidable challenge by using advanced artificial intelligence to create highly convincing manipulated content, undermining information authenticity and security. These sophisticated fabrications surpass traditional detection methods in complexity and realism. To address this issue, we aim to harness cutting-edge deep learning methodologies to engineer an innovative deepfake detection model. However, most of the models designed for deepfake detection are large, causing heavy storage and mem-ory consumption. In this research, we propose a lightweight convolution neural network (CNN) with squeeze and excitation block attention (SE) for Deepfake detection. The SE block module is designed to perform dynamic channel-wise feature recalibration. The SE block allows the network to emphasize informative features and suppress less useful ones, which leads to a more efficient and effective learning module. This module is integrated with a simple sequential model to perform Deepfake detection. The model is smaller in size and it achieves competing accuracy with the existing models for deepfake detection tasks. The model achieved an overall classification accuracy of 94.14% and AVC-ROC score of 0.985 on the Style GAN dataset from the Diverse Fake Face Dataset. Our proposed approach presents a promising avenue for combating the Deepfake challenge with minimal computational resources, developing efficient and scalable solutions for digital content verification.","","979-8-3503-8790-2","10.1109/icABCD62167.2024.10645262","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10645262","SE Block;CNN;Deepfake Detection;Entire Face Synthesis","Deep learning;Deepfakes;Accuracy;Convolution;Computational modeling;Predictive models;Artificial intelligence","","3","","21","IEEE","29 Aug 2024","1-2 Aug. 2024","1-2 Aug. 2024","IEEE","IEEE Conferences"
"ViT-Xplain: A Transparent Deepfake Detector for Consumer Electronics Based on Attention and Explainable AI","G. Husnain; A. B. M. Ali; A. Khan; A. Junaid; M. Usman; E. M. Awwad; A. A. Telba","Department of Computer Science, CECOS University of IT and Emerging Sciences, Peshawar, Pakistan; Air Conditioning Engineering Department, College of Engineering, University of Warith Al-Anbiyaa, Karbala, Iraq; Department of Computer Science, CECOS University of IT and Emerging Sciences, Peshawar, Pakistan; Department of Computer Science, CECOS University of IT and Emerging Sciences, Peshawar, Pakistan; Department of Public Health, National Health Services, Wales, UK; Department of Electrical Engineering, College of Engineering, King Saud University, P.O. Box 800, Riyadh, Saudi Arabia; Department of Electrical Engineering, College of Engineering, King Saud University, P.O. Box 800, Riyadh, Saudi Arabia",IEEE Transactions on Consumer Electronics,"","2025","PP","99","1","1","Consumer electronics platforms like social media, mobile apps and smart devices are becoming more vulnerable to deepfake videos, which can seriously harm content authenticity, user trust and legal safety. Many existing deepfake detection systems use deep neural networks that only give a final score, without explaining how the decision was made. This makes it difficult to use these systems in the real world, where people need clear reasons to trust what the model says. Problems like shortcut learning, video compression issues and background distractions also make these models less reliable. While some researchers have used convolutional and hybrid models to improve detection accuracy, they often ignore the need for explainable results. In this work, we introduce an explainable Vision Transformer (ViT) system that combines strong detection ability with clear, easy-to-understand explanations. The framework consists of five phases: dataset analysis and frame sampling, model training, evaluation and error analysis, attention roll-out and aggregation and explainability and trust scoring. Alongside predictions, the system produces attention-based visual overlays and quantitative metrics such as attention-to-face overlap, entropy concentration, clarity index and a trust score. Evaluated on the FaceForensics++ benchmark, our ViT model achieves 74.4% accuracy, 66.0% precision, 90.7% recall, 76.4% F1-score, 81.8 ROC AUC and 72.3 PR AUC. Attention maps consistently highlight facial regions with an average overlap score of 0.575 and higher alignment correlates with classifier confidence. The framework is lightweight, Python-based and deployable on standard hardware, making it practical for consumer platforms that require explainability, trust calibration and compliance-friendly audit features.","1558-4127","","10.1109/TCE.2025.3643884","King Saud University(grant numbers:ORF-2025-1108); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11300282","Deepfake Detection;Vision Transformer;Explainability;Attention-to-face Overlap;Trust Scoring","","","","","","IEEE","15 Dec 2025","","","IEEE","IEEE Early Access Articles"
"Deepfake Detection: A Systematic Literature Review","M. S. Rana; M. N. Nobi; B. Murali; A. H. Sung","Department of Computer Science, Northern Kentucky University, Highland Heights, KY, USA; Department of Computer Science, The University of Texas at San Antonio, San Antonio, TX, USA; School of Computing Sciences and Computer Engineering, The University of Southern Mississippi, Hattiesburg, MS, USA; School of Computing Sciences and Computer Engineering, The University of Southern Mississippi, Hattiesburg, MS, USA",IEEE Access,"11 Mar 2022","2022","10","","25494","25513","Over the last few decades, rapid progress in AI, machine learning, and deep learning has resulted in new techniques and various tools for manipulating multimedia. Though the technology has been mostly used in legitimate applications such as for entertainment and education, etc., malicious users have also exploited them for unlawful or nefarious purposes. For example, high-quality and realistic fake videos, images, or audios have been created to spread misinformation and propaganda, foment political discord and hate, or even harass and blackmail people. The manipulated, high-quality and realistic videos have become known recently as Deepfake. Various approaches have since been described in the literature to deal with the problems raised by Deepfake. To provide an updated overview of the research works in Deepfake detection, we conduct a systematic literature review (SLR) in this paper, summarizing 112 relevant articles from 2018 to 2020 that presented a variety of methodologies. We analyze them by grouping them into four different categories: deep learning-based techniques, classical machine learning-based methods, statistical techniques, and blockchain-based techniques. We also evaluate the performance of the detection capability of the various methods with respect to different datasets and conclude that the deep learning-based methods outperform other methods in Deepfake detection.","2169-3536","","10.1109/ACCESS.2022.3154404","Northern Kentucky University; University of Southern Mississippi; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9721302","Deepfake detection;video or image manipulation;digital media forensics;systematic literature review","Videos;Information integrity;Measurement;Faces;Deep learning;Computational modeling;Web pages","","324","","147","CCBY","24 Feb 2022","2022","","IEEE","IEEE Journals"
"An Improved Dense CNN Architecture for Deepfake Image Detection","Y. Patel; S. Tanwar; P. Bhattacharya; R. Gupta; T. Alsuwian; I. E. Davidson; T. F. Mazibuko","Department of Computer Science and Engineering, Institute of Technology, Nirma University, Ahmedabad, Gujarat, India; Department of Computer Science and Engineering, Institute of Technology, Nirma University, Ahmedabad, Gujarat, India; Department of Computer Science and Engineering, Amity School of Engineering and Technology, Amity University, Kolkata, India; Department of Computer Science and Engineering, Institute of Technology, Nirma University, Ahmedabad, Gujarat, India; Electrical Engineering Department, College of Engineering, Najran University, Najran, Saudi Arabia; Department of Electrical, Electronic and Computer Engineering, Cape Peninsula University of Technology, Bellville, South Africa; Department of Electrical Power Engineering, Durban University of Technology, Durban, South Africa",IEEE Access,"9 Mar 2023","2023","11","","22081","22095","Recent advancements in computer vision processing need potent tools to create realistic deepfakes. A generative adversarial network (GAN) can fake the captured media streams, such as images, audio, and video, and make them visually fit other environments. So, the dissemination of fake media streams creates havoc in social communities and can destroy the reputation of a person or a community. Moreover, it manipulates public sentiments and opinions toward the person or community. Recent studies have suggested using the convolutional neural network (CNN) as an effective tool to detect deepfakes in the network. But, most techniques cannot capture the inter-frame dissimilarities of the collected media streams. Motivated by this, this paper presents a novel and improved deep-CNN (D-CNN) architecture for deepfake detection with reasonable accuracy and high generalizability. Images from multiple sources are captured to train the model, improving overall generalizability capabilities. The images are re-scaled and fed to the D-CNN model. A binary-cross entropy and Adam optimizer are utilized to improve the learning rate of the D-CNN model. We have considered seven different datasets from the reconstruction challenge with 5000 deepfake images and 10000 real images. The proposed model yields an accuracy of 98.33% in AttGAN, [Facial Attribute Editing by Only Changing What You Want (AttGAN)] 99.33% in GDWCT,[Group-wise deep whitening-and-coloring transformation (GDWCT)] 95.33% in StyleGAN, 94.67% in StyleGAN2, and 99.17% in StarGAN [A GAN capable of learning mappings among multiple domains (StarGAN)] real and deepfake images, that indicates its viability in experimental setups.","2169-3536","","10.1109/ACCESS.2023.3251417","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10057390","Deepfake detection;CNN;convolutional neural network;GAN","Feature extraction;Deepfakes;Streaming media;Generative adversarial networks;Face recognition;Convolutional neural networks;Robustness","","93","","35","CCBYNCND","2 Mar 2023","2023","","IEEE","IEEE Journals"
"Domain Generalization via Aggregation and Separation for Audio Deepfake Detection","Y. Xie; H. Cheng; Y. Wang; L. Ye","State Key Laboratory of Media Convergence and Communication and the School of Information and Communication Engineering, Communication University of China, Beijing, China; State Key Laboratory of Media Convergence and Communication, Communication University of China, Beijing, China; State Key Laboratory of Media Convergence and Communication, Communication University of China, Beijing, China; State Key Laboratory of Media Convergence and Communication, Communication University of China, Beijing, China",IEEE Transactions on Information Forensics and Security,"21 Nov 2023","2024","19","","344","358","In this paper, we propose an Aggregation and Separation Domain Generalization (ASDG) method for Audio DeepFake Detection (ADD). Fake speech generated from different methods exhibits varied amplitude and frequency distributions rather than genuine speech. In addition, the spoofing attacks in training sets may not keep pace with the evolving diversity of real-world deepfake distributions. In light of this, we attempt to learn an ideal feature space that can aggregate real speech and separate fake speech to achieve better generalizability in the detection of unseen target domains. Specifically, we first propose a feature generator based on Lightweight Convolutional Neural Networks (LCNN), which is employed for generating a feature space and categorizing the feature into real and fake. Meanwhile, single-side domain adversarial learning is leveraged to make only the real speech from different domains indistinguishable, which enables the distribution of real speech to be aggregated in the feature space. Furthermore, a triplet loss is adopted to separate the distribution of fake speech while aggregating the distribution of real speech. Finally, in order to test the generalizability of the model, we train it with three different English datasets and evaluate in harsh conditions: cross-language and noisy datasets. The extensive experiments show that ASDG outperforms the baseline models in cross-domain tasks and decreases Equal Error Rate (EER) by up to 39.24% when compared to that of RawNet2. It is proved that the proposed Aggregation and Separation Domain Generalization method can be an effective strategy to improve the model generalizability.","1556-6021","","10.1109/TIFS.2023.3324724","Natural Science Foundation of China(grant numbers:62201524,62271455,61971383); Fundamental Research Funds for the Central Universities(grant numbers:CUC23GZ016); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10286049","Audio deepfake detection;domain generalization;feature generator;triplet loss","Deepfakes;Task analysis;Training;Faces;Speech enhancement;Vocoders;Feature extraction","","36","","96","IEEE","16 Oct 2023","2024","","IEEE","IEEE Journals"
"Augmented Multi-Scale Spatiotemporal Inconsistency Magnifier for Generalized DeepFake Detection","Y. Yu; X. Zhao; R. Ni; S. Yang; Y. Zhao; A. C. Kot","Institute of Information Science, Beijing Jiaotong University, Beijing, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China; Rapid-Rich Object Search Lab, Interdisciplinary Graduate Programme, Nanyang Technological University, Singapore; Institute of Information Science, Beijing Jiaotong University, Beijing, China; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore",IEEE Transactions on Multimedia,"12 Dec 2023","2023","25","","8487","8498","Recently, realistic DeepFake videos have raised severe security concerns in society. Existing video-based detection methods observe local spatial regions with the coarse temporal view, thus it is difficult to obtain subtle spatiotemporal information, resulting in limited generalization ability. In this paper, we propose a novel Augmented Multi-scale Spatiotemporal Inconsistency Magnifier (AMSIM) with a Global Inconsistency View (GIV) and a more meticulous Multi-timescale Local Inconsistency View (MLIV), focusing on mining comprehensive and more subtle spatiotemporal cues. Firstly, the GIV that includs the global spatial and long-term temporal views is established to ensure comprehensive spatiotemporal clues are captured. Then, the MLIV with the critical local spatial and multi-timescale local temporal views is designed for magnifying the indetectable spatiotemporal abnormality. Subsequently, GIV is utilized to guide MLIV to dynamically find local spatiotemporal anomalies that are highly relevant to the overall video. Finally, to further obtain a generalized framework, the adversarial data augmentation is specially designed to expand source domains and simulate unseen forgery domains. Extensive experiments on six large-scale datasets show that our AMSIM outperforms state-of-the-art detection methods and remains effective when applied to unseen forgery techniques and datasets.","1941-0077","","10.1109/TMM.2023.3237322","National Key R&D Program of China(grant numbers:2021ZD0112100); National Natural Science Foundation of China(grant numbers:U1936212,62120106009); Beijing Natural Science Foundation(grant numbers:4222014); Rapid-Rich Object Search Laboratory; Nanyang Technological University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10018271","Adversarial data augmentation;generalized DeepFake detection;global guidance;multi-scale spatiotemporal inconsistency","Deepfakes;Spatiotemporal phenomena;Faces;Forgery;Heating systems;Detectors;Convolution","","31","","66","IEEE","18 Jan 2023","2023","","IEEE","IEEE Journals"
"PVASS-MDD: Predictive Visual-Audio Alignment Self-Supervision for Multimodal Deepfake Detection","Y. Yu; X. Liu; R. Ni; S. Yang; Y. Zhao; A. C. Kot","Institute of Information Science, Beijing Jiaotong University, Beijing, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China; Rapid-Rich Object Search Laboratory, Interdisciplinary Graduate Program, Nanyang Technological University, Jurong West, Singapore; Institute of Information Science, Beijing Jiaotong University, Beijing, China; School of Electrical and Electronic Engineering, Nanyang Technological University, Jurong West, Singapore",IEEE Transactions on Circuits and Systems for Video Technology,"12 Aug 2024","2024","34","8","6926","6936","Deepfake techniques can forge the visual or audio signals in the video, which leads to inconsistencies between visual and audio (VA) signals. Therefore, multimodal detection methods expose deepfake videos by extracting VA inconsistencies. Recently, deepfake technology has started VA collaborative forgery to obtain more realistic deepfake videos, which poses new challenges for extracting VA inconsistencies. Recent multimodal detection methods propose to first extract natural VA correspondences in real videos in a self-supervised manner, and then use the learned real correspondences as targets to guide the extraction of VA inconsistencies in the subsequent deepfake detection stage. However, the inherent VA relations are difficult to extract due to the modality gap, which leads to the limited auxiliary performance of the aforementioned self-supervised methods. In this paper, we propose Predictive Visual-audio Alignment Self-supervision for Multimodal Deepfake Detection (PVASS-MDD), which consists of PVASS auxiliary and MDD stages. In the PVASS auxiliary stage in real videos, we first devise a three-stream network to associate two augmented visual views with corresponding audio clues, leading to explore common VA correspondences based on cross-view learning. Secondly, we introduce a novel cross-modal predictive align module for eliminating VA gaps to provide inherent VA correspondences. In the MDD stage, we propose to the auxiliary loss to utilize the frozen PVASS network to align VA features of real videos, to better assist multimodal deepfake detector for capturing subtle VA inconsistencies. We conduct extensive experiments on existing widely used and latest multimodal deepfake datasets. Our method obtains a significant performance improvement compared to state-of-the-art methods.","1558-2205","","10.1109/TCSVT.2023.3309899","National Key Research and Development Program of China(grant numbers:2021ZD0112100); National NSF of China(grant numbers:62336001,U1936212,62120106009); Beijing NSF(grant numbers:4222014); Rapid-Rich Object Search (ROSE) Laboratory, Nanyang Technological University, Singapore; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10233898","Multimodal deepfake detection;visual-audio alignment;self-supervised auxiliary","Deepfakes;Visualization;Feature extraction;Forgery;Face recognition;Collaboration;Detection algorithms;Audio-visual systems;Self-supervised learning","","20","","70","IEEE","29 Aug 2023","Aug. 2024","","IEEE","IEEE Journals"
"Customized Transformer Adapter With Frequency Masking for Deepfake Detection","Z. Shi; H. Chen; Y. Jia; D. Zhang; W. Lu; X. Yang","College of Computer Science and Technology, Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, China; College of Computer Science and Technology, Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, China; College of Software, Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, China; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong, China; School of Computer Science and Engineering, Ministry of Education Key Laboratory of Information Technology, Guangdong Province Key Laboratory of Information Security Technology, Sun Yat-sen University, Guangzhou, China; School of Information Science and Technology, University of Science and Technology of China, Hefei, China",IEEE Transactions on Information Forensics and Security,"18 Jun 2025","2025","20","","5904","5918","The rapid advancement of AI-generated content has intensified concerns over deepfakes due to increasingly sophisticated and visually convincing forgeries. To this end, the pre-trained Vision Transformer (ViT) model has become a de facto choice for deepfake detection, thanks to its powerful learning capability. Despite favorable results achieved by existing ViT-based methods, they have inherent limitations that could result in suboptimal performance in scenarios with continuously evolving forgery techniques, such as overfitting to single forgery patterns or placing excessive emphasis on dominant forgery regions. In this paper, we propose CUTA, a simple yet effective deepfake detection paradigm that utilizes ViT adapters as the medium and fully exploits the spatial- and frequency-domain features of given images to overcome the limitations of existing methods. Specifically, CUTA focuses on frequency domain masking within the input space, which obscures parts of the high-frequency image to intensify the training challenge while preserving subtle forgery cues in the frequency domain to facilitate comprehensive forgery representations. Furthermore, we propose two task-customized modules within the ViT model, i.e., the texture enhancement module and the multi-scale perceptron module, to seamlessly integrate local texture and rich contextual features. These two modules ensure an organic interaction between the task-specific forgery patterns and general semantic features within the pre-trained ViT framework. The experimental results on several publicly available benchmarks demonstrate CUTA’s superiority in performance, particularly showcasing its significant advantages in both cross-dataset and cross-manipulation scenarios. Code and models are available at https://github.com/Zenanshi92/CUTA","1556-6021","","10.1109/TIFS.2025.3574983","National Natural Science Foundation of China(grant numbers:62276112,62441237); Key Projects of Science and Technology Development Plan of Jilin Province(grant numbers:20230201088GX); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11018133","Deepfake detection;vision transformer;ViT adapter;frequency domain masking","Forgery;Deepfakes;Semantics;Faces;Frequency-domain analysis;Feature extraction;Training;Transformers;Adaptation models;Visualization","","2","","93","IEEE","29 May 2025","2025","","IEEE","IEEE Journals"
"MEViT: Generalization of Deepfake Detection With Meta-Learning EfficientNet Vision Transformer","V. -N. Tran; H. -S. Le; P. Choi; S. -H. Lee; K. -R. Kwon","Department of Artificial Intelligence Convergence, Pukyong National University, Busan, South Korea; Falcuty of Information Systems, University of Economics and Law, Ho Chi Minh City, Vietnam; Department of Artificial Intelligence Convergence, Pukyong National University, Busan, South Korea; Division of Computer and AI Engineering, Dong-A University, Busan, South Korea; Department of Artificial Intelligence Convergence, Pukyong National University, Busan, South Korea",IEEE Open Journal of the Computer Society,"4 Jun 2025","2025","6","","789","800","Deepfakes are digitally manipulated videos that appear realistic but are actually fake. With the rapid advances in deep generative models, the accessibility and sophistication of such manipulation technologies are increasing, making it more challenging to detect fake content. Different facial forgery techniques result in complex data distributions, and most existing deepfake detection approaches rely on convolutional neural networks (CNNs) that treat the task as a binary classification problem. While these methods achieve high accuracy on specific datasets, their generalization performance across datasets is often poor due to overfitting to manipulation techniques seen during training. In this study, we propose a model called MEViT, which integrates the EfficientNet Vision Transformer with a meta-learning framework to enhance generalization in deepfake detection. Furthermore, we introduce a pair-discrimination loss to push the feature representations of fake samples away from those of real samples, and a domain adjustment loss to reduce domain shifts across different manipulation methods. The MEViT model is trained on a specific manipulation method in the FaceForensics++ dataset and evaluated on other unseen methods from the same dataset. Additionally, we conduct extensive experiments on multiple deepfake benchmarks, including FaceForensics++ and CelebDF-v2, and compare our method with various state-of-the-art approaches to demonstrate its effectiveness.","2644-1268","","10.1109/OJCS.2025.3568044","Ministry of Science and ICT; Information Technology Research Center(grant numbers:IITP-2024-2020-0-01797); Institute for Information; 2024 BK21 FOUR Program of Pukyong National University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10992261","Deep learning;deepfake detection;GAN;generalization;meta-learning;video forensics","Deepfakes;Metalearning;Training;Forgery;Face recognition;Adaptation models;Transformers;Computer vision;Proposals;Generative adversarial networks","","1","","53","CCBY","7 May 2025","2025","","IEEE","IEEE Journals"
"Continual Deepfake Detection based on Multi-Perspective Sample Selection Mechanism","Y. Lian; X. Zhu; D. He; B. Sun; R. Zhang","School of Electrical and Information Engineering, Tianjin University, Tianjin, China; School of Electrical and Information Engineering, Tianjin University, Tianjin, China; School of Electrical and Information Engineering, Tianjin University, Tianjin, China; School of Electrical and Information Engineering, Tianjin University, Tianjin, China; School of Electrical and Information Engineering, Tianjin University, Tianjin, China",IEEE Signal Processing Letters,"","2025","PP","99","1","5","The rapid development and malicious use of deepfakes pose a significant crisis of trust. To cope with the evolving deepfake technologies, an increasing number of detection methods adopt the continual learning paradigm, but they often suffer from catastrophic forgetting. Although replay-based methods mitigate this issue by storing a portion of samples from historical tasks, their sample selection strategies usually rely on a single metric, which may lead to the omission of critical samples and consequently hinder the construction of a robust instance memory bank. In this paper, we propose a novel Multi-perspective Sample Selection Mechanism (MSSM) for continual deepfake detection, which jointly evaluates prediction error, temporal instability, and sample diversity to preserve informative and challenging samples in the instance memory bank. Furthermore, we design a Hierarchical Prototype Generation Mechanism (HPGM) that constructs prototypes at both the category and task levels, which are stored in the prototype memory bank. Extensive experiments under two evaluation protocols demonstrate that the proposed method achieves state-of-the-art performance.","1558-2361","","10.1109/LSP.2025.3638634","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11271144","Continual DeepFake Detection;Catastrophic Forgetting;Multi-perspective Sample Selection Mechanism","Prototypes;Deepfakes;Forgery;Training;Mutual information;Continuing education;Measurement;Protocols;Faces;Spatiotemporal phenomena","","","","","IEEE","28 Nov 2025","","","IEEE","IEEE Early Access Articles"
"EVDO: An Enhanced Framework for Deepfake Detection in Videos Through Optical Flow and Temporal-Spatial Analysis","M. M. Melouk; M. Shao; A. Basit; C. Abouzahir; R. Zhou; M. Shafique","eBRAIN Laboratory, Division of Engineering, New York University (NYU) Abu Dhabi, Abu Dhabi, United Arab Emirates; eBRAIN Laboratory, Division of Engineering, New York University (NYU) Abu Dhabi, Abu Dhabi, United Arab Emirates; eBRAIN Laboratory, Division of Engineering, New York University (NYU) Abu Dhabi, Abu Dhabi, United Arab Emirates; eBRAIN Laboratory, Division of Engineering, New York University (NYU) Abu Dhabi, Abu Dhabi, United Arab Emirates; eBRAIN Laboratory, Division of Engineering, New York University (NYU) Abu Dhabi, Abu Dhabi, United Arab Emirates; eBRAIN Laboratory, Division of Engineering, New York University (NYU) Abu Dhabi, Abu Dhabi, United Arab Emirates",IEEE Access,"2 Oct 2025","2025","13","","169367","169380","As generative AI advances, the realism of synthetic media has sparked serious concerns in security, privacy, and misinformation. This issue is particularly concerning with the rise of deepfake technologies that manipulate facial imagery, undermining media authenticity. While existing research has largely focused on image-based deepfake detection with specialized feature extractors, detecting deepfakes in video, especially with broad generalization across varied manipulation techniques, remains a substantial challenge. This paper introduces EVDO, a novel framework designed to detect deepfake videos by integrating temporal and spatial analysis for enhanced detection accuracy. Our approach leverages optical flow techniques to capture subtle temporal manipulation artifacts between video frames overlooked in spatial analysis. Using a FlowFormer++ model for temporal analysis, frame pairs are sampled to produce cost volumes that highlight essential motion regions and capture manipulation-specific artifacts through optical flow images which encode temporal dependencies. A flow-finetuned detector then extracts flow-level features indicative of deepfake manipulation. Complementing this, Xception-based spatial detectors analyze each frame individually, generating high-dimensional embeddings that capture frame-specific anomalies. Fusing these temporal and spatial embeddings enables comprehensive binary classification of deepfakes. Validated on the FaceForensics++ benchmark, EVDO significantly improves generalization. Our proposed temporal path contributes correct classifications to around 12% of datapoints. EVDO achieves a video AUC of 99.13% (99.43% of end-to-end SOTA methods) while enabling forensically verifiable manipulation detection.","2169-3536","","10.1109/ACCESS.2025.3614455","NYU Abu Dhabi (NYUAD) Center for CyberSecurity (CCS); Tamkeen through the NYUAD Research Institute under Award G1104; NYUAD High Performance Computing (HPC) Center for providing Necessary Compute Resources for the Experiments; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11179989","Deepfake detection;temporal-spatial analysis;optical flow;deep-learning","Deepfakes;Optical flow;Feature extraction;Detectors;Media;Faces;Analytical models;Motion artifacts;Privacy;Costs","","","","73","CCBY","25 Sep 2025","2025","","IEEE","IEEE Journals"
"Advancing Generalization in Deepfake Detection: Supervised Contrastive Representation Learning With Dual Stream Spatio-Temporal Features","S. Son; W. Kim","Department of Industrial Engineering, Yonsei University, Seodaemun-gu, Seoul, South Korea; Department of Industrial Engineering, Yonsei University, Seodaemun-gu, Seoul, South Korea",IEEE Access,"28 Aug 2025","2025","13","","148646","148667","Deepfake technologies have rapidly evolved, enabling highly realistic facial manipulations that are increasingly difficult to detect. However, existing detection models remain limited in their ability to generalize beyond the manipulation techniques used during training. As deepfake generation methods continue to diversify, enhancing generalization has become critical for deployment in real-world scenarios. To address this challenge, this paper proposes a robust and generalizable deepfake detection framework based on supervised contrastive learning. Rather than overfitting to generation-specific artifacts, the proposed method learns discriminative representations by integrating domain- and similarity-aware contrastive loss with distributional regularization. The framework adopts a dual-stream architecture consisting of a 3D CNN (I3D with Non-Local Blocks) to capture temporal dynamics and a 2D CNN (ResNet) for spatial features. The extracted features are fused and passed to a support vector machine (SVM) classifier to refine decision boundaries. Extensive experiments on FaceForensics++, Celeb-DF, and DFDC datasets demonstrate that the proposed model achieves superior generalization performance across diverse and unseen deepfake generation techniques, outperforming existing methods in cross-dataset settings. Additionally, explainability analyses validate the model’s focus on meaningful facial regions. Appendix experiments also highlight its potential for efficient deployment with minimal performance loss.","2169-3536","","10.1109/ACCESS.2025.3598782","Industrial Strategic Technology Development Program-Advanced Technology Center Plus (ATC+) (Development of Life Cycle Management Platform by Providing Artificial Intelligence-Based Real-Time Model Observability and Explainability) funded by the Ministry of Trade, Industry and Energy (MOTIE), South Korea(grant numbers:20023280); financially supported by the Korea Ministry of Land, Infrastructure and Transport (MOLIT) as the Innovative Talent Education Program for Smart City; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11124838","Attention mechanisms;contrastive learning;cross-dataset evaluation;deepfake;deepfake detection;explainable artificial intelligence;feature extraction;generalization","Deepfakes;Faces;Feature extraction;Training;Anomaly detection;Accuracy;Computational modeling;Visualization;Unsupervised learning;Image reconstruction","","","","53","CCBY","14 Aug 2025","2025","","IEEE","IEEE Journals"
"FLODA: Harnessing Vision-Language Models for Deepfake Assessment","S. Park; Y. Bae; G. Han; A. W. Olson","School of Integrated Technology, Yonsei University, Incheon, Republic of Korea; dept. Data Science, Hanyang University, Seoul, Republic of Korea; dept. Mechanical Engineering, Yonsei University, Seoul, Republic of Korea; Centre for Analytics and Artificial Intelligence Engineering, University of Toronto, Toronto, Canada",2025 IEEE International Conference on Consumer Electronics (ICCE),"26 Mar 2025","2025","","","1","8","The proliferation of advanced generative AI models has ushered in a new era of image creation, where the distinction between real and synthetic content has become increasingly blurred. This phenomenon poses significant challenges to the integrity and trustworthiness of digital content and AI systems. Recently, Vision-Language Models (VLMs) have shown great potential in addressing these challenges due to their superior performance in vision-language tasks. In this paper, we propose FLODA (FLorence-2 Optimized for Deepfake Assessment), an advanced method designed to surpass existing deepfake detection models. FLODA leverages the VLM model, Florence-2, and extends it by integrating image captioning and authenticity assessment into a single end-to-end architecture. By utilizing caption information, FLODA enhances visual analysis with contextual details, streamlining both caption generation and deepfake detection. To ensure FLODA's efficacy, we performed an ablation study to identify the optimal model configuration and demonstrated its contributions to performance improvements. We also compared our best FLODA model against existing benchmarks through rigorous evaluation. Notably, FLODA demonstrates strong generalization, showcasing its robustness across diverse scenarios with an average accuracy of 97.14%. This research advances digital content integrity and AI trustworthiness, providing a promising direction for future VLM applications. Code and models can be found at https://github.com/byh711/FLODA.","2158-4001","979-8-3315-2116-5","10.1109/ICCE63647.2025.10929816","National Research Foundation of Korea (NRF); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10929816","Deepfake Detection;AI-generated Images Detection;AI Integrity;Vision-Language Models (VLMs)","Training;Deepfakes;Visualization;Accuracy;Generative AI;Streaming media;Robustness;Faces;Resilience;Context modeling","","","","67","IEEE","26 Mar 2025","11-14 Jan. 2025","11-14 Jan. 2025","IEEE","IEEE Conferences"
"SAGNet: Decoupling Semantic-Agnostic Artifacts From Limited Training Data for Robust Generalization in Deepfake Detection","R. Tao; C. Tan; H. Liu; J. Wang; H. Qin; Y. Chang; W. Wang; R. Ni; Y. Zhao","Institute of Information Science, Beijing Jiaotong University, Beijing, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China; Zhongguancun Laboratory, Beijing, China; Center for Project-Based Learning (PBL), ETH Zürich, Zürich, Switzerland; Institute of Information Science, Beijing Jiaotong University, Beijing, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China",IEEE Transactions on Information Forensics and Security,"27 Jun 2025","2025","20","","6429","6442","Deepfake detection presents a significant challenge, particularly when the available training data is constrained to a limited set of semantic categories—a common and realistic scenario. In deepfake detection, the training labels typically indicate whether an image is real or fake, without specifying the semantic content, such as object classes. Moreover, we cannot know in advance the object categories present in an image to be detected. Ideally, a deepfake detection model should perform consistently across different semantic categories during inference, irrespective of the content. However, existing methods often exhibit significant performance bias between seen and unseen classes, struggling to generalize effectively. To address this issue, we propose Semantic-AGnostic artifact Network (SAGNet), an innovative and efficient approach designed to decouple semantic-agnostic artifacts from content-specific distributions in the training data. Our method eliminates semantic-specific biases, ensuring that the model focuses on universal artifacts related to image authenticity rather than content-dependent features. By employing this decoupling strategy, SAGNet greatly enhances the model’s generalization capacity, even when trained on limited data. Remarkably, through experiments, we demonstrate that SAGNet achieves performance comparable to models trained with 10 times more data, despite being trained on only 2 classes (comparing SAGNet trained on 2 classes with Ojha et al. (2023) trained on 20 categories). Furthermore, through extensive experiments, we show that SAGNet’s improvements are not only evident across different semantic categories but also extend to various generative methods, including multiple GAN-based and diffusion-based models. This cross-method generalization emphasizes SAGNet’s versatility and effectiveness in diverse generative scenarios. Overall, our method represents a significant advancement in deepfake detection, particularly in realistic situations where the training data is limited. The code is released at https://github.com/rstao-bjtu/SAGNet/","1556-6021","","10.1109/TIFS.2025.3581726","NSFC(grant numbers:U24B20179); Beijing NSF(grant numbers:L242021); Talent Fund of BJTU(grant numbers:2024XKRC047); Open Project of Anhui Provincial Key Laboratory of Multimodal Cognitive Computation, Anhui University(grant numbers:MMC202406); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11045799","Deep learning;computer vision;deepfake detection;robust generalization;AI generation","Deepfakes;Semantics;Training;Training data;Detectors;Adaptation models;Data models;Robustness;Image reconstruction;Faces","","","","93","IEEE","20 Jun 2025","2025","","IEEE","IEEE Journals"
"DeepFake Detection with Multi-View Fusion and Graph Convolutional Network","X. Xu; J. Chen; Y. Zhang; C. Li; A. K. Singh; Z. Lyu","School of Software, Dalian University of Technology, Dalian, China; School of Software, Dalian University of Technology, Dalian, China; School of Computing and Artificial Intelligence, Jiangxi University of Finance and Economics, Nanchang, China; China Telecommunication Technology Laboratory, China Academy of Information and Communications Technology, Beijing, China; Computer Science and Engineering Department, National Institute of Technology Patna, Bihar, India; Department of Game Design, Faculty of Arts, Uppsala University, Visby, Sweden",IEEE Transactions on Multimedia,"","2025","PP","99","1","14","Nowadays, massive amounts of facial images have been tampered with and then widely spread through social networks. Many studies have developed algorithms for frame-level DeepFake detection. However, they have low robustness due to their focus on tamper-independent features during training. To this end, we propose a framework, namely MIF-Net, based on multi-information fusion for robust frame-level DeepFake detection. Specifically, key landmarks and the facial area are first detected in the original frame. Then, the graph convolutional network constructs biometric information from these landmarks. Meanwhile, the facial region is processed into multi-view inputs by noise and edge enhancement algorithms. Finally, these products are encoded as high-level features and classified as real or fake. Five benchmark datasets are utilized for testing our model through within-dataset and cross-dataset validations. Extensive experiment results demonstrate that our proposed MIF-Net is robust and has advantages over peer algorithms.","1941-0077","","10.1109/TMM.2025.3618565","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11194129","DeepFake Detection;Deep Learning;Multi-View Fusion;Graph Convolutional Network;Attention Mechanism","Deepfakes;Feature extraction;Transformers;Faces;Noise;Forgery;Attention mechanisms;Image edge detection;Biological system modeling;Adaptation models","","","","","IEEE","6 Oct 2025","","","IEEE","IEEE Early Access Articles"
"ISTVT: Interpretable Spatial-Temporal Video Transformer for Deepfake Detection","C. Zhao; C. Wang; G. Hu; H. Chen; C. Liu; J. Tang","Department of Computer Science and Technology, Tongji University, Shanghai, China; Department of Computer Science and Technology, Tongji University, Shanghai, China; Oosto, Belfast, U.K; Alibaba Group, Hangzhou, China; College of Surveying and Geo-Informatics, Tongji University, Shanghai, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China",IEEE Transactions on Information Forensics and Security,"1 Feb 2023","2023","18","","1335","1348","With the rapid development of Deepfake synthesis technology, our information security and personal privacy have been severely threatened in recent years. To achieve a robust Deepfake detection, researchers attempt to exploit the joint spatial-temporal information in the videos, like using recurrent networks and 3D convolutional networks. However, these spatial-temporal models remain room to improve. Another general challenge for spatial-temporal models is that people do not clearly understand what these spatial-temporal models really learn. To address these two challenges, in this paper, we propose an Interpretable Spatial-Temporal Video Transformer (ISTVT), which consists of a novel decomposed spatial-temporal self-attention and a self-subtract mechanism to capture spatial artifacts and temporal inconsistency for robust Deepfake detection. Thanks to this decomposition, we propose to interpret ISTVT by visualizing the discriminative regions for both spatial and temporal dimensions via the relevance (the pixel-wise importance on the input) propagation algorithm. We conduct extensive experiments on large-scale datasets, including FaceForensics++, FaceShifter, DeeperForensics, Celeb-DF, and DFDC datasets. Our strong performance of intra-dataset and cross-dataset Deepfake detection demonstrates the effectiveness and robustness of our method, and our visualization-based interpretability offers people insights into our model.","1556-6021","","10.1109/TIFS.2023.3239223","National Natural Science Fund of China(grant numbers:62076184,61976158,61976160,62076182); Shanghai Innovation Action Project of Science and Technology(grant numbers:20511100700); Shanghai Natural Science Foundation(grant numbers:22ZR1466700); Fundamental Research Funds for the Central Universities and the State Key Laboratory of Integrated Services Networks, Xidian University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10024806","Deepfake detection;video transformer;deep learning interpretability","Deepfakes;Transformers;Visualization;Task analysis;Electronic mail;Shape;Robustness","","111","","59","IEEE","23 Jan 2023","2023","","IEEE","IEEE Journals"
"Dodging DeepFake Detection via Implicit Spatial-Domain Notch Filtering","Y. Huang; F. Juefei-Xu; Q. Guo; Y. Liu; G. Pu","School of Computer Science and Engineering, Nanyang Technological University, Jurong West, Singapore; Tandon School of Engineering, New York University, New York City, NY, USA; Centre for Frontier AI Research (CFAR), Agency for Science, Technology and Research (A*STAR), Institute of High Performance Computing (IHPC), Fusionopolis, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Jurong West, Singapore; Software Engineering Institute, East China Normal University, Shanghai, China",IEEE Transactions on Circuits and Systems for Video Technology,"12 Aug 2024","2024","34","8","6949","6962","The current high-fidelity generation and high-precision detection of DeepFake images are at an arms race. We believe that producing DeepFakes that are highly realistic and “detection evasive” can serve the ultimate goal of improving future generation DeepFake detection capabilities. In this paper, we propose a simple yet powerful pipeline to reduce the artifact patterns of fake images without hurting image quality by performing implicit spatial-domain notch filtering. We first demonstrate that frequency-domain notch filtering, although famously shown to be effective in removing periodic noise in the spatial domain, is infeasible for our task at hand due to the manual designs required for the notch filters. We, therefore, resort to a learning-based approach to reproduce the notch filtering effects, but solely in the spatial domain. We adopt a combination of adding overwhelming spatial noise for breaking the periodic noise pattern and deep image filtering to reconstruct the noise-free fake images, and we name our method DeepNotch. Deep image filtering provides a specialized filter for each pixel in the noisy image, producing filtered images with high fidelity compared to their DeepFake counterparts. Moreover, we also use the semantic information of the image to generate an adversarial guidance map to add noise intelligently. Our large-scale evaluation on 3 representative DeepFake detection methods (tested on 16 types of DeepFakes) has demonstrated that our technique significantly reduces the accuracy of these 3 fake image detection methods, 36.79% on average and up to 97.02% in the best case.","1558-2205","","10.1109/TCSVT.2023.3325427","National Key Research and Development Program of China(grant numbers:2020AAA0107800); Shanghai Collaborative Innovation Center of Trusted Industry Internet Software; National Research Foundation, Singapore; Defence Science Organization (DSO) National Laboratories under the Artificial Intelligence (AI) Singapore Programme (AISG)(grant numbers:AISG2-GC-2023-008); Agency for Science, Technology and Research (A*STAR) Centre for Frontier AI Research; National Research Foundation, Singapore; Cyber Security Agency under its National Cybersecurity Research and Development Programme(grant numbers:NCRP25-P04-TAICeN); NRF Investigatorship(grant numbers:NRF-NRFI06-2020-0001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10287378","DeepFake;DeepFake evasion;DeepFake detection","Deepfakes;Filtering;Notch filters;Image synthesis;Frequency-domain analysis;Fingerprint recognition;Detection algorithms","","22","","82","IEEE","18 Oct 2023","Aug. 2024","","IEEE","IEEE Journals"
"Analyzing Fairness in Deepfake Detection With Massively Annotated Databases","Y. Xu; P. Terhörst; M. Pedersen; K. Raja","Institutt for datateknologi og informatikk, Norges teknisk-naturvitenskapelige universitet, Gjøvik, Norway; Institutt for datateknologi og informatikk, Norges teknisk-naturvitenskapelige universitet, Gjøvik, Norway; Institutt for datateknologi og informatikk, Norges teknisk-naturvitenskapelige universitet, Gjøvik, Norway; Institutt for datateknologi og informatikk, Norges teknisk-naturvitenskapelige universitet, Gjøvik, Norway",IEEE Transactions on Technology and Society,"27 May 2024","2024","5","1","93","106","In recent years, image and video manipulations with Deepfake have become a severe concern for security and society. Many detection models and datasets have been proposed to detect Deepfake data reliably. However, there is an increased concern that these models and training databases might be biased and, thus, cause Deepfake detectors to fail. In this work, we investigate factors causing biased detection in public Deepfake datasets by (a) creating large-scale demographic and non-demographic attribute annotations with 47 different attributes for five popular Deepfake datasets and (b) comprehensively analysing attributes resulting in AI-bias of three state-of-the-art Deepfake detection backbone models on these datasets. The analysis shows how various attributes influence a large variety of distinctive attributes (from over 65M labels) on the detection performance which includes demographic (age, gender, ethnicity) and non-demographic (hair, skin, accessories, etc.) attributes. The results examined datasets show limited diversity and, more importantly, show that the utilised Deepfake detection backbone models are strongly affected by investigated attributes making them not fair across attributes. The Deepfake detection backbone methods trained on such imbalanced/biased datasets result in incorrect detection results leading to generalisability, fairness, and security issues. Our findings and annotated datasets will guide future research to evaluate and mitigate bias in Deepfake detection techniques. The annotated datasets and the corresponding code are publicly available. The code link is: https://github.com/xuyingzhongguo/DeepFakeAnnotations.","2637-6415","","10.1109/TTS.2024.3365421","European Research Consortium for Informatics and Mathematics; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10438899","Deepfake;deepfake detection;databases;bias;fairness;image manipulation;video manipulation","Deepfakes;Annotations;Databases;Reliability;Feature extraction;Image quality;Image annotation;Detection algorithms;Data integrity;Information integrity;Data models","","19","","61","CCBYNCND","16 Feb 2024","March 2024","","IEEE","IEEE Journals"
"Contrastive Learning for DeepFake Classification and Localization via Multi-Label Ranking","C. -Y. Hong; Y. -C. Hsu; T. -L. Liu","Institute of Information Science, Academia Sinica, Taiwan; Institute of Information Science, Academia Sinica, Taiwan; Institute of Information Science, Academia Sinica, Taiwan",2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),"16 Sep 2024","2024","","","17627","17637","We propose a unified approach to simultaneously addressing the conventional setting of binary deepfake classification and a more challenging scenario of uncovering what facial components have been forged as well as the exact order of the manipulations. To solve the former task, we consider mul-tiple instance learning (MIL) that takes each image as a bag and its patches as instances. A positive bag corresponds to a forged image that includes at least one manipulated patch (i.e., a pixel in the feature map). The formulation allows us to estimate the probability of an input image being a fake one and establish the corresponding contrastive MIL loss. On the other hand, tackling the component-wise deepfake problem can be reduced to solving multi-label prediction, but the requirement to recover the manipulation order further complicates the learning task into a multi-label ranking prob-lem. We resolve this difficulty by designing a tailor-made loss term to enforce that the rank order of the predicted multi-label probabilities respects the ground-truth order of the sequential modifications of a deepfake image. Through extensive experiments and comparisons with other relevant techniques, we provide extensive results and ablation studies to demonstrate that the proposed method is an overall more comprehensive solution to deepfake detection.","2575-7075","979-8-3503-5300-6","10.1109/CVPR52733.2024.01669","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10657466","DeepFake Detection;Contrastive Learning;Multiple Instance Learning","Location awareness;Deepfakes;Computer vision;Image resolution;Contrastive learning;Pattern recognition","","14","","44","IEEE","16 Sep 2024","16-22 June 2024","16-22 June 2024","IEEE","IEEE Conferences"
"MIS-AVoiDD: Modality Invariant and Specific Representation for Audio-Visual Deepfake Detection","V. S. Katamneni; A. Rattani","Dept. of Computer Science and Engineering, University of North Texas, Denton, USA; Dept. of Computer Science and Engineering, University of North Texas, Denton, USA",2023 International Conference on Machine Learning and Applications (ICMLA),"19 Mar 2024","2023","","","1371","1378","Deepfakes are synthetic media generated using deep generative algorithms and have posed a severe societal and political threat. Apart from facial manipulation and synthetic voice, recently, a novel kind of deepfakes has emerged with either audio or visual modalities manipulated. In this regard, a new generation of multimodal audio-visual deepfake detectors is being investigated to collectively focus on audio and visual data for multimodal manipulation detection. Existing multimodal (audio-visual) deepfake detectors are often based on the fusion of the audio and visual streams from the video. Existing studies suggest that these multimodal detectors often obtain equivalent performances with unimodal audio and visual deepfake detectors. We conjecture that the heterogeneous nature of the audio and visual signals creates distributional modality gaps and poses a sig-nificant challenge to effective fusion and efficient performance. In this paper, we tackle the problem at the representation level to aid the fusion of audio and visual streams for multimodal deepfake detection. Specifically, we propose the joint use of modality (audio and visual) invariant and specific representations. This ensures that the common patterns and patterns specific to each modality representing pristine or fake content are preserved and fused for multimodal deepfake manipulation detection. Our experimental results on FakeAVCeleb and KoDF audio-visual deepfake datasets suggest the enhanced accuracy of our proposed method over SOTA unimodal and multimodal audio-visual deepfake detectors by 17.8% and 18.4%, respectively. Thus, obtaining state-of-the-art performance.","1946-0759","979-8-3503-4534-6","10.1109/ICMLA58977.2023.00207","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10460064","Deepfakes;Audio-visual Deepfake Detection;Modality Invariant;Modality Specific Features","Representation learning;Deepfakes;Visualization;Detectors;Streaming media;Feature extraction;Streams","","10","","43","IEEE","19 Mar 2024","15-17 Dec. 2023","15-17 Dec. 2023","IEEE","IEEE Conferences"
"Eff-YNet: A Dual Task Network for DeepFake Detection and Segmentation","E. Tjon; M. Moh; T. -S. Moh","Department of Computer Science, San José State University, San José, CA, USA; Department of Computer Science, San José State University, San José, CA, USA; Department of Computer Science, San José State University, San José, CA, USA",2021 15th International Conference on Ubiquitous Information Management and Communication (IMCOM),"17 Mar 2021","2021","","","1","8","Advances in generative models and manipulation techniques have given rise to digitally altered videos known as deepfakes. These videos are difficult to identify for both humans and machines. Modern detection methods exploit various weaknesses in deepfake videos, such as visual artifacts and inconsistent posing. In this paper, we describe a novel architecture called Eff-YNet designed to detect visual differences between altered and unaltered areas. The architecture combines an EfficientNet encoder and a U-Net with a classification branch into a model capable of both classifying and segmenting deepfake videos. The task of segmentation helps train the classifier and also produces useful segmentation masks. We also implement ResNet 3D to detect spatiotemporal inconsistencies. To test these models, we run experiments against the Deepfake Detection Challenge dataset and show improvements over baseline classification models. Furthermore, we find that an ensemble of these two approaches improves performance over a single approach alone.","","978-1-6654-2318-2","10.1109/IMCOM51814.2021.9377373","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9377373","Deepfake detection;computer vision;deep learning;image segmentation;image classification;U-Net","Visualization;Three-dimensional displays;Spatiotemporal phenomena;Information management;Task analysis;Videos;Information integrity","","9","","24","IEEE","17 Mar 2021","4-6 Jan. 2021","4-6 Jan. 2021","IEEE","IEEE Conferences"
"Bot or Human? Detection of DeepFake Text with Semantic, Emoji, Sentiment and Linguistic Features","A. T. Y. Chong; H. N. Chua; M. B. Jasser; R. T. K. Wong","Department of Computing and Information Systems, Sunway University, Sunway City, Selangor, Malaysia; Department of Computing and Information Systems, Sunway University, Sunway City, Selangor, Malaysia; Department of Computing and Information Systems, Sunway University, Sunway City, Selangor, Malaysia; Department of Computing and Information Systems, Sunway University, Sunway City, Selangor, Malaysia",2023 IEEE 13th International Conference on System Engineering and Technology (ICSET),"30 Oct 2023","2023","","","205","210","Detecting machine-generated text (MGT), also known as Deepfake text, has become increasingly important in Artificial Intelligence (AI) age and social media platforms. With the proliferation of MGT and the potential consequences of its dissemination, there is a pressing need to develop effective methods for distinguishing between MGT and human-written text (HWT). Our research aim has two-fold: firstly, to examine the inherent differences between MGT and HWT on Twitter, and secondly, to develop a classifier specifically designed for MGT detection on the platform. This classifier utilizes contextualized text embeddings as its foundation while considering additional linguistic features, sentiment features, and emoji embeddings. Our experimental results demonstrate that incorporating additional features enhances the model's ability to detect MGT. Combining fine-tuned BERT embeddings with emoji and linguistic features using a multi-layer perceptron classifier achieves the highest accuracy rate of 88.3%. Our analysis reveals distinct characteristics of MGT compared to HWT, including differences in engagement behavior, linguistic patterns, named entities, sentiment expressions, and text perplexity. Our research contributes to the field of MGT detection by offering a comprehensive approach that combines semantic text embeddings with supplementary features. The proposed model provides a significant step forward in addressing the challenge of Deepfake text detection.","2470-640X","979-8-3503-4089-1","10.1109/ICSET59111.2023.10295100","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10295100","Artificial Intelligence;Machine Learning;Data Mining;Deepfake Detection;Feature Engineering","Deepfakes;Social networking (online);Semantics;Text detection;Pressing;Linguistics;Feature extraction;Systems engineering and theory;Artificial intelligence;Emojis","","9","","35","IEEE","30 Oct 2023","2-2 Oct. 2023","2-2 Oct. 2023","IEEE","IEEE Conferences"
"Undercover Deepfakes: Detecting Fake Segments in Videos","S. Saha; R. Perera; S. Seneviratne; T. Malepathirana; S. Rasnayaka; D. Geethika; T. Sim; S. Halgamuge","National University of Singapore, Singapore; University of Melbourne, Australia; University of Melbourne, Australia; University of Melbourne, Australia; National University of Singapore, Singapore; University of Melbourne, Australia; National University of Singapore, Singapore; University of Melbourne, Australia",2023 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW),"25 Dec 2023","2023","","","415","425","The recent renaissance in generative models, driven primarily by the advent of diffusion models and iterative improvement in GAN methods, has enabled many creative applications. However, each advancement is also accompanied by a rise in the potential for misuse. In the arena of the deepfake generation, this is a key societal issue. In particular, the ability to modify segments of videos using such generative techniques creates a new paradigm of deepfakes which are mostly real videos altered slightly to distort the truth. This paradigm has been under-explored by the current deepfake detection methods in the academic literature. In this paper, we present a deepfake detection method that can address this issue by performing deepfake prediction at the frame and video levels. To facilitate testing our method, we prepared a new benchmark dataset where videos have both real and fake frame sequences with very subtle transitions. We provide a benchmark on the proposed dataset with our detection method which utilizes the Vision Transformer based on Scaling and Shifting [38] to learn spatial features, and a Timeseries Transformer to learn temporal features of the videos to help facilitate the interpretation of possible deepfakes. Extensive experiments on a variety of deepfake generation methods show excellent results by the proposed method on temporal segmentation and classical video-level predictions as well. In particular, the paradigm we address will form a powerful tool for the moderation of deepfakes, where human oversight can be better targeted to the parts of videos suspected of being deepfakes. All experiments can be reproduced at: github.com/rgb91/temporal-deepfake-segmentation.","2473-9944","979-8-3503-0744-3","10.1109/ICCVW60793.2023.00048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10350955","deepfake;detection;temporal;frame;segmentation;forgery;forensics;biometric;vision;transformer;timeseries;scaling;shifting","Deepfakes;Computer vision;Conferences;Benchmark testing;Transformers;Feature extraction;Iterative methods","","8","","74","IEEE","25 Dec 2023","2-6 Oct. 2023","2-6 Oct. 2023","IEEE","IEEE Conferences"
"A Case Study on how Beautification Filters Can Fool Deepfake Detectors","A. Libourel; S. Husseini; N. Mirabet-Herranz; J. -L. Dugelay",Department of Digital Security EURECOM; Department of Digital Security EURECOM; Department of Digital Security EURECOM; Department of Digital Security EURECOM,2024 12th International Workshop on Biometrics and Forensics (IWBF),"22 Jul 2024","2024","","","1","6","The exponential growth of shared multimedia con-tent made necessary algorithms for deepfake detection. At the same time, beautification filters have become a popular tool and new filters are released every day. Therefore, is it possible to fool state-of-the-art (SotA) detectors by simply applying a beautification filter to the manipulated video? In this paper, we study the impact of beautification filters on Celeb-DF-B, a novel database created by applying popular social media beautification filters to a subset of real and fake videos from the Celeb-DF dataset. We evaluated the effect of beautification on three SotA passive deepfake detectors and on human evaluators. The results indicate that filters significantly alter the behavior of the three detectors studied, resulting in a notable decrease in the video-level AUC on the beautified subset of Celeb-DF-B. In the context of human-level performance, the use of filters similarly influences human decision-making, affecting the accurate categorization of videos as either real or fake.","","979-8-3503-5447-8","10.1109/IWBF62628.2024.10593932","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10593932","Deepfake detection;Social media filters;Beautification;Subjective evaluation","Deepfakes;Filters;Social networking (online);Databases;Forensics;Conferences;Decision making","","5","","29","IEEE","22 Jul 2024","11-12 April 2024","11-12 April 2024","IEEE","IEEE Conferences"
"A Comparative Study on Deepfake Detection Algorithms","A. Kaushal; S. Singh; S. Negi; S. Chhaukar","Department of Computer Engineering, Delhi Technological University, Delhi, India; Department of Computer Engineering, Delhi Technological University, Delhi, India; Department of Computer Engineering, Delhi Technological University, Delhi, India; Department of Computer Engineering, Delhi Technological University, Delhi, India","2022 4th International Conference on Advances in Computing, Communication Control and Networking (ICAC3N)","28 Mar 2023","2022","","","854","860","In recent years, the number of images and videos shared online increased and people have easy ways to access such content. “DeepFake” refers to any multimedia content created using deep learning technology in order to make it appear realistic. The creation of deepfake videos and images using deep learning techniques leads to very realistic “DeepFake” videos and images by changing the digital content of images and videos. Deepfake is widely recognized as one of artificial intelligence’s most dangerous uses. Deepfake makes it possible to place a person in a totally imaginary situation since it is used to imitate an activity that the person did not perform. Deepfakes have been becoming increasingly dangerous to democracy, society’s security and people’s privacy. The distribution of such deepfake content on various platforms urged the international community to revaluate the threat to social security posed by such content. It encouraged the researchers around the world to develop effective deepfake detection methods. In this paper we have discussed such approaches of deepfake detection in videos and images that are available in recent studies and have provided comparative review of research on deepfake detection algorithms. It also compares the different detection techniques and examines their limitations and advantages.","","978-1-6654-7436-8","10.1109/ICAC3N56670.2022.10074593","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10074593","Deepfake;Deep Learning;Deepfake Detection;Detection Accuracy;Artificial Intelligence;Generative Adversarial Networks","Deep learning;Deepfakes;Privacy;Streaming media;Security;Detection algorithms","","4","","36","IEEE","28 Mar 2023","16-17 Dec. 2022","16-17 Dec. 2022","IEEE","IEEE Conferences"
"Deepfake Detection With Combined Unsupervised-Supervised Contrastive Learning","J. Zheng; Y. Zhou; X. Hu; Z. Tang","School of Computer Science and Technology, No.200 Xiao Lingwei Street, Xuanwu District, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Technology, No.200 Xiao Lingwei Street, Xuanwu District, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Technology, No.200 Xiao Lingwei Street, Xuanwu District, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Technology, No.200 Xiao Lingwei Street, Xuanwu District, Nanjing University of Science and Technology, Nanjing, China",2024 IEEE International Conference on Image Processing (ICIP),"27 Sep 2024","2024","","","787","793","The malicious dissemination of fake images has caused a societal trust crisis, deepfake detection becomes a hot topic now. Through existing detection methods achieve good results in intra-dataset, their performance are poor for unknown manipulations or datasets. To deal with this problem, this paper proposes a new deepfake detection model with combined unsupervised-supervised contrastive learning. By combining unsupervised contrastive learning and supervised contrastive learning with deepfake detection together, the model can discover the essence of fake images from both individual and class features. In addition, a multi-scale attention fusion module is proposed, which helps to enhance the model stability by fusion global and local features of the image. Finally, lots of experiments prove that our method has good performance and generalization ability in intra-dataset, cross-dataset and cross-manipulation scenarios.","2381-8549","979-8-3503-4939-9","10.1109/ICIP51287.2024.10647603","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10647603","deepfake detection;contrastive learning;supervised contrastive learning;combined unsupervised-supervised contrastive learning","Deepfakes;Fuses;Diversity reception;Contrastive learning;Feature extraction;Stability analysis;Forgery","","4","","28","IEEE","27 Sep 2024","27-30 Oct. 2024","27-30 Oct. 2024","IEEE","IEEE Conferences"
"PRaNA: PRNU-based Technique to Tell Real and Deepfake Videos Apart","I. Amerini; M. Conti; P. Giacomazzi; L. Pajola","Sapienza University of Rome, Rome, Italy; University of Padua, Padua, Italy; University of Padua, Padua, Italy; University of Padua, Padua, Italy",2022 International Joint Conference on Neural Networks (IJCNN),"30 Sep 2022","2022","","","1","7","Videos are a powerful source of communication adopted in several contexts and used for both benign and malicious purposes (e.g., education vs. reputation damage). Nowadays, realistic video manipulation strategies like deepfake generators constitute a severe threat to our society in term of misinformation. While the wide range of the current research focuses on deepfake detection as a binary task, the identification of a real video among a pool of deepfakes sharing the same origin is not widely investigated. While the pool task might be more rare in real-life compared to the binary one, outcomes that derives from these analyses might let us better understand deepfake behaviours, benefiting binary deep fake detection as well. In this paper, we address the less investigated scenario by investigating the role of Photo Response Non-Uniformity (PRNU) in deepfake detection. Our analysis, in agreement with prior studies, shows that PRNU can be a valuable source to identify deepfake videos. In particular, we found that unique PRNU characteristics exist to distinguish real videos from their deepfake versions: real video autocorrelations tend to be lower compared to their deepfakes versions. Motivated by this, we propose PRaNA, a training-free strategy that leverages PRNU autocorrelation. Our results on three well-known datasets confirm our algorithm's robustness and transferability, with accuracy up to 66% when considering one real video in a pool of four deepfakes using the real video as a source, and up to 80% when only one deepfake is considered. Our work aims to open different strategies to counter deepfake diffusion.","2161-4407","978-1-7281-8671-9","10.1109/IJCNN55064.2022.9892413","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9892413","Deepfake detection;video forensics;photo response non-uniformity","Deepfakes;Neural networks;Education;Robustness;Generators;Autocorrelation;Task analysis","","3","","43","IEEE","30 Sep 2022","18-23 July 2022","18-23 July 2022","IEEE","IEEE Conferences"
"Towards More General Video-based Deepfake Detection through Facial Component Guided Adaptation for Foundation Model","Y. -H. Han; T. -M. Huang; K. -L. Hua; J. -C. Chen",Academia Sinica; Academia Sinica; Microsoft; Academia Sinica,2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),"13 Aug 2025","2025","","","22995","23005","The current deep generative models have enabled the creation of synthetic facial images with remarkable photorealism, raising significant societal concerns over their potential misuse. Despite rapid advancements in the field of deepfake detection, developing an efficient and effective approach for the generalized deepfake detection of unseen forgery samples remains challenging. To address this challenge, we leverage the rich semantic priors of foundation models and propose a novel side-network-based decoder that extracts spatial and temporal cues using the CLIP image encoder for generalized video-based Deepfake detection. Additionally, we introduce Facial Component Guidance (FCG) to enhance spatial learning generalizability by encouraging the model to focus on key facial regions. By leveraging the generic features of a vision-language foundation model, our approach demonstrates promising generalizability on challenging Deepfake datasets while also exhibiting superiority in training data efficiency, parameter efficiency, and model robustness. The source code is available at: https://github.com/aiiu-lab/DFD-FCG","2575-7075","979-8-3315-4364-8","10.1109/CVPR52734.2025.02141","National Science and Technology Council; Academia Sinica; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11093395","deepfake detection;computer vision;foundation model;peft;clip","Training;Deepfakes;Photorealism;Foundation models;Source coding;Semantics;Training data;Feature extraction;Robustness;Skin","","2","","57","IEEE","13 Aug 2025","10-17 June 2025","10-17 June 2025","IEEE","IEEE Conferences"
"Real is not True: Backdoor Attacks Against Deepfake Detection","H. Sun; Z. Li; L. Liu; B. Li","University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China",2023 9th International Conference on Big Data and Information Analytics (BigDIA),"15 Feb 2024","2023","","","130","137","The proliferation of malicious deepfake applications has ignited substantial public apprehension, casting a shadow of doubt upon the integrity of digital media. Despite the development of proficient deepfake detection mechanisms, they persistently demonstrate pronounced vulnerability to an array of attacks. It is noteworthy that the pre-existing repertoire of attacks predominantly comprises adversarial example attack, predominantly manifesting during the testing phase. In the present study, we introduce a pioneering paradigm denominated as ""Bad-Deepfake,"" which represents a novel foray into the realm of backdoor attacks levied against deepfake detectors. Our approach hinges upon the strategic manipulation of a delimited subset of the training data, enabling us to wield disproportionate influence over the operational characteristics of a trained model. This manipulation leverages inherent frailties inherent to deepfake detectors, affording us the capacity to engineer triggers and judiciously select the most efficacious samples for the construction of the poisoned set. Through the synergistic amalgamation of these sophisticated techniques, we achieve an remarkable performance—a 100% attack success rate (ASR) against extensively employed deepfake detectors.","2771-6902","979-8-3503-3007-6","10.1109/BigDIA60676.2023.10429108","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10429108","Deepfake detection;Backdoor attacks;Deep Neural Networks","Deepfakes;Neural networks;Training data;Detectors;Media;Fasteners;Testing","","2","","35","IEEE","15 Feb 2024","15-17 Dec. 2023","15-17 Dec. 2023","IEEE","IEEE Conferences"
"Enhancing Authenticity Verification with Transfer Learning and Ensemble Techniques in Facial Feature-Based Deepfake Detection","N. Qazi; I. Ahmed","Computer and Digitial Technolgies, University of East London, London, UK; Research and Development, Tietoevry Finland Oy, Finland",2024 14th International Conference on Pattern Recognition Systems (ICPRS),"23 Sep 2024","2024","","","1","6","Deepfake technology, facilitated by deep learning algorithms, has emerged as a significant concern due to its potential to deceive humans with fabricated content indistinguishable from reality. The proliferation of deepfake videos presents a formidable challenge, propagating misinformation across various sectors such as social media, politics, and healthcare. Detecting and mitigating these threats is imperative for fortifying defenses and safeguarding information integrity.This paper tackles the complexities associated with deepfake detection, emphasizing the necessity for innovative approaches given the constraints of available data and the evolving nature of forgery techniques. Our proposed solution focuses on leveraging facial features and transfer learning to discern fake videos from genuine ones, aiming to identify subtle manipulations in visual content. We systematically break down videos into frames, employ the Haar cascade algorithm for facial recognition, and utilize transfer learning to extract discriminative features. We evaluate multiple pre-trained models, including VGG16, ConvNeXtTiny, EfficientNetB0, EfficientNetB7, DenseNet201, ResNet152V2, Xception, NASNetMobile, and MobileNetV2, for feature extraction. Subsequently, we feed these features into a Deep Artificial Neural Network (DANN) for deepfake detection and employ ensemble learning to combine the strengths of the best-performing models for enhanced accuracy.We found that the ensemble model comprising ConvNextTiny, EfficientNetB0, and EfficientNetB7 showed enhanced accuracy in detecting deep fakes compared to alternative models achieving up to 98% accuracy through ensemble learning.","","979-8-3503-7565-7","10.1109/ICPRS62101.2024.10677831","Technische Universiteit Eindhoven; European Commission; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10677831","Deepfake detection;video classification;Transfer learning;EfficentNetB0;DenseNet;Ensemble learning","Deepfakes;Visualization;Accuracy;Social networking (online);Transfer learning;Medical services;Feature extraction","","2","","20","IEEE","23 Sep 2024","15-18 July 2024","15-18 July 2024","IEEE","IEEE Conferences"
"Detecting Deepfakes in Healthcare: A Review and Proposed Solution","R. Alnuaimi; M. Alawida; M. Almarzooqi; D. T. Alhalabi; H. A. Alamaireh","Information Technology Department, College of Technological Innovation, Zayed University, Abu Dhabi, UAE; CSIT Department, College of Engineering, Abu Dhabi University, Abu Dhabi, UAE; Information Technology Department, College of Technological Innovation, Zayed University, Abu Dhabi, UAE; Information Technology Department, College of Technological Innovation, Zayed University, Abu Dhabi, UAE; Information Technology Department, College of Technological Innovation, Zayed University, Abu Dhabi, UAE",2024 International Conference on Engineering and Emerging Technologies (ICEET),"12 Mar 2025","2024","","","1","6","The widespread use of Deepfake technology presents serious challenges to the integrity and security of healthcare systems. This study provides a detailed review of Deepfake de-tection methods designed particularly for the healthcare domain. We investigate the present methodologies, privacy concerns, and data security risks associated with Deepfakes in medical contexts. Based on a thorough analysis of the current literature, we offer a new approach framework for healthcare-specific Deepfake detection that incorporates powerful machine learning algorithms and privacy-preserving strategies. We highlight research gaps, challenges, and future possibilities for research in this crucial domain, emphasizing the need for reliable, ethical, and adaptive Deepfake detection systems in healthcare.","2831-3682","979-8-3315-3289-5","10.1109/ICEET65156.2024.10913568","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10913568","Key Words;Deepfake;Deepfake Detection;Medical Deepfakes;Machine Learning Deepfake","Deepfakes;Ethics;Data privacy;Machine learning algorithms;Reviews;Law;Data security;Medical services;Machine learning;Reliability","","2","","25","IEEE","12 Mar 2025","27-28 Dec. 2024","27-28 Dec. 2024","IEEE","IEEE Conferences"
"An Effective Approach for Deepfake Video Detection using Binarized Neural Network","P. K; A. Pandey; B. Rudra","Department of Information Technology, National Institute of Technology, Surathkal, Karnataka, India; Department of Information Technology, National Institute of Technology, Surathkal, Karnataka, India; Department of Information Technology, National Institute of Technology, Surathkal, Karnataka, India",2025 IEEE International Conference on Interdisciplinary Approaches in Technology and Management for Social Innovation (IATMSI),"9 May 2025","2025","3","","1","6","The rise of DeepFake technologies, especially in audio and video, poses significant threats to information integrity, security, and privacy. Artificially driven Artificial Intelligence (AI) methods and their advancement make it difficult to trace synthetic media through deepfakes that closely approximate real speech, facial expressions, and body movements. Consequently, traditional methods of detecting these are losing the race because they cannot compete with the newly invented methods that are more advanced in comparison. This paper proposes a lightweight and scalable approach to deepfake video detection using Binarized Neural Networks (BNNs). We integrate BNNs with Convolutional Neural Networks (CNNs) and Multi-task Cascaded Convolutional Networks (MTCNN) to boost feature extraction and analysis while making sure that this is done at a computational efficiency, especially to be deployed in resource-constrained systems such as mobile and embedded devices. The binarization of network weights and activations naturally deals with the trade-off regarding detection accuracy and computational cost. Our approach introduces a practical solution for real-time deepfake detection, thus advancing toward more secure and trusted digital environments. Our proposed model has achieved an accuracy of 80%.","","979-8-3315-2169-1","10.1109/IATMSI64286.2025.10984516","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10984516","Deepfake Detection;Convolutional Neural Networks;Binarized Neural Networks;Video Processing;Multitask Cascaded Convolutional Networks","Deepfakes;Technological innovation;Accuracy;Neural networks;Streaming media;Real-time systems;Computational efficiency;Convolutional neural networks;Security;Artificial intelligence","","1","","14","IEEE","9 May 2025","6-8 March 2025","6-8 March 2025","IEEE","IEEE Conferences"
"Deepfake Detection Using Deep Learning","P. R. S; P. D; S. G; S. R. K; G. B","Department of Computer Science and Engineering, Sri Eshwar College of Engineering, Coimbatore, India; Department of Computer Science and Engineering, Sri Eshwar College of Engineering, Coimbatore, India; Department of Computer Science and Engineering, Sri Eshwar College of Engineering, Coimbatore, India; Department of Computer Science and Engineering, Sri Eshwar College of Engineering, Coimbatore, India; Department of Computer Science and Engineering, Sri Eshwar College of Engineering, Coimbatore, India",2024 10th International Conference on Advanced Computing and Communication Systems (ICACCS),"23 Oct 2024","2024","1","","1768","1774","In recent decades, rapid advancements in AI, machine learning, and deep learning have yielded new methods and tools for manipulating multimedia. While this technology has primarily found applications in legitimate fields such as entertainment and education, there have been instances of malicious users exploiting it for unlawful or nefarious purposes. For instance, individuals have used these techniques to create highly realistic fake videos, images, or audio recordings, with the intention of spreading misinformation, propaganda, inciting political discord, promoting hate, or even engaging in harassment and blackmail. These manipulated and hyper-realistic media have gained notoriety as “Deepfakes” in recent times. The literature has documented various approaches to address the challenges posed by Deepfakes.","2575-7288","979-8-3503-8436-9","10.1109/ICACCS60874.2024.10717155","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10717155","Deepfake detection;video or image manipulation;digital media forensics","Deep learning;Deepfakes;Visualization;Weapons;Neural networks;Organizations;Media;Streaming media;Robustness;Protection","","1","","24","IEEE","23 Oct 2024","14-15 March 2024","14-15 March 2024","IEEE","IEEE Conferences"
"Identification of Deepfakes using Strategic Models and Architectures","S. R. Nallapati; D. Dommeti; S. Medhalavalasa; K. K. Bonku; P. V. V. S. Srinivas; D. Bhattacharyya","Department of CSE, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India; Department of CSE, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India; Department of CSE, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India; Department of CSE, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India; Department of CSE, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India; Department of CSE, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India",2023 International Conference on Sustainable Computing and Data Communication Systems (ICSCDS),"25 Apr 2023","2023","","","75","82","Deepfake technology has been rapidly evolving and expanding in recent years. It has become increasingly easy to manipulate multimedia content, making it harder to detect what is real and what is manipulated. The research aims to explore how neural networks can be used to detect deepfake in multimedia, helping to protect users from potentially malicious and deceptive content. The aim is to explore what neural networks are, how they can be used to detect deepfakes and the potential implications of this technology. The research also aims to evaluate the advantages and disadvantages of using neural networks for deepfake detection. As the world of deepfake technology continues to evolve, this research will provide an overview of the latest developments in deepfake detection and their potential impact. The goal of this research is to use neural networks to detect deepfakes and to identify suspicious content to alert users. This could help protect users from being exposed to malicious content and help content producers ensure the integrity of their work. As deepfake technology continues to evolve, neural networks may become an essential tool for quickly and accurately detecting deepfakes in multimedia. The research explores topics like, CNN, 3D CNN, GATED RECURRENT UNIT and Architectures like Xception, VGG16, InceptionV3 and ResNet50V2. The outcomes are graphically represented and analyzed. the comparative stratification of the approach is done to analyze and detect deepfakes.","","978-1-6654-9199-0","10.1109/ICSCDS56580.2023.10104880","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10104880","Deepfake Detection;Deep Learning;Convolutional Neural Network;Gated Recurrent Unit;Image Noise Patterns","Deepfakes;Visualization;Three-dimensional displays;Neural networks;Computer architecture;Media;Logic gates","","1","","18","IEEE","25 Apr 2023","23-25 March 2023","23-25 March 2023","IEEE","IEEE Conferences"
"Review of Deepfake Detection Techniques and Challenges","N. S. Ahmad Sharawardi; S. -H. Liew; P. Turumugon; A. Subramaniam","Faculty of Computing and Information Technology, Tunku Abdul Rahman University of Management and Technology Tanjung Bungah, Pulau Pinang, Malaysia; Faculty of Computer Science and Information Technology, Universiti Malaysia Sarawak (UNIMAS), Kota Samarahan, Sarawak, Malaysia; Faculty of Computing and Information Technology, Tunku Abdul Rahman University of Management and Technology Tanjung Bungah, Pulau Pinang, Malaysia; Faculty of Computing and Information Technology, Tunku Abdul Rahman University of Management and Technology Tanjung Bungah, Pulau Pinang, Malaysia","2025 IEEE International Conference on Computation, Big-Data and Engineering (ICCBE)","28 Nov 2025","2025","","","867","872","The proliferation of deepfake technology, powered by advanced generative models such as generative adversarial networks (GANs), presents challenges in digital media authenticity, public trust, and cybersecurity. We reviewed recent advancements in deepfake detection across multiple modalities, including image, video, and audio. Benchmark datasets, such as FaceForensics++, the deepfake detection challenge (DFDC), and Celeb-deepfake (Celeb-DF), have been used to develop diverse detection models. These models encompass approaches based on EfficientNet-driven transfer learning, convolutional neural network-long short-term memory (CNN-LSTM) hybrids for temporal feature extraction, graph-based neural architectures, and ensemble methods that integrate deep learning with handcrafted features. Although certain models report detection accuracies as high as 99.99% on specific datasets, many exhibit limited generalizability across different benchmarks, particularly when confronted with compression artifacts. Additionally, real-time deployment remains constrained by substantial computational demands. Emerging threats, including adversarial perturbations and diffusion-based synthetic media, necessitate the development of more resilient detection strategies. Proactive countermeasures such as blockchain-based timestamping, digital watermarking, and cryptographic hashing have been adopted to enhance media integrity. The results of the review underscore the need for lightweight, interpretable, and multimodal detection frameworks to generalize the models' applicability across diverse domains, thereby supporting reliable and scalable media verification in increasingly complex digital environments.ion.","","979-8-3315-3244-4","10.1109/ICCBE65177.2025.11255645","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11255645","deepfake detection;generative adversarial networks (GANs);convolutional neural networks (CNNs);hybrid models;spatial-temporal models","Training;Deep learning;Deepfakes;Adaptation models;Accuracy;Computational modeling;Biological system modeling;Media;Benchmark testing;Real-time systems","","","","35","IEEE","28 Nov 2025","27-29 June 2025","27-29 June 2025","IEEE","IEEE Conferences"
"Comparative Analysis Of Deep Learning for Robust Deepfake Detection","R. Kapoor; V. Mehndiratta; J. Singh","Christ University, Bangalore; Christ University, Bangalore; Christ University, Bangalore",2024 4th International Conference on Advancement in Electronics & Communication Engineering (AECE),"13 Mar 2025","2024","","","1067","1072","With Deepfake technology rapidly growing and its use on the rise, there is an increased demand for effectiveness of its detection. This paper performs a comparative analysis of 4 deep learning algorithms – Meso-4, MesoInception-4, Resnet50, DenseNet-121. We will investigate each algorithm’s architecture, performance validation and versatility. The indepth overview will shed some light on accuracy, precision, recall, F1 score, etc. The dataset will encompass the real and fake community videos for a well-rounded assess on each algorithm’s effectiveness. The results of the research will help to with the potential practical applications of the reviewed algorithms, and mention possible changes and improvements. The results of the research have shown both strengths and weaknesses of each algorithm, giving clarity as to the potential use in practice, and changes that could be made in future. The overall aim of the dissolution is to guide the reader through the process of understanding the difference between the 4 algorithms – Meso-4, MesoInception-4, Resnet-50 and DenseNet-121.","","979-8-3503-6472-9","10.1109/AECE62803.2024.10911049","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10911049","Deepfake detection;Deep learning;Meso-4;MesoInception-4;ResNet-50;DenseNet-121","Deep learning;Deepfakes;Accuracy;Decision making;Media;Feature extraction;Security;Reliability;Residual neural networks;Overfitting","","","","15","IEEE","13 Mar 2025","22-23 Nov. 2024","22-23 Nov. 2024","IEEE","IEEE Conferences"
"DeepShield: AI-Powered Deepfake Detection","S. Sharma; K. Gupta","Department of Computer Science Engineering, Sharda School of Engineering and Technology, Sharda University, Greater Noida, India; Department of Computer Science Engineering, Sharda School of Engineering and Technology, Sharda University, Greater Noida, India",2025 5th International Conference on Intelligent Technologies (CONIT),"24 Sep 2025","2025","","","1","7","The growing pervasiveness of deepfake technology is enormous in its threats to digital integrity, cybersecurity, and the diffusion of misinformation. Public opinion can be manipulated by deepfake media, identity authentication can be challenged, and digital trust can be harmed. To curb such threats, we introduce DeepShield, a new AI-powered deepfake detection system that combines spatial and temporal analysis for strong forgery detection. Our approach integrates a ResNeXt-based Convolutional Neural Network (CNN) for extracting spatial features and a Long Short-Term Memory (LSTM) network for detecting temporal abnormalities between video frames. DeepShield is trained on benchmark datasets such as FaceForensics++ and DFDC and reaches an accuracy of $\mathbf{8 1. 9 7 \%}$ with $\mathbf{8 3. 4 \%}$ recall and $\mathbf{8 0. 4 \%}$ F1-score, all while having good generalization. Though not surpassing state-of-the-art models in bare accuracy, DeepShield prioritizes scalability, robustness against unseen manipulations, and deployability. We also provide future directions such as transformer-based architecture and multimodal detection, thus positioning DeepShield as a step towards robust real-time video authentication in digital forensics and cybersecurity.","","979-8-3315-2233-9","10.1109/CONIT65521.2025.11167853","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11167853","Deepfake detection;Convolutional Neural Networks (CNN);Long Short-Term Memory (LSTM);ResNeXt;Video Authentication","Deepfakes;Accuracy;Computational modeling;Authentication;Computer architecture;Feature extraction;Transformers;Robustness;Convolutional neural networks;Long short term memory","","","","25","IEEE","24 Sep 2025","20-22 June 2025","20-22 June 2025","IEEE","IEEE Conferences"
"Neuro-Behavioral Deepfake Detection: Leveraging Human Micro-Expression Analysis for High-Precision Forgery Identification","T. N. Kumar; A. GV; A. D; G. P; J. S","Department of Computer Science and Engineering, Mahendra Engineering College, Tamil Nadu, India; Department of Computer Science and Engineering, Mahendra Engineering College, Tamil Nadu, India; Department of Computer Science and Engineering, Mahendra Engineering College, Tamil Nadu, India; Department of Computer Science and Engineering, Mahendra Engineering College, Tamil Nadu, India; Department of Computer Science and Engineering, Mahendra Engineering College, Tamil Nadu, India",2025 4th International Conference on Innovative Mechanisms for Industry Applications (ICIMIA),"20 Oct 2025","2025","","","1155","1161","The swift advancement of deepfake technology has escalated concerns about the integrity of digital media, demanding innovative and robust detection strategies. Traditional methods, which primarily target visual inconsistencies such as unnatural facial movements or blending artifacts, are increasingly ineffective against sophisticated deepfake algorithms. This paper introduces the Micro-Expression Assisted Deepfake Detection (ME-ADD) model, a novel approach that enhances forgery detection by analyzing human micro-expressions—fleeting, involuntary facial movements that reveal authentic emotions and are difficult for AI to replicate accurately. By integrating a hierarchical convolutional recurrent neural network (HCRNN) for micro-expression recognition with established deepfake detection frameworks like XceptionNet, ME-ADD exploits subtle neuro-behavioral cues to achieve superior detection precision. This model combines temporal analysis of micro-expressions with spatial feature extraction to identify inconsistencies in manipulated videos, offering a significant advancement in media forensics. The proposed neuro-behavioral methodology not only addresses the limitations of conventional approaches but also provides a resilient solution to combat the growing threat of high-quality deepfakes in diverse applications, from social media to security.","","979-8-3315-5386-9","10.1109/ICIMIA67127.2025.11200578","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11200578","Deepfake Detection;Micro-Expression Recognition;Neuro-Behavioral Analysis;Convolutional Neural Networks;Media Forensics","Deepfakes;Analytical models;Visualization;Recurrent neural networks;Social networking (online);Forensics;Biological system modeling;Media;Feature extraction;Forgery","","","","18","IEEE","20 Oct 2025","3-5 Sept. 2025","3-5 Sept. 2025","IEEE","IEEE Conferences"
"Blockchain Based Deepfake Video Detection Using Deep Learning","B. Colaco; B. Patil; S. Gharat; S. Gawande","Department Of Computer Engineering, Vidyavardhini’s College of Engineering and Technology, India; Department Of Computer Engineering, Vidyavardhini’s College of Engineering and Technology, India; Department Of Computer Engineering, Vidyavardhini’s College of Engineering and Technology, India; Department Of Computer Engineering, Vidyavardhini’s College of Engineering and Technology, India",2025 International Conference on Emerging Trends in Industry 4.0 Technologies (ICETI4T),"26 Aug 2025","2025","","","1","7","Deepfake identification has become an essential issue in the digital world as AI generated manipulated videos are being utilized more and more maliciously. In order to provide a trustworthy technique for detecting deep-fake video, proposed system employs an integrated deep learning method involving Long Short-Term Memory (LSTM), ResNeXt, and Convolutional Neural Networks (CNN). CNN and ResNeXt are used to analyze video frames and extract spatial data, whereas LSTM analyzes the temporal dynamics between frames. These obtained features are employed to determine the variations and irregularities frequently found in deepfake movies. The Python and PyTorch frameworks used in the model’s development and implementation provide high accuracy and efficiency. The results are verified as well and safely saved on blockchain, offering an infallible, transparent way to identify deepfakes. The fields of media integrity, digital forensics, and cybersecurity are greatly advanced by this program’s helpful tool for preventing online fraud and disinformation.","","979-8-3315-0696-4","10.1109/ICETI4T63625.2025.11132246","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11132246","Deepfake Detection;Deep Learning (DL);convolutional Neural Network (CNN);ResNeXt;Long Short-Term Memory (LSTM);Blockchain (BC);Temporal Analysis;Video Processing(VP);PyTorch","Deep learning;Deepfakes;Social networking (online);Motion pictures;Market research;Spatial databases;Blockchains;Convolutional neural networks;Long short term memory;Python","","","","15","IEEE","26 Aug 2025","6-7 June 2025","6-7 June 2025","IEEE","IEEE Conferences"
"Exploring Deepfake Image Forensics: The Role of CNNs, RNNs, GANs and Vision Transformers in Synthetic Media Detection","V. V D; S. K. G; B. Sundarambal; K. N; C. Selvaganesan; S. V","Department Of Computer Science And Business Systems, Chennai Institute Of Technology, Chennai, India; Department Of Computer Science And Business Systems, Chennai Institute Of Technology, Chennai, India; Department Of Computer Science And Business Systems, Chennai Institute Of Technology, Chennai, India; Department Of Computer Science And Business Systems, Chennai Institute Of Technology, Chennai, India; Department Of Computer Science And Business Systems, Chennai Institute Of Technology, Chennai, India; Department Of Computer Science And Business Systems, Chennai Institute Of Technology, Chennai, India",2025 International Conference on Data Science and Business Systems (ICDSBS),"20 Jun 2025","2025","","","1","8","The advancement of deepfake technology, which is the ability to produce synthetic media of convincingly real likenesses, has created enormous hurdles in the verification and security of digital content. In this light, several deep learning techniques have been employed in identifying deepfake content and lessening its effects. The paper looks at the most recent progress made in deepfake image forensics, especially Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), Generative Adversarial Networks (GAN), and Vision Transformers (ViTs). Models based on these CNN, particularly VGG16, VGG19 and ResNet50, are quite useful in the detection of deepfakes by spatial analysis features while time series videos are well dealt with by RNN for pattern anomalies. In addition, deep learning networks Generative Adversarial Networks that are commonly used for elaborating on deepfakes have also been incorporated in the creation of counter diagnostic models to improve the detection. Hybrid approaches using CNNs and ViTs are also becoming popular in deepfake image/video detection. In addition, systems with multiple detection techniques and different preprocessing methods have resulted in better performance of the system. The paper finally argues that there will always be a need for new designs by comparing the efficiency of deepfake detection techniques, The existing systems may grow old due to the advances in new deepfakes systems.","","979-8-3315-8560-0","10.1109/ICDSBS63635.2025.11031813","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11031813","Deepfake Detection;CNN;ViTs;GAN;RNN;Image Manipulation;Deep Learning Techniques;Image Generation;Privacy","Deep learning;Deepfakes;Analytical models;Image forensics;Recurrent neural networks;Media;Generative adversarial networks;Transformers;Data models;Convolutional neural networks","","","","37","IEEE","20 Jun 2025","17-18 April 2025","17-18 April 2025","IEEE","IEEE Conferences"
"Spoofed Audio Detection Using a Fusion of Transformer Based Architectures","M. Bulut; G. Tahaoglu; G. Ulutas; B. Ustubioglu; A. Ustubioglu; M. Ulutas; S. Dincer; T. Altun","Department of Computer Engineering, Karadeniz Technical University, Trabzon, Türkiye; Department of Computer Engineering, Karadeniz Technical University, Trabzon, Türkiye; Department of Computer Engineering, Karadeniz Technical University, Trabzon, Türkiye; Department of Computer Engineering, Karadeniz Technical University, Trabzon, Türkiye; Department of Computer Engineering, Trabzon University, Trabzon, Türkiye; Department of Computer Engineering, Karadeniz Technical University, Trabzon, Türkiye; Department of Computer Engineering, Karadeniz Technical University, Trabzon, Türkiye; Department of Computer Engineering, Turkcell Global Bilgi, İstanbul, Türkiye",2025 18th International Conference on Information Security and Cryptology (ISCTürkiye),"11 Nov 2025","2025","","","1","6","Through the rapid evolution of deepfake audio generation, and more importantly, its quite simplified access through easy-to-use tools, synthetic speech generation and its abuse have become a considerable threat over the years. It becomes clear that the detection of the spoofed audio will be a growing concern in the future. So, building robust and reliable methods to achieve the highest detection rates is needed. To address this issue, we proposed a method to detect the spoofed audio from genuine audio effectively. We utilized the cochleagram images for feature extraction, which is the closest to the human ear's biology, and used ViT and XCiT architectures for classification purposes. At the end, to eliminate deficiencies of one architecture to another, we adapted Late Score Fusing, achieving 6.94 % EER and 0.11 $\min$ t-DCF score on the ASVspoof2019 LA benchmark dataset, surpassing the state-of-the-art methods.","","979-8-3315-5709-6","10.1109/ISCTrkiye68593.2025.11224850","Scientific and Technological Research Council of Turkey (TUBITAK)(grant numbers:5250011); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11224850","Cyber security;Fake Audio Detection;Audio Deepfake Detection;Deepfakes;Deepfake Audio Detection","Deepfakes;Evolution (biology);Buildings;Ear;Benchmark testing;Feature extraction;Transformers;Reliability;Speech synthesis;Computer crime","","","","25","IEEE","11 Nov 2025","22-23 Oct. 2025","22-23 Oct. 2025","IEEE","IEEE Conferences"
"Enhancing Accuracy in Image Recognition for Deepfaked Images using Convolutional Networks Compared with LSTM Algorithm","C. A. S; S. R; S. Krishnan","Department of Computer Science and Engineering, Saveetha School of Engineering, Saveetha Institute of Medical and Technical Science, Chennai, India; Department of Computer Science and Engineering, Saveetha School of Engineering, Saveetha Institute of Medical and Technical Science, Chennai, India; Department of Computer Science and Engineering, Saveetha School of Engineering, Saveetha Institute of Medical and Technical Science, Chennai, Tamilnadu",2025 7th International Conference on Innovative Data Communication Technologies and Application (ICIDCA),"16 Dec 2025","2025","","","1868","1873","The rapid development of deepfake technologies has brought serious questions about the authenticity of digital content and the creation of effective detection tools is required. The proposed study will increase the precision of deepfake image recognition by comparing the results of Convolutional Neural Networks (CNNs) with Long Short-Term Memory (LSTM) algorithms. A Kaggle dataset of real and synthetically generated deepfake images under different conditions was used as a training and evaluation dataset. Two experimental groups were created, Group 1 used CNNs and Group 2 used LSTM models, and 20 samples in each group (N = 40). A priori evaluation by ClinCalc.com determined an 80 percent statistical power, which meets the behavioral science significance (0.05, 0.2) criteria. The outcome showed that CNNs had a higher accuracy of 97.15 that was much higher in comparison to the LSTM model that had 57.33. Statistical significance was confirmed by a two-tailed significance test (p = 0.001, p < 0.05), which revealed the higher ability of CNNs to extract and analyze visual features to detect deepfakes. Such results highlight the potential of CNNs to detect manipulated images and serve as a basis to develop more resistant and dependable deepfake detectors based on the state- of-the-art feature extraction and transfer learning methods.","","979-8-3315-1414-3","10.1109/ICIDCA66325.2025.11280513","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11280513","Deepfake Detection;Image Recognition;Convolutional Neural Networks (CNN);LSTM Algorithm;Accuracy Improvement;Transfer Learning;Adversarial Attack","Resistance;Training;Deepfakes;Visualization;Accuracy;Image recognition;Transfer learning;Feature extraction;Convolutional neural networks;Long short term memory","","","","20","IEEE","16 Dec 2025","6-8 Oct. 2025","6-8 Oct. 2025","IEEE","IEEE Conferences"
"A deepfake video detection method based on multi-modal deep learning method","Y. Zhang; X. Li; J. Yuan; Y. Gao; L. Li","Key Laboratory of Trustworthy Distributed Computing and Service, Beijing University of Posts and Telecommunications, Beijing, P.R. China; Key Laboratory of Trustworthy Distributed Computing and Service, Beijing University of Posts and Telecommunications, Beijing, P.R. China; Key Laboratory of Trustworthy Distributed Computing and Service, Beijing University of Posts and Telecommunications, Beijing, P.R. China; Key Laboratory of Trustworthy Distributed Computing and Service, Beijing University of Posts and Telecommunications, Beijing, P.R. China; Key Laboratory of Trustworthy Distributed Computing and Service, Beijing University of Posts and Telecommunications, Beijing, P.R. China","2021 2nd International Conference on Electronics, Communications and Information Technology (CECIT)","1 Apr 2022","2021","","","28","33","Recently, most deepfake video classification tasks depend on frame-level features and try to train deep neural networks to characterize fake videos. Although this kind of methods can achieve good results, they also waste the audio information and timing information of the deepfake video dataset. Therefore, to make better use of the audio information, we propose a multi-modal method to detect deepfake videos. The principle of our method is based on the mismatch between audio information and visual information, such as the inconsistency of mouth shape and voice. We calculate the modality dissonance score(MDS score) of videos to classify true/false videos. Extensive experiments reach 84.4% accuracy on the DFDC dataset, which demonstrates the effectiveness of our method.","","978-1-6654-3757-8","10.1109/CECIT53797.2021.00014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9742162","deepfake detection;multi-modality;adaptive modality dissonance;deep learning;deep neural network","Deep learning;Visualization;Shape;Neural networks;Mouth;Timing;Information and communication technology","","","","22","IEEE","1 Apr 2022","27-29 Dec. 2021","27-29 Dec. 2021","IEEE","IEEE Conferences"
"DAF-Net: A Data-Analytics-Driven Adaptive Framework for Deepfake Detection Using Hybrid Deep Learning Models","R. PushpaLakshmi","Department of CSE(Cyber Security), PSNA College of Engineering and Technology, Dindigul, India",2025 IEEE International Conference on Advances in Computing Research On Science Engineering and Technology (ACROSET),"16 Dec 2025","2025","","","1","7","The emergence of deepfake technology, which is driven by sophisticated Generative Adversarial Networks (GANs), has presented a significant cybersecurity threat. Cybercrimes including identity theft, social engineering, and disinformation now use deepfakes, which are artificially modified videos, pictures, or sounds. Because these synthetic dangers are constantly changing, traditional detection techniques sometimes fall short. The unique multi-modal system DAF-Net (Data-Analytics-Driven Adaptive Framework for Deepfake Detection), which integrates contextual data analytics and deep learning, is proposed in this research. DAF-Net combines a Transformer encoder for temporal inconsistencies, a Convolutional Neural Network (EfficientNet) for spatial features, and Wav2Vec 2.0 for audio-based manipulation detection. Together, these models provide highly accurate deepfake detection across modalities. One of DAF-Net's unique features is its Data Analytics and Visualisation Module, which assigns a Contextual Risk Score and identifies spreading trends using metadata. Tested on datasets like FaceForensics++, DFDC, and ASVspoof 2021, DAF-Net outperformed current techniques with an accuracy of 93.6% for video and 91.2% for audio deepfakes. 87% of high-impact threats have their priorities accurately determined by risk scoring. DAF-Net provides a scalable, intelligent defence solution for practical cybersecurity applications by fusing data analytics and adaptive deep learning.","","978-1-6654-5810-8","10.1109/ACROSET66531.2025.11280662","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11280662","deepfake detection;adaptive deep learning;cybersecurity;data analytics;transformer networks;risk scoring","Deep learning;Deepfakes;Adaptation models;Data analysis;Accuracy;Adaptive systems;Computational modeling;Transformers;Feature extraction;Load modeling","","","","30","IEEE","16 Dec 2025","27-28 Sept. 2025","27-28 Sept. 2025","IEEE","IEEE Conferences"
"Pandora's Black or White Box: Are AI Tools Undermining Evidence?","E. Williams; J. Rodgers; S. Chandler-Crnigoj; K. Jones; C. Robinson","Faculty of Engineering Technology, Liverpool John Moores University, Liverpool, England; Police Service of Scotland, Edinburgh, Scotland; Faculty of Engineering Technology, Liverpool John Moores University, Liverpool, England; Faculty of Engineering Technology, Liverpool John Moores University, Liverpool, England; Faculty of Engineering Technology, Liverpool John Moores University, Liverpool, England",2025 International Conference on Computer Systems and Technologies (CompSysTech),"2 Sep 2025","2025","","","1","6","The proliferation of synthetic media, particularly deepfakes, is having a significant impact on society in general and the criminal justice system in particular. The increase in deepfake audio and video evidence presents significant challenges to digital forensics, where accurate detection is essential for maintaining the integrity of evidence. With limited manual methods available for identifying manipulated content, forensic professionals are increasingly turning to AI-enabled detection tools. This research examines whether the application of professional-grade AI tools for deepfake detection introduces changes to original files, such as modifications to metadata, compression artefacts, or structural alterations, that could compromise their integrity and admissibility in legal contexts. The investigation has focused on 2 professional tools currently widely employed within audio and video forensic units of UK police forces. The work undertaken employs controlled testing to assess the extent and nature of such changes. It evaluates whether these tools adhere to ethical and procedural standards, particularly regarding the chain of custody and evidentiary reliability. The findings aim to inform the integration of AI tools into audio/video forensic workflows, addressing critical concerns about balancing advanced detection capabilities with the preservation of file authenticity. Through identifying potential risks and challenges, the study seeks to support policymakers, forensic practitioners, and legal professionals in ensuring that advancements in synthetic media detection uphold the foundational principles of evidence handling and judicial integrity.","","979-8-3315-4322-8","10.1109/CompSysTech65493.2025.11137140","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11137140","Artificial Intelligence;Forensics;Digital Forensics;Deepfake Detection;Policing","Deepfakes;Ethics;Magnetic resonance imaging;Digital forensics;Media;Metadata;Turning;Artificial intelligence;Standards;Testing","","","","23","IEEE","2 Sep 2025","27-28 June 2025","27-28 June 2025","IEEE","IEEE Conferences"
"Hybrid CNN–Transformer Ensemble for Robust Deepfake Video Detection","K. Saksham; A. Agrawal","Indian Institute of Information Technology Allahabad, Prayagraj, Uttar Pradesh, India; Indian Institute of Information Technology Allahabad, Prayagraj, Uttar Pradesh, India",2025 IEEE 6th India Council International Subsections Conference (INDISCON),"2 Dec 2025","2025","","","1","6","The advent of deepfake videos, driven by generative models like GANs, poses an increasingly formidable threat to media integrity and digital security. These manipulations can be detected using models capable of identifying local visual artifacts as well as contextual inconsistencies at a larger scale. In this paper, we introduce a two-level ensemble model based on Convolutional Neural Networks and Vision Transformers to effectively process spatial and temporal patterns in video data. The system proposed here performs $98.97 \%$ on the AVLips dataset and 95.19% on DFDC, showing robust performance across datasets with different compression and manipulation levels. By combining the complementary strengths of CNNs and Transformers, the ensemble enhances reliability and generalization across different conditions. This work is part of building reliable deepfake detection tools for practical use in media verification and forensic analysis.","","979-8-3315-1504-1","10.1109/INDISCON66021.2025.11251858","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11251858","Deepfake Detection;Ensemble Learning;Convolutional Neural Networks (CNNs);Vision Transformers (ViT;CvT);Transfer Learning;Xception Network;Temporal and Spatial Features;ResNet;Cross-Dataset Generalization;Video Forensics","Deepfakes;Computer vision;Visualization;Forensics;Transfer learning;Media;Video compression;Transformers;Convolutional neural networks;Ensemble learning","","","","18","IEEE","2 Dec 2025","21-23 Aug. 2025","21-23 Aug. 2025","IEEE","IEEE Conferences"
"Detecting Deepfakes and Artificial Intelligence-Generated Art","F. P. Rajeev; S. D. Shetty","Computer Science and Engineering Birla Institute of Technology and Science, Pilani Dubai Campus, Dubai, United Arab Emirates; Computer Science and Engineering Birla Institute of Technology and Science, Pilani Dubai Campus, Dubai, United Arab Emirates",2024 International Conference on Computational Intelligence and Network Systems (CINS),"10 Feb 2025","2024","","","1","7","Recent years have seen innovative advancements in Artificial Intelligence (AI) in the realms of image and video processing, speech and audio recognition, and pattern recognition, leading to the boom in AI art and deepfakes. The evolution of ChatGPT, Dalle-2, and Midjourney has sparked debate about whether AI art qualifies as true art and whether it will eventually displace human artists and creators. AI art generation models are trained on large datasets, often consisting of copyrighted art. Due to this, the resulting picture produced is frequently a manipulated version of the art piece, namely through various techniques - CutMix, Adversarial Data Poisoning, Inpainting, and Style Transfer. This manipulation constitutes a violation of the rights held by the artists. On a similar note, deep fakes pose threats to privacy and security. Society is entering a new age of misinformation and confusion, where they are victims of deepfake phishing scams, identity theft, and malicious political interference. These issues necessitate the development of state-of-the-art algorithms to detect real-life photos and videos, as well as painting and art manipulation. This paper dives deep into the topic of AI art and Deepfake detection, highlighting the most efficient machine learning classification techniques on the DeepfakeArt Challenge and Deepfake Detection Challenge dataset. It aims to highlight the best algorithm that provides reliable results and assists future research in this newly emerging area.","","979-8-3315-0410-6","10.1109/CINS63881.2024.10864456","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10864456","Deepfake Detection;AI Art;Visual Manipulation;Image Authenticity","Training;Deepfakes;Art;Machine learning algorithms;Computational modeling;Speech recognition;Classification algorithms;Artificial intelligence;Speech processing;Video recording","","","","18","IEEE","10 Feb 2025","28-29 Nov. 2024","28-29 Nov. 2024","IEEE","IEEE Conferences"
"Adaptive GAN-Based Watermarking for Robust Deepfake Detection","S. Chanda; M. Das; S. Maity; B. Naskar; A. Ghosh; A. Biswas; T. S. Panda; A. Das","Institute of Engineering & Management, Kolkata, University of Engineering and Management, Kolkata, Kolkata, India; Institute of Engineering & Management, Kolkata, University of Engineering and Management, Kolkata, Kolkata, India; Institute of Engineering & Management, Kolkata, University of Engineering and Management, Kolkata, Kolkata, India; Institute of Engineering & Management, Kolkata, University of Engineering and Management, Kolkata, Kolkata, India; Institute of Engineering & Management, Kolkata, University of Engineering and Management, Kolkata, Kolkata, India; Institute of Engineering & Management, Kolkata, University of Engineering and Management, Kolkata, Kolkata, India; Belda College, Belda, India; Institute of Engineering & Management, Kolkata, University of Engineering and Management, Kolkata, Kolkata, India",2025 International Conference on Engineering Innovations and Technologies (ICoEIT),"31 Oct 2025","2025","","","586","591","Progressions in Generative Adversarial Networks (GANs) have amplified the threat of deepfakes, challenging digital trust and authenticity. This paper proposes a novel GAN-based visible watermarking framework that uses a generator-discriminator layer in a looping fashion to embed indistinguishable, anti-tamper patterns into video frames. Spatial and temporal features are extracted through CNN and RNN architectures, while attention mechanisms specify the manipulated facial regions. Evaluated on FaceForensics++, Celeb-DF, and DFDC datasets using six frameworks. Unlike existing approaches, it effectively detects both watermarked and nonwatermarked deepfakes and resists compression and motionrelated tampering. This work presents a scalable, interpretable detection pipeline combining proactive watermarking with passive feature-based analysis.","","979-8-3315-2595-8","10.1109/ICoEIT63558.2025.11211773","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11211773","Deepfake Detection;Generative Adversarial Networks;Digital Watermarking;Computer Vision;Deep Learning;Media Authentication","Training;Deepfakes;Visualization;Technological innovation;Scalability;Watermarking;Resists;Feature extraction;Generative adversarial networks;Robustness","","","","16","IEEE","31 Oct 2025","4-5 July 2025","4-5 July 2025","IEEE","IEEE Conferences"
"A Novel Approach to Deepfake Detection: Leveraging Fused Facial and Body Dynamics With a CNN–Transformer Hybrid Network","K. P. Rahatwal; S. Pundir; M. Wazid; V. Bhat K","Department of Computer Science and Engineering, Graphic Era (Deemed to be University), Dehradun, India; Department of Computer Science and Engineering, Graphic Era (Deemed to be University), Dehradun, India; Department of Computer Science and Engineering, Graphic Era (Deemed to be University), Dehradun, India; School of Computer Engineering, Manipal Institute of Technology, Manipal Academy of Higher Education, Manipal, India",IEEE Access,"24 Nov 2025","2025","13","","197085","197108","The rapid advancement of generative models like Generative Adversarial Networks (GANs) has contributed significantly to the creation of deep-fake videos. These synthetic videos pose serious threats to personal privacy, public trust, and societal stability, as they manipulate reality and influence perception of other. While Convolutional Neural Networks (CNNs) have shown progress in deepfake detection, many existing approaches struggle to effectively capture temporal inconsistencies across video frames. In this study, a novel hybrid deepfake detection model is proposed that uses both spatial and motion based features. The model utilizes VGG16 to extract high-level facial features and Google MoveNet to capture upper body pose information from data. Each video is divided into sequences of 20 frames, and the combined feature vectors of shape (20, 563) are passed through a deep learning architecture comprising a 1D Convolutional layer followed by a Transformer encoder. This setup enables the model to learn both intra frame and inter-frame dependencies. The model was trained and evaluated using a combined dataset of real and synthetic facial images, supplemented with an additional video dataset consisting of 408 authentic and 795 deepfake samples. Evaluation results demonstrate the effectiveness of the proposed approach, with the model achieving an accuracy of 84.48%. These findings show the potential of the proposed system for practical and reliable automated deepfake detection.","2169-3536","","10.1109/ACCESS.2025.3632155","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11242102","CNN;Conv1D;deepfake detection;GAN;pose estimation;transformer;VGG16","Deepfakes;Feature extraction;Convolutional neural networks;Transformers;Generative adversarial networks;Forgery;Accuracy;Robustness;Recurrent neural networks;Pose estimation","","","","60","CCBYNCND","12 Nov 2025","2025","","IEEE","IEEE Journals"
"Dynamic Lip Motion Analysis for Deepfake Detection","A. Castiglione; L. Cimmino; V. Loia; M. Nappi; C. Sorrentino","Dept. of Management & Innovation Systems, University of Salerno, Italy; Dept. of Computer Science, University of Salerno, Italy; Dept. of Management & Innovation Systems, University of Salerno, Italy; Dept. of Computer Science, University of Salerno, Italy; Dept. of Computer Science, University of Salerno, Italy",2025 25th International Conference on Control Systems and Computer Science (CSCS),"30 Sep 2025","2025","","","452","459","The proliferation of deepfake videos poses a significant threat to the integrity of digital media, given their capacity to disseminate misinformation and undermine the reliability of visual content. As synthetic audiovisual forgeries become increasingly realistic, they are being used in coordinated disinformation efforts, contributing to the broader issue of information disorder, which compromises public trust, media authenticity, and the verifiability of digital evidence. This study investigates the effectiveness of spatio-temporal features, extracted using Local Binary Patterns on Three Orthogonal Planes (LBP-TOP), in distinguishing synthetic from authentic video content. The approach focuses on the dynamic characteristics of the labial region, where inconsistencies in facial motion are more likely to occur in deepfake videos. LBP-TOP is employed to capture subtle texture and motion variations across spatial and temporal dimensions. Preliminary empirical evaluations conducted on benchmark deepfake datasets demonstrate the efficacy of the proposed approach, emphasizing the importance of localized temporal analysis in enhancing detection accuracy. The results highlight the potential of region-specific facial modelling as a computationally efficient yet discriminative strategy in the context of video forensics and the mitigation of synthetic media-based disinformation.","2379-0482","979-8-3315-7343-0","10.1109/CSCS66924.2025.00073","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11181647","Deepfake Detection;Misinformation;Spatiotemporal Feature Extraction;Local Binary Patterns on Three Orthogonal Planes (LBP-TOP);Digital Video Forensics","Deepfakes;Adaptation models;Visualization;Forensics;Computational modeling;Dynamics;Benchmark testing;Feature extraction;Robustness;Forgery","","","","29","IEEE","30 Sep 2025","27-30 May 2025","27-30 May 2025","IEEE","IEEE Conferences"
"A Detailed Exploration to Deepfake: A Cybersecurity Threat","G. Kasera; M. Solanki; H. Kaur; K. Shah","Computer Science and Engineering, Pandit Deendayal Energy University, Gandhinagar, India; Computer Science and Engineering, Pandit Deendayal Energy University, Gandhinagar, India; Computer Science and Engineering, Pandit Deendayal Energy University, Gandhinagar, India; Computer Science and Engineering, Pandit Deendayal Energy University, Gandhinagar, India","2025 IEEE International Students' Conference on Electrical, Electronics and Computer Science (SCEECS)","2 Apr 2025","2025","","","1","6","The advancement of AI-technologies has brought both innovation and considerable challenges particularly with the emergence of deep fakes-realistic but false images, videos or audios created using deep learning algorithms. These deepfakes pose a serious threat as they can spread misleading information or content which are utilized for malicious purposes. This paper focuses on the creation of deepfake and emphasizing on various models like GANs, CNNs, and LSTMs. This paper also provides a comparative analysis of various deepfake detection techniques and prevention measures to take into considerations.","2688-0288","979-8-3315-2983-3","10.1109/SCEECS64059.2025.10940812","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10940812","Deepfake;Generative Adversarial Networks (GANs);Convolutional Neural Networks (CNNs);Recurrent Neural Networks;Long Short-Term Memory (LSTM);Deepfake Detection;Cybercrime;Fake Media Prevention;Misinformation","Deep learning;Computer science;Deepfakes;Technological innovation;Recurrent neural networks;Prevention and mitigation;Generative adversarial networks;Convolutional neural networks;Computer crime;Long short term memory","","","","20","IEEE","2 Apr 2025","18-19 Jan. 2025","18-19 Jan. 2025","IEEE","IEEE Conferences"
"HybridNet: Advancing Deepfake Detection Through Residual, SE, and Depthwise Convolutions","A. Kumar","University of Illinois Chicago, Chicago, IL, USA",IEEE Access,"15 Dec 2025","2025","13","","207541","207552","Deepfake media pose a significant threat to digital information integrity, necessitating robust detection strategies. We propose HybridNet, a convolutional network for deepfake detection that integrates residual connections (ResNet), depthwise separable convolutions (EfficientNet principles), and Squeeze–and–Excitation (SE) blocks to balance high accuracy with computational efficiency. HybridNet incorporates uncertainty quantification via softmax confidence thresholds and interpretability through Gradient–weighted Class Activation Mapping (Grad–CAM) visualizations. Enhanced by a Hybrid Frequency–Spatial Attention (HFSA) module, it improves generalization across datasets. We evaluate HybridNet on FaceForensics++ (HQ) (96% accuracy), Celeb-DF v2 (97%), and the DFDC-preview split, where performance improves from 89% (baseline) to 93.2% with data augmentation and PGD-based robustness enhancements. Unlike prior detectors that are either black–box CNNs or heavy transformer architectures, HybridNet offers a practical trade–off between interpretability, efficiency, and accuracy. Additional evaluations against transformer–based models, compression robustness, fairness across demographics, adversarial attacks, and deployment feasibility underscore HybridNet’s versatility and reliability. Ablations confirm the contribution of each architectural component. We report confidence intervals and stress–test under codec compression, noise, and blur to substantiate robustness claims.","2169-3536","","10.1109/ACCESS.2025.3640106","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11275676","Deepfake detection;convolutional neural networks;residual networks;depthwise separable convolution;Squeeze–and–Excitation;interpretability;Grad–CAM;transformers;fairness","Transformers;Deepfakes;Accuracy;Convolutional neural networks;Robustness;Feature extraction;Computer architecture;Noise;Detectors;Standards","","","","45","CCBY","3 Dec 2025","2025","","IEEE","IEEE Journals"
"A Deepfake Detection Model Based on the Integration of ResNet50 and LSTM","X. Huang; Y. Zheng; X. Jiang","Maynooth International Engineering College, Fuzhou University, Fuzhou, China; Maynooth International Engineering College, Fuzhou University, Fuzhou, China; Maynooth International Engineering College, Fuzhou University, Fuzhou, China","2025 IEEE 5th International Conference on Electronic Technology, Communication and Information (ICETCI)","24 Jul 2025","2025","","","561","565","Video processing has consistently been a focal point of interest in both the media industry and academia, particularly against the backdrop of continuous advancements in digital signal processing technology. These videos are sometimes misused to disseminate false information or damage reputations. This paper aims to develop a video authenticity recognition system using advanced deep learning models. In terms of technical implementation, the ResNet50 model is employed for image feature extraction to detect subtle inconsistencies and artifacts, such as unnatural facial movements and irregular lighting variations in videos. Additionally, LSTM is used to capture the temporal sequence features of the video. Experimental results indicate that the model achieves an accuracy rate of 81.25% in detecting deepfake videos. Additionally, the model achieved a recall rate of 1, which holds significant practical value. This achievement provides strong support for the accurate detection and labeling of videos, playing a crucial role in preserving information authenticity and ensuring media security.","","979-8-3315-3372-4","10.1109/ICETCI64844.2025.11084255","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11084255","Computer Vision;Deepfake Detection;ResNet50;LSTM","Deepfakes;Accuracy;Forensics;Media;Performance metrics;Neural radiance field;Feature extraction;Long short term memory;Residual neural networks;Resilience","","","","6","IEEE","24 Jul 2025","23-25 May 2025","23-25 May 2025","IEEE","IEEE Conferences"
"A Computer Vision Model to Identify Deepfakes to Combat Misinformation During Political Events","A. Narayan; S. Fox","Computer Vision Research Concentration, Pioneer Academics, Bengaluru, India; Mathematics, Statistics, and Computer Science, Macalester College, St Paul, USA","2024 IEEE 11th Uttar Pradesh Section International Conference on Electrical, Electronics and Computer Engineering (UPCON)","12 May 2025","2024","","","1","11","With rampant use of technology, deepfake videos have emerged as a critical issue in today's global landscape of rapid information dissemination, leading to new dimensions of influence and power. Political events frequently fall victim to misinformation; emphasizing that the authenticity of such propagated media is paramount. The aim of this paper is to utilize advanced AI and ML algorithms to combat the rising challenge of deepfakes - hyper-realistic videos that appear convincingly genuine to the human eye. This work utilizes Error Level Analysis to detect compression inconsistencies between frames and compares this approach with a modified CNN architecture. The modified InceptionResnetVl model that was created achieved a training accuracy of 78% and a validation accuracy of 75% when tested on the DeepFake Detection Challenge dataset. This was also tested with the Presidential Deepfake Dataset. A potential extension of this paper would be the integration of ELA with the modified CNN model significantly improving training efficiency and achieving a higher accuracy while also increasing computational simplicity.","2687-7767","979-8-3503-7872-6","10.1109/UPCON62832.2024.10983603","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10983603","Deepfake Detection;CNN;Error-Level Analysis;Hyper-realistic frame detection;Media authenticity verification;Political Misinformation","Training;Deepfakes;Visualization;Accuracy;Image analysis;Computational modeling;Lighting;Computer architecture;Optimization;Context modeling","","","","27","IEEE","12 May 2025","29 Nov.-1 Dec. 2024","29 Nov.-1 Dec. 2024","IEEE","IEEE Conferences"
"Improving Deepfake Detection by Mixing Top Solutions of the DFDC","A. Trabelsi; M. M. Pic; J. -L. Dugelay","Digital Security Department, EURECOM, Biot, France; SURYS, Digital Labs, France; Digital Security Department, EURECOM, Biot, France",2022 30th European Signal Processing Conference (EUSIPCO),"18 Oct 2022","2022","","","643","647","The falsification of faces in videos is a growing phenomenon over the years. One of the most popular ways to tamper a face in a video is known as “deepfake”, Today, many tools exist to allow anyone to create a deepfake to discredit an individual or usurp an identity. Fortunately, the detection of deepfakes is an increasing topic of interest for the scientific community. As a result, many efforts have been made to develop mechanisms to automatically identify deepfake videos. In addition, several public deepfakes datasets have been built to help researchers to develop more effective detection methods. The most recent and also the most complete of these datasets is the one built by Facebook as part of the international DeepFake Detection Challenge (DFDC). Thousands of different frameworks, mainly based on deep learning, have been proposed during this challenge. The best solution that has been proposed obtains the accuracy of 82% on the DFDC dataset. However, the accuracy of this method is only 65% on unseen videos from the Internet. In this paper we analyse the five best methods of the DFDC and their complementarity. In addition, we experimented different assembly strategies (boosting, bagging and stacking) among these solutions. We show that we can achieve a large improvement $(+ 41\%$ on log loss and $+2.26\%$ on accuracy) when we carefully choose the models to be assembled with the most appropriate right merging method to use.","2076-1465","978-90-827970-9-1","10.23919/EUSIPCO55093.2022.9909905","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9909905","deepfake detection;deepfake detection challenge;ensembling","Deep learning;Deepfakes;Social networking (online);Stacking;Merging;Europe;Signal processing","","14","","23","","18 Oct 2022","29 Aug.-2 Sept. 2022","29 Aug.-2 Sept. 2022","IEEE","IEEE Conferences"
"Exploiting Style Latent Flows for Generalizing Deepfake Video Detection","J. Choi; T. Kim; Y. Jeong; S. Baek; J. Choi","Dept. of Advanced Imaging, Chung-Ang Univ, Korea; Dept. of Advanced Imaging, Chung-Ang Univ, Korea; Image Vision, NAVER Cloud, Korea; AI Graduate School, UNIST, Korea; Dept. of Advanced Imaging, Chung-Ang Univ, Korea",2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),"16 Sep 2024","2024","","","1133","1143","This paper presents a new approach for the detection of fake videos, based on the analysis of style latent vectors and their abnormal behavior in temporal changes in the generated videos. We discovered that the generated facial videos suffer from the temporal distinctiveness in the temporal changes of style latent vectors, which are inevitable during the generation of temporally stable videos with various facial expressions and geometric transformations. Our framework utilizes the StyleGRU module, trained by contrastive learning, to represent the dynamic properties of style latent vectors. Additionally, we introduce a style attention module that integrates StyleGRU-generated features with content-based features, enabling the detection of visual and temporal artifacts. We demonstrate our approach across various benchmark scenarios in deepfake detection, showing its superiority in cross-dataset and cross-manipulation scenarios. Through further analysis, we also validate the importance of using temporal changes of style latent vectors to improve the generality of deepfake video detection.","2575-7075","979-8-3503-5300-6","10.1109/CVPR52733.2024.00114","Artificial Intelligence Graduate School Program(Chung-Ang University)(grant numbers:2020-0-01336); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10654869","Deepfake Detection;Face Forgery Detection","Representation learning;Deepfakes;Visualization;Data preprocessing;Dogs;Contrastive learning;Feature extraction","","20","","60","IEEE","16 Sep 2024","16-22 June 2024","16-22 June 2024","IEEE","IEEE Conferences"
"Deep Learning based Model for Deepfake Image Detection: An Analytical Approach","Neha; B. Arora","Department of Computer Science & Information Technology, Central University of Jammu, Bagla (Rahya Suchani), India; Department of Computer Science Engineering, Central University of Jammu, Bagla (Rahya Suchani), India",2023 3rd International Conference on Innovative Mechanisms for Industry Applications (ICIMIA),"18 Apr 2024","2023","","","1019","1027","Recent years have witnessed great improvement in deepfake technology, spurred by advancements in deep learning models and improved processing capacity. Generative models at the cutting edge of technology have made it possible to produce convincingly realistic synthetic videos, images, and even audio recordings. Deeply fabricated media has the power to harm not just individuals but also our society, institutions, countries, religions, and others. These fake images may circulate online in low quality and contain many forms of distortion that could impair the effectiveness of detection methods. Our study employed a dataset of 140K Real and Fake images to analyse how image distortions affect the detection model using one of the deep learning models, DenseNet. This is accomplished by adding blur and noise to the original dataset and feeding it to the trained neural network to discriminate real and deepfake images. The results demonstrate that the model’s accuracy decreased with the low-quality dataset.","","979-8-3503-4363-2","10.1109/ICIMIA60377.2023.10426561","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10426561","Deepfake Generation;Deepfake Detection;Deep Learning;Generative Adversarial Networks;Face Manipulation;Image Distortions","Deep learning;Deepfakes;Analytical models;Neural networks;Industry applications;Media;Distortion","","3","","58","IEEE","18 Apr 2024","21-23 Dec. 2023","21-23 Dec. 2023","IEEE","IEEE Conferences"
"Autonomous Detection and Evaluation of Deepfakes: A Comprehensive Study","R. Sunil; P. Mer; A. Diwan","Computer Engineering Department, Marwadi University, Rajkot, India; Computer Engineering Department, Marwadi University, Rajkot, India; CE - AI & Bigdata, Marwadi University, Rajkot, India",2023 Seventh International Conference on Image Information Processing (ICIIP),"28 May 2024","2023","","","35","40","In recent times, there has been a notable advancement in deepfake techniques and the accessibility of extensive, cost-free databases. Consequently, even folks lacking technological expertise can now edit or produce visually authentic samples for various goals, both benign and harmful in nature. This paper provides a comprehensive analysis of the classification of methods used for deepfake generation and detection. The paper considers numerous factors, including the identified forgery, methodology or techniques used, evaluation metrics used for performance analysis, and the utilized dataset. By studying the development of deepfakes and the most up-to-date deepfake detecting methods, this study gives a full picture of deepfake techniques and makes it easier to come up with new, more reliable methods to fight the growing difficulty of deepfakes.","2640-074X","979-8-3503-7140-6","10.1109/ICIIP61524.2023.10537789","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10537789","Deepfakes;CNN;Artifacts;Face Swap;Facial Reenactment;Synthetic Media;GANs;Deepfake Detection","Measurement;Deepfakes;Databases;Information processing;Forgery;Performance analysis;Reliability","","3","","38","IEEE","28 May 2024","22-24 Nov. 2023","22-24 Nov. 2023","IEEE","IEEE Conferences"
"Towards Spatio-temporal Collaborative Learning: An End-to-End Deepfake Video Detection Framework","W. Guo; S. Du; H. Deng; Z. Yu; L. Feng","Dalian University of Technology, Dalian, China; Dalian University of Technology, Dalian, China; Dalian University of Technology, Dalian, China; Dalian University of Technology, Dalian, China; School of Innovation and Entrepreneurship, Dalian University of Technology, Dalian, China",2023 International Joint Conference on Neural Networks (IJCNN),"2 Aug 2023","2023","","","1","8","With the rapid development of facial tampering techniques, the deepfake detection task has attracted widespread social concerns. Most existing video-based methods adopt temporal convolution to learn temporal discontinuities directly, where they might neglect to explore both local detail mutation and inconsistent global expression semantics in the temporal dimension. This makes it difficult to learn more discriminative forgery cues. To mitigate this issue, we introduce a novel deepfake video detection framework specifically designed to capture fine-grained traces of tampering. Concretely, we first present a Multi-layered Feature Extraction module (MFE) that constructs comprehensive spatio-temporal representations by stitching different levels of features together. Afterward, we propose a Bidirectional temporal Artifact Enhancement module (BAE), which exploits local differences between adjacent frames to enhance frame-level features. Moreover, we present a Cross temporal Stride Aggregation strategy (CSA) to mine inconsistent global semantics and adaptively obtain multi-timescale representations. Extensive experiments on several benchmarks demonstrate that the proposed method outperforms state-of-the-art performance compared to other competitive approaches.","2161-4407","978-1-6654-8867-9","10.1109/IJCNN54540.2023.10191479","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10191479","Deepfake Detection;Spatio-temporal Modeling;Face Forensics;Deep Learning","Deepfakes;Visualization;Federated learning;Semantics;Neural networks;Detectors;Benchmark testing","","1","","27","IEEE","2 Aug 2023","18-23 June 2023","18-23 June 2023","IEEE","IEEE Conferences"
"ConfR: Conflict Resolving for Generalizable Deepfake Detection","J. Chen; J. Tian; C. Yu; X. Wang; Z. Li; Y. Chai; J. Dai; J. Han","Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Microelectronics, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China",2024 IEEE International Conference on Multimedia and Expo (ICME),"30 Sep 2024","2024","","","1","6","Deepfake detectors often encounter performance degradation when tested on unseen forgery methods. Existing literature tries to capture common features among multiple source forgery domains. However, we show that conflict arises in the shared feature space when each domain expresses domain-specific bias. If left unresolved, this conflict might mislead the model to learn domain-specific features and lead to inferior generalization. In this paper, we propose a new learning approach, Conflict Resolving (ConfR), designed to minimize conflict and learn features that generalize across forgeries. ConfR incorporates two key elements: the Intra-Domain Consistency Preserving (ICP) loss ensures updating consistency within forgery types, and the Inter-Domain Conflict Resolving (ICR) Module resolves updating conflicts between different forgery types. Extensive experiments demonstrate that ConfR significantly improves upon the state-of-the-art method, highlighting its potential for more generalizable deepfake detection.","1945-788X","979-8-3503-9015-5","10.1109/ICME57554.2024.10687795","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10687795","Deepfake Detection;Face Forgery Detection","Degradation;Deepfakes;Interference;Detectors;Forgery;Stability analysis","","1","","37","IEEE","30 Sep 2024","15-19 July 2024","15-19 July 2024","IEEE","IEEE Conferences"
"Advanced Deepfake Detection using Machine Learning Algorithms: A Statistical Analysis and Performance Comparison","M. S. Rana; A. H. Sung","Computing and Software Engineering, Florida Gulf Coast University, Fort Myers, FL; Computing Sciences and Computer Engineering, The University of Southern Mississippi, Hattiesburg, MS",2024 7th International Conference on Information and Computer Technologies (ICICT),"3 Jun 2024","2024","","","75","81","As techniques and tools for synthetic media and Deepfakes continue to advance, it is increasingly clear that video, audio and images can no longer be relied upon as truthful recordings of reality. Every digital communication channel is now vulnerable to manipulation, and there is widespread use of Deepfakes to propagate misinformation and disinformation, inflame political discord, defame opposition, commit cyber frauds or blackmail individuals. While deep learning (DL) methods have been widely used to identify Deepfakes, this paper demonstrates that classical machine learning (ML) methods can achieve superior performance--comparable with or exceeding state-of-the-art DL methods in detecting Deepfakes. Using the traditional procedures of feature development and selection, training, and testing of ML classifiers for the task actually provides better understandability and interpretability while consuming much less computing resource. In addition, an omnibus test, the Analysis of Variance (ANOVA), is conducted to compare the performance of multiple ML models. We present experiments that achieve 99.84% accuracy on the FaceForecics++ dataset, 99.38% accuracy on the DFDC dataset, 99.66% accuracy on the VDFD dataset, and 99.43% accuracy on the Celeb-DF dataset. Our study thus challenges the notion that DL approaches are the only effective way to detect Deepfakes and demonstrates that judicious use of ML approaches can be highly efficacious and cost-effective.","2769-4542","979-8-3503-8562-5","10.1109/ICICT62343.2024.00019","Florida Gulf Coast University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10541828","Deepfakes;Deepfake Detection;Face Manipulation;Machine Learning;Analysis of Variance;Omnibus Test","Training;Deepfakes;Machine learning algorithms;Generative AI;Recording;Fraud;Task analysis","","","","44","USGov","3 Jun 2024","15-17 March 2024","15-17 March 2024","IEEE","IEEE Conferences"
"Selective Domain-Invariant Feature for Generalizable Deepfake Detection","Y. Lai; G. Yang; Y. He; Z. Luo; S. Li","Department of Artificial Intelligence, Xiamen University, Xiamen, China; Department of Artificial Intelligence, Xiamen University, Xiamen, China; Reconova Technologies, Xiamen, China; Department of Artificial Intelligence, Xiamen University, Xiamen, China; Department of Artificial Intelligence, Xiamen University, Xiamen, China","ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","18 Mar 2024","2024","","","2335","2339","With diverse presentation forgery methods emerging continually, detecting the authenticity of images has drawn growing attention. Although existing methods have achieved impressive accuracy in training dataset detection, they still perform poorly in the unseen domain and suffer from forgery of irrelevant information such as background and identity, affecting generalizability. To solve this problem, we proposed a novel framework Selective Domain-Invariant Feature (SDIF), which reduces the sensitivity to face forgery by fusing content features and styles. Specifically, we first use a Farthest-Point Sampling (FPS) training strategy to construct a task-relevant style sample representation space for fusing with content features. Then, we propose a dynamic feature extraction module to generate features with diverse styles to improve the performance and effectiveness of the feature extractor. Finally, a domain separation strategy is used to retain domain-related features to help distinguish between real and fake faces. Both qualitative and quantitative results in existing benchmarks and proposals demonstrate the effectiveness of our approach.","2379-190X","979-8-3503-4485-1","10.1109/ICASSP48485.2024.10447889","National Natural Science Foundation of China; Wuyi University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10447889","DeepFake Detection;Domain Adaption","Training;Deepfakes;Sensitivity;Benchmark testing;Feature extraction;Forgery;Proposals","","10","","28","IEEE","18 Mar 2024","14-19 April 2024","14-19 April 2024","IEEE","IEEE Conferences"
"Continual Unsupervised Domain Adaptation for Audio Deepfake Detection","X. Chen; W. Lu; R. Zhang; J. Xu; X. Lu; L. Zhang; J. Wei","College of Intelligence and Computing, Tianjin University, Tianjin, China; College of Intelligence and Computing, Tianjin University, Tianjin, China; College of Intelligence and Computing, Tianjin University, Tianjin, China; College of Intelligence and Computing, Tianjin University, Tianjin, China; National Institute of Information and Communications Technology, Kyoto, Japan; Speech@FIT, Brno University of Technology, Brno, Czechia; College of Intelligence and Computing, Tianjin University, Tianjin, China","ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","7 Mar 2025","2025","","","1","5","Audio deepfake detection (ADD) aims to verify the authenticity of audio. However, its performance declines sharply when facing significant domain discrepancies caused by unknown datasets. Unsupervised domain adaptation (UDA) has been applied to mitigate domain mismatch. However, as generative models evolve, existing UDA methods struggle with catastrophic forgetting when facing continuously emerging spoofing methods. To address this challenge, we introduce continual UDA for ADD, which involves sequentially training across multiple target domains with continual learning. We propose a causality-distillation-based continual domain adversarial training framework for continual UDA, called CD-DAT. Specifically, we employ the domain adversarial training (DAT) framework to learn both spoofing-discriminative and domain-invariant deep features. In addition, we design a continual learning algorithm utilizing causality distillation to capture the mapping between utterances and classes, effectively mitigating forgetting and maintaining generalization. Experiments demonstrated that CD-DAT improved detection performance across all domains, confirming its memory stability and learning plasticity.","2379-190X","979-8-3503-6874-1","10.1109/ICASSP49660.2025.10890538","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10890538","Audio deepfake detection;continual learning;unsupervised domain adaptation;causality distillation","Training;Continuing education;Deepfakes;Transfer learning;Signal processing algorithms;Cause effect analysis;Signal processing;Feature extraction;Stability analysis;Speech processing","","2","","46","IEEE","7 Mar 2025","6-11 April 2025","6-11 April 2025","IEEE","IEEE Conferences"
"Deepfake Video Detection by Combining Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN)","Y. Al-Dhabi; S. Zhang","College of Software, Northeastern University, Shenyang, Liaoning, China; College of Software, Northeastern University, Shenyang, Liaoning, China","2021 IEEE International Conference on Computer Science, Artificial Intelligence and Electronic Engineering (CSAIEE)","4 Oct 2021","2021","","","236","241","Nowadays, people are facing an emerging problem called deepfake videos. These videos were created using deep learning technology. Some are created just for fun, while others are trying to manipulate your opinions, cause threats to your privacy, reputation, and so on. Sometimes, deepfake videos created using the latest algorithms can be hard to distinguish with the naked eye. That's why we need better algorithms to detect deepfake. The system we are going to present is based on a combination of CNN and RNN, as research shows that using CNN and RNN combined achieve better results. We are going to use a pre-trained CNN model called Resnext50. Using this, we save the time of training the model from scratch. The proposed system uses Resnext pretrained model for Feature Extraction and these extracted features are used to train the Long short-term memory (LSTM). Using CNN and RNN combined, we capture the inter frames as well as intra frames features which will be used to detect if the video is real or fake. We evaluated our method using a large collection of deepfake videos gathered from a variety of distribution sources. We demonstrate how our system may obtain competitive results while utilizing a simplistic architecture.","","978-1-6654-2204-8","10.1109/CSAIEE54046.2021.9543264","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9543264","Deep learning;Deepfake Detection;convolutional Neural Network (CNN);Recurrent Neural Network (RNN)","Training;Privacy;Recurrent neural networks;Computer architecture;Feature extraction;Solids;Convolutional neural networks","","38","","23","IEEE","4 Oct 2021","20-22 Aug. 2021","20-22 Aug. 2021","IEEE","IEEE Conferences"
"Frequency-Aware Attentional Feature Fusion for Deepfake Detection","C. Tian; Z. Luo; G. Shi; S. Li","Department of Artificial Intelligence, Xiamen University, Xiamen, China; Department of Artificial Intelligence, Xiamen University, Xiamen, China; Fujian Key Laboratory of Big Data Application and Intellectualization for Tea Industry, Wuyi University, Wuyishan, China; Department of Artificial Intelligence, Xiamen University, Xiamen, China","ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","5 May 2023","2023","","","1","5","Various face manipulation techniques develop rapidly and can easily generate high-quality fake images or videos, posing significant ethical concerns when used for malicious purposes. Although recent works achieve significant performance in deepfake detection, they still suffer from overfitting issues. To deal with this problem, we propose a novel framework to aggregate diverse information for deepfake detection from both RGB and frequency. Specially, we first introduce a channel attention module to assemble local and global contexts to overcome the potential semantic inconsistency on local artifacts and global features. Then we design a spatial-frequency feature fusion module to fuse the RGB-frequency information comprehensively. Moreover, a variant attention module is further proposed to improve feature discrimination. Extensive experiments demonstrate that our method maintains comparable performance in intra-dataset and cross-dataset evaluation.","2379-190X","978-1-7281-6327-7","10.1109/ICASSP49357.2023.10094654","National Natural Science Foundation of China; Natural Science Foundation of Fujian Province; Wuyi University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10094654","DeepFake Detection;Feature Fusion","Deepfakes;Ethics;Fuses;Aggregates;Semantics;Signal processing;Feature extraction","","20","","37","IEEE","5 May 2023","4-10 June 2023","4-10 June 2023","IEEE","IEEE Conferences"
"Cross-Modality and Within-Modality Regularization for Audio-Visual Deepfake Detection","H. Zou; M. Shen; Y. Hu; C. Chen; E. S. Chng; D. Rajan","Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore","ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","18 Mar 2024","2024","","","4900","4904","Audio-visual deepfake detection scrutinizes manipulations in public video using complementary multimodal cues. Current methods, which train on fused multimodal data for multimodal targets face challenges due to uncertainties and inconsistencies in learned representations caused by independent modality manipulations in deepfake videos. To address this, we propose cross-modality and within-modality regularization to preserve modality distinctions during multimodal representation learning. Our approach includes an audio-visual transformer module for modality correspondence and a cross-modality regularization module to align paired audio-visual signals, preserving modality distinctions. Simultaneously, a within-modality regularization module refines unimodal representations with modality-specific targets to retain modal-specific details. Experimental results on the public audio-visual dataset, FakeAVCeleb, demonstrate the effectiveness and competitiveness of our approach.","2379-190X","979-8-3503-4485-1","10.1109/ICASSP48485.2024.10447248","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10447248","Audio-visual fusion;deepfake detection;contrastive learning;representation regularization","Representation learning;Deepfakes;Uncertainty;Signal processing;Transformers;Acoustics;Speech processing","","7","","23","IEEE","18 Mar 2024","14-19 April 2024","14-19 April 2024","IEEE","IEEE Conferences"
"Deepfake video detection using InceptionResnetV2","S. Guefrechi; M. B. Jabra; H. Hamam","Faculty of Engineering, Uni de Moncton, Moncton, NB, Canada; Faculty of Engineering, Uni de Moncton, Moncton, NB, Canada; Faculty of Engineering, Uni de Moncton, Moncton, NB, Canada",2022 6th International Conference on Advanced Technologies for Signal and Image Processing (ATSIP),"28 Jun 2022","2022","","","1","6","Recently, deepfake face-swapping technology has become popular, making it easy to create ultra-realistic fake videos. Detecting the authenticity of videos is becoming increasingly important due to the potential negative impact videos can have on the world. This research is a method for developing a deep learning model, which can make a distinction between real and fake videos. Research papers on the subject of transfer learning in the domain of computer vision to take advantage of the earlier created neural network functions for image classification and to create new models based on them. Deep learning continues to evolve in both generating and detecting deepfakes. Models developed to detect deepfakes are designed using older datasets, may become outdated over time, and require new detection techniques all the time. Research results are promising with over 90% accuracy and areas for development and further development","2687-878X","978-1-6654-5116-1","10.1109/ATSIP55956.2022.9805902","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9805902","Deepfake;Video authenticity;Deepfake detection;Fine-tuning;InceptionResnet-V2","Deep learning;Computer vision;Computational modeling;Image processing;Transfer learning;Neural networks;Image classification","","5","","26","IEEE","28 Jun 2022","24-27 May 2022","24-27 May 2022","IEEE","IEEE Conferences"
"Spoofing Attack Augmentation: Can Differently-Trained Attack Models Improve Generalisation?","W. Ge; X. Wang; J. Yamagishi; M. Todisco; N. Evans","EURECOM, France; National Institute of Informatics, Japan; National Institute of Informatics, Japan; EURECOM, France; EURECOM, France","ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","18 Mar 2024","2024","","","12531","12535","A reliable deepfake detector or spoofing countermeasure (CM) should be robust in the face of unpredictable spoofing attacks. To encourage the learning of more generaliseable artefacts, rather than those specific only to known attacks, CMs are usually exposed to a broad variety of different attacks during training. Even so, the performance of deeplearning-based CM solutions are known to vary, sometimes substantially, when they are retrained with different initialisations, hyper-parameters or training data partitions. We show in this paper that the potency of spoofing attacks, also deep-learning-based, can similarly vary according to training conditions, sometimes resulting in substantial degradations to detection performance. Nevertheless, while a RawNet2 CM model is vulnerable when only modest adjustments are made to the attack algorithm, those based upon graph attention networks and self-supervised learning are reassuringly robust. The focus upon training data generated with different attack algorithms might not be sufficient on its own to ensure generaliability; some form of spoofing attack augmentation at the algorithm level can be complementary.","2379-190X","979-8-3503-4485-1","10.1109/ICASSP48485.2024.10448016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10448016","anti-spoofing;deepfake detection;countermeasure;text-to-speech;deep learning","Training;Degradation;Signal processing algorithms;Training data;Signal processing;Acoustics;Speaker recognition","","4","","23","IEEE","18 Mar 2024","14-19 April 2024","14-19 April 2024","IEEE","IEEE Conferences"
"Comparative Analysis of Deepfake Detection Models","O. Jannu; V. Sekar; T. Padhy; P. Padalkar","Dept. of Information Technology, The Bombay Salesian Society’s Don Bosco Institute of Technology, Mumbai, India; Dept. of Information Technology, The Bombay Salesian Society’s Don Bosco Institute of Technology, Mumbai, India; Dept. of Information Technology, The Bombay Salesian Society’s Don Bosco Institute of Technology, Mumbai, India; Dept. of Information Technology, The Bombay Salesian Society’s Don Bosco Institute of Technology, Mumbai, India",2024 IEEE 9th International Conference for Convergence in Technology (I2CT),"10 Jun 2024","2024","","","1","8","Deepfakes, which leverage advanced machine learning techniques such as generative adversarial networks (GANs), pose a significant threat to the integrity of visual content and raise concerns about misinformation and identity theft. This research provides a comparative analysis of various deepfake detection models, aiming to dissect their strengths and weaknesses. Notable architectures like Xception and ResNet50 exhibit high accuracy, precision, and recall with minimal gender bias. However, the Swin Transformer, while excelling in fake image detection, faces challenges with real images, suggesting potential bias. The CNN model demonstrates subpar performance, emphasizing limitations in classifying both fake and real images effectively. MobileNet shows moderate overall performance but maintains balanced precision and recall. The study recommends an ensemble approach to combine model strengths and address individual weaknesses. Future work should focus on refining model architectures, exploring ensemble strategies, and mitigating biases in real image detection.","","979-8-3503-9447-4","10.1109/I2CT61223.2024.10543823","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10543823","Deepfakes;Deepfake Detection;Comparative Analysis;Neural Networks;Machine Learning;Ensemble Approach;Biases;Model Evaluation","Deepfakes;Analytical models;Visualization;Refining;Transformers;Generative adversarial networks;Ensemble learning","","4","","14","IEEE","10 Jun 2024","5-7 April 2024","5-7 April 2024","IEEE","IEEE Conferences"
"Video Normalization in Identifying Fake Videos Using a Long Short-Term Memory Model","K. Thakkar; D. Lo","Wheeler High School, Marietta, Georgia; Computer Science, Kennesaw State University, Marietta, Georgia",SoutheastCon 2023,"8 May 2023","2023","","","266","270","As the misinformation crisis continues, it creates a generation more politically divided than ever before. One of the most concerning types of misinformation are Deepfake videos, which use Generative Adversarial Networks to replace an existing video with another person’s face. Deepfake videos can interfere with diplomatic relations, reduce trust in journalism, and can tamper with court video evidence, which is why it is imperative to detect these videos accurately. Long Short-Term Memory models (LSTMs) are a type of Recurrent Neural Network, meaning that they are able to remember sequential information, which is helpful for processing the frames of a video. LSTMs are special in that they can account for lags between frames of a video, which makes them perfect for Deepfake video detection. One of the potential ways to increase the accuracy of a neural network is normalization, which ensures the input data are on the same scale, so the machine has to process a lower range of data. Because the effect of normalization varies for each dataset, in this study, image normalization was used- each pixel of the frames of Deepfake videos were converted to an RGB value of 0 to 255 to see if this can increase the accuracy of the LSTM model for Deepfake detection. First, a baseline LSTM model was created for Deepfake detection with the Pytorch library, and a classification accuracy of 88.191% was achieved. After that, the first ten frames of the Deepfake videos in the dataset were passed through an image normalization algorithm. This yielded an accuracy of 94.274%, illustrating that the addition of a video normalization algorithm to Deepfake videos increased the accuracy of the Deepfake detection LSTM model by 6.083%. This is a substantial improvement, and the study showed that video normalization can be very beneficial for Deepfake video detection.","1558-058X","978-1-6654-7611-9","10.1109/SoutheastCon51012.2023.10115139","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10115139","Deepfake Detection;Long Short-term Memory (LSTM);Video Normalization","Deepfakes;Recurrent neural networks;Journalism;Generative adversarial networks;Libraries;Classification algorithms;Long short term memory","","4","","18","IEEE","8 May 2023","1-16 April 2023","1-16 April 2023","IEEE","IEEE Conferences"
"No Matter Small or Big Lip Motion: DeepFake Detection with Regularized Feature Learning on Semantic Information","Z. Yang; L. -p. Chau; B. Wen",Nanyang Technological University; The Hong Kong Polytechnic University; Nanyang Technological University,2023 IEEE 6th International Conference on Multimedia Information Processing and Retrieval (MIPR),"22 Sep 2023","2023","","","1","6","The use of DeepFake technologies to create hyper-realistic faces has sparked serious security concerns. Recent advances on DeepFake detection showed promise on algorithm generalization to unseen manipulation methods by identifying high-level semantic irregularities. However, the extracted features are not always robust, as the sample variations such as different motion magnitudes can easily degrade the feature-vector representations of their semantic information. In this work, we propose DTNet, a novel deep method that further regularizes feature learning toward more robust DeepFake Detection. To be specific, the proposed DTNet contains Deviation Regularization that penalizes samples with deviated motion magnitudes in the loss function, and Temporal Continuity Preservation, which helps keep and learn patterns of temporal continuity in feature space regardless of motion magnitudes. Experimental results show that our method effectively mitigates the impact of motion magnitudes on feature vectors, thereby improving the generalization ability.","2770-4319","979-8-3503-0781-8","10.1109/MIPR59079.2023.00034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10254427","Deepfake detection;semantic information;regularization;loss function","Representation learning;Deepfakes;Lips;Semantics;Information processing;Feature extraction;Security","","","","24","IEEE","22 Sep 2023","30 Aug.-1 Sept. 2023","30 Aug.-1 Sept. 2023","IEEE","IEEE Conferences"
"Deepfake Detection with Data Privacy Protection","M. Wu; F. Wang; X. Wu; F. Yu; B. Wang; Z. Song","Dalian University of Technology, Dalian, China; Dalian University of Technology, Dalian, China; Dalian University of Technology, Dalian, China; Dalian University of Technology, Dalian, China; Dalian University of Technology, Dalian, China; National Computer Network Emergency Response Technical Team/ Coordination Center of China, Beijing, China",2022 IEEE 24th International Workshop on Multimedia Signal Processing (MMSP),"22 Nov 2022","2022","","","1","5","As image and video forgery can be easily used for malicious purposes, the detection of such forgeries has social and technical significance. In this work, we are particularly interested in the detection of Deepfake. For privacy and sensitive data preserving reasons, we engage a flank attack using Federated Learning, a distributed framework-based model which keeps data locally during training while uploading model parameters for aggregate instead. We propose a shallow network for tampering face detection. Also, we made some progress in promoting cross-dataset detection performance which is crucial in Deepfake detection. Our experiments show a well-balanced trade-off result between detection performance and privacy preservation.","2473-3628","978-1-6654-7189-3","10.1109/MMSP55362.2022.9949458","National Natural Science Foundation of China(grant numbers:U1936117,62106037,62076052); Open Project Program of the National Laboratory of Pattern Recognition (NLPR)(grant numbers:202100032); Fundamental Research Funds for the Central Universities(grant numbers:DUT21GF303,DUT20TD110,DUT20RC(3)088); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9949458","Deepfake Detection;Federated Learning","Training;Deepfakes;Data privacy;Privacy;Federated learning;Distributed databases;Signal processing","","","","31","IEEE","22 Nov 2022","26-28 Sept. 2022","26-28 Sept. 2022","IEEE","IEEE Conferences"
"Real-World Audio Deepfake Detection Using SSL-Based Speech Models and Diverse Training Data","K. Schäfer; M. Neu","Fraunhofer SIT, ATHENE, Darmstadt, Germany; Federal Office for Information Security (BSI), Bonn, Germany",2025 IEEE 37th International Conference on Tools with Artificial Intelligence (ICTAI),"15 Dec 2025","2025","","","1465","1469","The potential for audio deepfakes to be used for malevolent purposes is increasing in line with advances in artificial intelligence and synthesis methods. With this, the need for reliable audio deepfake detectors increased. Most audio deepfake detectors comprise two principal components: a frontend, which is responsible for feature extraction, and a back-end, which performs the classification. Self-supervised learning (SSL) based front-ends are right now the most promising when faced with real-world data. We tested different combinations of six SSL-based front-ends and four back-ends, i.e. classifiers, using nine variously combined training sets, enabling the inclusion of the majority of the currently available training sets for audio deepfake detection. The combination of Wav2Vec2.0 XLS-R (2b) as the front-end and GF as the back-end performed best with an EER of 0.73% on the in-the-wild dataset, outperforming the current SOTA. Furthermore, our findings highlighted the significance of training set constellations and the utilisation of large front-ends.","2375-0197","979-8-3315-4919-0","10.1109/ICTAI66417.2025.00212","National Research Center for Applied Cybersecurity ATHENE; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11272686","Audio Deepfake Detection;SSL;Training Data;Data Augmentation","Training;Degradation;Deepfakes;Training data;Detectors;Self-supervised learning;Data augmentation;Feature extraction;Reliability;Artificial intelligence","","","","24","IEEE","15 Dec 2025","3-5 Nov. 2025","3-5 Nov. 2025","IEEE","IEEE Conferences"
"An Innovative Model of Deepfake Detection in Video Using 3D EfficientnetB7 with Spatial Attention","T. Rajesh; S. Maruthuperumal","Department of Computer Science and Engineering, Bharath Institute of Higher Education & Research, Chennai, India; Department of Computer Science and Engineering, Bharath Institute of Higher Education & Research, Chennai, India",2025 12th International Conference on Computing for Sustainable Global Development (INDIACom),"21 Aug 2025","2025","","","1","6","Nowadays, the face-swapping Deepfake models are relatively spread, producing a large amount of realistic fake videos that create concerns for countries and people's privacy. Because of the fake video's negative impacts on the world, differentiating the Deepfake and the original videos has become a significant problem. The Deepfakes can be leveraged for slander, political advantages, and to defame the public figure's reputation. Despite Deepfake's imperfections, people find it hard to differentiate among manipulated and authentic videos and images. As a result, it is significant to have automated models that effectively and accurately categorize the digital content's variability. Deepfakes enable the automatic creation and generation of (false) video content, e.g., via the Generative Adversarial Networks (GANs). The technology of Deepfake is a controversial mechanism with large problems affecting society. Distinct current Deepfake identification strategies employ the video's single frames and concentrate on the image's spatial data to infer the video's authenticity. Several effective techniques utilize the manipulated video's temporal inconsistencies. Nevertheless, the experiment highly concentrates on the spatial features. To eliminate these problems, this work develops a new mechanism for detecting Deepfakes. The novelty of the developed work is to identify the Deepfakes from the video thus helping to prevent fake news propagation and also improving the media's credibility. In the beginning, the necessary videos for implementing the model are obtained from the available resources. Further, these images are passed to the 3D EfficientnetB7 with Spatial Attention (3DENetB7-SA) model for detecting the input videos as real or fake. Finally, the necessary validations for the implemented model are carried out with the support of important performance measures over existing models to ensure the efficacy of the suggested Deepfake detection framework.","","978-93-80544-60-1","10.23919/INDIACom66777.2025.11115212","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11115212","Deepfake Detection;Raw Videos;Real and Fake Images;3D EfficientnetB7;Spatial Attention","Deep learning;Deepfakes;Solid modeling;Privacy;Three-dimensional displays;Computational modeling;Generative adversarial networks;Spatial databases;Background noise;Spatial resolution","","","","23","","21 Aug 2025","2-4 April 2025","2-4 April 2025","IEEE","IEEE Conferences"
"Enhancing Global Security: A Robust CNN Model for Deepfake Video Detection","M. Solaiman; M. S. Rana","Software Engineering Daffodil International University, Dhaka, Bangladesh; Computing and Software Engineering Florida Gulf Coast University, Fort Myers, United States",2024 7th International Conference on Information and Computer Technologies (ICICT),"3 Jun 2024","2024","","","238","243","In recent years, the rapid advancements in machine learning (ML), artificial intelligence (AI), and deep learning (DL) have ushered in a new era of sophistication in image and video manipulation techniques. Notably, the emergence of Deepfake technology, driven by AI, has garnered substantial attention. Deepfakes involve training DL models on extensive datasets of similar faces and subsequently mapping one person's expressions onto another's face, resulting in deceptively realistic fake videos that can be virtually indistinguishable from authentic ones. The proliferation of Deepfakes poses various threats, including the potential to incite political turmoil, coerce individuals, or fabricate false terrorist incidents. This trend undermines privacy, consent, and the trustworthiness of digital media. Consequently, there is a pressing need to continually advance Deepfake detection and prevention methodologies to safeguard against their malevolent use and uphold the integrity of digital content. This paper introduces a Convolutional Neural Network (CNN) based DL model specifically developed for the classification of Deepfake video frames. Our model exhibits impressive performance, as validated by a thorough analysis on the VDFD dataset, where it achieves an outstanding average precision, recall, and F1-score of 95%, 94%, and 94%, respectively. Moreover, our model showcases its efficacy across various widely recognized Deepfake datasets, including FF++, Celeb-DF, and DFDC, with frame detection average rates for precision, recall, and F1-score ranging from 80% to 85%. These compelling results signify that our proposed CNN-based frame detection technique is a powerful tool for Deepfake detection, emphasizing the critical significance of automated Deepfake detection with an exceptionally high detection rate. This technology represents a pivotal step toward protecting against the potential misuse of Deepfakes, reinforcing the security and integrity of digital content in our modern world.","2769-4542","979-8-3503-8562-5","10.1109/ICICT62343.2024.00044","Florida Gulf Coast University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10541483","Global Security;Deepfakes;Deepfake detection;CNN;Versatile Deepfake Dataset;Video manipulation detection","Training;Deep learning;Deepfakes;Privacy;Social networking (online);Terrorism;Pressing","","4","","41","USGov","3 Jun 2024","15-17 March 2024","15-17 March 2024","IEEE","IEEE Conferences"
"FAClue: Exploring Frequency Clues by Adaptive Frequency-Attention for Deepfake Detection","W. Liang; Y. Wu; J. Wu; J. Xu","College of Artificial Intelligence, Nankai University, Tianjin, P. R. China; College of Artificial Intelligence, Nankai University, Tianjin, P. R. China; College of Artificial Intelligence, Nankai University, Tianjin, P. R. China; College of Artificial Intelligence, Nankai University, Tianjin, P. R. China",2023 42nd Chinese Control Conference (CCC),"18 Sep 2023","2023","","","7621","7626","Detecting fake faces produced by face forgery technologies attracts intensive attention in recent years. Deep learning approaches have shown their effectiveness in deepfake detection task. Some previous deep learning-based methods exploit forgery artifacts in spatial domain but easily overfit the specific forgery patterns. Therefore, some works utilize additional frequency domain information to obtain generalized features. We consider to improve the frequency-based methods in two aspects: 1) extracting discriminative frequency features comprehensively; 2) mining complementary features in different domains sufficiently. In this paper, we propose a dual-stream network named FAClue for deepfake detection, which extracts comprehensive frequency information to complement spatial domain features. Specifically, the FAClue consists of three main components. A Frequency-Attention Extractor (FAE) is proposed to adaptively highlight prominent frequency bands from both global and local perspectives. A RGB-Frequency Complementary Enhancement (RFCE) module is developed to mine complementary information between RGB and frequency domains in an explicit manner. A Frequency Guided Attention (FGA) module is designed to fuse different domain features and generate discriminative features for detection. Extensive experiments on three benchmark datasets demonstrate the FAClue achieves competitive performance compared with state-of-the-art methods.","1934-1768","978-988-75815-4-3","10.23919/CCC58697.2023.10240940","National Natural Science Foundation of China(grant numbers:62002177); Natural Science Foundation of Tianjin City(grant numbers:19JCQNJC00300,21JCYBJC00110); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10240940","Deepfake Detection;Frequency Domain;Attention Mechanism;Feature Fusion","Learning systems;Deepfakes;Visualization;Fuses;Frequency-domain analysis;Benchmark testing;Feature extraction","","1","","40","","18 Sep 2023","24-26 July 2023","24-26 July 2023","IEEE","IEEE Conferences"
"Coexistence of Deepfake Defenses: Addressing the Poisoning Challenge","J. Park; L. H. Park; H. E. Ahn; T. Kwon","Graduate School of Information, Yonsei University, Seoul, South Korea; Graduate School of Information, Yonsei University, Seoul, South Korea; Graduate School of Information, Yonsei University, Seoul, South Korea; Graduate School of Information, Yonsei University, Seoul, South Korea",IEEE Access,"25 Jan 2024","2024","12","","11674","11687","As Generative Adversarial Networks advance, deepfakes have become increasingly realistic, thereby escalating societal, economic, and political threats. In confronting these heightened risks, the research community has identified two promising defensive strategies: proactive deepfake disruption and reactive deepfake detection. Typically, proactive and reactive defenses coexist, each addressing the shortcomings of the other. However, this paper brings to the fore a critical yet overlooked issue associated with the simultaneous deployment of these deepfake countermeasures. Genuine images gathered from the Internet, already imbued with disrupting perturbations, can lead to data poisoning in the training datasets of deepfake detection models, thereby severely affecting detection accuracy. We propose an improved training framework to address this problem in deepfake detection models. Our approach involves purifying the disrupting perturbations in disruptive images using a backward process of the denoising diffusion probabilistic model (DDPM). Images purified using our DDPM-based technique closely mimic the original, unperturbed images, thereby enabling the successful generation of deepfake images for training purposes. Moreover, our purification process outperforms DiffPure, a prominent adversarial purification method, in terms of speed. While conventional defensive techniques struggle to preserve detection accuracy in the face of a poisoned training dataset, our framework markedly reduces this accuracy drop, thus achieving superior performance across a range of detection models. Our experiments demonstrate that deepfake detection models trained using our framework exhibit an increase in detection accuracy ranging from 11.24%p to 45.72%p when compared to models trained with the DiffPure method. Our implementation is available at https://github.com/seclab-yonsei/Anti-disrupt.","2169-3536","","10.1109/ACCESS.2024.3353785","Institute of Information and Communications Technology Planning and Evaluation (IITP); Korea Government through the Ministry of Science and Information and Communications Technology (MSIT), South Korea, (Advanced and Proactive AI Platform Research and Development Against Malicious Deepfakes)(grant numbers:RS-2023-00230337); MSIT under the Information Technology Research Center (ITRC) Support Program supervised by IITP(grant numbers:IITP-2023-2020-0-01602); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10399770","Deepfake;deepfake detection;deepfake disruption;data poisoning;adversarial purification","Deepfakes;Biological system modeling;Training;Perturbation methods;Security;Computer crime;Purification","","10","","127","CCBYNCND","15 Jan 2024","2024","","IEEE","IEEE Journals"
"A Multi-Layer Capsule-based Forensics Model for Fake Detection of Digital Visual Media","S. S. Khalil; S. M. Youssef; S. N. Saleh","Computer Engineering Department, College of Engineering and Technology, Arab Academy for Science, Technology and Maritime Transport, Abu Qir, Alexandria, Egypt; Computer Engineering Department, College of Engineering and Technology, Arab Academy for Science, Technology and Maritime Transport, Abu Qir, Alexandria, Egypt; Computer Engineering Department, College of Engineering and Technology, Arab Academy for Science, Technology and Maritime Transport, Abu Qir, Alexandria, Egypt","2020 International Conference on Communications, Signal Processing, and their Applications (ICCSPA)","2 Apr 2021","2021","","","1","6","The dangers generated from synthesized multimedia are increasing every day. The creation of the so-called Deepfakes multimedia is vastly evolving, making the detection task harder every day. Researchers and corporations are interested in exploring the technology limits and are coming up with new tools every year to create more robust fake media. In this paper, a new enhanced fake video detection model is introduced addressing many of the face-swapping threats and the low generalization problem. A preprocessing stage is proposed to minimize the noise in the data to enhance their quality. The proposed architecture uses a modified application of capsule neural networks (CapsNet) with an enhanced routing technique. It does not require a lot of training data and generates a small number of training parameters making it fast to build. The model was trained and tested using the DFDC-P dataset and the results have proven that it outperformed other detectors in terms of detection recall, weighted precision, and F1 score.","","978-1-7281-6535-6","10.1109/ICCSPA49915.2021.9385719","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9385719","deepfake detection;capsule network;capsnet","Training;Visualization;Training data;Media;Tools;Videos;Information integrity","","8","","41","IEEE","2 Apr 2021","16-18 March 2021","16-18 March 2021","IEEE","IEEE Conferences"
"Mixture of Experts Fusion for Fake Audio Detection Using Frozen wav2vec 2.0","Z. Wang; R. Fu; Z. Wen; J. Tao; X. Wang; Y. Xie; X. Qi; S. Shi; Y. Lu; Y. Liu; C. Li; X. Liu; G. Li","University of Chinese Academy of Sciences, Beijing, China; Institute of Automation, Chinese Academy of Science, Beijing, China; Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing, China; Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; Institute of Automation, Chinese Academy of Science, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; Shanghai Polytechnic University, China; University of Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; AI Lab, Tencent, Beijing, China; Institute of Automation, Chinese Academy of Science, Beijing, China; Institute of Automation, Chinese Academy of Science, Beijing, China","ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","7 Mar 2025","2025","","","1","5","Speech synthesis technology has posed a serious threat to speaker verification systems. Currently, the most effective fake audio detection methods utilize pretrained models, and integrating features from various layers of pretrained model further enhances detection performance. However, most of the previously proposed fusion methods require fine-tuning the pretrained models, resulting in excessively long training times and hindering model iteration when facing new speech synthesis technology. To address this issue, this paper proposes a feature fusion method based on the Mixture of Experts, which extracts and integrates features relevant to fake audio detection from layer features, guided by a gating network based on the last layer feature, while freezing the pretrained model. Experiments conducted on the ASVspoof2019 and ASVspoof2021 datasets demonstrate that the proposed method achieves competitive performance compared to those requiring fine-tuning.","2379-190X","979-8-3503-6874-1","10.1109/ICASSP49660.2025.10888990","National Natural Science Foundation of China; National Social Science Fund of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10888990","Fake Audio Detection;Mixture of Experts;Pretrained Model;Wav2Vec 2.0;Audio DeepFake Detection","Training;Deepfakes;Analytical models;Signal processing;Feature extraction;Acoustics;Speech synthesis","","6","","33","IEEE","7 Mar 2025","6-11 April 2025","6-11 April 2025","IEEE","IEEE Conferences"
"Generalizable Audio Deepfake Detection via Latent Space Refinement and Augmentation","W. Huang; Y. Gu; Z. Wang; H. Zhu; Y. Qian","AI Institute Department of Computer Science and Engineering, Auditory Cognition and Computational Acoustics Lab, MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University, Shanghai, China; Ant Group, Shanghai, China; Ant Group, Shanghai, China; Ant Group, Shanghai, China; AI Institute Department of Computer Science and Engineering, Auditory Cognition and Computational Acoustics Lab, MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University, Shanghai, China","ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","7 Mar 2025","2025","","","1","5","Advances in speech synthesis technologies, like text-to-speech (TTS) and voice conversion (VC), have made detecting deepfake speech increasingly challenging. Spoofing countermeasures often struggle to generalize effectively, particularly when faced with unseen attacks. To address this, we propose a novel strategy that integrates Latent Space Refinement (LSR) and Latent Space Augmentation (LSA) to improve the generalization of deepfake detection systems. LSR introduces multiple learnable prototypes for the spoof class, refining the latent space to better capture the intricate variations within spoofed data. LSA further diversifies spoofed data representations by applying augmentation techniques directly in the latent space, enabling the model to learn a broader range of spoofing patterns. We evaluated our approach on four representative datasets, i.e. ASVspoof 2019 LA, ASVspoof 2021 LA and DF, and In-The-Wild. The results show that LSR and LSA perform well individually, and their integration achieves competitive results, matching or surpassing current state-of-the-art methods.","2379-190X","979-8-3503-6874-1","10.1109/ICASSP49660.2025.10888328","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10888328","audio deepfake detection;anti-spoofing;generalization","Deepfakes;Refining;Prototypes;Data visualization;Signal processing;Robustness;Data models;Acoustics;Text to speech","","4","","29","IEEE","7 Mar 2025","6-11 April 2025","6-11 April 2025","IEEE","IEEE Conferences"
"Deep fake Image Detection Based on Deep Learning Using a Hybrid CNN-LSTM with Machine Learning Architectures as Classifier","O. A. H. H. Al-Dulaimi; S. Kurnaz","Department of Electrical & Computer Engineering Institute of Graduate Studies, Altinbas University, Istanbul, Turkey; Department of Electrical & Computer Engineering Institute of Graduate Studies, Altinbas University, Istanbul, Turkey","2024 International Congress on Human-Computer Interaction, Optimization and Robotic Applications (HORA)","12 Jun 2024","2024","","","1","7","One of the most important and difficult subjects in social communication is detecting deepfake images and videos. Deepfake techniques have developed widely, making this technology quite available and proficient enough so that there is worry about its bad application. Considering this issue, discovering fake faces is very important for ensuring security and preventing sociopolitical issues on a private and general level. Deep learning provides higher performance than typical image processing approaches when it comes to deepfake detection. This work presents construction of an artificial intelligence system, which is capable of detecting deepfake from more than one dataset. This study proposes neural network models based on deep learning using random forest (RF) and support vector machines (SVM) as classifier for deepfake detection. The use of two classifiers (RF) and (SVM) and their combination with a convolutional neural network is the first study of its kind in the field of deepfake detection in images from three open-source datasets (FaceForensics++, FaceAntiSpoofing, and iFakeFaceDB). This proposed method shows an accuracy of 96%, 87% and 52% in iFakeFaceDB, CelebA-Spoof, FaceForensics++ and respectively.","","979-8-3503-9463-4","10.1109/HORA61326.2024.10550728","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10550728","Convolutional neural network;DeepFake detection;Machine learning","Support vector machines;Deep learning;Training;Deepfakes;Soft sensors;Data models;Convolutional neural networks","","4","","34","IEEE","12 Jun 2024","23-25 May 2024","23-25 May 2024","IEEE","IEEE Conferences"
"EfficientNet-Based Deepfake Detection: A Robust Approach for Real and Fake Media Classification","E. Jain; D. Kundra","Centre for Research Impact & Outcome, Chitkara University Institute of Engineering and Technology, Chitkara University, Rajpura, Punjab, India; Chitkara Centre for Research and Development, Chitkara University, Himachal Pradesh, India",2024 Global Conference on Communications and Information Technologies (GCCIT),"6 Feb 2025","2024","","","1","6","Deepfakes are an up-and-coming form of synthetic media-previously unrealistically realistic video, image, audio, or even live broadcast montaging faces or voices to create an impression of likeness. While opening new ways of creative expression, deepfakes create serious problems in many domains: misinformation, identity theft, defamation-the list increasingly goes on-jeopardizing the reliability of visual evidence in the modern world. As manipulations grow more and more sophisticated, the need to apply effective detection methods is critical. The present work is devoted to the application of the deep convolutional neural network EfficientNetB0 for deepfake detection. EfficientNetB0 is a scalable and computationally efficient architecture that will be applied in the differentiation of real and manipulated images by subtle irregularities in facial features and textures often invisible to the human naked eye. This model is trained on both real and deepfake images, with its optimized configuration to find these minute differences. Data augmentation techniques combined with regularization techniques, including dropout and global average pooling, enhance the capability of the model for generalization over diverse datasets. It achieved 90% on both training and validation, hence did a great job in detecting deepfakes. The confusion matrix further justifies the efficiency of the model in correctly classifying real and fake images. EfficientNetB0 has tremendous potential and can be very useful as a tool in mitigating risks due to manipulated media by helping one contribute toward preserving digital information integrity in an ever-evolving landscape.","","979-8-3503-8891-6","10.1109/GCCIT63234.2024.10862025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10862025","Deepfake Detection;EfficientNet;Deep Learning;Misinformation;Image Manipulation;Neural Networks","Training;Deepfakes;Visualization;Solid modeling;Accuracy;Solids;Data models;Robustness;Optimization;Overfitting","","2","","15","IEEE","6 Feb 2025","25-26 Oct. 2024","25-26 Oct. 2024","IEEE","IEEE Conferences"
"Attention-Enhanced CNN for High-Performance Deepfake Detection: A Multi-Dataset Study","S. Dasgupta; K. Badal; S. Chittam; M. Tasnim Alam; K. Roy","Department of Computer Science, North Carolina A&T State University, Greensboro, NC, USA; Department of Computer Science, North Carolina A&T State University, Greensboro, NC, USA; Department of Computer Science, North Carolina A&T State University, Greensboro, NC, USA; Department of Computer Science, North Carolina A&T State University, Greensboro, NC, USA; Department of Computer Science, North Carolina A&T State University, Greensboro, NC, USA",IEEE Access,"16 Jun 2025","2025","13","","101980","101993","Deepfakes, which emerge from advanced deep learning techniques, present complex ethical and security challenges across media and communication landscapes. While offering creative potential in education and entertainment, synthetic media technologies simultaneously threaten societal trust through potential misinformation, opinion manipulation, privacy violations, and identity fraud. With the advancement of deep learning models, creating deepfake images has become easier and more convincing, resulting in the development of reliable deepfake detection models. This research works with a method that combines multi-head self-attention (MHSA) with a custom-designed convolutional neural network (CNN) to develop a robust deepfake detection model. We created a dataset called the Center for Cyber Defense DeepFake (CCDDF) dataset by generating fake images using publicly available Artificial Intelligence (AI) tools and trained our model on these data, achieving a detection accuracy of 97% and an AUC score of 99.58. Additionally, we evaluated our model on the 140K Real and Fake Faces dataset and the Celeb-DF v2 dataset, where it demonstrated exceptional performance with accuracies of 98% and 94% respectively, and corresponding AUC scores of 99.75 and 98.72. We utilized attention heatmap visualizations to analyze the model’s decision-making process to enhance qualitative interpretability. Our results demonstrate the effectiveness of combining multi-head self-attention with a convolutional neural network for deepfake detection, highlighting its strong performance across multiple datasets and its potential for real-world applications.","2169-3536","","10.1109/ACCESS.2025.3578343","National Science Foundation (NSF)(grant numbers:1900187); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029187","Deepfake detection;convolutional neural networks (CNNs);multi-head self attention (MHSA);attention heatmap visualization;hybrid CNN-attention model","Deepfakes;Convolutional neural networks;Feature extraction;Accuracy;Computational modeling;Computer architecture;Training;Deep learning;Data models;Analytical models","","1","","58","CCBY","10 Jun 2025","2025","","IEEE","IEEE Journals"
"Deepfake Technologies in Financial Fraud: Generation, Detection, and Mitigation Strategies","A. Shetye; N. Jain; S. Borade; V. Kumar","Information Technology, Shah and Anchor Kutchhi Engineering College, Mumbai, India; Cyber Security, Shah and Anchor Kutchhi Engineering College, Mumbai, India; Cyber Security, Shah and Anchor Kutchhi Engineering College; Cyberpeace Foundation",2025 Global Conference in Emerging Technology (GINOTECH),"17 Jul 2025","2025","","","1","6","As audio and video deepfake technologies advance, their application in financial fraud has become a pressing concern for individuals, institutions, and regulators. This comprehensive survey explores the methods employed in the generation of deepfake content specifically for fraudulent purposes, as well as the detection techniques designed to combat such threats. We categorize deepfake generation methods, including voice synthesis, facial reenactment, and synthetic media creation, detailing the underlying algorithms and their potential exploitation in schemes like identity theft, phishing, and unauthorized transactions. In addition, we analyze various detection strategies that leverage machine learning, signal processing, and forensic analysis to identify deepfake content. The survey highlights the challenges faced in detecting increasingly sophisticated deepfakes, such as data scarcity, the evolving nature of fraud tactics, and the necessity for real-time detection capabilities. We also discuss regulatory and ethical implications, emphasizing the importance of developing robust frameworks for accountability and transparency. By presenting a holistic view of the current state of financial fraud related to deepfake technologies, this survey aims to inform stakeholders and stimulate further research in prevention and detection methodologies, ultimately contributing to a safer financial ecosystem.","","979-8-3315-0775-6","10.1109/GINOTECH63460.2025.11076798","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11076798","deepfake generation;deepfake detection;financial fraud","Surveys;Deepfakes;Regulators;Prevention and mitigation;Finance;Signal processing algorithms;Pressing;Signal processing;Real-time systems;Stakeholders","","1","","56","IEEE","17 Jul 2025","9-11 May 2025","9-11 May 2025","IEEE","IEEE Conferences"
"Enhancing Deepfake Detection Through Hybrid MobileNet-LSTM Model with Real-Time Image and Video Analysis","V. S. Anandhasivam; A. K. Anusri; M. Logeshwar; R. Gopinath","Computer Science and Engineering, K. S. Rangasamy College of Technology, Tiruchengode, India; Computer Science and Engineering, K. S. Rangasamy College of Technology, Tiruchengode, India; Computer Science and Engineering, K. S. Rangasamy College of Technology, Tiruchengode, India; Computer Science and Engineering, K. S. Rangasamy College of Technology, Tiruchengode, India",2024 4th International Conference on Ubiquitous Computing and Intelligent Information Systems (ICUIS),"13 Feb 2025","2024","","","1989","1995","The race to crush information integrity and public trust is being won by one thing: deepfakes, AI manipulated media. The goal is to enhance the Deepfake detection using MobileNet V3 and LSTM network. MobileNet's lightweight CNN architecture is able to induce the visual features in an image by an image and in a video and can pick up the slight visual clues of textures and facial structure. Some temporal inconsistencies that cannot be seen by image base methods are then analyzed using an LSTM network. The hybrid model is trained on real and deepfake media datasets, and is thus adaptable to emerging deepfake techniques. This has a user face interface to analyze the real time and fly media to get the analysis and analysis score and visual feedback of the identified artifacts. Unique to this system is its versatility for images and videos, and its real time capability, making it a suitable choice for practical use in social media, journalism, and law enforcement combating the spread of misinformation with a guarantee of digital media authenticity","","979-8-3315-2963-5","10.1109/ICUIS64676.2024.10867159","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10867159","media integrity;real-time detection;temporal modeling;image analysis;video analysis;mobilenet-lstm;deepfake detection","Deepfakes;Visualization;Analytical models;Adaptation models;Accuracy;Social networking (online);Media;Streaming media;Real-time systems;Long short term memory","","1","","19","IEEE","13 Feb 2025","12-13 Dec. 2024","12-13 Dec. 2024","IEEE","IEEE Conferences"
"Efficient Deepfake Detection Using Convolutional Neural Network","D. Samal; P. Agrawal; V. Madaan; V. Goyal","School of Computer Applications Lovely Professional University, Punjab, India; School of Computer Science & Engineering Lovely Professional University, Punjab, India; School of Computer Science & Engineering Lovely Professional University, Punjab, India; Department of Computer Science, University Punjabi University India, Punjab, India","2025 International Conference on Intelligent Control, Computing and Communications (IC3)","16 Apr 2025","2025","","","187","192","In recent times, generative AI has advanced quickly, and Generative Adversarial Network (GAN) has been used to create realistic-looking fake multimedia. It is still quite difficult to identify these Artificial Intelligence (AI) generated fake photos. Therefore, the proliferation of fake media incites fear in social groups and can harm a person's or community's reputation by influencing public attitudes and perceptions about them. The Convolution Neural Network (CNN) is a useful weapon for combating deepfakes. While the majority of approaches use image datasets with a few images and pre-trained models to demonstrate the fake detection accuracy, this paper presents an efficient CNN architecture, which is trained and tested on a balanced dataset of over 1,40,000 images namely 140k Real and Fake Faces dataset available on Kaggle, comprising 1,00,000 training images and 40,000 test and validation images combined. The proposed CNN model's learning rate is increased by applying an adam optimizer and sparse-categorical cross entropy. With a validation accuracy of 95.40%, a testing accuracy of 95.18% and an Area Under Curve (AUC) score of 0.98, the specially trained CNN model establishes a new standard for the identification and categorization of deepfake images.","","979-8-3315-2749-5","10.1109/IC363308.2025.10957581","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10957581","deepfake detection;GAN;CNN;real image;fake image;proposed model","Training;Deepfakes;Adaptation models;Accuracy;Computational modeling;Weapons;Computer architecture;Generative adversarial networks;Data models;Convolutional neural networks","","1","","18","IEEE","16 Apr 2025","13-14 Feb. 2025","13-14 Feb. 2025","IEEE","IEEE Conferences"
"Cross-Domain Deepfake Detection Based on Latent Domain Knowledge Distillation","C. Wang; L. Meng; Z. Xia; N. Ren; B. Ma","Key Laboratory of Computing Power Network and Information Security, Ministry of Education, Shandong Computer Science Center, Qilu University of Technology (Shandong Academy of Sciences), Jinan, China; Key Laboratory of Computing Power Network and Information Security, Ministry of Education, Shandong Computer Science Center, Qilu University of Technology (Shandong Academy of Sciences), Jinan, China; Key Laboratory of Computing Power Network and Information Security, Ministry of Education, Shandong Computer Science Center, Qilu University of Technology (Shandong Academy of Sciences), Jinan, China; College of Information, Shenyang Institute of Engineering, Shenyang, China; Key Laboratory of Computing Power Network and Information Security, Ministry of Education, Shandong Computer Science Center, Qilu University of Technology (Shandong Academy of Sciences), Jinan, China",IEEE Signal Processing Letters,"27 Feb 2025","2025","32","","896","900","The rapid development of deepfake technology poses challenges to face-centered data security. Existing methods primarily focus on how to transfer deepfake detectors from the source domain to the target domain to handle diverse deepfake techniques. In practical application scenarios, it is usually difficult to access the true and false labels of the source domain. In this letter, we introduce a new adaptation framework called Latent Domain Knowledge Distillation (LDKD) for cross-domain deepfake detection. In the proposed framework, we construct a knowledge distillation structure that includes a student network and a teacher network, which are jointly optimized in a coupled manner to facilitate the model's adaptation to the target domain. Furthermore, to improve the quality of pseudo-labels generated by the teacher network, we propose a Fourier Latent Domain Generation Module (FLGM) and a Stochastic Complementary Mask Module (SCMM). The former is used to generate latent domains to bridge domain differences at the image level, while the latter is employed to mine richer contextual cues for the model. Extensive cross-domain experimental results demonstrate that our method achieves state-of-the-art performance, and the model analysis proves the effectiveness of our key components.","1558-2361","","10.1109/LSP.2025.3540941","National Natural Science Foundation of China(grant numbers:62302249,62272255); Taishan Scholar(grant numbers:tsqn202306251); Shandong Lifting Engineering(grant numbers:SDAST2024QTA086); Shandong Youth Innovation Team(grant numbers:2022KJ124,2024KJH035); Natural Science Foundation of Shandong Province(grant numbers:ZR2023QF032,ZR2022LZH011); Ability Improvement Project of Science and Technology SMES in Shandong Province(grant numbers:2023TSGC0217,2022TSGC2485); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10882912","Cross-domain deepfake detection;Fourier latent domain generation;knowledge distillation;stochastic complementary mask","Deepfakes;Adaptation models;Stochastic processes;Predictive models;Data models;Context modeling;Training;Forgery;Detectors;Knowledge engineering","","1","","34","IEEE","11 Feb 2025","2025","","IEEE","IEEE Journals"
"Hybrid Deep Learning for Detecting Fake Medical Images and Heart Sounds.","P. Soundarya; R. Vijayalakshmi; P. P. Dharshini","dept of Computer Science and Engineering, Velammal College of Engineering and Technology, Madurai, India; dept of Computer Science and Engineering, Velammal College of Engineering and Technology, Madurai, India; dept of Computer Science and Engineering, Velammal College of Engineering and Technology, Madurai, India","2025 Eleventh International Conference on Bio Signals, Images, and Instrumentation (ICBSII)","29 May 2025","2025","","","1","6","The rapid development of deepfake technology has raised serious concerns in numerous fields, particularly in healthcare, where manipulating medical data could compromise patient safety and undermine the reliability of diagnostic processes. This study presents innovative methodology for identifying deepfake alterations in medical images and audio, focusing on MRI and CT scans and heart sound recordings. The proposed system integrates advanced image and audio processing techniques to detect synthetic modifications. Medical images undergo pre-processing steps such as resizing, grayscale conversion, noise injection, and data augmentation, while heart sounds are examined using feature extraction techniques like the Zero Crossing Rate. To detect manipulated regions in images, YOLOv8 is employed, followed by classification through deep-learning models like VGG-19 and ResNet-50. Important metrics are implemented to assess the system’s performance, namely accuracy 99.7, precision 86.6, recall 92.8, F1-score 89.6, error rate 0.215, and confusion matrix, ensuring comprehensive assessment of its reliability. Outcomes highlight effectiveness of this approach in identifying deepfake medical data with high accuracy 99.7, offering a vital solution for maintaining the integrity of healthcare diagnostics in the face of evolving threats from synthetic data manipulation.","2768-6450","979-8-3315-1386-3","10.1109/ICBSII65145.2025.11013282","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11013282","Medical deepfake detection;Image processing;Audio processing;Deep learning;Hybrid approach;ResNet-50;VGG-19;Yolov8","Heart;Deep learning;Deepfakes;Accuracy;Medical services;Safety;Recording;Reliability;Medical diagnostic imaging;Synthetic data","","","","17","IEEE","29 May 2025","26-28 March 2025","26-28 March 2025","IEEE","IEEE Conferences"
"Deepfake Detection Using Advanced Learning Frameworks and Benchmark Evaluation","M. B; J. N; N. P; T. J; T. Mohapatra","Artificial Intelligence & Data Science, K.S. School of Engineering and Management, Bengaluru, India; Artificial Intelligence & Data Science, K.S. School of Engineering and Management, Bengaluru, India; Artificial Intelligence & Data Science, K.S. School of Engineering and Management, Bengaluru, India; Artificial Intelligence & Data Science, K.S. School of Engineering and Management, Bengaluru, India; Artificial Intelligence & Data Science, K.S. School of Engineering and Management, Bengaluru, India","2025 IEEE International Conference on Compute, Control, Network & Photonics (ICCCNP)","14 Nov 2025","2025","","","1","6","Recent advances in generative AI have produced highly realistic fake images and videos, exacerbating misinformation and security risks. Deepfake detection methods can be categorized into traditional ML (e.g. SVMs, decision trees with handcrafted features), supervised deep learning (CNNs, RNNs/LSTMs, EfficientNet, etc.), and self-supervised learning techniques (e.g. contrastive learning with attention mechanisms). Popular benchmarks – FaceForensics++, Celeb-DF, DFDC and others – provide large video datasets for evaluation, but they embed specific artifacts and demographic biases. In practice, detectors also face challenges of overfitting, large model size, computational cost, and dependence on extensive labeled data, all of which hinder real-time deployment. Emerging solutions aim to overcome these gaps. For example, attention-based and transformer models (often lightweight) have been used to capture subtle spatiotemporal inconsistencies, improving robustness to post-processing. Multimodal fusion (combining visual, audio, or textual cues) and domain-adaptive training have also been explored to reduce bias and enhance generalization. This survey synthesizes these trends – outlining a structured taxonomy of approaches, reviewing benchmark datasets and their limits, and highlighting challenges (generalization, bias, performance) and promising directions (attention mechanisms, multimodal and domain-adaptive learning) in deepfake detection.","","979-8-3315-3539-1","10.1109/ICCCNP63914.2025.11233705","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11233705","Deepfake detection;GAN;CNN;LSTM;FaceForensics++;DFDC","Training;Surveys;Deepfakes;Visualization;Attention mechanisms;Computational modeling;Taxonomy;Benchmark testing;Transformers;Spatiotemporal phenomena","","","","20","IEEE","14 Nov 2025","18-19 Sept. 2025","18-19 Sept. 2025","IEEE","IEEE Conferences"
"AWaveFormer: Audio Wavelet Transformer Network for Generalized Audio Deepfake Detection","R. Wang; Z. Chen; B. Wang; Z. Ba; K. Ren","School of Information and Communication Engineering, Dalian University of Technology, Dalian, Liaoning, China; School of Information and Communication Engineering, Dalian University of Technology, Dalian, Liaoning, China; School of Information and Communication Engineering, Dalian University of Technology, Dalian, Liaoning, China; School of Cyber Science and Technology, Zhejiang University, Hangzhou, Zhejiang, China; School of Cyber Science and Technology, Zhejiang University, Hangzhou, Zhejiang, China","IEEE Transactions on Audio, Speech and Language Processing","2 Oct 2025","2025","33","","4020","4032","Rapid advancements in speech synthesis technology have made it easier to produce realistic synthetic speech, which poses serious threats to public privacy and security. Recent studies have investigated pre-trained models for feature extraction and adopted advanced architectures, including convolutional and graph neural networks, for deepfake detection. Although these methods improve detection performance to some extent, their generalization and robustness still face challenges. To address this issue, in this paper, we propose a forgery detection method based on the fusion of dual pre-trained features and an optimized Transformer architecture. Specifically, we use a cross-attention mechanism to fuse the audio features extracted from pre-trained Wav2vec 2.0 and WavLM, and replace the token mixer in the traditional Transformer architecture with wavelet transform and multi-scale pooling operations. By combining dual pre-trained features, we extract more comprehensive and discriminative features while optimizing the Transformer architecture, which not only reduces time complexity but also enhances detection performance. We conducted experiments on several datasets, and the results show that our model achieves impressive detection performance with EERs of 0.13%, 2.33%, 3.63%, 10.25%, 5.15%, and 0.21% on the ASVspoof 2019LA, ASVspoof 2021LA, ASVspoof 2021DF, In-the-Wild, Fake-or-Real, and ASVspoof 2015LA evaluation datasets, respectively.","2998-4173","","10.1109/TASLPRO.2025.3611229","National Natural Science Foundation of China(grant numbers:62372452); Youth Innovation Promotion Association of the Chinese Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11168216","Audio deepfake detection;multi-scale learning;Wav2Vec 2.0;WavLM;wavelet transform","Feature extraction;Deepfakes;Wavelet transforms;Transformers;Computer architecture;Speech processing;Speech synthesis;Computational efficiency;Computational modeling;Training","","","","54","IEEE","17 Sep 2025","2025","","IEEE","IEEE Journals"
"Enhancing Deepfake Detection with CBAM-Integrated CNN Models","M. I. Haider; U. Singh","Department of Computer Science and Engineering, Defence Institute of Advanced Technology, Pune, India; Department of Computer Science and Engineering, Defence Institute of Advanced Technology, Pune, India",2025 3rd International Conference on Inventive Computing and Informatics (ICICI),"15 Jul 2025","2025","","","630","635","The proliferation of deepfake content poses a growing threat to public trust, digital security, and information integrity. This paper presents a novel deepfake detection approach based on a Convolutional Neural Network enhanced with a Convolutional Block Attention Module (CBAM-CNN). Unlike traditional models that rely on broad visual cues or handcrafted features, the proposed architecture leverages attention mechanisms to selectively amplify manipulation-specific signals in both spatial and channel dimensions. We evaluate our model on a reduced version of the OpenForen-sics dataset, which includes high-resolution, diverse manipulations created through a GAN-based face-swapping pipeline with refined blending masks. The proposed CBAM-CNN achieves an AUC of 0.958 and an overall accuracy of 89%, outperforming baseline CNN architectures in precision and consistency. By reducing false positives and adapting effectively to complex facial forgeries, our approach demonstrates strong generalization and reliability across unseen test samples. This work contributes to the advancement of secure AI applications and digital media forensics by offering an interpretable, efficient, and scalable solution for deepfake detection.","","979-8-3315-3830-9","10.1109/ICICI65870.2025.11069856","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11069856","Deepfake detection;CBAM-CNN;Convolutional Neural Networks;GANs","Training;Deepfakes;Attention mechanisms;Computational modeling;Computer architecture;Media;Real-time systems;Forgery;Computational efficiency;Convolutional neural networks","","","","18","IEEE","15 Jul 2025","4-6 June 2025","4-6 June 2025","IEEE","IEEE Conferences"
"Detection of Real and Manipulated Videos using the Transfer Learning Approach of Deep-Learning Models","B. R. Reddy; D. C. Rup; M. Rohith; M. Belwal","Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Bengaluru, India; Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Bengaluru, India; Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Bengaluru, India; Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Bengaluru, India",2024 5th IEEE Global Conference for Advancement in Technology (GCAT),"20 Mar 2025","2024","","","1","7","Deepfake (manipulated images and videos) identification is critical in multimedia forensics, as it can spread misinformation, threaten privacy, and have legal implications. To address this problem, researchers and practitioners are developing deepfake detection techniques that use deep-learning models and computer vision algorithms to analyse the authenticity of images and videos. This study proposes a novel approach providing robust and scalable deepfake detection by using transfer learning in feature extraction and deep-learning models to train features extracted from the video dataset. The transfer-learning has been experimented with the ResNet, XceptionNet, and VGG16 models for feature extractions. Further, the deep-learning models Long short-term memory (LSTM) and Bidirectional long short-term memory (Bi-LSTM) have been experimented with to train the extracted features. To rigorously test the proposed approach, the data set under the experiment combined the three benchmark datasets - The Deepfake Detection Challenge (DFDC), Celeb-DF, and Face-Forensics++ datasets. The prediction rate achieved was 96 % and above on average by the proposed approach for the datasets under consideration for the experiments. The proposed approach performs better than the state-of-the-art techniques, gaining a higher accuracy of 96% and above.","","979-8-3503-7668-5","10.1109/GCAT62922.2024.10924003","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10924003","Computer Vision;XceptionNet;ResNet;VGG16;Deepfake Detection;Deep Learning;Transfer Learning","Deep learning;Deepfakes;Computer vision;Privacy;Computational modeling;Forensics;Transfer learning;Streaming media;Feature extraction;Long short term memory","","","","35","IEEE","20 Mar 2025","4-6 Oct. 2024","4-6 Oct. 2024","IEEE","IEEE Conferences"
"Deepfake Detection for Enhanced Security in Workplace Environments Using Deep Learning Techniques","M. Asaduzzaman; M. M. Hassan; T. Bhuiyan","Department of Software Engineering, Daffodil International University, Dhaka, Bangladesh; Dept. of Computer Science & Engineering, Southeast University, Bangladesh; School of IT, Washington University of Science & Technology, Virginia, USA",2025 8th International Conference on Information and Computer Technologies (ICICT),"3 Jul 2025","2025","","","173","179","Deepfake technology's widespread use poses serious risks to workplace security by eroding confidence and making it easier for nefarious actions including identity theft, data breaches, and disinformation. Even while current detection techniques make use of sophisticated deep learning models, their generalisability, computing efficiency, and resilience to hostile attacks sometimes cause them to fail in practical applications. In order to improve identification accuracy and liveness verification, this study presents a unique hybrid detection framework that combines face and speech features with feature-level fusion and multimodal biometric analysis. The suggested system is excellent at identifying subtle deepfake changes because it integrates convolutional neural networks (CNNs) for feature extraction and a Bi-LSTM-based classifier for temporal analysis. Additionally, the framework uses a multi-task learning approach that makes it possible to detect and locate deepfake artefacts simultaneously, enhancing the performance and interpretability of the model. Tested on extensive datasets, including DeepfakeTIMIT and AVSpeech, the system obtained a detection accuracy of 98.7%, exceeding state-of-the-art approaches. This strategy shows a lot of promise for implementation in work settings, offering strong defence against new threats while maintaining user privacy and operational scalability. Future research will examine real-time deployment and edge computing technologies for extensive workplace applications.","2769-4542","979-8-3315-0518-9","10.1109/ICICT64582.2025.00033","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11058521","Deepfake Detection;Workplace Security;Deep Learning Techniques;Multimodal Biometrics;CNN-RNN Hybrid Model;Liveness Detection;Adversarial Resilience","Deep learning;Biometrics;Deepfakes;Accuracy;Computational modeling;Biological system modeling;Employment;Feature extraction;Real-time systems;Resilience","","","","22","IEEE","3 Jul 2025","14-16 March 2025","14-16 March 2025","IEEE","IEEE Conferences"
"Towards Deepfake Detection for Everyone: A Lightweight Deepfake Detection Algorithm (LiDD)","A. Krishnan; A. Basu","Cox School of Business, Southern Methodist University, Dallas, TX, USA; Cox School of Business, Southern Methodist University, Dallas, TX, USA",2025 IEEE Conference on Artificial Intelligence (CAI),"7 Jul 2025","2025","","","1168","1174","Modern AI technologies such as Autoencoders, Generative Adversarial Networks (GANs), and Diffusion Models have advanced Deepfake content generation remarkably over the past few years. The risks associated with malicious deepfakes have motivated significant advances in methods for detecting deepfake content, but the most effective methods require substantial computational resources and processing time. Unfortunately, while deepfake generation does not typically face time constraints, deepfake detection methods are unlikely to be broadly adopted unless they are efficient even on modest computing devices. In this paper, we propose a lightweight algorithm for deepfake detection that achieves impressive performance on various reference deepfaking techniques, even though it utilizes relatively sophisticated deep learning models with over 4 M parameters, and even on modest CPU-based laptop computers. This approach paves the way for integration into public infrastructures like web browsers and multimedia players, advancing global efforts to combat digital disinformation and strengthen the security of online platforms.","","979-8-3315-2400-5","10.1109/CAI64502.2025.00293","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050625","Deepfake detection;Lightweight algorithm;Resource-constrained;Deep learning;Public infrastructure","Deep learning;Performance evaluation;Deepfakes;Portable computers;Public infrastructure;Vectors;Real-time systems;Multisensory integration;Time factors;Security","","","","39","IEEE","7 Jul 2025","5-7 May 2025","5-7 May 2025","IEEE","IEEE Conferences"
"SpectralFusionNet: Adaptive Frequency-Spatial Feature Fusion for Robust Deepfake Detection","X. Song; C. Wu; Z. Liu","School of Information Science and Engineering, Linyi University, Linyi, China; School of Information Science and Engineering, Linyi University, Linyi, China; School of Information Science and Engineering, Linyi University, Linyi, China",2025 IEEE 8th International Conference on Electronic Information and Communication Technology (ICEICT),"17 Sep 2025","2025","","","484","489","With the rapid advancement of Generative Adversarial Networks (GANs), deepfake technology poses significant threats to social trust and information security, while current detection methods suffer from limited generalization ability, single feature dependency, and insufficient environmental robustness. To address these challenges, this paper proposes SpectralFusion-Net (SFN), a novel deepfake detection framework that adaptively fuses frequency domain and spatial domain. SFN introduces four key innovations: (1) An end-to-end fusion architecture enabling dynamic interaction between frequency-spatial domain features, (2) a frequency domain dynamic selection network that adaptively evaluates the importance of different frequency components, (3) a dual-channel attention fusion strategy for effective integration of complex frequency spectrum components, and (4) an adaptive frequency domain mask generation mechanism for flexible adaptation to different forgery types. Extensive experiments on DFFD and FaceForensics++ datasets demonstrate that SFN achieves superior performance with 96.05% average accuracy on FF++ and maintains 90.46% accuracy under heavy compression scenarios (c40), significantly outperforming existing methods in detection accuracy, generalization ability, and environmental robustness, particularly when facing unknown forgery types and low-quality images.","2836-7782","979-8-3315-9505-0","10.1109/ICEICT66683.2025.11159858","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11159858","Deepfake detection;Frequency domain analysis;Feature fusion;Attention mechanism;Generative adversarial networks","Deepfakes;Accuracy;Image coding;Attention mechanisms;Frequency-domain analysis;Zero shot learning;Feature extraction;Generative adversarial networks;Forgery;Robustness","","","","33","IEEE","17 Sep 2025","26-28 July 2025","26-28 July 2025","IEEE","IEEE Conferences"
"Defeating Multimodal Information Manipulation By A Web 3.0 Decentralized Identity (DID)-Based Accountability Framework","X. Wang; H. Qiu; J. Shen; W. Chen; A. Choi; W. Zhao","Department of Computer Science, Florida Polytechnic University, Lakeland, FL, USA; Department of Engineering Technology, Fort Valley State University, Fort Valley, GA, USA; Department of Engineering Technology, SUNY Polytechnic Institute, Utica, NY, USA; Department of Information Systems and Technology Management, Slippery Rock University of Pennsylvania, PA, USA; Department of Electrical & Computer Engineering, Mercer University, Macon, GA, USA; Department of Electrical and Computer Engineering, Cleveland State University, Cleveland, OH, USA",2025 IEEE World AI IoT Congress (AIIoT),"12 Aug 2025","2025","","","0359","0364","Multimodal information manipulation such as deep-fake videos, AI-generated text, has become a critical threat in the digital age. While deep learning-based detection models have shown promise, they suffer from generalization failures when faced with out-of-distribution samples. This paper proposes a paradigm shift: instead of relying solely on detection, we leverage Web 3.0 Decentralized Identifiers (DIDs) to enforce accountability across the entire information dissemination chain, from content creators to Internet Service Providers (ISPs), platforms, and end-users. By binding each actor to a cryptographically verifiable identity, our framework ensures traceability, tamper-proof provenance, and economic disincentives for malicious behavior. We detail the architecture, enforcement mechanisms, and advantages over traditional methods, demonstrating how DID-based systems can mitigate manipulation proactively rather than reactively.","","979-8-3315-2508-8","10.1109/AIIoT65859.2025.11105270","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11105270","Multimodal manipulation;Deepfake detection;Generalization failure;Decentralized Identifiers (DIDs);Cryptographic verification;Tamper-proof provenance;Proactive mitigation","Semantic Web;Deepfakes;Protocols;Prevention and mitigation;Scalability;Web and internet services;Information age;Internet of Things;Interoperability;Lenses","","","","32","IEEE","12 Aug 2025","28-30 May 2025","28-30 May 2025","IEEE","IEEE Conferences"
"Teacher-Student Structure for Domain Adaptation in Ensemble Audio-Visual Video Deepfake Detection","E. Abolhasani; M. Ramezani; H. R. Rabieei","Department of Computer Engineering, Sharif University of Technology; Department of Computer Engineering, Sharif University of Technology; Department of Computer Engineering, Sharif University of Technology",IEEE Transactions on Artificial Intelligence,"","2025","PP","99","1","10","The rapid advancement of generative AI models is leading to more realistic deepfake media, encompassing the manipulation of audio, video, or both. This raises severe privacy and societal concerns. Numerous studies in this area have yielded promising intra-domain results; however, these models frequently exhibit decreased efficacy when faced with data from dissimilar domains. Consequently, recent deepfake detection approaches focus on enhancing the generalization ability through multiple techniques that incorporate all input modalities, including audio, images, and their interactions. In this regard, we propose the EAV-DFD method, a generalized deep ensemble audiovisual model (EAV-DFD) combined with a domain adaptation mechanism utilizing a teacher-student framework to enhance the model’s ability to perform and generalize effectively across unseen domains. To evaluate the model’s performance, we used the FakeAVCeleb dataset as the primary domain and the DFDC, Deepfake_TIMIT, and PolyGlotFake datasets as an unseen domain. Our experimental results demonstrate that the proposed framework is efficient in domain adaptation, improving AUC performance of the model by 4.09%, 17.94%, and 0.5% on three unseen datasets, using only a small portion of them to train the student model. This leads to a novel deepfake detection model capable of adapting to new domains and interpreting which modality has been manipulated, highlighting the potential of our approach for real-world applications.","2691-4581","","10.1109/TAI.2025.3642217","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11293372","Deepfake Detection;Ensemble Learning;Audio-Visual;Domain Adaptation;Teacher-Student","Adaptation models;Deepfakes;Visualization;Feature extraction;Videos;Data models;Transformers;Solid modeling;Training;Media","","","","","IEEE","10 Dec 2025","","","IEEE","IEEE Early Access Articles"
"Smartphone-based Deepfake Detection Through Transfer Learning and Lightweight Knowledge Distillation Technique","S. S. Khan; R. Hossain; S. H. Bishal; R. Khan","Electrical and Computer Engineering, North South University, Dhaka, Bangladesh; Electrical and Computer Engineering, North South University, Dhaka, Bangladesh; Electrical and Computer Engineering, North South University, Dhaka, Bangladesh; Electrical and Computer Engineering, North South University, Dhaka, Bangladesh",2024 27th International Conference on Computer and Information Technology (ICCIT),"10 Jun 2025","2024","","","675","680","The advancement of artificial intelligence technology has been growing rapidly. Generative adversarial network, a subfield of artificial intelligence technology, generates fake faces with more realistic features, which are much harder to identify by human beings. Deepfake is the concept used to describe the creation or alteration of films, images, or audio using artificial intelligence or machine learning methods to mislead or deceive audiences. In this study, we proposed an image classification model that can classify deepfake images with a higher level of accuracy. The developed model in this research attempts to use a custom CNN model, Knowledge Distillation technique, and pre-trained models. Pre-trained models are used to avoid the computational cost of training a CNN from scratch. The images of deepfake employed in this work were fed into the deep convolutional neural network without extensive preprocessing, and the deep features from the images were extracted in several layers. The hyperparameters of the custom CNN model have been optimized using the cuckoo search optimization (CSO)-based metaheuristic technique. The Xception and DenseNet models achieved the best performances with test accuracies of 99% and 98%, respectively. The mean training time of Knowledge Distillation is 115 seconds for every epoch, significantly lower than other models. The Knowledge Distillation model has been utilized to expand the deepfake detection system into a website and Android smartphone application due to its small number of parameters and lowest training time. Finally, the developed mobile application was evaluated by 50 volunteers.","2474-9656","979-8-3315-1909-4","10.1109/ICCIT64611.2024.11022522","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11022522","Deep Learning;deepfake detection;image classification;knowledge distillation;transfer learning","Training;Knowledge engineering;Deep learning;Deepfakes;Accuracy;Computational modeling;Transfer learning;Metaheuristics;Convolutional neural networks;Image classification","","","","20","IEEE","10 Jun 2025","20-22 Dec. 2024","20-22 Dec. 2024","IEEE","IEEE Conferences"
"Deep Fake Detection with Hybrid Activation Function Enabled Adaptive Milvus Optimization-Based Deep Convolutional Neural Network","H. Mashetty; N. Erukulla; S. Belidhe; N. Jella; V. r. Pishati; B. K. Enesheti","AI Research Independent Researcher, GA; Enterprise Data Analytics, Duluth, GA; Information Technology Independent Researcher; Information Technology Independent Researcher; Information Technology Independent Researcher; Information Technology Independent Researcher",2025 6th International Conference on Mobile Computing and Sustainable Informatics (ICMCSI),"20 Feb 2025","2025","","","1159","1166","Deep fake detection plays an essential role in digital world platforms that effectively identify the fake content of audio and video streams, which disseminated more on social media platforms in recent years. Several researchers have undertaken to detect the fake context, which faced certain challenges such as information authentication, media security, stolen identities, damaging someone's personal life, and so on. Thus, to enhance the detection accuracy and to overcome the challenges of existing methods, the Hybrid activation function enabled adaptive Milvus optimization-based Deep Convolutional Neural Network (HA2MilO-DCN) model is developed in the research. The integration of the hybrid activation function with the base DCNN model effectively enhanced the scalability and efficiency to achieve the desired detection results. Furthermore, the adaptive Milvus optimization (AMilO) effectively tunes the hyperparameter of the model, which is inspired by the social behavior of Milvus and aids in attaining prominent detection outcomes. Therefore, the HA2MilO-DCN attains a high range of detection accuracy with performance metrics such as Accuracy, Recall, and Precision. Under the utilization of the Faceforensics++ dataset, the model attains effective detection outcomes when compared with other conventional methods. The obtained evaluation metrics values are 95.72%, 94.91%, and 96.52% respectively.","","979-8-3315-2266-7","10.1109/ICMCSI64620.2025.10883193","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10883193","Deepfake detection;Deep Convolutional Neural network;Adaptive Milvus optimization;Audio signals;Video streams","Measurement;Adaptation models;Deepfakes;Accuracy;Adaptive systems;Social networking (online);Streaming media;Convolutional neural networks;Time complexity;Streams","","","","28","IEEE","20 Feb 2025","7-8 Jan. 2025","7-8 Jan. 2025","IEEE","IEEE Conferences"
"Beyond Accuracy: Explainable Multimodal Deepfake Detection Through Cross-Modal Feature Analysis and Dynamic Attention Weighting","T. Rahman; R. Chakma; T. Mahmud","Department of Computer Science and Engineering, Rangamati Science and Technology University; Department of Computer Science and Engineering, Rangamati Science and Technology University; Department of Computer Science and Engineering, Rangamati Science and Technology University","2025 International Conference on Quantum Photonics, Artificial Intelligence, and Networking (QPAIN)","29 Sep 2025","2025","","","1","6","The advent of deepfake technology in recent years has significantly transformed the domain of video synthesis, facilitating the production of convincing synthetic films. The study explains a method for detecting deepfakes that uses both visual and sound analysis with special neural networks and a technique that combines the two types of information. We have a system that uses an EfficientNetB0- based CNN to analyze face images and a bidirectional LSTM to process audio features, showing that combining both types of data makes detection stronger than using just one type. Our research on the AVLips dataset shows that different types of data learn in different ways-visual features help with quick learning at first but are more likely to overfit, while audio features lead to a more consistent learning process. Using explainable AI methods, we find that visual deepfake signs are mainly seen around the eyes and mouth, while specific MFCC coefficients (specifically 2 and 9) offer important distinguishing information in the audio part. The fusion model attains an accuracy of 87.25 %, surpassing the visual-only model at 85.25 % and the audio-only model at 81 %. In addition to performance measurements, our study offers important information regarding feature relevance across modalities and illustrates how attention mechanisms may adjust modality contributions depending on the reliability of individual samples. This study improves the field by highlighting the benefits of understanding multimodal methods and identifying specific patterns across different types of data that characterize deepfake content.","","979-8-3315-9694-1","10.1109/QPAIN66474.2025.11171737","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11171737","CNN;EfficientNetBO;LSTM;MFCC;AVLips;Deepfake Detection;Multimodal","Deepfakes;Visualization;Accuracy;Attention mechanisms;Mouth;Production;Media;Feature extraction;Robustness;Mel frequency cepstral coefficient","","","","24","IEEE","29 Sep 2025","31 July-2 Aug. 2025","31 July-2 Aug. 2025","IEEE","IEEE Conferences"
"Flexible Multi-Modality Deepfake Identification with Dynamic Learning and Cross-Modality Inconsistency","E. J. J; K. K. P; M. S. M; R. J","Department of Information Technology, Velammal College of Engineering & Technology, Madurai, India; Department of Information Technology, Velammal College of Engineering & Technology, Madurai, India; Department of Information Technology, Velammal College of Engineering & Technology, Madurai, India; Department of Information Technology, Velammal College of Engineering & Technology, Madurai, India","2025 3rd International Conference on Advancements in Electrical, Electronics, Communication, Computing and Automation (ICAECA)","2 Jun 2025","2025","","","1","6","Rapid advances in generative models, that produce hyper-realistic modifications of photos and videos, have contributed to deepfake detection more difficult. Current detection approaches are very costly, making real-time detection difficult, and they often suffer with generalization, particularly when faced with unknown deepfake techniques. An Adaptive Multi-Modality Framework is proposed, presenting a unique set of methods for reliable and effective deepfake detection in order to overcome these drawbacks. The framework incorporates Self-Supervised Patch-Based Learning for smooth detection of localized manipulations, Dynamic Discriminator Learning (DDL) in adaptively evolve against new deepfake generation techniques, and Cross-Modality Inconsistency Scoring (CMIS) to detect anomalies across spatial, temporal, and audio-visual domains. The Inconsistency Score (IS), a novel metric that measures the probability of modified material, unifies these elements. This method allows for real-time application, improves detection accuracy, and guarantees flexibility in response to new threats. The investigations reveal that the proposed method has the potential to transform fake identification techniques by surpassing state-of-the-art techniques.","","979-8-3315-2543-9","10.1109/ICAECA63854.2025.11012276","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11012276","Cross-Modality Inconsistency Scoring;Adaptive Deepfake Detection;Dynamic Discriminator Learning","Training;Deepfakes;Accuracy;Transforms;Self-supervised learning;Real-time systems;Telecommunication computing;Security;Reliability;Standards","","","","15","IEEE","2 Jun 2025","4-5 April 2025","4-5 April 2025","IEEE","IEEE Conferences"
"Deepfake Video Detection: A Comprehensive Survey of Advanced Machine Learning and Deep Learning Techniques to Combat Synthetic Video Manipulation","T. Anusha; A. Srinagesh","Department of CSE, Acharya Nagarjuna University, Guntur, Andhra Pradesh, INDIA; Department of CSBS, R.V.R. & J.C College of Engineering, Guntur, Andhra Pradesh, INDIA",2025 International Conference on Multi-Agent Systems for Collaborative Intelligence (ICMSCI),"27 Feb 2025","2025","","","1033","1041","The detection of deepfake videos has become a critical area of research due to the widespread use of manipulated content across digital platforms. With the increasing sophistication of generative models deepfake videos have reached a level of realism that makes them challenging to detect. This survey paper provides an extensive review of 70 research papers published from 2021 to 2024, categorizing the existing detection techniques into three primary groups such as supervised learning techniques, unsupervised learning techniques, and hybrid methods. These methods leverage labelled datasets to train models to identify subtle artefacts in manipulated videos. Notable advancements have been made by integrating CNNs with RNNs to capture both spatial and temporal patterns, enhancing detection accuracy. Unsupervised learning techniques, such as clustering algorithms and anomaly detection methods, are increasingly being explored for deepfake detection. Hybrid methods combine the strengths of both supervised and unsupervised techniques, improving detection performance. CNN-RNN architectures integrated with attention mechanisms are an example, as they enhance the focus on manipulated regions within videos. Additionally, multimodal approaches that combine both visual and audio cues have been introduced to address the complexity of detecting deepfakes across various media types. This review identifies the challenges faced by current detection systems, such as limitations in datasets, high computational costs, and a lack of robustness against evolving manipulation techniques. To address these challenges, future research should focus on developing more diverse datasets, enhancing the generalizability of models, and improving computational efficiency to support real-time applications. The most promising approach for advancing deepfake detection systems involves integrating multi-modal techniques, advanced deep learning architectures, and scalable designs.","","979-8-3315-0982-8","10.1109/ICMSCI62561.2025.10894187","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10894187","Deepfake detection;Supervised learning;Unsupervised learning;Hybrid methods;Generative Adversarial Networks;Convolutional Neural Networks;Recurrent Neural Networks","Surveys;Measurement;Deepfakes;Reviews;Supervised learning;Neural networks;Media;Robustness;Real-time systems;Unsupervised learning","","","","40","IEEE","27 Feb 2025","20-22 Jan. 2025","20-22 Jan. 2025","IEEE","IEEE Conferences"
"Inference-Time Noise Addition for Improving Adversarial Robustness of Audio Deepfake Detection System","I. Kim; T. -P. Doan; S. Hong; S. Jung","Soongsil University, Seoul, South Korea; Soongsil University, Seoul, South Korea; Oregon State University, Corvallis, OR, USA; Soongsil University, Seoul, South Korea",IEEE Access,"2 Dec 2025","2025","13","","200669","200682","As artificial intelligence technology advances, the generalization performance of audio deepfake detection systems has improved rapidly and significantly. However, these systems still face substantial challenges when confronted with adversarial attacks. To address this issue, many studies have proposed defense methods against such attacks. Nevertheless, only a limited number of studies have focused on defenses in the context of audio deepfake detection. With the development of deep learning, deepfake detection methods are increasingly designed and deployed based on deep learning models. As a result, deepfake detection systems can be applied across various fields and are not restricted to specific data types or domains. Such approaches are referred to as ‘domain-independent’ defense methods and can be applied to a wide range of tasks, including adversarial training. However, they have limitations, such as requiring significant computing resources or potentially degrading original performance. In this paper, we propose Inference-Time Noise Addition (ITNA), an effective and efficient adversarial attack defense method that minimizes the original performance degradation. ITNA adds Gaussian noise once to the input audio sample during the inference phase. It is highly resource efficient, as it does not require additional training or separate AI components. Furthermore, ITNA minimizes performance degradation as much as possible and provides scalability that can be used with other defense methods. We provide a theoretical explanation of the effectiveness of ITNA and validate it through experimental results. Our experiments were conducted on the ASVspoof2021 DF evaluation (official deepfake audio dataset from the ASVspoof community), In-The-Wild (collected in real environments) and DSD-Corpus datasets (includes various synthesizer samples). And experiments results demonstrate the effectiveness of ITNA, reducing the average misclassification rate and the attack success rate of detection systems by 4.48% and 31.90%, respectively. We also demonstrate the effectiveness of ITNA through comparative experiments with alternative noise type and existing noise-based defense method.","2169-3536","","10.1109/ACCESS.2025.3635633","Institute of Information and Communications Technology Planning and Evaluation (IITP) grant funded by Korean Government [Ministry of Science and Information and Communication Technology (MSIT)] (Advanced and Proactive AI Platform Research and Development Against Malicious Deepfakes, 50%)(grant numbers:RS-2023-00230337); Institute of Information and Communications Technology Planning and Evaluation (IITP) grant funded by Korean Government (MSIT) (Robust Deepfake Audio Detection Development Against Adversarial Attacks, 50%)(grant numbers:RS-2023-00263037); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11263781","Adversarial attack defense;audio deepfake detection;inference-time noise addition","Deepfakes;Glass box;Closed box;Perturbation methods;Data models;Computational modeling;Feature extraction;Deep learning;Robustness;Predictive models","","","","91","CCBY","21 Nov 2025","2025","","IEEE","IEEE Journals"
