Jiajia Li, Ziyi Pan, Teng Xiao, Ping Wang, Qibiao Hu, Jingrui Hou,
EmoSense: A multimodal sentiment-aware framework for music short video AI-generated content detection,
Information Processing & Management,
Volume 63, Issue 2, Part B,
2026,
104473,
ISSN 0306-4573,
https://doi.org/10.1016/j.ipm.2025.104473.
(https://www.sciencedirect.com/science/article/pii/S0306457325004145)
Abstract: The rapid spread of AI-generated content (AIGC) music short videos on social media has introduced new challenges for information authenticity and public trust. Although existing studies have explored multimodal detection techniques, they often fail to model the nuanced emotional and semantic interplay between modalities—particularly the alignment between musical affect and visual-textual content. Such limitations significantly hinder detection accuracy in complex, sentiment-rich AIGC scenarios. To address these challenges, we propose EmoSense, a sentiment-aware framework tailored for music short video AIGC detection. EmoSense comprises two key modules: a Sentiment Alignment Module that models emotional-semantic coherence across text, audio, and visuals via cross-modal embedding, and a Trace Analysis Module that detects spatial–temporal inconsistencies characteristic of synthetic content. Additionally, A deep fusion strategy further enhances cross-modal complementarity, improving both robustness and generalization. To support evaluation, we introduce MSV-AIGC, a real-world, human-annotated multimodal dataset containing 2912 labeled samples (1562 authentic and 1350 AI-generated), covering aligned those modalities. Experimental results show that EmoSense outperforms state-of-the-art baseline on this dataset, achieving 2.27% gains in accuracy and surpassing GPT-4V by 10.7%, highlighting its robustness in detecting synthetic music short videos.
Keywords: Multimodal; AI-generated content detection; Sentiment analysis; Music short video; Feature fusion

Mubarak Alrashoud,
Deepfake video detection methods, approaches, and challenges,
Alexandria Engineering Journal,
Volume 125,
2025,
Pages 265-277,
ISSN 1110-0168,
https://doi.org/10.1016/j.aej.2025.04.007.
(https://www.sciencedirect.com/science/article/pii/S111001682500465X)
Abstract: Deepfake technology creates highly realistic manipulated videos using deep learning models, which makes distinguishing between authentic and fake content extremely difficult. This technology can negatively affect society by breaching privacy and spreading misinformation. This paper presents a comprehensive survey of the recent deepfake video detection approaches and methods. Each deepfake video method is analyzed according to its ability to generalize diverse deepfake fabrication techniques and real-world scenes. We reviewed around 103 articles which eventually shrunk down to 73 based on the screening criteria like abstract/title/irrelevant focus/duplication. The study primarily covers audio-based, visual-based, and multi-modal detection methods. Also, it discusses the usage of Convolutional Neural Networks (CNNs), frequency-domain analysis, and audio-visual synchronization in deepfake video detection and evaluates the strengths and shortcomings of these techniques. Moreover, the study explores major issues such as low resolution, video compression, and adversarial attacks, which prove to be a barrier to making deepfake video detection processes robust. By connecting findings from numerous studies, this research draws attention to the development of standard benchmarking SOPs and multi-modal detection techniques to improve detection performance.
Keywords: Deepfake video detection; CNNs; Frequency-domain analysis; Multi-modal detection; Adversarial attacks; Video compression; Audio-visual synchronization

Diya Garg, Rupali Gill,
Unmasking Deepfakes: A Review of Current Datasets, Tools, and Detection Features,
Procedia Computer Science,
Volume 259,
2025,
Pages 1737-1748,
ISSN 1877-0509,
https://doi.org/10.1016/j.procs.2025.04.129.
(https://www.sciencedirect.com/science/article/pii/S1877050925012311)
Abstract: Deepfake technology is a new way to alter digital content and create videos that look very real. The responsible use of deepfake technology is essential, as its inappropriate application can lead to significant consequences, from harming individual’s reputations to influencing public opinion. Nowadays, this technology is being misused for spreading false information or deceiving people as well, making it crucial to develop an effective method for the detection of synthetic media. The current research focuses on various aspects such as datasets, features, tools, and techniques used in field of deepfake detection. Further investigation of gaps like lack of multi-modal approach, less work on hybrid models, and unseen datasets associated with current research work has also been done. The existing deep learning models being used for deepfake detection faces several challenges. There is no such model that works well with the different types of datasets. Also, the methods used to create deepfakes are changing quickly, making it even more difficult for existing detection models to obtain better performance. In order to overcome the challenges, it is proposed to design a hybrid learning framework for deepfake detection using a multi-modal approach.
Keywords: Deepfake; Detection; Deep learning; Fake; Video forgery; Image forgery

Shubham Sharma, Arvind Selwal,
Improved Deepfake Detection with Optimized Preprocessing for Low-Quality Images,
Procedia Computer Science,
Volume 258,
2025,
Pages 507-516,
ISSN 1877-0509,
https://doi.org/10.1016/j.procs.2025.04.286.
(https://www.sciencedirect.com/science/article/pii/S1877050925013882)
Abstract: Deepfake detection has been one of the fastest-growing areas of research due to the increasing threat manipulated media is posing to the world. One of the major challenges still underlying this problem, it remains poorly researched how to detect deepfakes in low-quality images[1]. In this paper, a framework is proposed to enhance the Mesonet model in the detection of deepfakes using the implementation of a preprocessing optimization layer. This layer refines the quality of input images through an enhanced preprocessing layer. In our experiments, deepfake images were generated from a DCGAN model trained on the CelebA dataset, simulating the real-world scenarios of low-quality deepfakes. Our framework was tested on a dataset comprising 1,000 low-quality real images and 1,000 low-quality deepfake images, also derived from the CelebA dataset. Accuracy was found to increase from 69.40% to 92.50% in the optimized model. Moreover, the area under the ROC curve increased from 0.75—75% to 0.96—96%, also improving the model’s discriminatory power very much. These results shed light on the proportion of preprocessing-related optimizations for performance improvement in deepfake detection. This work has contributed to the deepfake detection methodology with robust ways to improve model performance under very challenging conditions. While the research has significantly enhanced the detection which can be seen when dealing with low quality-wire etc., there are still some issues associated with the complexity of the approach. This extra requirement makes the demand for additional computing more critical. Intuitively, the researchers could direct future works towards seeking more flexible and efficient optimization without sacrificing the desirable accuracy and the ability to use limited resources.
Keywords: Deepfake Detection; Low-Quality Images; Mesonet Model; DCGAN; Image Enhancement; Deep Learning

 Preeti, Manoj Kumar, Hitesh Kumar Sharma,
A GAN-Based Model of Deepfake Detection in Social Media,
Procedia Computer Science,
Volume 218,
2023,
Pages 2153-2162,
ISSN 1877-0509,
https://doi.org/10.1016/j.procs.2023.01.191.
(https://www.sciencedirect.com/science/article/pii/S1877050923001916)
Abstract: DeepFake uses Generative + Adversarial Network for successfully switching the identities of two people. Large public databases and deep learning methods are now rapidly available because of the proliferation of easily accessible tools online. It has resulted in the emergence of very real appealing fake content that produced a bad impact and challenges for society to deal. Pre-trained generative adversarial networks (GANs) that can flawlessly substitute one person's face in a video or image for that other are proving supportive for implementing deepfake. This paper primarily presented a study of methods used to implement deepfake. Also, discuss the main deepfake's manipulation and detection techniques, and the implementation and detection of deepfake using Deep Convolution-based GAN models. A study of Comparative analyses of proposed GAN with other exiting GAN models using parameters Inception Score “IS” and Fréchet Inception Distance “FID” is also embedded. Along with the abovementioned, the paper discusses open issues and future trends that should be considered to advance in the field.
Keywords: Digital Forensics; Image Vision; Deep Learning; Generative adversarial network; Deep Fakes; Media Forensics; Face Manipulation; Face Recognition

Akanbi Bolakale AbdulQudus, Oluwatosin Ahmed Amodu, Umar Ali Bukar, Raja Azlina Raja Mahmood, Anies Faziehan Zakaria, Saki-Ogah Queen, Zurina Mohd Hanapi,
A Contemporary and Comprehensive Bibliometric Exposition on Deepfake Research and Trends,
Computers, Materials and Continua,
Volume 84, Issue 1,
2025,
Pages 153-236,
ISSN 1546-2218,
https://doi.org/10.32604/cmc.2025.061427.
(https://www.sciencedirect.com/science/article/pii/S1546221825005521)
Abstract: This paper provides a comprehensive bibliometric exposition on deepfake research, exploring the intersection of artificial intelligence and deepfakes as well as international collaborations, prominent researchers, organizations, institutions, publications, and key themes. We performed a search on the Web of Science (WoS) database, focusing on Artificial Intelligence and Deepfakes, and filtered the results across 21 research areas, yielding 1412 articles. Using VOSviewer visualization tool, we analyzed this WoS data through keyword co-occurrence graphs, emphasizing on four prominent research themes. Compared with existing bibliometric papers on deepfakes, this paper proceeds to identify and discuss some of the highly cited papers within these themes: deepfake detection, feature extraction, face recognition, and forensics. The discussion highlights key challenges and advancements in deepfake research. Furthermore, this paper also discusses pressing issues surrounding deepfakes such as security, regulation, and datasets. We also provide an analysis of another exhaustive search on Scopus database focusing solely on Deepfakes (while not excluding AI) revealing deep learning as the predominant keyword, underscoring AI’s central role in deepfake research. This comprehensive analysis, encompassing over 500 keywords from 8790 articles, uncovered a wide range of methods, implications, applications, concerns, requirements, challenges, models, tools, datasets, and modalities related to deepfakes. Finally, a discussion on recommendations for policymakers, researchers, and other stakeholders is also provided.
Keywords: Deepfake; bibliometric; deepfake detection; deep learning; recommendations

Thanh Thi Nguyen, Quoc Viet Hung Nguyen, Dung Tien Nguyen, Duc Thanh Nguyen, Thien Huynh-The, Saeid Nahavandi, Thanh Tam Nguyen, Quoc-Viet Pham, Cuong M. Nguyen,
Deep learning for deepfakes creation and detection: A survey,
Computer Vision and Image Understanding,
Volume 223,
2022,
103525,
ISSN 1077-3142,
https://doi.org/10.1016/j.cviu.2022.103525.
(https://www.sciencedirect.com/science/article/pii/S1077314222001114)
Abstract: Deep learning has been successfully applied to solve various complex problems ranging from big data analytics to computer vision and human-level control. Deep learning advances however have also been employed to create software that can cause threats to privacy, democracy and national security. One of those deep learning-powered applications recently emerged is deepfake. Deepfake algorithms can create fake images and videos that humans cannot distinguish them from authentic ones. The proposal of technologies that can automatically detect and assess the integrity of digital visual media is therefore indispensable. This paper presents a survey of algorithms used to create deepfakes and, more importantly, methods proposed to detect deepfakes in the literature to date. We present extensive discussions on challenges, research trends and directions related to deepfake technologies. By reviewing the background of deepfakes and state-of-the-art deepfake detection methods, this study provides a comprehensive overview of deepfake techniques and facilitates the development of new and more robust methods to deal with the increasingly challenging deepfakes.
Keywords: Deepfakes; Face manipulation; Artificial intelligence; Deep learning; Autoencoders; GAN; Forensics; Survey

Gueltoum Bendiab, Houda Haiouni, Isidoros Moulas, Stavros Shiaeles,
Deepfakes in digital media forensics: Generation, AI-based detection and challenges,
Journal of Information Security and Applications,
Volume 88,
2025,
103935,
ISSN 2214-2126,
https://doi.org/10.1016/j.jisa.2024.103935.
(https://www.sciencedirect.com/science/article/pii/S2214212624002370)
Abstract: Deepfake technology presents significant challenges for digital media forensics. As deepfakes become increasingly sophisticated, the ability to detect and attribute manipulated media becomes more difficult. The main challenge lies in the realistic and convincing nature of deepfakes, which can deceive human perception and traditional forensic techniques. Furthermore, the widespread availability of open-source deepfake tools and increasing computational power contribute to the ease with which malicious actors can create and disseminate deepfakes. The challenges posed by deepfakes for digital media forensics are multifaceted. Therefore, the development of sophisticated detection algorithms, the creation of comprehensive datasets, and the establishment of legal frameworks are crucial in addressing these challenges. This paper provides a comprehensive analysis of current methods for deepfake generation and the issues surrounding their detection. It also explores the potential of modern AI-based detection techniques in combating the proliferation of deepfakes. This analysis aims to contribute to advancing deepfake detection by highlighting the limits of current detection techniques, the most relevant issues, the upcoming challenges, and suggesting future directions for research.
Keywords: Deepfake; Artificial intelligence; Digital media forensics; Security; Deepfake detection

Pengpeng Yang, Chen Zhou, Dasara Shullani, Lanxi Liu, Daniele Baracchi,
A Comprehensive Review on File Containers-Based Image and Video Forensics,
Computers, Materials and Continua,
Volume 85, Issue 2,
2025,
Pages 2487-2526,
ISSN 1546-2218,
https://doi.org/10.32604/cmc.2025.069129.
(https://www.sciencedirect.com/science/article/pii/S1546221825009105)
Abstract: Images and videos play an increasingly vital role in daily life and are widely utilized as key evidentiary sources in judicial investigations and forensic analysis. Simultaneously, advancements in image and video processing technologies have facilitated the widespread availability of powerful editing tools, such as Deepfakes, enabling anyone to easily create manipulated or fake visual content, which poses an enormous threat to social security and public trust. To verify the authenticity and integrity of images and videos, numerous approaches have been proposed, which are primarily based on content analysis and their effectiveness is susceptible to interference from various image or video post-processing operations. Recent research has highlighted the potential of file containers analysis as a promising forensic approach that offers efficient and interpretable results. However, there is still a lack of review articles on this kind of approach. In order to fill this gap, we present a comprehensive review of file containers-based image and video forensics in this paper. Specifically, we categorize the existing methods into two distinct stages, qualitative analysis and quantitative analysis. In addition, an overall framework is proposed to organize the exiting approaches. Then, the advantages and disadvantages of the schemes used across different forensic tasks are provided. Finally, we outline the trends in this research area, aiming to provide valuable insights and technical guidance for future research.
Keywords: Image and video forensics; file containers analysis; content analysis; Deepfakes

Sonam Singh, Amol Dhumane,
Unmasking digital deceptions: An integrative review of deepfake detection, multimedia forensics, and cybersecurity challenges,
MethodsX,
Volume 15,
2025,
103632,
ISSN 2215-0161,
https://doi.org/10.1016/j.mex.2025.103632.
(https://www.sciencedirect.com/science/article/pii/S2215016125004765)
Abstract: Deepfakes, which are driven by developments in generative AI, seriously jeopardize public trust, cybersecurity, and the veracity of information. This study offers a comprehensive analysis of the most recent methods for creating and detecting deepfakes in image, video, and audio modalities. With a focus on their advantages and disadvantages in cross-dataset and real-world scenarios, we compile the latest developments in transformer-based detection models, multimodal biometric defenses, and Generative Adversarial Networks (GANs). We provide implementation-level information such as pseudocode workflows, hyperparameter settings, and preprocessing pipelines for popular detection frameworks to improve reproducibility. We also examine the implications of cybersecurity, including identity theft and biometric spoofing, as well as policy-oriented solutions that incorporate federated learning, explainable AI, and ethical protections. By enriching technical insights with interdisciplinary perspectives, this review charts a roadmap for building robust, scalable, and trustworthy deepfake detection systems.
Keywords: Deepfake detection; Generative adversarial networks (GANs); Synthetic media, biometric spoofing; Cyber security threats; Multimedia forensics; AI policy frameworks; Explainable AI; Federated learning; Digital deception; Face synthesis; Speech cloning; Identity theft; Cross-dataset evaluation; Ethical AI

Walter Matli,
Extending the theory of information poverty to deepfake technology,
International Journal of Information Management Data Insights,
Volume 4, Issue 2,
2024,
100286,
ISSN 2667-0968,
https://doi.org/10.1016/j.jjimei.2024.100286.
(https://www.sciencedirect.com/science/article/pii/S2667096824000752)
Abstract: The advent of deepfake technology has introduced complex challenges to the information technology landscape, simultaneously presenting benefits and novel risks and ethical considerations. This paper delves into the evolution of deepfakes through the prism of information poverty theory, scrutinising how deepfakes may contribute to a growing information access/use inequality. The research focuses on the risks of misinformation and the ensuing expansion of digital divides, particularly when manipulative media could delude individuals lacking access to legitimate information sources. The study outlines the potential exacerbation of information asymmetries and examines the societal implications across various demographics. By integrating an analytical discussion on the risks associated with deepfakes, the study aligns the observed trends with the theoretical underpinnings of information poverty. As part of its contribution, the paper offers actionable policy-making recommendations and educational strategies to combat the proliferation of harmful deepfake content. The article aims to ensure a more equitable distribution of authentic information and foster media literacy. Through a multifaceted approach, this study endeavours to provide a foundational understanding for stakeholders to navigate the ethical minefield posed by deepfakes and to instil a framework for information equity in the digital era. The article provides critical insights into the discourse on deepfake technology and its relation to information poverty, underscoring the urgent need for equitable access to informed digital spaces. As deepfake technology evolves and more data emerges, a societal demand exists for comprehensive knowledge about deepfakes to promote discernment, decision-making and awareness. Policymakers are tasked with recognising the significance of widening access to sophisticated information technologies whilst addressing their negative repercussions. Their efforts will be particularly crucial for disseminating knowledge about deepfakes to those with limited or non-existent information and communication awareness and infrastructures. Learning from past successes and failures becomes pivotal in shaping effective strategies to address the challenges posed by deepfakes and fostering accessible, informed digital communities.
Keywords: Deepfake technology; Information poverty theory; Artificial intelligence (AI); Synthetic media; Societal implications; Technological advancements

Md Tanvir Islam, Ik Hyun Lee, Ahmed Ibrahim Alzahrani, Khan Muhammad,
MEXFIC: A meta ensemble eXplainable approach for AI-synthesized fake image classification,
Alexandria Engineering Journal,
Volume 116,
2025,
Pages 351-363,
ISSN 1110-0168,
https://doi.org/10.1016/j.aej.2024.12.031.
(https://www.sciencedirect.com/science/article/pii/S111001682401617X)
Abstract: In the evolving landscape of artificial intelligence (AI), differentiating between authentic and artificially generated images poses a significant challenge, primarily due to the rapidly enhancing quality of AI-generated images. This paper systematically evaluates state-of-the-art classification models to distinguish authentic images from those synthetically produced using the CIFAKE dataset. We introduce FakeGPT and PFake, two new test datasets featuring genuine and AI-generated synthetic images with specific keywords paralleling the generation of the CIFAKE dataset. We use the transfer learning technique to train the state-of-the-art classification models on the CIFAKE training set, followed by rigorous evaluation against the CIFAKE, FakeGPT, and PFake test datasets. Further, we explore ensemble approaches, including stacking, voting, bagging, and meta-ensemble learning. The culmination of our extensive research efforts is the Meta Ensemble eXplainable Fake Image Classifier (MEXFIC), which stands out with a notable accuracy of 94% and 96.61% against the Stable Diffusion generated CIFAKE and PFake datasets, respectively. This is a significant improvement over the ConvNextLarge model, achieving the highest accuracy of 92.54% among the state-of-the-art models. Our study showcases the competitive edge of MEXFIC that highlights the necessity for more robust models capable of identifying AI-synthesized images, as evidenced by the performance on the challenging FakeGPT dataset.
Keywords: Fake image classification; AI-synthesized image classification; AI-generated image classification; Image authenticity verification; Smart surveillance; CIFAKE

Tuba Arif, David Camacho, Jong Hyuk Park,
Unveiling cybersecurity mysteries: A comprehensive survey on digital forensics trends, threats, and solutions in network security,
Journal of Network and Computer Applications,
Volume 243,
2025,
104296,
ISSN 1084-8045,
https://doi.org/10.1016/j.jnca.2025.104296.
(https://www.sciencedirect.com/science/article/pii/S1084804525001936)
Abstract: The field of digital forensics is undergoing a paradigm shift because security breaches are now occurring outside of conventional domains such as mobile devices, databases, networks, multimedia, cloud platforms, and the Internet of Things (IoT) all require a complete approach. This study report reveals a high level of ambiguities and process redundancies within the subdomains of digital forensics through the completion of a Systematic Literature Review (SLR). To address this, we suggest a high-level theoretical metamodel that unifies tasks, operations, procedures, and methods of research across many subdomains that will help forensic investigators during digital investigations to organize and integrate evidence. The study also discusses the necessity of global perspectives in research on digital forensics and provides a qualitative evaluation of past surveys, highlighting similar difficulties, obstacles, and key issues across domains, whereas earlier surveys concentrated on domains. The findings through examination offer a multidimensional knowledge of the difficulties in digital forensics and suggested metamodels help to create a more cohesive and integrated approach to digital investigations, establishing an environment for further study and collaborations in this crucial domain.
Keywords: Cyber security; Digital forensics; Network security; Artificial intelligence; Data privacy

Michał Choraś, Konstantinos Demestichas, Agata Giełczyk, Álvaro Herrero, Paweł Ksieniewicz, Konstantina Remoundou, Daniel Urda, Michał Woźniak,
Advanced Machine Learning techniques for fake news (online disinformation) detection: A systematic mapping study,
Applied Soft Computing,
Volume 101,
2021,
107050,
ISSN 1568-4946,
https://doi.org/10.1016/j.asoc.2020.107050.
(https://www.sciencedirect.com/science/article/pii/S1568494620309881)
Abstract: Fake news has now grown into a big problem for societies and also a major challenge for people fighting disinformation. This phenomenon plagues democratic elections, reputations of individual persons or organizations, and has negatively impacted citizens, (e.g., during the COVID-19 pandemic in the US or Brazil). Hence, developing effective tools to fight this phenomenon by employing advanced Machine Learning (ML) methods poses a significant challenge. The following paper displays the present body of knowledge on the application of such intelligent tools in the fight against disinformation. It starts by showing the historical perspective and the current role of fake news in the information war. Proposed solutions based solely on the work of experts are analysed and the most important directions of the application of intelligent systems in the detection of misinformation sources are pointed out. Additionally, the paper presents some useful resources (mainly datasets useful when assessing ML solutions for fake news detection) and provides a short overview of the most important R&D projects related to this subject. The main purpose of this work is to analyse the current state of knowledge in detecting fake news; on the one hand to show possible solutions, and on the other hand to identify the main challenges and methodological gaps to motivate future research.
Keywords: Fake news; Machine Learning; Social media; Media content manipulation; Disinformation detection

Ashish Kumar, Divya Singh, Rachna Jain, Deepak Kumar Jain, Chenquan Gan, Xudong Zhao,
Advances in DeepFake detection algorithms: Exploring fusion techniques in single and multi-modal approach,
Information Fusion,
Volume 118,
2025,
102993,
ISSN 1566-2535,
https://doi.org/10.1016/j.inffus.2025.102993.
(https://www.sciencedirect.com/science/article/pii/S1566253525000661)
Abstract: In recent years, generative artificial intelligence has gained momentum and created extremely realistic synthetic multimedia content that can spread misinformation and mislead society. Deepfake detection is a technique consisting of frameworks, algorithms and approaches to predict manipulated contents namely, image, audio and video. To this end, we have analyzed and explored various deepfake detection frameworks by categorizing them as single-modal or multi-modal approaches. To provide better understanding and clarity, single-modal approaches are further categorized as conventional and advanced techniques. Conventional techniques extract complementary handcrafted features and classify them using machine-learning-based algorithms. On the other hand, advanced techniques adopt deep learning and hybrid algorithms to detect deepfakes. Multi-modal techniques utilize a mixture of two or more modalities for feature extraction and fuse them to obtain the final classification scores. These techniques are also categorized either as deep learning or hybrid techniques. The complementary features, multiple modalities, and deep learning models are fused adaptively using score-level or feature-level fusion. The advantages, features, practical applications, and limitations under each category are highlighted to address the challenges and determine future trends to counter deepfakes. In addition, recommendations are also elaborated to evaluate the potential of artificial intelligence in deepfake detection for providing a safer and more reliable digital world.
Keywords: DeepFake; Artificial intelligence; Generative adversarial network; Fusion algorithms; Transformer; Detection

Ramcharan Ramanaharan, Deepani B. Guruge, Johnson I. Agbinya,
DeepFake video detection: Insights into model generalisation — A Systematic review,
Data and Information Management,
Volume 9, Issue 4,
2025,
100099,
ISSN 2543-9251,
https://doi.org/10.1016/j.dim.2025.100099.
(https://www.sciencedirect.com/science/article/pii/S2543925125000075)
Abstract: Deep learning generative models have progressed to a stage where distinguishing fake images and videos has become difficult, posing risks to personal integrity, potentially leading to social instability, and disrupting government functioning. Existing reviews have mainly focused on the approaches used to detect DeepFakes, and the data sets used for those approaches. However, challenges persist when attempting to generalise detection techniques to identify previously unseen datasets. The purpose of this systematic review is to explore state-of-the-art frameworks for DeepFake detection and provide readers with an understanding of the strengths and weaknesses of current approaches, as well as the generalisability of existing detection techniques. The study indicates that generalising DeepFake detection remains a challenge that requires further research. Moreover, 46.3% of the selected publications agreed that DeepFake detection techniques could be generalised to identify various types of DeepFakes. A key limitation in achieving generalisation is the tendency of models to overfit to available data datasets, reducing their effectiveness in adapting to new or unseen types of DeepFakes. This review emphasises the need for the development of extensive and diverse datasets that more accurately reflect the wide range of DeepFake manipulations encountered in real-world applications. Lastly, the paper explores potential advancements that could pave the way to the next generation of solutions against DeepFakes.
Keywords: DeepFake; Detection; Generalisability; Systematic review; Machine learning

Mark S. Nixon, Alberto S. Aguado,
Chapter 5 - Low-level feature extraction (including edge detection)∗,
Editor(s): Mark S. Nixon, Alberto S. Aguado,
Feature Extraction and Image Processing for Computer Vision (Fifth Edition),
Academic Press,
2026,
Pages 213-304,
ISBN 9780443366864,
https://doi.org/10.1016/B978-0-443-36686-4.00013-4.
(https://www.sciencedirect.com/science/article/pii/B9780443366864000134)
Abstract: We shall define low-level features to be those basic features that can be extracted automatically from an image without any shape information (information about spatial relationships). As such, thresholding is actually a form of low-level feature extraction performed as a point operation. Naturally, all of these approaches can be used in high-level feature extraction, where we find shapes in images. There are very basic techniques and more advanced ones, and we shall look at some of the most popular approaches. The first-order detectors are equivalent to first-order differentiation and, naturally, the second-order edge detection operators are equivalent to a one-higher level of differentiation. An alternative form of edge detection is called phase congruency, and we shall again see the frequency domain used to aid analysis; this time for low-level feature extraction. We shall also consider corner detection, which can be thought of as detecting those points where lines bend very sharply with high curvature and saliency, which are important points. These are the other low-level features that again can be extracted automatically from the image. Finally, we shall investigate techniques that describe motion, called optical flow.
Keywords: Canny; Context aware saliency; Corner detection; Correlation; Curvature; DeepFlow; Differential approach; Edge detection; FAST; First and second order operators; Harris; Implementation; Laplacian of Gaussian; Marr-Hildreth; Optical flow; ORB; Phase congruency; Prewitt; Roberts; Saliency; SIFT; Sobel; SURF; Velocity and acceleration; Window size; Zero-crossing detection

Helena Liz-López, Mamadou Keita, Abdelmalik Taleb-Ahmed, Abdenour Hadid, Javier Huertas-Tato, David Camacho,
Generation and detection of manipulated multimodal audiovisual content: Advances, trends and open challenges,
Information Fusion,
Volume 103,
2024,
102103,
ISSN 1566-2535,
https://doi.org/10.1016/j.inffus.2023.102103.
(https://www.sciencedirect.com/science/article/pii/S1566253523004190)
Abstract: Generative deep learning techniques have invaded the public discourse recently. Despite the advantages, the applications to disinformation are concerning as the counter-measures advance slowly. As the manipulation of multimedia content becomes easier, faster, and more credible, developing effective forensics becomes invaluable. Other works have identified this need but neglect that disinformation is inherently multimodal. Overall in this survey, we exhaustively describe modern manipulation and forensic techniques from the lens of video, audio and their multimodal fusion. For manipulation techniques, we give a classification of the most commonly applied manipulations. Generative techniques can be exploited to generate datasets; we provide a list of current datasets useful for forensics. We have reviewed forensic techniques from 2018 to 2023, examined the usage of datasets, and given a comparative analysis of each modality. Finally, we give another comparison of end-to-end forensics tools for end-users. From our analysis clear trends are found with diffusion models, dataset granularity, explainability techniques, synchronisation improvements, and learning task diversity. We find a roadmap of deep challenges ahead, including multilinguality, multimodality, improving data quality (and variety), all in an adversarial ever-changing environment.
Keywords: Multimedia data manipulation generation; Multimedia data forensics; Deep Learning; Video; Audio; Multimodal

Ankit Yadav, Dinesh Kumar Vishwakarma,
Datasets, clues and state-of-the-arts for multimedia forensics: An extensive review,
Expert Systems with Applications,
Volume 249, Part C,
2024,
123756,
ISSN 0957-4174,
https://doi.org/10.1016/j.eswa.2024.123756.
(https://www.sciencedirect.com/science/article/pii/S0957417424006225)
Abstract: With the large chunks of social media data being created daily and the parallel rise of realistic multimedia tampering methods, detecting and localising tampering in images and videos has become essential. This survey focusses on approaches for tampering detection in multimedia data using deep learning models. Specifically, it presents a detailed analysis of publicly available benchmark datasets for malicious manipulation detection. It also offers a comprehensive list of tampering clues and commonly used deep learning architectures. Next, it discusses the current state-of-the-art tampering detection methods, categorizing them into meaningful types such as deepfake detection methods, splice tampering detection methods, copy-move tampering detection methods, etc. and discussing their strengths and weaknesses. Top results achieved on benchmark datasets, comparison of deep learning approaches against traditional methods and critical insights from the recent tampering detection methods are also discussed. Lastly, the research gaps, future direction and conclusion are discussed to provide an in-depth understanding of the tampering detection research arena.
Keywords: Tampering detection; Localization; Forgery; Manipulation; Deep learning; Convolutional neural networks

Mirko Casu, Luca Guarnera, Pasquale Caponnetto, Sebastiano Battiato,
GenAI mirage: The impostor bias and the deepfake detection challenge in the era of artificial illusions,
Forensic Science International: Digital Investigation,
Volume 50,
2024,
301795,
ISSN 2666-2817,
https://doi.org/10.1016/j.fsidi.2024.301795.
(https://www.sciencedirect.com/science/article/pii/S2666281724001197)
Abstract: This paper examines the impact of cognitive biases on decision-making in forensics and digital forensics, exploring biases such as confirmation bias, anchoring bias, and hindsight bias. It assesses existing methods to mitigate biases and improve decision-making, introducing the novel “Impostor Bias”, which arises as a systematic tendency to question the authenticity of multimedia content, such as audio, images, and videos, often assuming they are generated by AI tools. This bias goes beyond evaluators' knowledge levels, as it can lead to erroneous judgments and false accusations, undermining the reliability and credibility of forensic evidence. Impostor Bias stems from an a priori assumption rather than an objective content assessment, and its impact is expected to grow with the increasing realism of AI-generated multimedia products. The paper discusses the potential causes and consequences of Impostor Bias, suggesting strategies for prevention and counteraction. By addressing these topics, this paper aims to provide valuable insights, enhance the objectivity and validity of forensic investigations, and offer recommendations for future research and practical applications to ensure the integrity and reliability of forensic practices.
Keywords: Forensic sciences; Cognitive biases; Cognitive psychology; Digital forensics; Synthetic data; Impostor bias; Generative AI; GAN; Diffusion models; Deepfake detection

Vidya K, Praveen Ramesh, Hrithik Viknesh, Sanjay Devanand,
Compressed Deepfake Detection using Spatio-Temporal Approach with Model Pruning,
Procedia Computer Science,
Volume 230,
2023,
Pages 436-444,
ISSN 1877-0509,
https://doi.org/10.1016/j.procs.2023.12.099.
(https://www.sciencedirect.com/science/article/pii/S187705092302104X)
Abstract: Deepfake is a deep learning technology that replaces source person face photos with the target person face photos in a movie to create a video of the target by executing the actions performed by source person. Due to the limited storage capacity and network bandwidth constraints, compressed media is now commonly employed in social networks. The goal of this research study is to determine whether or not a given compressed video is a deepfake. To do this, both the spatial and temporal components of the video should be considered, and the findings will be integrated by using an appropriate fusion approach. Hence, the deep learning model used in the spatial approach is pruned using the Network Pruning technique to achieve a better performance. The combined prediction of the spatial and temporal approaches indicates whether the given video is deepfake or not.
Keywords: Compressed; Fusion; Pruning; Spatio-Temporal features

Battula Thirumaleshwari Devi, Rajkumar Rajasekaran,
Deepfake Video Detection Using Ada-Boosting on the DFDC Dataset,
Procedia Computer Science,
Volume 258,
2025,
Pages 1091-1101,
ISSN 1877-0509,
https://doi.org/10.1016/j.procs.2025.04.344.
(https://www.sciencedirect.com/science/article/pii/S1877050925014462)
Abstract: The rapid proliferation of deepfake videos, generated using advanced machine learning techniques to create highly realistic but misleading content, poses significant challenges across various sectors, including cybersecurity, media integrity, and personal privacy. Detecting these deepfakes has become essential for maintaining trust in digital media and preventing malicious exploitation. This paper presents a novel approach to deepfake video detection by employing the AdaBoost algorithm, a powerful ensemble learning method recognized for its ability to improve classification performance by focusing on difficult-to-classify instances. Using the Deepfake Detection Challenge (DFDC) dataset, our study demonstrates that the AdaBoost classifier, when coupled with a carefully designed feature set, achieves competitive accuracy in detecting deepfake videos. Our results show that this approach provides an effective solution for deepfake detection, with strong recall performance, making it a viable method for real-world applications.
Keywords: Deepfake detection; AdaBoost; DFDC dataset; ensemble learning; machine learning; video forensics

Lazarus Kwao, Jing Ma, Sophyani Banaamwini Yussif, Matthew Quayson,
MCDF: Multimodal information fusion and causal analysis for election misinformation detection,
Information Fusion,
Volume 125,
2026,
103470,
ISSN 1566-2535,
https://doi.org/10.1016/j.inffus.2025.103470.
(https://www.sciencedirect.com/science/article/pii/S1566253525005433)
Abstract: The rapid spread of election-related misinformation on social media poses a serious threat to public trust, democratic decision-making, and social stability. This form of misinformation is particularly persuasive and difficult to detect as it uses different types of content (modalities), including text, images, captions, and social interactions. These challenges undermine efforts to ensure trustworthy elections and enable timely intervention by policymakers and fact-checkers. However, existing detection approaches struggle with feature misalignment, cross-modal inconsistencies, and noisy social data, thereby limiting their ability to accurately classify misinformation and explain its propagation. To address these challenges, we propose MCDF, a Multimodal Causal Detection Framework, integrating fusion-driven misinformation detection with causal analysis. Our framework consists of three key components: (1) a multimodal rumor detection module, which employs Graph Convolutional Networks (GCNs) for social interaction modeling, Vision Transformers (ViTs) for visual feature extraction, and RoBERTa for text-caption encoding, dynamically aligned via Tensor Fusion Networks (TFNs); (2) a Noise-Gating Mechanism, which refines feature alignment by filtering misleading or redundant inputs, ensuring robust misinformation classification; and (3) DEMATEL, a causal inference module that quantifies misinformation drivers, bridging misinformation classification with explainability. We evaluate our model on Twitter (X), FakeNewsNet (GossipCO and PolitiFact), and a curated Ghana-specific election dataset, demonstrating state-of-the-art performance in both classification and causal inference. MCDF offers a practical and interpretable framework for combating misinformation in real-world political communication, providing actionable insights for electoral stakeholders, fact-checkers, and social media analysts.
Keywords: Multimodal rumor detection; Causal analysis; DEMATEL; African election misinformation; Noise-Gating Mechanisms; Tensor Fusion Networks; Ghana elections

Shubham Sharma, Arvind Selwal,
Potential of artificial intelligence in deepfake media: From generation to detection mechanisms, state-of-the-art, and challenges,
Computer Science Review,
Volume 60,
2026,
100866,
ISSN 1574-0137,
https://doi.org/10.1016/j.cosrev.2025.100866.
(https://www.sciencedirect.com/science/article/pii/S157401372500142X)
Abstract: Artificial intelligence (AI) plays an important role in the generation of deepfakes by leveraging advanced machine learning models to create hyper-realistic synthetic media across visual, audio, and multimodal formats. The rapid evolution of deepfake technologies, alongside the exponential growth of digital media, demands a comprehensive and critical examination of current capabilities and challenges. Although the concept of media manipulation is not new, the sophistication and accessibility of AI-driven deepfakes present significant threats of misinformation to society and hence cause societal manipulation. This manuscript presents a systematic review of deepfake generation and detection techniques from 2017 to 2025, highlighting the progression of generative models and evaluating detection strategies. The main focus of this work is on the state-of-the-art (SOTA) techniques using adversarial networks, vision transformers (ViTs), attention mechanisms, hybrid learning frameworks, and ensemble models. The study thoroughly examines the benefits and drawbacks of existing methods. It also points out how vulnerable detection systems are to adversarial attacks and compares modern methods with traditional forensic and heuristic approaches. The paper critically analyzes the strengths and limitations of existing models, underscores the susceptibility of detection systems to adversarial attacks, and contrasts contemporary approaches with traditional forensic and heuristic-based methods. In addition to technical insights, the review puts a major focus on practical concerns such as scalability, regulatory frameworks, and the broader societal impact of the deepfake technology. By including benchmark datasets, standard tools, performance evaluation metrics, and relevant policy discussions, the manuscript presents a forward-looking perspective on the ongoing arms race between deepfake generation and detection. The study ends by highlighting the need for strong, flexible, and understandable detection systems, backed by effective policy measures, to reduce the growing risks posed by deepfakes.
Keywords: Artificial intelligence; Deep learning; Deepfakes; Deepfake detection; Generative adversarial networks (GAN); Autoencoders; Vision transformers (ViT); Explainable AI

Gaurav Kumar, Chhavi Dhiman,
Decoding fake news fabrications and trends: A comprehensive survey,
Neurocomputing,
Volume 653,
2025,
131118,
ISSN 0925-2312,
https://doi.org/10.1016/j.neucom.2025.131118.
(https://www.sciencedirect.com/science/article/pii/S0925231225017904)
Abstract: Increased internet access has led to a surge in online content across blogs, websites, news portals, and social media, where people actively share personal ideas, opinions, ideologies while seeking information of their interest. However, relying on individual sources can lead to information overload and the spread of unverified data, often shaped by personal biases. This lack of fact-based reliability fuelled the generation and spread of fake news, undermining trust in digital information ecosystems. To tackle these challenges, Fake News Detection (FND) has become a crucial research area, drawing significant attention of experts to develop solutions to combat misinformation and restore trust in online information. This paper provides a comprehensive review of the changing patterns of fake news trends over time, tracing its shift from text to visual and eventually hybrid formats over the past decade. It reviews the generation and propagation of fake news, explores detection methods and highlights the challenges for efficient detection, including how human and algorithmic bias unknowingly contributes to its spread. The paper discusses key research questions and their implications, emphasizing why multimodal sentiment analysis outperforms other methods for detecting complex, malicious intent. It also provides an overview of popular datasets and resources, along with a bibliometric analysis highlighting key authors and leading institutes in the research area. Finally, it discusses the future direction of fake news detection, underscoring the need for continuous advancements in this rapidly evolving domain.
Keywords: News fabrication; Fake news generation (FNG); Fake news propagation (FNP); Fake news detection (FND); Early detection; Changing trends; Social-media; Misinformation; Disinformation; Malinformation; LLMs; XAI; DeepFake

Ehsan Nowroozi, Ali Dehghantanha, Reza M. Parizi, Kim-Kwang Raymond Choo,
A survey of machine learning techniques in adversarial image forensics,
Computers & Security,
Volume 100,
2021,
102092,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2020.102092.
(https://www.sciencedirect.com/science/article/pii/S0167404820303655)
Abstract: Image forensic plays a crucial role in both criminal investigations (e.g., dissemination of fake images to spread racial hate or false narratives about specific ethnicity groups or political campaigns) and civil litigation (e.g., defamation). Increasingly, machine learning approaches are also utilized in image forensics. However, there are also a number of limitations and vulnerabilities associated with machine learning-based approaches (e.g., how to detect adversarial (image) examples), and there are associated real-world consequences (e.g., inadmissible evidence, or wrongful conviction). Therefore, with a focus on image forensics, this paper surveys techniques that can be used to enhance the robustness of machine learning-based binary manipulation detectors in various adversarial scenarios.
Keywords: Image forensics; Adversarial machine learning; Adversarial learning; Adversarial setting; Image manipulation detection; Cyber security

Fakhar Abbas, Araz Taeihagh,
Unmasking deepfakes: A systematic review of deepfake detection and generation techniques using artificial intelligence,
Expert Systems with Applications,
Volume 252, Part B,
2024,
124260,
ISSN 0957-4174,
https://doi.org/10.1016/j.eswa.2024.124260.
(https://www.sciencedirect.com/science/article/pii/S0957417424011266)
Abstract: Due to the fast spread of data through digital media, individuals and societies must assess the reliability of information. Deepfakes are not a novel idea but they are now a widespread phenomenon. The impact of deepfakes and disinformation can range from infuriating individuals to affecting and misleading entire societies and even nations. There are several ways to detect and generate deepfakes online. By conducting a systematic literature analysis, in this study we explore automatic key detection and generation methods, frameworks, algorithms, and tools for identifying deepfakes (audio, images, and videos), and how these approaches can be employed within different situations to counter the spread of deepfakes and the generation of disinformation. Moreover, we explore state-of-the-art frameworks related to deepfakes to understand how emerging machine learning and deep learning approaches affect online disinformation. We also highlight practical challenges and trends in implementing policies to counter deepfakes. Finally, we provide policy recommendations based on analyzing how emerging artificial intelligence (AI) techniques can be employed to detect and generate deepfakes online. This study benefits the community and readers by providing a better understanding of recent developments in deepfake detection and generation frameworks. The study also sheds a light on the potential of AI in relation to deepfakes.
Keywords: Deep learning; Deepfakes; Detection and generation; Artificial Intelligence (AI); Policy recommendations; Literature review

MD Sarfaraz Momin, Abu Sufian, Debaditya Barman, Marco Leo, Cosimo Distante, Naser Damer,
Explainable deepfake detection across different modalities: An overview of methods and challenges,
Image and Vision Computing,
Volume 163,
2025,
105738,
ISSN 0262-8856,
https://doi.org/10.1016/j.imavis.2025.105738.
(https://www.sciencedirect.com/science/article/pii/S0262885625003269)
Abstract: The increasing use of deepfake technology enables the creation of realistic and deceptive content, raising concerns about several serious issues, including biometric authentication, misinformation, politics, privacy, and trust. Many Deepfake Detection (DD) models are entering the market to combat the misuse of deepfakes. With these developments, one primary issue occurs in ensuring the explainability of the proposed detection models to understand the rationale of the decision. This paper aims to investigate the state-of-the-art explainable DD models across multiple modalities, including image, video, audio, and text. Unlike existing surveys that focus on detection methodologies with minimal attention to explainability and limited modality coverage, this paper directly focuses on these gaps. It offers a comprehensive analysis of advanced explainability techniques, including Grad-CAM, LIME, SHAP, LRP, Saliency Maps, and Anchors, for detecting deceptive content across the modalities. It identifies the strengths and limitations of existing models and outlines research directions to enhance explainability and interpretability in future works. By exploring these models, we aim to enhance transparency, provide deeper insights into model decisions, and bridge the gap between detection accuracy with explainability in DD models.
Keywords: Machine learning; Deep learning; Generative AI; Deepfake; Explainable AI

Akshay Agarwal, Nalini Ratha,
Chapter 8 - Manipulating faces for identity theft via morphing and deepfake: Digital privacy,
Editor(s): Venu Govindaraju, Arni S.R. Srinivasa Rao, C.R. Rao,
Handbook of Statistics,
Elsevier,
Volume 48,
2023,
Pages 223-241,
ISSN 0169-7161,
ISBN 9780443184307,
https://doi.org/10.1016/bs.host.2022.12.003.
(https://www.sciencedirect.com/science/article/pii/S016971612200058X)
Abstract: Digital face images can be easily manipulated for obfuscating or impersonating an identity. Several techniques are used for face manipulation, both traditional computer vision based such as morphing, and modern deep learning based such as deepfake. Morphing and deepfake techniques became advanced enough in creating photorealistic face images. Due to that, these techniques pose a serious threat to identity theft and can significantly harm at a personal level such as the risk of reputation and money, and the national level such as interference in the election. In this chapter, we review (i) different stealthy ways of identity threat generation techniques, (ii) popular databases used in this research direction, and (iii) defense algorithms build to detect these manipulated images. We further provide key open challenges which need to be addressed to make the defense algorithms robust, generalized, and to handle the adaptive nature of the attacks.
Keywords: Deepfake; Identity swap; Digital threats; Vulnerability of deep face recognition; Privacy and security

Muhammad Zubair, Saqib Hakak,
Exploring the Landscape of Compressed DeepFakes: Generation, Dataset and Detection,
Neurocomputing,
Volume 619,
2025,
129116,
ISSN 0925-2312,
https://doi.org/10.1016/j.neucom.2024.129116.
(https://www.sciencedirect.com/science/article/pii/S0925231224018873)
Abstract: In today’s era of social media, where information spreads rapidly through platforms like YouTube, Facebook, and Twitter, the development of generative models have given rise to a phenomenon called DeepFakes. This survey aims to provide a comprehensive overview of compressed DeepFakes research, covering various detection and generation techniques and datasets. It presents the details of detection methods, including experimental settings such as datasets, algorithms, feature selection, and results. The survey also highlights the existing challenges and future directions.
Keywords: Fake news; DeepFakes; Social Engineering; MultiMedia Forensics; Forgery detection; GenerativeAI; Compression
