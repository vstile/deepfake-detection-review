"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Any-Resolution AI-Generated Image Detection by Spectral Learning","D. Karageorgiou; S. Papadopoulos; I. Kompatsiaris; E. Gavves","Information Technologies Institute, CERTH, Greece; Information Technologies Institute, CERTH, Greece; Information Technologies Institute, CERTH, Greece; University of Amsterdam, The Netherlands",2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),"13 Aug 2025","2025","","","18706","18717","Recent works have established that AI models introduce spectral artifacts into generated images and propose approaches for learning to capture them using labeled data. However, the significant differences in such artifacts among different generative models hinder these approaches from generalizing to generators not seen during training. In this work, we build upon the key idea that the spectral distribution of real images constitutes both an invariant and highly discriminative pattern for AI-generated image detection. To model this under a self-supervised setup, we employ masked spectral learning using the pretext task of frequency reconstruction. Since generated images constitute out-of-distribution samples for this model, we propose spectral reconstruction similarity to capture this divergence. Moreover, we introduce spectral context attention, which enables our approach to efficiently capture subtle spectral inconsistencies in images of any resolution. Our spectral AI-generated image detection approach (SPAI) achieves a 5.5% absolute improvement in AUC over the previous state-of-the-art across 13 recent generative approaches, while exhibiting robustness against common online perturbations. Code is available on https://mever-team.github.io/spai.","2575-7075","979-8-3315-4364-8","10.1109/CVPR52734.2025.01743","Horizon Europe; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11094582","synthetic image detection;ai generated image detection;self supervised learning;image forensics;media forensics;deepfake detection;spectral learning","Training;Image resolution;Generative AI;Perturbation methods;Detectors;Robustness;Generators;Pattern recognition;Noise measurement;Image reconstruction","","2","","79","IEEE","13 Aug 2025","10-17 June 2025","10-17 June 2025","IEEE","IEEE Conferences"
"A Lightweight CNN for Efficient Deepfake Detection of Low-resolution Images in Frequency Domain","S. D; R. S; S. Ravi; V. M; P. M. P. U","School of Computer Science and Engineering, Vellore Institute of Technology, Vellore, Tamilnadu; School of Computer Science and Engineering, Vellore Institute of Technology, Vellore, Tamilnadu; School of Computer Science and Engineering, Vellore Institute of Technology, Vellore, Tamilnadu; School of Computer Science and Engineering, Vellore Institute of Technology, Vellore, Tamilnadu; CapitalOne, San Francisco, USA",2024 Second International Conference on Emerging Trends in Information Technology and Engineering (ICETITE),"18 Apr 2024","2024","","","1","6","Deepfake detection in frequency domain is extensively explored for two reasons –artifacts generated by the up-sampling layer of Generative Adversarial Networks are more prominent in the frequency domain and some image processing tasks are simpler and efficient in this domain. Traditional convolutional neural networks outperform the machine learning models for their ability to detect deepfakes of low-resolution images also. But these networks involve numerous trainable parameters resulting in huge computation cost, time and high memory requirements. This paper presents a lightweight Convolutional Neural Network (CNN) architecture that is optimized for efficient deepfake detection of low-resolution images in the frequency domain. The proposed model achieves almost the same accuracy as that of the traditional network but with the parameter requirement reduced by 92%. This renders the model suitable for use in memory-constrained and power-constrained environments such as mobile devices and other embedded systems.","","979-8-3503-2820-2","10.1109/ic-ETITE58242.2024.10493406","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10493406","Deepfake detection;frequency domain;pixel domain;lightweight CNN;depthwise separable convolution","Deepfakes;Frequency-domain analysis;Computational modeling;Memory management;Machine learning;Market research;Mobile handsets","","1","","21","IEEE","18 Apr 2024","22-23 Feb. 2024","22-23 Feb. 2024","IEEE","IEEE Conferences"
"WaveDIF: Wavelet Sub-Band based Deepfake Identification in Frequency Domain","A. Dutta; A. K. Das; R. Naskar; R. S. Chakraborty","IIT, Kharagpur; IIEST, Shibpur; IIEST, Shibpur; IIT, Kharagpur",2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW),"15 Sep 2025","2025","","","6302","6311","With the more realistic convergence of Deepfakes, its' identification becomes more demanding. Recently, numerous deepfake detection techniques have been proposed, most of which are in the spatio-temporal domain. While these methods have shown promise, many of them neglect convincing artifacts that exhibit different patterns across frequency domains. This research proposes WaveDIF, a strict frequency domain, lightweight deepfake video detection algorithm using wavelet sub-band energies. In WaveDIF, for feature extraction, each video undergoes a Discrete Fourier Transform to filter out high-frequency noisy details (quite evident in deepfakes). These representations are then decomposed into their respective wavelet sub-bands -LL (Low-Low), LH (Low-High), HL (High-Low), and HH (High-High) passing them through a Haar Filter, following which the energy values (particular to each sub-band) are computed. These energy values are then used to learn a linear decision boundary (using regression analysis), which is then used for classification. This enables an interpretable, lightweight deterministic technique for the detection of synthesized videos, besides achieving an accuracy comparable to the state-of-the-art. Experimental results on popular deepfake video datasets shows over 92% accuracy for in-dataset evaluation, and 88% accuracy for cross dataset evaluation.","2160-7516","979-8-3315-9994-2","10.1109/CVPRW67362.2025.00627","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11148061","lightweight deepfake detection;frequency domain analysis;wavelet sub-band energies;discrete fourier transform;discrete wavelet transform","Deepfakes;Adaptation models;Accuracy;Wavelet domain;Frequency-domain analysis;Computational modeling;Discrete Fourier transforms;Pipelines;Feature extraction;Regression analysis","","2","","34","IEEE","15 Sep 2025","11-12 June 2025","11-12 June 2025","IEEE","IEEE Conferences"
"Deepfake Detection via Spatial-Frequency Attention Network","S. Guo; M. Gao; G. Zhang; C. Liu; Q. Li","School of Electrical and Electronic Engineering, Shandong Provincial Key Laboratory of New Power Distribution and Utilization Technology and Equipment, Shandong University of Technology, Zibo, China; School of Electrical and Electronic Engineering, Shandong Provincial Key Laboratory of New Power Distribution and Utilization Technology and Equipment, Shandong University of Technology, Zibo, China; School of Electrical and Electronic Engineering, Shandong Provincial Key Laboratory of New Power Distribution and Utilization Technology and Equipment, Shandong University of Technology, Zibo, China; School of Electrical and Electronic Engineering, Shandong Provincial Key Laboratory of New Power Distribution and Utilization Technology and Equipment, Shandong University of Technology, Zibo, China; Faculty of Artificial Intelligence in Education, Central China Normal University, Wuhan, China",IEEE Transactions on Consumer Electronics,"","2025","PP","99","1","1","Artificial Intelligence Generated Content (AIGC) makes creating realistic synthetic media a breeze. Facial forgery technologies threaten consumer electronics, such as smartphones, intelligent payment systems, and smart home Internet of Things (IoT) devices. These threats undermine identity authentication security and compromise user privacy. To address this problem, this paper introduces a wavelet-based Spatial and Frequency Domain Attention Network (SFANet) for deepfake detection. The SFANet comprises a wavelet transform-based feature decoupling module, a dual attention module, and a cross-modality fusion module. The spatial features are first decomposed into high-and low-frequency components by wavelet transform. Subsequently, a dual attention mechanism is built to adjust frequency-domain weights dynamically. Finally, a cross-modality fusion module is introduced to integrate spatial and frequency-domain features for enhanced detection. Experimental results on three benchmark datasets, namely FaceForensics++, WildDeepfake, and Celeb-DF V2, prove that SFANet achieves superior detection performance compared to state-of-the-art models. This research provides a powerful tool to combat AI-driven misinformation and advances the field of synthetic content detection in consumer electronics. The implementation of SFANet will be publicly available at https://github.com/siyouguo/SFANet.","1558-4127","","10.1109/TCE.2025.3614720","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11182301","Deepfake Detection;Frequency Domain;Wavelet Transform;Attention Mechanism;Cross-Domain Fusion","Deepfakes;Frequency-domain analysis;Wavelet transforms;Feature extraction;Transforms;Consumer electronics;Privacy;Wavelet domain;Convolution;Forgery","","","","","IEEE","26 Sep 2025","","","IEEE","IEEE Early Access Articles"
"Learned Image Compression for Deepfake Detection","A. Gnutti; A. Alkhateeb; C. -H. Kao; E. D. Cannas; S. Mandelli; W. -H. Peng; R. Leonardi; P. Migliorati","Department of Information Engineering, University of Brescia, Italy; Department of Information Engineering, University of Brescia, Italy; Department of Information Engineering, University of Brescia, Italy; Department of Electronics, Information, and Bioengineering, Politecnico di Milano, Italy; Department of Electronics, Information, and Bioengineering, Politecnico di Milano, Italy; Department of Computer Science, National Yang Ming Chiao Tung University, Taiwan; Department of Information Engineering, University of Brescia, Italy; Department of Information Engineering, University of Brescia, Italy",2025 33rd European Signal Processing Conference (EUSIPCO),"17 Nov 2025","2025","","","1377","1381","Learned image compression introduces new challenges for image forensics, as deepfake detectors may mistakenly classify authentic images as artificially generated due to compression artifacts or misidentify synthetic images that have undergone neural compression as real. In this paper, the first neural image compression system specifically designed for deepfake detection is presented. To achieve this, spatial-frequency modulation adapters are integrated into an existing image compression architecture, eliminating the need to retrain the underlying codec. Images decoded with the proposed method achieve detection performance comparable to uncompressed images while also exhibiting superior perceptual quality than images reconstructed from conventional image compression.","","978-9-4645-9362-4","10.23919/EUSIPCO63237.2025.11226598","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11226598","Learned image compression;coding for machines;deepfake detection","Deepfakes;Image forensics;Image coding;Codecs;Europe;Detectors;Signal processing;Image reconstruction","","","","22","","17 Nov 2025","8-12 Sept. 2025","8-12 Sept. 2025","IEEE","IEEE Conferences"
"Harmonizing Dynamic Frequency Analysis with Attention Mechanisms for Efficient Facial Image Authenticity Detection","Y. Zhao; J. Li; L. Wang","School of Computer and Information Engineering, Hefei University of Technology, Hefei, China; School of Computer and Information Engineering, Hefei University of Technology, Hefei, China; Anhui Communications Vocational and Technical College, Hefei, China",2023 International Conference on Computer Science and Automation Technology (CSAT),"25 Mar 2024","2023","","","348","352","Deepfake detection is increasingly critical in security and digital forensics. Our research presents a novel method that synergizes dynamic frequency domain analysis with attention mechanisms to discern Deepfakes more effectively. This approach is developed in response to the inadequacies of existing techniques when confronted with sophisticated image alterations. By leveraging frequency domain subtleties and an advanced attention mechanism, our model achieves heightened accuracy in identifying key facial anomalies. Our experimental results show that DFAM could yield 93.94% accuracy rate which is the best compared with state-of-the-arts on Deepfakes dataset.","","979-8-3503-7143-7","10.1109/CSAT61646.2023.00097","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10471603","deepfake detection;dynamic frequency domain analysis;attention mechanisms","Computer science;Deepfakes;Automation;Frequency-domain analysis;Digital forensics;Security","","1","","22","IEEE","25 Mar 2024","6-8 Oct. 2023","6-8 Oct. 2023","IEEE","IEEE Conferences"
"Face Swapping Attack Detection Using Multistream Feature Embeddings","G. Kotov; O. Nakov; M. Lazarova; P. Nakov; G. Georgiev","Department of Computer Systems, Faculty of Computer Systems and Technologies, Technical University of Sofia, Sofia, Bulgaria; Department of Computer Systems, Faculty of Computer Systems and Technologies, Technical University of Sofia, Sofia, Bulgaria; Department of Computer Systems, Faculty of Computer Systems and Technologies, Technical University of Sofia, Sofia, Bulgaria; Department of Computer Systems, Faculty of Computer Systems and Technologies, Technical University of Sofia, Sofia, Bulgaria; Department of Computer Systems, Faculty of Computer Systems and Technologies, Technical University of Sofia, Sofia, Bulgaria",2025 13th International Scientific Conference on Computer Science (COMSCI),"13 Nov 2025","2025","","","1","6","The paper presents a novel multi-stream feature embedding approach to detect face swapping attacks and distinguish them from fully AI-generated face images. The suggested multi-stream feature embedding architecture combines global features from Vision Transformers, local artifacts from convolutional neural networks, and frequency-domain analysis. Thus the model captures complementary forensic cues often missed by single-stream approaches. The processing pipeline employs image preprocessing and face alignment stage to standardize the input data as required by the tree different streams utilized in the suggested architecture. Attention-based modular fusion is applied for the feature embeddings extracted from each stream to generate unified representation with dynamic weighting thus improving both robustness and interpretability of the model as it selectively relies on the most informative stream based on the input's generative characteristics. Based on the suggested approach a classification model is trained for three classes: real, face-swapped, AI-generated images using diverse mix of images from both curated and real-world datasets. The experimental results demonstrate strong performance of the model that effectively detects AI-generated faces using global and spectral anomalies, while identifying face swaps through localized inconsistencies.","","979-8-3315-9814-3","10.1109/COMSCI67172.2025.11225271","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11225271","deepfake detection;AI-generated faces;face swapping;multi-stream;feature embeddings","Trees (botanical);Frequency-domain analysis;Forensics;Pipelines;Computer architecture;Feature extraction;Transformers;Robustness;Image preprocessing;Faces","","","","33","IEEE","13 Nov 2025","13-15 Sept. 2025","13-15 Sept. 2025","IEEE","IEEE Conferences"
"Fourier-Based GAN Fingerprint Detection Using ResNet50","S. T. Erukude; V. C. Marella; S. R. Veluru","Department of Computer Science, Kansas State University, Manhattan, USA; College of Business Administration, Kansas State University, Manhattan, USA; College of Business Administration, Kansas State University, Manhattan, USA",2025 9th International Conference on Inventive Systems and Control (ICISC),"13 Oct 2025","2025","","","971","976","The rapid rise of photorealistic images produced from Generative Adversarial Networks (GANs) poses a serious challenge for image forensics and industrial systems requiring reliable content authenticity. This paper uses frequency-domain analysis combined with deep learning to solve the problem of distinguishing StyleGAN-generated images from real ones. Specifically, a two-dimensional Discrete Fourier Transform (2D DFT) was applied to transform images into the Fourier domain, where subtle periodic artifacts become detectable. A ResNet50 neural network is trained on these transformed images to differentiate between real and synthetic ones. The experiments demonstrate that the frequency-domain model achieves a 92.8 percent and an AUC of 0.95, significantly outperforming the equivalent model trained on raw spatial-domain images. These results indicate that the GAN-generated images have unique frequency-domain signatures or “fingerprints”. The method proposed highlights the industrial potential of combining signal processing techniques and deep learning to enhance digital forensics and strengthen the trustworthiness of industrial AI systems.","","979-8-3315-1247-7","10.1109/ICISC65841.2025.11187724","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11187724","Deepfake Detection;Frequency-Domain Analysis;Image Forensics;StyleGAN Fingerprints;Trustworthy AI Systems","Deep learning;Image forensics;Deepfakes;Adaptation models;Frequency-domain analysis;Discrete Fourier transforms;Fingerprint recognition;Generative adversarial networks;Artificial intelligence;Residual neural networks","","","","15","IEEE","13 Oct 2025","12-13 Aug. 2025","12-13 Aug. 2025","IEEE","IEEE Conferences"
"MDCF-Net: Multi-Scale Dual-Branch Network for Compressed Face Forgery Detection","J. Zhou; X. Zhao; Q. Xu; P. Zhang; Z. Zhou","Shanghai Film Academy, Shanghai University, Shanghai, China; Shanghai Film Academy, Shanghai University, Shanghai, China; Shanghai Film Academy, Shanghai University, Shanghai, China; Shanghai Film Academy, Shanghai University, Shanghai, China; Shanghai Film Academy, Shanghai University, Shanghai, China",IEEE Access,"30 Apr 2024","2024","12","","58740","58749","Face forgery detection aims to identify manipulated or altered facial images or videos created using artificial intelligence. Existing detection methods exhibit favorable performance on high-quality videos, but the videos in daily applications are commonly compressed into low-quality formats via social media. The detection difficulty is increased by the poor quality, indistinct detail features, and noises such as artifacts in these images or videos. To address this challenge, we propose a multi-scale dual-branch network for compressed face forgery, called MDCF-Net, effectively capturing cross-domain forgery features at various scales in compressed facial images. The MDCF-Net comprises two branches: an RGB domain branch utilizing Transformers to extract multi-scale fine-texture features from the original RGB images; a frequency domain branch designed to capture artifacts in low-quality videos by extracting global spectral features as a supplementary measure. Then, we introduce a feature fusion module (FFM) based on multi-head attention to merge diverse feature representations in a spatial-frequency complementary manner. Extensive comparative experiments on public datasets such as FaceForensics++, Celeb-DF, and WildDeepfake demonstrate the significant advantage of MDCF-Net in detecting highly compressed and low-quality forged images or videos, especially in achieving state-of-the-art performance on the FaceForensics++ low-quality dataset. Our approach presents a new perspective and technology for low-quality face forgery detection.","2169-3536","","10.1109/ACCESS.2024.3390217","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10504285","Face forgery;deepfake detection;transformers;frequency domain;two-branch;feature fusion","Feature extraction;Frequency-domain analysis;Face recognition;Forgery;Transformers;Deepfakes;Image coding","","8","","44","CCBYNCND","17 Apr 2024","2024","","IEEE","IEEE Journals"
"Multi-Cue Fusion for Forgery Detection: a Spatial-Frequency and Chromatic Approach","Z. Yang; R. Tao; C. Zhang; X. Zheng","Institute of Information Science, Beijing Jiaotong University, Beijing, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China; State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences",2025 IEEE International Conference on Intelligence and Security Informatics (ISI),"21 Oct 2025","2025","","","89","94","With the rapid development of Deepfake technology, the fake content it generates poses a serious threat to information credibility and personal privacy. Existing detection methods are often limited to single-domain feature analysis. Spatial domain methods focus on texture and structural features, but often ignore frequency domain forgery traces. Although frequency domain methods can extract frequency information, they often lose the integrity of spatial details and chromatic features. To address these challenges, this paper proposes a novel dual-branch detection framework that integrates multimodal feature analysis in spatial, frequency and chromatic domains, effectively utilizes multiple forgery cues, and demonstrates good robustness and generalization for Deepfake detection. Specifically, we extract appropriate frequency domain forgery cues and spatial texture features from grayscale images through discrete cosine transform (DCT) and multiband adaptive filters to capture diverse frequency patterns. At the same time, we separate phase features and chromatic texture cues from the chromaticity channels of the YCbCr color space through a phase extraction module to reconstruct finegrained chromaticity representation. In addition, distribution consistency loss and weight prediction modules are proposed to optimize the statistical properties and discriminant consistency of grayscale and chromaticity features. Extensive experiments on benchmark deepfake detection datasets demonstrate the effectiveness of our approach, showing good adaptability to complex forgery scenarios.","2837-6617","979-8-3315-1276-7","10.1109/ISI65680.2025.11201145","Beijing Natural Science Foundation(grant numbers:L242021); National Natural Science Foundation of China(grant numbers:62476021,72225011,72434005,62072026); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11201145","Deepfake Detection;Multi-Domain Analysis;Frequency Transform;Phase Decomposition","Deepfakes;Visualization;Frequency-domain analysis;Transforms;Gray-scale;Feature extraction;Forgery;Robustness;Discrete cosine transforms;Security","","","","19","IEEE","21 Oct 2025","12-13 July 2025","12-13 July 2025","IEEE","IEEE Conferences"
"Trinity Detector: Text-Assisted and Attention Mechanisms Based Spectral Fusion for Diffusion Generation Image Detection","J. Song; D. Ye; Y. Zhang","Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, Wuhan, China; Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, Wuhan, China; Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, Wuhan, China",IEEE Signal Processing Letters,"9 Jan 2025","2025","32","","501","505","Artificial Intelligence Generated Content (AIGC) techniques, represented by text-to-image generation, have led to a malicious use of deep forgeries, raising concerns about the trustworthiness of multimedia content. Experimental results demonstrate that traditional forgery detection methods perform poorly in adapting to diffusion model-generated scenarios, while existing diffusion-specific techniques lack robustness against post-processed images. In response, we propose the Trinity Detector, which integrates coarse-grained text features from a Contrastive Language-Image Pretraining (CLIP) encoder with fine-grained artifacts in the pixel domain to achieve semantic-level image detection, significantly enhancing model robustness. To enhance sensitivity to diffusion-generated image features, a Multi-spectral Channel Attention Fusion Unit (MCAF) is designed. It adaptively fuses multiple preset frequency bands, dynamically adjusting the weight of each band, and then integrates the fused frequency-domain information with the spatial co-occurrence of the two modalities. Extensive experiments validate that our Trinity Detector improves transfer detection performance across black-box datasets by an average of 14.3% compared to previous diffusion detection models and demonstrating superior performance on post-processed image datasets.","1558-2361","","10.1109/LSP.2024.3522851","National Natural Science Foundation of China(grant numbers:62072343,62472325); Fundamental Research Funds for the Central Universities(grant numbers:2042023kf0228); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10816560","DeepFake;diffusion;forgery detection","Frequency-domain analysis;Detectors;Feature extraction;Discrete cosine transforms;Forgery;Semantics;Robustness;Image coding;Diffusion models;Data mining","","4","","21","IEEE","26 Dec 2024","2025","","IEEE","IEEE Journals"
"Pixel Bleach Network for Detecting Face Forgery Under Compression","C. Li; Z. Zheng; Y. Bin; G. Wang; Y. Yang; X. Li; H. T. Shen","Center for Future Multimedia and School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; Center for Future Multimedia and School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; Center for Future Multimedia and School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; Center for Future Multimedia and School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; Center for Future Multimedia and School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Aeronautics and Astronautics, University of Electronic Science and Technology of China, Chengdu, China; Center for Future Multimedia and School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China",IEEE Transactions on Multimedia,"24 Jul 2024","2024","26","","2585","2597","The existing face forgery algorithms have achieved remarkable progress in how to generate reasonable facial images and can even successfully deceive human beings. Considering public security, face forgery detection is of vital importance, making it essential to design face forgery detection algorithms to detect forgery images over the Internet. Despite the great success achieved by the existing Deepfake detection algorithms, they usually failed to achieve satisfactory Deepfake detection performance when deployed to handle the forgery videos in practice. One significant reason is compression. The videos over the Internet are inevitably compressed considering the transmission efficiency. The video compression results in significant Deepfake detection performance degradation for the existing Deepfake detection algorithms. To address this issue, in this article, we propose a generic, simple yet effective “bleaching” pre-processing module based on the generative model and the high-level feature representations to produce a bleached image, which shares a similar appearance with the compressed images. The bleached images with recovered information can be identified accurately by the optimized Deepfake detection models without retraining. The proposed method has utilized a redesigned feature representation, which serves as a navigator to effectively and sufficiently alter the feature distribution in the high-dimensional space to remedy the difference between real facial images and forgery counterparts. Thus, the proposed method can successfully avoid misclassification. Comprehensive and extensive experiments are carried out on four low-quality Faceforensics++ datasets, demonstrating the effectiveness of our method in recovering the information loss caused by the compression artifacts across various backbones and compression.","1941-0077","","10.1109/TMM.2023.3301242","National Natural Science Foundation of China(grant numbers:U20B2063,62220106008,62102070); Sichuan Science and Technology Program(grant numbers:2023NSFSC1392); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10202582","Deepfake detection;robust deepfake detection under compression;adversarial learning","Deepfakes;Image coding;Forgery;Faces;Detection algorithms;Feature extraction;Generators","","3","","67","IEEE","2 Aug 2023","2024","","IEEE","IEEE Journals"
"Detection of Deepfake Medical Images Based on Spatial and Frequency Domain Analysis","P. P; G. R. S","Research Scholar Centre for Development of Imaging Technology, University of Kerala, Kerala, India; Department of Computer Science, Government College Kariavattom, Trivandrum, Kerala",2024 IEEE 16th International Conference on Computational Intelligence and Communication Networks (CICN),"27 Jan 2025","2024","","","611","617","The advent of deepfake technologies poses a significant threat to reliance on medical imaging. This can lead to misdiagnosis and threaten patient safety. To address this issue, this study introduces a novel deep-learning approach that integrates spatial and frequency–domain analyses to detect manipulated medical images. The proposed approach combines the pre-trained EfficientNet-B0 model for spatial feature extraction with the Discrete Wavelet Transform (DWT) for frequency-domain analysis. The model was validated using the CT-GAN dataset comprising real and GAN-generated fake CT scan images. Individually, the EfficientNet-B0 model achieved an accuracy of 97.03%, and the DWT-based analysis reached 97.84%. Combining both approaches, the hybrid model achieved an overall accuracy of 99.6%. Data augmentation and weighted cross-entropy loss were employed to enhance the training process and address class imbalance. Performance was assessed using standard metrics, including accuracy, precision, recall, F1-score, Receiver Operating Characteristic (ROC), and precision-recall curves. These results demonstrate the strengths of our model in detecting minor variations in an image and validating the power of combining frequency analysis with spatial evaluation. This method holds great promise for protecting the integrity of medical imaging against deepfake threats.","2472-7555","979-8-3315-0526-4","10.1109/CICN63059.2024.10847427","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10847427","Biomedical imaging;Deep learning;Medical Deepfake Detection;Computational modeling","Deepfakes;Analytical models;Accuracy;Computational modeling;Frequency-domain analysis;Computed tomography;Feature extraction;Wavelet analysis;Discrete wavelet transforms;Medical diagnostic imaging","","1","","21","IEEE","27 Jan 2025","22-23 Dec. 2024","22-23 Dec. 2024","IEEE","IEEE Conferences"
"SpectralFusionNet: Adaptive Frequency-Spatial Feature Fusion for Robust Deepfake Detection","X. Song; C. Wu; Z. Liu","School of Information Science and Engineering, Linyi University, Linyi, China; School of Information Science and Engineering, Linyi University, Linyi, China; School of Information Science and Engineering, Linyi University, Linyi, China",2025 IEEE 8th International Conference on Electronic Information and Communication Technology (ICEICT),"17 Sep 2025","2025","","","484","489","With the rapid advancement of Generative Adversarial Networks (GANs), deepfake technology poses significant threats to social trust and information security, while current detection methods suffer from limited generalization ability, single feature dependency, and insufficient environmental robustness. To address these challenges, this paper proposes SpectralFusion-Net (SFN), a novel deepfake detection framework that adaptively fuses frequency domain and spatial domain. SFN introduces four key innovations: (1) An end-to-end fusion architecture enabling dynamic interaction between frequency-spatial domain features, (2) a frequency domain dynamic selection network that adaptively evaluates the importance of different frequency components, (3) a dual-channel attention fusion strategy for effective integration of complex frequency spectrum components, and (4) an adaptive frequency domain mask generation mechanism for flexible adaptation to different forgery types. Extensive experiments on DFFD and FaceForensics++ datasets demonstrate that SFN achieves superior performance with 96.05% average accuracy on FF++ and maintains 90.46% accuracy under heavy compression scenarios (c40), significantly outperforming existing methods in detection accuracy, generalization ability, and environmental robustness, particularly when facing unknown forgery types and low-quality images.","2836-7782","979-8-3315-9505-0","10.1109/ICEICT66683.2025.11159858","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11159858","Deepfake detection;Frequency domain analysis;Feature fusion;Attention mechanism;Generative adversarial networks","Deepfakes;Accuracy;Image coding;Attention mechanisms;Frequency-domain analysis;Zero shot learning;Feature extraction;Generative adversarial networks;Forgery;Robustness","","","","33","IEEE","17 Sep 2025","26-28 July 2025","26-28 July 2025","IEEE","IEEE Conferences"
"FAClue: Exploring Frequency Clues by Adaptive Frequency-Attention for Deepfake Detection","W. Liang; Y. Wu; J. Wu; J. Xu","College of Artificial Intelligence, Nankai University, Tianjin, P. R. China; College of Artificial Intelligence, Nankai University, Tianjin, P. R. China; College of Artificial Intelligence, Nankai University, Tianjin, P. R. China; College of Artificial Intelligence, Nankai University, Tianjin, P. R. China",2023 42nd Chinese Control Conference (CCC),"18 Sep 2023","2023","","","7621","7626","Detecting fake faces produced by face forgery technologies attracts intensive attention in recent years. Deep learning approaches have shown their effectiveness in deepfake detection task. Some previous deep learning-based methods exploit forgery artifacts in spatial domain but easily overfit the specific forgery patterns. Therefore, some works utilize additional frequency domain information to obtain generalized features. We consider to improve the frequency-based methods in two aspects: 1) extracting discriminative frequency features comprehensively; 2) mining complementary features in different domains sufficiently. In this paper, we propose a dual-stream network named FAClue for deepfake detection, which extracts comprehensive frequency information to complement spatial domain features. Specifically, the FAClue consists of three main components. A Frequency-Attention Extractor (FAE) is proposed to adaptively highlight prominent frequency bands from both global and local perspectives. A RGB-Frequency Complementary Enhancement (RFCE) module is developed to mine complementary information between RGB and frequency domains in an explicit manner. A Frequency Guided Attention (FGA) module is designed to fuse different domain features and generate discriminative features for detection. Extensive experiments on three benchmark datasets demonstrate the FAClue achieves competitive performance compared with state-of-the-art methods.","1934-1768","978-988-75815-4-3","10.23919/CCC58697.2023.10240940","National Natural Science Foundation of China(grant numbers:62002177); Natural Science Foundation of Tianjin City(grant numbers:19JCQNJC00300,21JCYBJC00110); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10240940","Deepfake Detection;Frequency Domain;Attention Mechanism;Feature Fusion","Learning systems;Deepfakes;Visualization;Fuses;Frequency-domain analysis;Benchmark testing;Feature extraction","","1","","40","","18 Sep 2023","24-26 July 2023","24-26 July 2023","IEEE","IEEE Conferences"
"FTDKD: Frequency-Time Domain Knowledge Distillation for Low-Quality Compressed Audio Deepfake Detection","B. Wang; Y. Tang; F. Wei; Z. Ba; K. Ren","School of Information and Communication Engineering, Dalian University of Technology, Dalian, China; School of Information and Communication Engineering, Dalian University of Technology, Dalian, China; Alibaba Group, Hangzhou, Zhejiang, China; School of Cyber Science and Technology, Zhejiang University, Hangzhou, Zhejiang, China; School of Cyber Science and Technology, Zhejiang University, Hangzhou, Zhejiang, China","IEEE/ACM Transactions on Audio, Speech, and Language Processing","21 Nov 2024","2024","32","","4905","4918","In recent years, the field of audio deepfake detection has witnessed significant advancements. Nonetheless, the majority of solutions have concentrated on high-quality audio, largely overlooking the challenge of low-quality compressed audio in real-world scenarios. Low-quality compressed audio typically suffers from a loss of high-frequency details and time-domain information, which significantly undermines the performance of advanced deepfake detection systems when confronted with such data. In this paper, we introduce a deepfake detection model that employs knowledge distillation across the frequency and time domains. Our approach aims to train a teacher model with high-quality data and a student model with low-quality compressed data. Subsequently, we implement frequency-domain and time-domain distillation to facilitate the student model's learning of high-frequency information and time-domain details from the teacher model. Experimental evaluations on the ASVspoof 2019 LA and ASVspoof 2021 DF datasets illustrate the effectiveness of our methodology. On the ASVspoof 2021 DF dataset, which consists of low-quality compressed audio, we achieved an Equal Error Rate (EER) of 2.82%. To our knowledge, this performance is the best among all deepfake voice detection systems tested on the ASVspoof 2021 DF dataset. Additionally, our method proves to be versatile, showing notable performance on high-quality data with an EER of 0.30% on the ASVspoof 2019 LA dataset, closely approaching state-of-the-art results.","2329-9304","","10.1109/TASLP.2024.3492796","National Natural Science Foundation of China(grant numbers:62076052,62106037); Science and Technology Innovation Foundation of Dalian(grant numbers:2021JJ12GX018); Application Fundamental Research Project of Liaoning Province(grant numbers:2022JH2/101300262); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10747292","Audio deepfake detection;low-quality compressed audio;knowledge distillation","Deepfakes;Data models;Feature extraction;Time-domain analysis;Predictive models;Forgery;Detectors;Time-frequency analysis;Speech enhancement;Mel frequency cepstral coefficient","","8","","68","IEEE","7 Nov 2024","2024","","IEEE","IEEE Journals"
"Spatial-Temporal Frequency Forgery Clue for Video Forgery Detection in VIS and NIR Scenario","Y. Wang; C. Peng; D. Liu; N. Wang; X. Gao","State Key Laboratory of Integrated Services Networks, School of Cyber Engineering, Xidian University, Xi’an, China; State Key Laboratory of Integrated Services Networks, School of Cyber Engineering, Xidian University, Xi’an, China; State Key Laboratory of Integrated Services Networks, School of Cyber Engineering, Xidian University, Xi’an, China; State Key Laboratory of Integrated Services Networks, School of Telecommunications Engineering, Xidian University, Xi’an, China; Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing, China",IEEE Transactions on Circuits and Systems for Video Technology,"7 Dec 2023","2023","33","12","7943","7956","In recent years, with the rapid development of face editing and generation, more and more fake videos are circulating on social media, which has caused extreme public concerns. Existing face forgery detection methods based on frequency domain find that the GAN forged images have obvious grid-like visual artifacts in the frequency spectrum. But for synthesized videos, these methods only confine to a single frame and pay little attention to the most discriminative part and temporal frequency clue among different frames. To take full advantage of the rich information in video sequences, this paper performs video forgery detection on both spatial and temporal frequency domains and proposes a Discrete Cosine Transform-based Forgery Clue Augmentation Network (FCAN-DCT) to achieve a more comprehensive spectrum spatial-temporal feature representation. FCAN-DCT totally consists of a backbone network and two branches: Compact Feature Extraction (CFE) module and Frequency Temporal Attention (FTA) module. We conduct thorough experimental assessments on three visible light (VIS) based datasets (i.e.,, FaceForensics++, Celeb-DF (v2), WildDeepfake), and our self-built video forgery dataset DeepfakeNIR, which is the first video forgery dataset on near-infrared (NIR) modality. The experimental results demonstrate the effectiveness and robustness of our method for detecting forgery videos in both VIS and NIR scenarios.DeepfakeNIR and code are available at https://github.com/AEP-WYK/DeepfakeNIR.","1558-2205","","10.1109/TCSVT.2023.3281475","National Natural Science Foundation of China(grant numbers:62276198,U22A2035,U22A2096,62036007,61922066,61906143,61902297,61806152,61876142); Key Research and Development Program of Shaanxi Program(grant numbers:2023-YBGY-231); Young Elite Scientists Sponsorship Program by CAST(grant numbers:2022QNRC001); Guangxi Natural Science Foundation Program(grant numbers:2021GXNSFDA075011); Natural Science Basic Research Plan in Shaanxi Province of China(grant numbers:2022JQ-696); Technology Innovation Leading Program of Shaanxi(grant numbers:2022QFY01-15); CCF-Tencent Open Fund; Open Research Projects of Zhejiang Laboratory(grant numbers:2021KG0AB01); Fundamental Research Funds for the Central Universities(grant numbers:QTZX23083,QTZX23042,XJS221502); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10138610","Near-infrared face;face forgery detection;deepfake","Forgery;Face recognition;Frequency-domain analysis;Feature extraction;Faces;Discrete cosine transforms;Deepfakes","","25","","72","IEEE","30 May 2023","Dec. 2023","","IEEE","IEEE Journals"
"FALCON: Frequency-Aware Lightweight Convolutional Optimized Network","H. Maan; H. Hooda; H. Verma; A. Kaushal","Department of Computer Engineering, Delhi Technological University, Delhi, India; Department of Computer Engineering, Delhi Technological University, Delhi, India; Department of Computer Engineering, Delhi Technological University, Delhi, India; Department of Computer Engineering, Delhi Technological University, Delhi, India",2025 3rd International Conference on Inventive Computing and Informatics (ICICI),"15 Jul 2025","2025","","","1019","1026","The rise of deepfakes-images or videos that are manipulated using AI techniques like GANs-has created serious challenges in the areas of media trust, security, and online safety. Many existing methods for detecting deepfakes depend on visible image features or large, complex models like transformers. These models often struggle to detect newer types of deepfakes and require high computational power, which makes them hard to use on mobile or low-power devices. To address these issues, we propose FALCON (Frequency-Aware Lightweight Convolutional Optimized Network), a simple and efficient deep learning model for deepfake detection. The main goal of FALCON is to improve accuracy while keeping the model small and fast enough to run on real-time systems and low-resource devices. FALCON works in the frequency domain, where deepfakes often leave hidden traces. It uses three key techniques: High-Frequency Residual Injection (HFRI) to boost fake signals early in the network, Frequency Convolutional Layers (FCL) to analyze amplitude and phase patterns, and High-Frequency Refined Features (HFRF) to improve feature detection in deeper layers. We trained the model using techniques like mixed-precision, gradient clipping, and early stopping for better performance and stability. On the Kaggle “Deepfake and Real Images” dataset, FALCON achieved 90% accuracy, 0.90 F1-score, and 0.97 AUC, outperforming other lightweight models. FALCON is ideal for real-time, reliable deepfake detection on everyday devices. This study highlights the effectiveness of frequency-domain learning as a practical and generalizable approach for deepfake detection.","","979-8-3315-3830-9","10.1109/ICICI65870.2025.11069816","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11069816","Convolutional Neural Networks;Deep Learning;Deepfake Detection;Frequency Domain;High-Frequency Features","Performance evaluation;Deep learning;Deepfakes;Accuracy;Convolution;Frequency-domain analysis;Computational modeling;Feature extraction;Transformers;Real-time systems","","","","25","IEEE","15 Jul 2025","4-6 June 2025","4-6 June 2025","IEEE","IEEE Conferences"
"Dodging DeepFake Detection via Implicit Spatial-Domain Notch Filtering","Y. Huang; F. Juefei-Xu; Q. Guo; Y. Liu; G. Pu","School of Computer Science and Engineering, Nanyang Technological University, Jurong West, Singapore; Tandon School of Engineering, New York University, New York City, NY, USA; Centre for Frontier AI Research (CFAR), Agency for Science, Technology and Research (A*STAR), Institute of High Performance Computing (IHPC), Fusionopolis, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Jurong West, Singapore; Software Engineering Institute, East China Normal University, Shanghai, China",IEEE Transactions on Circuits and Systems for Video Technology,"12 Aug 2024","2024","34","8","6949","6962","The current high-fidelity generation and high-precision detection of DeepFake images are at an arms race. We believe that producing DeepFakes that are highly realistic and “detection evasive” can serve the ultimate goal of improving future generation DeepFake detection capabilities. In this paper, we propose a simple yet powerful pipeline to reduce the artifact patterns of fake images without hurting image quality by performing implicit spatial-domain notch filtering. We first demonstrate that frequency-domain notch filtering, although famously shown to be effective in removing periodic noise in the spatial domain, is infeasible for our task at hand due to the manual designs required for the notch filters. We, therefore, resort to a learning-based approach to reproduce the notch filtering effects, but solely in the spatial domain. We adopt a combination of adding overwhelming spatial noise for breaking the periodic noise pattern and deep image filtering to reconstruct the noise-free fake images, and we name our method DeepNotch. Deep image filtering provides a specialized filter for each pixel in the noisy image, producing filtered images with high fidelity compared to their DeepFake counterparts. Moreover, we also use the semantic information of the image to generate an adversarial guidance map to add noise intelligently. Our large-scale evaluation on 3 representative DeepFake detection methods (tested on 16 types of DeepFakes) has demonstrated that our technique significantly reduces the accuracy of these 3 fake image detection methods, 36.79% on average and up to 97.02% in the best case.","1558-2205","","10.1109/TCSVT.2023.3325427","National Key Research and Development Program of China(grant numbers:2020AAA0107800); Shanghai Collaborative Innovation Center of Trusted Industry Internet Software; National Research Foundation, Singapore; Defence Science Organization (DSO) National Laboratories under the Artificial Intelligence (AI) Singapore Programme (AISG)(grant numbers:AISG2-GC-2023-008); Agency for Science, Technology and Research (A*STAR) Centre for Frontier AI Research; National Research Foundation, Singapore; Cyber Security Agency under its National Cybersecurity Research and Development Programme(grant numbers:NCRP25-P04-TAICeN); NRF Investigatorship(grant numbers:NRF-NRFI06-2020-0001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10287378","DeepFake;DeepFake evasion;DeepFake detection","Deepfakes;Filtering;Notch filters;Image synthesis;Frequency-domain analysis;Fingerprint recognition;Detection algorithms","","22","","82","IEEE","18 Oct 2023","Aug. 2024","","IEEE","IEEE Journals"
"Deepfake Detection Based on Multi-scale RGB-Frequency Feature Fusion","Y. Meng; X. Wang; X. Wang; Z. Liu; H. Zhou","School of Electronic and Electrical Engineering, Ningxia University, Yinchuan, China; Ningxia Key Laboratory of Intelligent Sensing for Desert Information, Ningxia University, Yinchuan, China; School of Electronic and Electrical Engineering, Ningxia University, Yinchuan, China; School of Electronic and Electrical Engineering, Ningxia University, Yinchuan, China; School of Electronic and Electrical Engineering, Ningxia University, Yinchuan, China",2024 2nd International Conference on Intelligent Perception and Computer Vision (CIPCV),"14 Aug 2024","2024","","","46","50","Withthe rapid advancement of Deepfake technology, Deepfake content is becoming increasingly realistic and is being widely utilized in political forgery, financial fraud, and the dissemination of false news. In order to more accurately detect Deepfake images and adapt the detection model to various compression scenarios, we propose a forgery detection model based on multi-scale Rgb-Frequency domain feature extraction. This model employs different scale size feature extraction in CNN and extracts multi-scale features in the RGB domain. Subsequently, different feature sequences are input into the Transformer decoder to establish connections between modules and perform classification. The results demonstrate that MRFD exhibits strong robustness and generalization ability when adapting to changes in compression rates. On the LQ dataset of FF++, the ACC and AUC are 90.87% and 93.87%, respectively. The ACC on HQ dataset reaches 97.54% with an AUC of 99.27%.","","979-8-3503-6009-7","10.1109/CIPCV61763.2024.00018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10624085","Deepfake detection;CNN combined with ViT;Rgb-Frequency domain feature fusion;multi-scale feature extraction","Deepfakes;Adaptation models;Image coding;Finance;Network architecture;Feature extraction;Transformers","","3","","22","IEEE","14 Aug 2024","17-19 May 2024","17-19 May 2024","IEEE","IEEE Conferences"
"Blockwise Spectral Analysis for Deepfake Detection in High-fidelity Videos","H. Huang; N. Sun; X. Lin","ACT, AU, University of New South Wales; ACT, AU, University of New South Wales; VIC, AU, Deakin University",2022 IEEE 9th International Conference on Data Science and Advanced Analytics (DSAA),"8 Feb 2023","2022","","","1","9","Deepfakes have gained widespread attention as they may give rise to a series of risks ranging from personal reputation damages to national security breaches. A mainstream approach to generating deepfakes is based on Generative Adversarial Networks (GAN). Various methods have been proposed to detect GAN-generated fake content. However, most of them only target a specific GAN and do not generalize well to other unseen GAN architectures. Moreover, many existing methods show poor performance on deepfakes that are imperceptible to the human eye as they heavily rely on visual artifacts, such as unblinking eyes and asymmetric faces. In this work, we exploit the spectral artifacts left by up-sampling operations that are universally used in GAN architectures for detecting high-fidelity deepfake videos. We first divide video frames into blocks containing the most informative areas, e.g., face, eyes, and mouth areas, and use their spectrum to train a ResNet-based classifier to detect GAN-generated images. Experimental results on public datasets show that our method is effective in detecting high-fidelity deepfakes and generalizes well across GANs with the same or similar up-sampling operations.","","978-1-6654-7330-9","10.1109/DSAA54385.2022.10032370","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10032370","Disinformation Detection;Deepfakes;Spectral Artifacts;Generative Adversarial Networks","Training;Deepfakes;Visualization;Pipelines;Mouth;Generative adversarial networks;Reliability","","3","","36","IEEE","8 Feb 2023","13-16 Oct. 2022","13-16 Oct. 2022","IEEE","IEEE Conferences"
"WaViT-CDC: Wavelet Vision Transformer With Central Difference Convolutions for Spatial-Frequency Deepfake Detection","N. E. A. Badr; J. -C. Nebel; D. Greenhill; X. Liang","School of Computer Science and Mathematics, Kingston University London, London, U.K.; School of Computer Science and Mathematics, Kingston University London, London, U.K.; School of Computer Science and Mathematics, Kingston University London, London, U.K.; School of Computer Science and Mathematics, Kingston University London, London, U.K.",IEEE Open Journal of Signal Processing,"16 Jun 2025","2025","6","","621","630","The increasing popularity of generative AI has led to a significant rise in deepfake content, creating an urgent need for generalized and reliable deepfake detection methods. Since existing approaches rely on either spatial-domain features or frequency-domain features, they struggle to generalize across unseen datasets, especially those with subtle manipulations. To address these challenges, a novel end-to-end Wavelet Central Difference Convolutional Vision Transformer framework is designed to enhance spatial-frequency deepfake detection. Unlike previous methods, this approach applies the Discrete Wavelet Transform for multi-level frequency decomposition and Central Difference Convolution to capture local fine-grained discrepancies and focus on texture variances, while also incorporating Vision Transformers for global contextual understanding. The Frequency-Spatial Feature Fusion Attention module integrates these features, enabling the effective detection of fake artifacts. Moreover, in contrast to earlier work, subtle perturbations to both spatial and frequency domains are introduced to further improve generalization. Generalization cross-dataset evaluations demonstrate that WaViT-CDC outperforms state-of-the-art methods, when trained on both low-quality and high-quality face images, achieving an average performance increase of 2.5% and 4.5% on challenging high-resolution, real-world datasets such as Celeb-DF and WildDeepfake.","2644-1322","","10.1109/OJSP.2025.3571679","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11007485","Deepfake detection;central difference convolutions;vision transformer;spatial-frequency analysis;discrete wavelet transform;subtle perturbations;cross-dataset generalization","Feature extraction;Deepfakes;Frequency-domain analysis;Discrete wavelet transforms;Perturbation methods;Computer vision;Transformers;Convolution;Computational modeling;Wavelet analysis","","","","57","CCBY","20 May 2025","2025","","IEEE","IEEE Journals"
"Space–Frequency and Global–Local Attentive Networks for Sequential Deepfake Detection","G. Zhang; Q. Li; M. Gao; S. Guo; G. Jeon; A. M. Abdelmoniem","School of Electrical and Electronic Engineering, Shandong University of Technology, Zibo, China; School of Electronic Engineering and Computer Science, Queen Mary University of London, London, U.K.; School of Electrical and Electronic Engineering, Shandong University of Technology, Zibo, China; School of Electrical and Electronic Engineering, Shandong University of Technology, Zibo, China; Department of Embedded Systems Engineering, Incheon National University, Incheon, South Korea; School of Electronic Engineering and Computer Science, Queen Mary University of London, London, U.K.",IEEE Transactions on Computational Social Systems,"6 Oct 2025","2025","12","5","2940","2948","The widespread misinformation generated by deepfake systems has emerged as a significant challenge in the dynamic realm of digital media. It poses threats to credibility, privacy, and security of information in daily life. Moreover, the increasing accessibility to facial editing tools further enables users to alter facial characteristics subtly through a series of intricate steps. To address the issue, we introduce a space–frequency and global–local attentive network (SFGLA-Net) for sequential deepfake detection. This method is designed to identify and analyze the sophisticated manipulated attributes of deepfake images. Specifically, we introduce a space–frequency fusion module to leverage the deep feature extracted in spatial and frequency domains, so as to exploit subtle inconsistencies and artifacts that are not perceptible in the spatial domain alone. Additionally, we design a global–local attention module to pinpoint the manipulated areas more accurately. Extensive experiments demonstrate the superior performance of the proposed method by significantly outperforming existing techniques in sequential deepfake detection. The code is available at https://github.com/guishengzhanga/SFGLA.","2329-924X","","10.1109/TCSS.2025.3541346","National Natural Science Foundation of Shandong Province(grant numbers:ZR2022MF307); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10904029","Deepfake;global–local consistency;sequential deepfake detection;space–frequency fusion","Deepfakes;Feature extraction;Frequency-domain analysis;Forgery;Data mining;Transformers;Attention mechanisms;Kernel;Faces;Accuracy","","3","","33","IEEE","25 Feb 2025","Oct. 2025","","IEEE","IEEE Journals"
"Multi-domain Multi-scale DeepFake Detection for Generalization","T. Liu; Y. Liu; N. Li; H. Shi","School of Computer Science and Artificial Intelligence, Liaoning Normal University, Dalian, China; School of Computer Science and Artificial Intelligence, Liaoning Normal University, Dalian, China; School of Computer Science and Artificial Intelligence, Liaoning Normal University, Dalian, China; School of Computer Science and Artificial Intelligence, Liaoning Normal University, Dalian, China",2024 4th International Conference on Electronic Information Engineering and Computer Communication (EIECC),"25 Mar 2025","2024","","","1485","1492","As deepfake detection technology progresses and application scenarios broaden, it becomes challenging for detection models within a single domain or single scale to handle the complex application environments, leading to limited accuracy and generalization capabilities of the detection models. To address the above problems, we propose a Multi-domain Multi-scale DeepFake Detection model. First, we employ the RetinaFace framework to preprocess and augment the image data, which directs the model’s attention to the relevant regions of the image. Next, we utilize the EfficientNet-B0 network for rapid coarse-grained feature extraction. Building on these coarse-grained features, we design two modules to capture forgery traces at multiple levels: a spatial-domain fine-grained feature extraction module based on multi-scale analysis and a frequency-domain fine-grained feature extraction module leveraging the Fast Fourier Transform. Finally, the dual-domain features are fused using a multi-channel attention mechanism, enabling the model to comprehensively analyze images from various perspectives. Additionally, we implement a Particle Swarm Optimization (PSO) strategy to optimize the hyper-parameters of the network model. The proposed model demonstrates significant advantages over other algorithms, particularly in cross-dataset detection, exhibiting strong generalization, robustness, and adaptability. When trained on the FF++ dataset and tested on the Celeb-DF dataset, it achieves an AUC of 91.7%. This represents a 14.8% improvement in cross-dataset performance compared to the best existing model.","","979-8-3315-3462-2","10.1109/EIECC64539.2024.10929576","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10929576","DeepFake Detection;Multi-domain Multi-scale;P article Swarm Optimization;Data Preprocessing and Augmentation;Generalization","Training;Deepfakes;Adaptation models;Accuracy;Attention mechanisms;Frequency-domain analysis;Feature extraction;Robustness;Data models;Particle swarm optimization","","","","30","IEEE","25 Mar 2025","27-29 Dec. 2024","27-29 Dec. 2024","IEEE","IEEE Conferences"
"Cross-Domain Deepfake Detection Based on Latent Domain Knowledge Distillation","C. Wang; L. Meng; Z. Xia; N. Ren; B. Ma","Key Laboratory of Computing Power Network and Information Security, Ministry of Education, Shandong Computer Science Center, Qilu University of Technology (Shandong Academy of Sciences), Jinan, China; Key Laboratory of Computing Power Network and Information Security, Ministry of Education, Shandong Computer Science Center, Qilu University of Technology (Shandong Academy of Sciences), Jinan, China; Key Laboratory of Computing Power Network and Information Security, Ministry of Education, Shandong Computer Science Center, Qilu University of Technology (Shandong Academy of Sciences), Jinan, China; College of Information, Shenyang Institute of Engineering, Shenyang, China; Key Laboratory of Computing Power Network and Information Security, Ministry of Education, Shandong Computer Science Center, Qilu University of Technology (Shandong Academy of Sciences), Jinan, China",IEEE Signal Processing Letters,"27 Feb 2025","2025","32","","896","900","The rapid development of deepfake technology poses challenges to face-centered data security. Existing methods primarily focus on how to transfer deepfake detectors from the source domain to the target domain to handle diverse deepfake techniques. In practical application scenarios, it is usually difficult to access the true and false labels of the source domain. In this letter, we introduce a new adaptation framework called Latent Domain Knowledge Distillation (LDKD) for cross-domain deepfake detection. In the proposed framework, we construct a knowledge distillation structure that includes a student network and a teacher network, which are jointly optimized in a coupled manner to facilitate the model's adaptation to the target domain. Furthermore, to improve the quality of pseudo-labels generated by the teacher network, we propose a Fourier Latent Domain Generation Module (FLGM) and a Stochastic Complementary Mask Module (SCMM). The former is used to generate latent domains to bridge domain differences at the image level, while the latter is employed to mine richer contextual cues for the model. Extensive cross-domain experimental results demonstrate that our method achieves state-of-the-art performance, and the model analysis proves the effectiveness of our key components.","1558-2361","","10.1109/LSP.2025.3540941","National Natural Science Foundation of China(grant numbers:62302249,62272255); Taishan Scholar(grant numbers:tsqn202306251); Shandong Lifting Engineering(grant numbers:SDAST2024QTA086); Shandong Youth Innovation Team(grant numbers:2022KJ124,2024KJH035); Natural Science Foundation of Shandong Province(grant numbers:ZR2023QF032,ZR2022LZH011); Ability Improvement Project of Science and Technology SMES in Shandong Province(grant numbers:2023TSGC0217,2022TSGC2485); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10882912","Cross-domain deepfake detection;Fourier latent domain generation;knowledge distillation;stochastic complementary mask","Deepfakes;Adaptation models;Stochastic processes;Predictive models;Data models;Context modeling;Training;Forgery;Detectors;Knowledge engineering","","1","","34","IEEE","11 Feb 2025","2025","","IEEE","IEEE Journals"
"FreqDebias: Towards Generalizable Deepfake Detection via Consistency-Driven Frequency Debiasing","H. Kashiani; N. A. Talemi; F. Afghah",Clemson University; Clemson University; Clemson University,2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),"13 Aug 2025","2025","","","8775","8785","Deepfake detectors often struggle to generalize to novel forgery types due to biases learned from limited training data. In this paper, we identify a new type of model bias in the frequency domain, termed spectral bias, where detectors overly rely on specific frequency bands, restricting their ability to generalize across unseen forgeries. To address this, we propose FreqDebias, a frequency debiasing framework that mitigates spectral bias through two complementary strategies. First, we introduce a novel Forgery Mixup (Fo-Mixup) augmentation, which dynamically diversifies frequency characteristics of training samples. Second, we incorporate a dual consistency regularization (CR), which enforces both local consistency using class activation maps (CAMs) and global consistency through a von Mises-Fisher (vMF) distribution on a hyperspherical embedding space. This dual CR mitigates over-reliance on certain frequency components by promoting consistent representation learning under both local and global supervision. Extensive experiments show that FreqDebias significantly enhances cross-domain generalization and outperforms state-of-the-art methods in both cross-domain and in-domain settings.","2575-7075","979-8-3315-4364-8","10.1109/CVPR52734.2025.00820","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11094766","deepfake detection;frequency debiasing;spurious correlations;generalization","Training;Representation learning;Deepfakes;Computer vision;Frequency-domain analysis;Training data;Detectors;Forgery;Frequency diversity;Pattern recognition","","","","72","IEEE","13 Aug 2025","10-17 June 2025","10-17 June 2025","IEEE","IEEE Conferences"
"Multiple Feature Mining Based on Local Correlation and Frequency Information for Face Forgery Detection","S. Liu; Q. Jiang; X. Jin; Z. He; W. Zhou; S. Yao; Q. Wang","Engineering Research Center of Cyberspace, Yunnan University, Kunming, China; School of Software, Yunnan University, Kunming, China; School of Software, Yunnan University, Kunming, China; School of Software, Yunnan University, Kunming, China; School of Software, Yunnan University, Kunming, China; School of Software, Yunnan University, Kunming, China; School of Software, Yunnan University, Kunming, China",2022 IEEE 34th International Conference on Tools with Artificial Intelligence (ICTAI),"18 Apr 2023","2022","","","1347","1354","As facial image manipulation techniques developed, deep fake detection attracted extensive attentions. Although researchers have made remarkable progresses in deepfake detection recently, which is still suffering from two limitations: a) current detectors achieve high accuracy in the high-quality videos and images, but it is hard to capture local and subtle artifacts in the low-quality and high-compression media; b) few of deep fake detection methods gain satisfying performance under cross-database scenario, because detector overfit to specific color textures producing by same manipulation algorithm. Inspired the above issues, this paper proposes a novel framework fusing local related features and frequency information to mine the forgery patterns. Firstly, we design multi-feature enhancement module, which amplifies implicit local disc repancies and capture spatial correlation from three shallow feature layers and high-level semantic layer guided by attention maps. Secondly, dual frequency decomposition module is proposed for disassembling high-frequency and low-frequency features, the forgery artifacts are exposed after dual cross attention block processing in the frequency spectrum. Features from the two streams are fused to the classification for the final result. Comprehensive experiments demonstrate the superior performance of our proposed approach in the low-quality benchmark database and cross-dataset sce-nario.","2375-0197","979-8-3503-9744-4","10.1109/ICTAI56018.2022.00204","National Natural Science Foundation of China(grant numbers:62002313, 62101481); Applied Basic Research Foundation of Yunnan Province(grant numbers:202201AT070156); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10098069","face forgery detection;deep fake manipulation;deepfake image detection;attention mechanism;multiple feature mining","Deepfakes;Correlation;Image coding;Image color analysis;Semantics;Detectors;Media","","4","","40","IEEE","18 Apr 2023","31 Oct.-2 Nov. 2022","31 Oct.-2 Nov. 2022","IEEE","IEEE Conferences"
"Customized Transformer Adapter With Frequency Masking for Deepfake Detection","Z. Shi; H. Chen; Y. Jia; D. Zhang; W. Lu; X. Yang","College of Computer Science and Technology, Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, China; College of Computer Science and Technology, Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, China; College of Software, Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, China; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong, China; School of Computer Science and Engineering, Ministry of Education Key Laboratory of Information Technology, Guangdong Province Key Laboratory of Information Security Technology, Sun Yat-sen University, Guangzhou, China; School of Information Science and Technology, University of Science and Technology of China, Hefei, China",IEEE Transactions on Information Forensics and Security,"18 Jun 2025","2025","20","","5904","5918","The rapid advancement of AI-generated content has intensified concerns over deepfakes due to increasingly sophisticated and visually convincing forgeries. To this end, the pre-trained Vision Transformer (ViT) model has become a de facto choice for deepfake detection, thanks to its powerful learning capability. Despite favorable results achieved by existing ViT-based methods, they have inherent limitations that could result in suboptimal performance in scenarios with continuously evolving forgery techniques, such as overfitting to single forgery patterns or placing excessive emphasis on dominant forgery regions. In this paper, we propose CUTA, a simple yet effective deepfake detection paradigm that utilizes ViT adapters as the medium and fully exploits the spatial- and frequency-domain features of given images to overcome the limitations of existing methods. Specifically, CUTA focuses on frequency domain masking within the input space, which obscures parts of the high-frequency image to intensify the training challenge while preserving subtle forgery cues in the frequency domain to facilitate comprehensive forgery representations. Furthermore, we propose two task-customized modules within the ViT model, i.e., the texture enhancement module and the multi-scale perceptron module, to seamlessly integrate local texture and rich contextual features. These two modules ensure an organic interaction between the task-specific forgery patterns and general semantic features within the pre-trained ViT framework. The experimental results on several publicly available benchmarks demonstrate CUTA’s superiority in performance, particularly showcasing its significant advantages in both cross-dataset and cross-manipulation scenarios. Code and models are available at https://github.com/Zenanshi92/CUTA","1556-6021","","10.1109/TIFS.2025.3574983","National Natural Science Foundation of China(grant numbers:62276112,62441237); Key Projects of Science and Technology Development Plan of Jilin Province(grant numbers:20230201088GX); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11018133","Deepfake detection;vision transformer;ViT adapter;frequency domain masking","Forgery;Deepfakes;Semantics;Faces;Frequency-domain analysis;Feature extraction;Training;Transformers;Adaptation models;Visualization","","2","","93","IEEE","29 May 2025","2025","","IEEE","IEEE Journals"
"MaskSim: Detection of synthetic images by masked spectrum similarity analysis","Y. Li; Q. Bammey; M. Gardella; T. Nikoukhah; J. -M. Morel; M. Colom; R. G. Von Gioi","Université Paris-Saclay, ENS Paris-Saclay, CNRS, Centre Borelli, France; Université Paris-Saclay, ENS Paris-Saclay, CNRS, Centre Borelli, France; Instituto de Matemática Pura e Aplicada, Rio de Janeiro, Brazil; Université Paris-Saclay, ENS Paris-Saclay, CNRS, Centre Borelli, France; Department of Mathematics, City University of Hong Kong, Kowloon, Hong Kong; Université Paris-Saclay, ENS Paris-Saclay, CNRS, Centre Borelli, France; Université Paris-Saclay, ENS Paris-Saclay, CNRS, Centre Borelli, France",2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW),"27 Sep 2024","2024","","","3855","3865","Synthetic image generation methods have recently revolutionized the way in which visual content is created. This opens up creative opportunities but also presents challenges in preventing misinformation and crime. However, these methods leave traces in the Fourier spectrum that are invisible to humans, but can be detected by specialized tools. This paper describes a semi-white-box method for detecting synthetic images by revealing anomalous patterns in the spectral domain. Specifically, we train a mask to enhance the most discriminative frequencies and simultaneously train a reference pattern that resembles the patterns produced by a given generative method. The proposed method produces explainable results with state-of-the-art performances and highlights cues that can be used as forensic evidence. Code is available at https://github.com/li-yanhao/masksim.","2160-7516","979-8-3503-6547-4","10.1109/CVPRW63382.2024.00390","Horizon Europe; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10678228","synthetic image detection;diffusion image detection;deepfake detection;diffusion model;generative model;image forensics","Visualization;Computer vision;Image coding;Image synthesis;Forensics;Conferences;Transform coding","","6","","77","IEEE","27 Sep 2024","17-18 June 2024","17-18 June 2024","IEEE","IEEE Conferences"
"Frequency-Assisted Temporal Upsampling Artifacts Representation Learning for Face Forgery Detection","R. Sun; X. Yu; F. Wang; Z. Da; Y. Zhang; J. Gao","Key Laboratory of Knowledge Engineering with Big Data, Ministry of Education, School of Computer and Information, Anhui Province Key Laboratory of Industry Safety and Emergency Technology, Hefei University of Technology, Hefei, China; Key Laboratory of Knowledge Engineering with Big Data, Ministry of Education, School of Computer and Information, Anhui Province Key Laboratory of Industry Safety and Emergency Technology, Hefei University of Technology, Hefei, China; Key Laboratory of Knowledge Engineering with Big Data, Ministry of Education, School of Computer and Information, Anhui Province Key Laboratory of Industry Safety and Emergency Technology, Hefei University of Technology, Hefei, China; Key Laboratory of Knowledge Engineering with Big Data, Ministry of Education, School of Computer and Information, Anhui Province Key Laboratory of Industry Safety and Emergency Technology, Hefei University of Technology, Hefei, China; Key Laboratory of Knowledge Engineering with Big Data, Ministry of Education, School of Computer and Information, Anhui Province Key Laboratory of Industry Safety and Emergency Technology, Hefei University of Technology, Hefei, China; Key Laboratory of Knowledge Engineering with Big Data, Ministry of Education, School of Computer and Information, Anhui Province Key Laboratory of Industry Safety and Emergency Technology, Hefei University of Technology, Hefei, China","IEEE Transactions on Biometrics, Behavior, and Identity Science","25 Sep 2025","2025","7","4","728","739","Recently, the highly realistic deepfake images have aroused the potential for deepfake abuse, and both the detection and its generalization remain challenging. Existing deepfake video detection methods strive to capture distinguishing features between fake and real faces through temporal modeling. However, these works provide local supervision between sampled video frames, but overlook intra-frame generative artifacts, which can function as an useful indicators for detection. To mitigate the issue, we propose a temporal-frequential convolutional network based on the representation of upsampling artifacts, which can automatically capture incoherent artifacts representation in different ends. Specifically, we design the Upsampling Artifacts Representation Module (UARM), which captures upsampling artifacts introduced in generation end based on the relationship between pixels, and then we probe the deep coupling of intra-frame global frequency information with inter-frame incoherence, and design the Frequency-Assisted Temporal Incoherence Module (FATIM), which can facilitate the detection of temporal information in RGB domain by frequency domain information, and the Self-tuned Convolutions Module (SCM) is designed to supplement information and adjust it automatically in the learning process. In addition, the Information Fusion Module (IFM) is designed to couple multiple information and establish a more comprehensive representation. With the above modules, our proposed method can learn robust features in both generation end and detection end. Extensive experiments demonstrate that our method outperforms other state-of-the-art video detection methods by a large margin on the challenging DFDC and FF++ in low-quality.","2637-6407","","10.1109/TBIOM.2025.3569645","China Postdoctoral Science Foundation(grant numbers:2022M720981); National Natural Science Foundation of China Youth Foud(grant numbers:62302142); National Natural Science Foundation of China(grant numbers:61876057); Anhui Province Natural Science Foundation(grant numbers:2208085MF158); Key Research Plan of Anhui Province - Strengthening Police with Science and Technology(grant numbers:202004d07020012); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11003101","DeepFake detection;upsampling artifacts;multiple end;temporal-frequential convolution","Faces;Deepfakes;Frequency-domain analysis;Forgery;Feature extraction;Data mining;Kernel","","","","55","IEEE","13 May 2025","Oct. 2025","","IEEE","IEEE Journals"
"Wavelet-based GAN Fingerprint Detection using ResNet50","S. T. Erukude; S. Reddy Veluru; V. C. Marella","Department of Computer Science, Kansas State University, Manhattan, USA; College of Business Administration, Kansas State University, Manhattan, USA; College of Business Administration, Kansas State University, Manhattan, USA",2025 4th International Conference on Innovative Mechanisms for Industry Applications (ICIMIA),"20 Oct 2025","2025","","","382","387","Identifying images generated by Generative Adversarial Networks (GANs) has become a significant challenge in digital image forensics. This research presents a wavelet-based detection method that uses discrete wavelet transform (DWT) preprocessing and a ResNet50 classification layer to differentiate the StyleGAN-generated images from real ones. Haar and Daubechies wavelet filters are applied to convert the input images into multi-resolution representations, which will then be fed to a ResNet50 network for classification, capitalizing on subtle artifacts left by the generative process. Moreover, the wavelet-based models are compared to an identical ResNet50 model trained on spatial data. The Haar and Daubechies preprocessed models achieved a greater accuracy of 93.8 percent and 95.1 percent, much higher than the model developed in the spatial domain (accuracy rate of 81.5 percent). The Daubechies-based model outperforms Haar, showing that adding layers of descriptive frequency patterns can lead to even greater distinguishing power. These results indicate that the GAN-generated images have unique wavelet-domain artifacts or ""fingerprints."" The method proposed illustrates the effectiveness of wavelet-domain analysis to detect GAN images and emphasizes the potential of further developing the capabilities of future deepfake detection systems.","","979-8-3315-5386-9","10.1109/ICIMIA67127.2025.11200674","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11200674","Deepfake Detection;Wavelet-domain analysis;Image forensics;StyleGAN Fingerprints","Image forensics;Deepfakes;Accuracy;Digital images;Fingerprint recognition;Generative adversarial networks;Feature extraction;Wavelet analysis;Discrete wavelet transforms;Residual neural networks","","","","15","IEEE","20 Oct 2025","3-5 Sept. 2025","3-5 Sept. 2025","IEEE","IEEE Conferences"
"Context-Aware Deepfake Detection for Securing AI-Driven Financial Transactions","C. Liu; G. Zhang; S. Guo; Q. Li; G. Jeon; M. Gao","School of Electrical and Electronic Engineering, Shandong University of Technology, Zibo, China; School of Electrical and Electronic Engineering, Shandong University of Technology, Zibo, China; School of Electrical and Electronic Engineering, Shandong University of Technology, Zibo, China; School of Electronic Engineering and Computer Science, Queen Mary University of London, London, U.K.; Department of Embedded Systems Engineering, Incheon National University, Incheon, South Korea; School of Electrical and Electronic Engineering, Shandong University of Technology, Zibo, China",IEEE Transactions on Computational Social Systems,"2 Dec 2025","2025","12","6","5342","5349","The rapid advancement of deepfake technology has threatened the community’s sense of security, particularly in the context of face-based payment systems. Thus, deepfake detection has emerged as a critical issue demanding immediate attention. However, the generalization performance of existing detection models is limited as they are overly reliant on specific forged features while ignoring the common forged features. To address this problem, we introduce the context-aware decoupling network (CADNet) for deepfake detection. Specifically, a context self-calibration (CSC) module is constructed to guide the network to focus on local forged regions. It enlarges possible regions to increase the likelihood of forgery cues. Meanwhile, a frequency domain decoupling (FDD) module is introduced to extract and fuse different frequency components. It realizes the collaborative representation optimization of global semantics and local details. The experimental results prove that the proposed model exhibits strong generalization capability across multiple standard datasets. It achieves average area under the curve (AUC) values of 98.64% for in-domain evaluation and 75.52% for cross-dataset generalization.","2329-924X","","10.1109/TCSS.2025.3577753","Shandong Province Undergraduate Teaching Reform Project(grant numbers:Z2024184); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11073561","Context self-calibration (CSC);deepfake detection;facial payment;frequency domain decoupling (FDD);generalization","Deepfakes;Feature extraction;Forgery;Frequency-domain analysis;Image reconstruction;Wavelet transforms;Faces;Convolution;Fuses;Finance","","","","43","IEEE","8 Jul 2025","Dec. 2025","","IEEE","IEEE Journals"
"Low Resolution Deepfake Face Detection using Multi-Scale Discrete Cosine Transform and Vision Transformer","M. Uddin; Z. Fu; X. Zhang; A. B. H. Arnob","School of Computer Science, Nanjing University of Information Science and Technology, Nanjing, China; School of Computer Science, Nanjing University of Information Science and Technology, Nanjing, China; School of Computer Science, Nanjing University of Information Science and Technology, Nanjing, China; School of Artificial Intelligence, Nanjing University of Information Science and Technology, Nanjing, China","2025 3rd International Conference on Intelligent Systems, Advanced Computing and Communication (ISACC)","22 Apr 2025","2025","","","1134","1139","Deepfake technology uses generative adversarial networks to produce highly authentic counterfeit images and videos, which raises a significant global security concern by disseminating fake information through online platforms, especially on social media. Researchers have developed sophisticated models for deepfake detection, demonstrating high performance on high-resolution images. However, their effectiveness significantly diminishes when applied to low-resolution images. We propose a simple framework that utilizes multi-scale discrete cosine transform and vision transformer for low-resolution deepfake face detection. This framework introduces a multi-scale frequency filter fusion approach to extract subtle frequency features in the frequency domain. Our proposed network has been tested on the FaceForensics++ and Celeb-DF datasets, and it outperforms existing models, achieving superior AUC and F1 scores.","","979-8-3315-2389-3","10.1109/ISACC65211.2025.10969193","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10969193","Deepfake Face Detection;Discrete Cosine Transform;Vision Transformer;Computer Vision","Deepfakes;Image resolution;Social networking (online);Frequency-domain analysis;Transformers;Feature extraction;Discrete cosine transforms;Face detection;Security;Intelligent systems","","","","19","IEEE","22 Apr 2025","27-28 Feb. 2025","27-28 Feb. 2025","IEEE","IEEE Conferences"
"Local Region Frequency Guided Dynamic Inconsistency Network for Deepfake Video Detection","P. Yue; B. Chen; Z. Fu","Engineering Research Center of Digital Forensics affiliated with Ministry of Education, Nanjing, China; Engineering Research Center of Digital Forensics affiliated with Ministry of Education, Nanjing, China; Engineering Research Center of Digital Forensics affiliated with Ministry of Education, Nanjing, China",Big Data Mining and Analytics,"28 Aug 2024","2024","7","3","889","904","In recent years, with the rapid development of deepfake technology, a large number of deepfake videos have emerged on the Internet, which poses a huge threat to national politics, social stability, and personal privacy. Although many existing deepfake detection methods exhibit excellent performance for known manipulations, their detection capabilities are not strong when faced with unknown manipulations. Therefore, in order to obtain better generalization ability, this paper analyzes global and local inter-frame dynamic inconsistencies from the perspective of spatial and frequency domains, and proposes a Local region Frequency Guided Dynamic Inconsistency Network (LFGDIN). The network includes two parts: Global SpatioTemporal Network (GSTN) and Local Region Frequency Guided Module (LRFGM). The GSTN is responsible for capturing the dynamic information of the entire face, while the LRFGM focuses on extracting the frequency dynamic information of the eyes and mouth. The LRFGM guides the GTSN to concentrate on dynamic inconsistency in some significant local regions through local region alignment, so as to improve the model's detection performance. Experiments on the three public datasets (FF++, DFDC, and Celeb-DF) show that compared with many recent advanced methods, the proposed method achieves better detection results when detecting deepfake videos of unknown manipulation types.","2097-406X","","10.26599/BDMA.2024.9020030","National Natural Science Foundation of China(grant numbers:62072251,U22B2062); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10654681","deepfake video detection;dynamic inconsistency;local region;local region frequency","Deepfakes;Privacy;Frequency-domain analysis;Mouth;Lighting;Stability analysis;Spatiotemporal phenomena","","10","","46","","28 Aug 2024","September 2024","","TUP","TUP Journals"
"Face Forgery Detection via Multi-Feature Fusion and Local Enhancement","D. Zhang; J. Chen; X. Liao; F. Li; J. Chen; G. Yang","School of Computer and Communication Engineering, Changsha University of Science and Technology, Changsha, China; School of Computer and Communication Engineering, Changsha University of Science and Technology, Changsha, China; College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; School of Computer and Communication Engineering, Changsha University of Science and Technology, Changsha, China; School of Computer and Communication Engineering, Changsha University of Science and Technology, Changsha, China; College of Computer Science and Electronic Engineering, Hunan University, Changsha, China",IEEE Transactions on Circuits and Systems for Video Technology,"30 Sep 2024","2024","34","9","8972","8977","With the rapid growth of Internet technology, security concerns have risen, particularly with the prevalence of Deepfakes, a popular visual forgery technique. Therefore, there is necessary to research more powerful methods to detect Deepfakes. However, many Convolutional Neural Networks-based detection methods struggle with cross-database performance, often overfitting to specific color textures. We observe that image noises can weaken the influence of color textures and expose the forgery traces in the noise domain. This is because tampering techniques, when altering face images, disrupt the consistency of feature distribution in the noise space. And the forgery traces in the noise space are complementary to the tampering artifacts present in the image space information. Therefore, we propose a novel face forgery detection network that combines spatial domain and noise domain. Our Dual Feature Fusion Module and Local Enhancement Attention Module contribute to more comprehensive feature representations, enhancing our method’s discriminative ability. Experimental results demonstrate superior performance compared to existing methods on mainstream datasets. https://github.com/jhchen1998/DeepfakeDetection.","1558-2205","","10.1109/TCSVT.2024.3390945","National Natural Science Foundation of China(grant numbers:62172059,62272160,U22A2030,61972142); Scientific Research Fund of Hunan Provincial Education Department of China(grant numbers:22A0200); Science Fund for Distinguished Young Scholars of Hunan Province(grant numbers:2024JJ2025); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10504924","Deepfakes;face forgery detection;spatial domain;noise domain","Noise measurement;Feature extraction;Forgery;Face recognition;Deepfakes;Filters;Frequency-domain analysis;Detection algorithms","","29","","32","IEEE","18 Apr 2024","Sept. 2024","","IEEE","IEEE Journals"
"Deepfake Detection using Multi-Stream Convolutional Neural Networks with Attention-based Fusion","M. Sankaran; M. Alwbaidy; L. K. R; S. D. Govardhan; P. P. Selvam","USA; Department of Computers Techniques Engineering, College of Technical Engineering, The Islamic University, Najaf, Iraq; Department of Electronics and Communication Engineering, Nitte Meenakshi Institute of Technology, Nitte (Deemed to be University), Bengaluru, India; Department of Electronics and Communication Engineering, Dhanalakshmi Srinivasan College of Engineering and Technology, Mamallapuram, India; Doctoral Studies and Intellectual Property Rights, Meenakshi Academy of Higher Education & Research (Deemed to be University), Chennai, India",2025 International Conference on Intelligent Communication Networks and Computational Techniques (ICICNCT),"18 Nov 2025","2025","","","1","6","In recent years, DeepFake technology has rapidly evolved by enabling the development of highly realistic forged facial videos that pose serious threats to digital trust and security. Traditional deep learning approaches, although effective in image classification, usually struggle to generalize against subtle manipulation artifacts, compression noise, and temporal inconsistencies. To address these challenges, a MultiStream Convolutional Neural Network (MS-CNN) framework is proposed for robust deepfake detection. Initially, utilizes the FaceForensics++ dataset which is a widely recognized benchmark containing authentic and manipulated facial videos. Preprocessing incorporates face detection, alignment, and the generation of complementary modalities, which include frequency-domain representations, residual noise maps, and temporal signals, such as rPPG and optical flow. These multimodal inputs were passed through parallel CNN streams for feature extraction to capture spatial, spectral, and temporal inconsistencies. The extracted features are combined using an attention-based adaptive fusion mechanism that dynamically learns the relative importance of each modality. Finally, a fully connected softmax classifier produces end-to-end predictions that differentiate between real and fake videos. The experimental results show that the MS-CNN obtains higher accuracy (99.77 %), precision (98.95 %), recall (98.45 %), and F1score (98.76 %) when compared with the existing CNN model, which improves detection robustness and generalization in different manipulation techniques.","","979-8-3315-8623-2","10.1109/ICICNCT66124.2025.11232837","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11232837","deepfake detection;multi-stream convolutional neural networks;residual noise maps;softmax classifier;temporal signals","Training;Deepfakes;Accuracy;Computational modeling;Noise;Feature extraction;Transformers;Robustness;Convolutional neural networks;Security","","","","15","IEEE","18 Nov 2025","5-6 Sept. 2025","5-6 Sept. 2025","IEEE","IEEE Conferences"
"Fake Face Detection Based on Fusion of Spatial Texture and High-Frequency Noise","D. Zhang; F. Qi; J. Chen; J. Chen; R. Gong; Y. Tian; L. Zhang","Hunan Provincial Key Laboratory of Intelligent Processing of Big Data on Transportation, School of Computer and Communication Engineering, Changsha University of Science and Technology, Changsha, China; Hunan Provincial Key Laboratory of Intelligent Processing of Big Data on Transportation, School of Computer and Communication Engineering, Changsha University of Science and Technology, Changsha, China; Hunan Provincial Key Laboratory of Intelligent Processing of Big Data on Transportation, School of Computer and Communication Engineering, Changsha University of Science and Technology, Changsha, China; Hunan Provincial Key Laboratory of Intelligent Processing of Big Data on Transportation, School of Computer and Communication Engineering, Changsha University of Science and Technology, Changsha, China; Changsha Social Work College, Changsha, China; Changkuangao Beijing Technology Co., Ltd., Beijing, China; School of Computer and Artificial Intelligence, Huaihua University, Huaihua, China",Chinese Journal of Electronics,"18 Feb 2025","2025","34","1","212","221","The rapid development of the Internet has led to the widespread dissemination of manipulated facial images, significantly impacting people's daily lives. With the continuous advancement of Deepfake technology, the generated counterfeit facial images have become increasingly challenging to distinguish. There is an urgent need for a more robust and convincing detection method. Current detection methods mainly operate in the spatial domain and transform the spatial domain into other domains for analysis. With the emergence of transformers, some researchers have also combined traditional convolutional networks with transformers for detection. This paper explores the artifacts left by Deepfakes in various domains and, based on this exploration, proposes a detection method that utilizes the steganalysis rich model to extract high-frequency noise to complement spatial features. We have designed two main modules to fully leverage the interaction between these two aspects based on traditional convolutional neural networks. The first is the multi-scale mixed feature attention module, which introduces artifacts from high-frequency noise into spatial textures, thereby enhancing the model's learning of spatial texture features. The second is the multiscale channel attention module, which reduces the impact of background noise by weighting the features. Our proposed method was experimentally evaluated on mainstream datasets, and a significant amount of experimental results demonstrate the effectiveness of our approach in detecting Deepfake forged faces, outperforming the majority of existing methods.","2075-5597","","10.23919/cje.2023.00.342","National Natural Science Foundation of China(grant numbers:62172059); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10891978","Deepfakes detection;Steganalysis rich model;Image forensics;Mix attention","Deepfakes;Adaptation models;Attention mechanisms;Noise;Transforms;Transformers;Feature extraction;Internet;Convolutional neural networks;Faces","","6","","30","","18 Feb 2025","January 2025","","CIE","CIE Journals"
"MIFAE-Forensics: Masked Image-Frequency AutoEncoder for DeepFake Detection","H. Wang; Z. Liu; S. Wang","School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University","ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","7 Mar 2025","2025","","","1","5","With continuously evolving generative models and increasingly diverse face forgery products, there is a growing demand for DeepFake detectors with stronger generalization ability and robustness. Previous works mainly capture method-specific forgery artifacts in the training set, thus failing to generalize well to unseen manipulations. In this paper, our key insight is that exploring common characteristics of natural faces is more ideal to alleviate overfitting rather than relying on specific forgery clues, as all sorts of manipulated images have intrinsic distributional differences from those captured by cameras. Hence, we propose a two-stage method, termed MIFAE-Forensics. Specifically, it reconstructs both facial semantics and local details from masked facial regions and high-frequency components, respectively, aiming to capture natural facial consistency in spatial domain and high-frequency details in frequency domain simultaneously. This facilitates the learning of a robust and transferable facial representation specialized for DeepFake detection. Subsequently, the pre-trained model is further fine-tuned to perform binary forgery classification along with reconstructing real faces in spatial domain, which ensures that the detector can maintain the ability to model real faces and encourages it to make decisions based on reconstruction discrepancies. Extensive experiments show superior results over state-of-the-arts on a wide range of DeepFake detection benchmarks. Our code is available at https://github.com/Mark-Dou/Forensics.","2379-190X","979-8-3503-6874-1","10.1109/ICASSP49660.2025.10889125","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10889125","Masked Image Modeling;DeepFake Detection","Training;Deepfakes;Face recognition;Semantics;Detectors;Benchmark testing;Forgery;Speech processing;Image reconstruction;Overfitting","","1","","35","IEEE","7 Mar 2025","6-11 April 2025","6-11 April 2025","IEEE","IEEE Conferences"
"Domain Generalization via Aggregation and Separation for Audio Deepfake Detection","Y. Xie; H. Cheng; Y. Wang; L. Ye","State Key Laboratory of Media Convergence and Communication and the School of Information and Communication Engineering, Communication University of China, Beijing, China; State Key Laboratory of Media Convergence and Communication, Communication University of China, Beijing, China; State Key Laboratory of Media Convergence and Communication, Communication University of China, Beijing, China; State Key Laboratory of Media Convergence and Communication, Communication University of China, Beijing, China",IEEE Transactions on Information Forensics and Security,"21 Nov 2023","2024","19","","344","358","In this paper, we propose an Aggregation and Separation Domain Generalization (ASDG) method for Audio DeepFake Detection (ADD). Fake speech generated from different methods exhibits varied amplitude and frequency distributions rather than genuine speech. In addition, the spoofing attacks in training sets may not keep pace with the evolving diversity of real-world deepfake distributions. In light of this, we attempt to learn an ideal feature space that can aggregate real speech and separate fake speech to achieve better generalizability in the detection of unseen target domains. Specifically, we first propose a feature generator based on Lightweight Convolutional Neural Networks (LCNN), which is employed for generating a feature space and categorizing the feature into real and fake. Meanwhile, single-side domain adversarial learning is leveraged to make only the real speech from different domains indistinguishable, which enables the distribution of real speech to be aggregated in the feature space. Furthermore, a triplet loss is adopted to separate the distribution of fake speech while aggregating the distribution of real speech. Finally, in order to test the generalizability of the model, we train it with three different English datasets and evaluate in harsh conditions: cross-language and noisy datasets. The extensive experiments show that ASDG outperforms the baseline models in cross-domain tasks and decreases Equal Error Rate (EER) by up to 39.24% when compared to that of RawNet2. It is proved that the proposed Aggregation and Separation Domain Generalization method can be an effective strategy to improve the model generalizability.","1556-6021","","10.1109/TIFS.2023.3324724","Natural Science Foundation of China(grant numbers:62201524,62271455,61971383); Fundamental Research Funds for the Central Universities(grant numbers:CUC23GZ016); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10286049","Audio deepfake detection;domain generalization;feature generator;triplet loss","Deepfakes;Task analysis;Training;Faces;Speech enhancement;Vocoders;Feature extraction","","36","","96","IEEE","16 Oct 2023","2024","","IEEE","IEEE Journals"
"What Does an Audio Deepfake Detector Focus on? A Study in the Time Domain","P. Grinberg; A. Kumar; S. Koppisetti; G. Bharaj","EPFL, Switzerland; Reality Defender Inc., USA; Reality Defender Inc., USA; Reality Defender Inc., USA","ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","7 Mar 2025","2025","","","1","5","Adding explanations to audio deepfake detection (ADD) models will enable insights on the decision making process and thus boost their real-world application. In this paper, we propose a relevancy-based explainable AI (XAI) method to analyze the predictions of transformer-based ADD models. We compare against standard Grad-CAM and SHAP-based methods, using quantitative faithfulness metrics as well as a partial spoof test, to comprehensively analyze the relative importance of different temporal regions in an audio. We consider large datasets, unlike previous works where only limited utterances are studied, and find that the XAI methods differ in their explanations. The proposed relevancy-based XAI method performs the best overall on a variety of metrics. Further investigation on the relative importance of speech/non-speech, phonetic content, and voice onsets/offsets suggests that the XAI results obtained from a limited set of utterances do not necessarily hold when evaluated on large datasets.","2379-190X","979-8-3503-6874-1","10.1109/ICASSP49660.2025.10887568","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10887568","Deepfake Detection;Model Interpretation;Explainable AI","Measurement;Deepfakes;Time-frequency analysis;Noise;Predictive models;Phonetics;Transformers;Time-domain analysis;Speech processing;Standards","","2","","38","IEEE","7 Mar 2025","6-11 April 2025","6-11 April 2025","IEEE","IEEE Conferences"
"Constructing New Backbone Networks via Space-Frequency Interactive Convolution for Deepfake Detection","Z. Guo; Z. Jia; L. Wang; D. Wang; G. Yang; N. Kasabov","School of Computer Science and Technology, Xinjiang University, Urumqi, China; School of Computer Science and Technology, Xinjiang University, Urumqi, China; School of Computer Science and Technology, Xinjiang University, Urumqi, China; College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; School of Engineering, Computing and Mathematical Sciences, Auckland University of Technology, Auckland, New Zealand",IEEE Transactions on Information Forensics and Security,"21 Nov 2023","2024","19","","401","413","The serious concerns over the negative impacts of Deepfakes have attracted wide attentions in the community of multimedia forensics. The existing detection works achieve deepfake detection by improving the traditional backbone networks to capture subtle manipulation traces. However, there is no attempt to construct new backbone networks with different structures for Deepfake detection by improving the internal feature representation of convolution. In this work, we propose a novel Space-Frequency Interactive Convolution (SFIConv) to efficiently model the manipulation clues left by Deepfake. To obtain high-frequency features from tampering traces, a Multichannel Constrained Separable Convolution (MCSConv) is designed as the component of the proposed SFIConv, which learns space-frequency features via three stages, namely generation, interaction and fusion. In addition, SFIConv can replace the vanilla convolution in any backbone networks without changing the network structure. Extensive experimental results show that seamlessly equipping SFIConv into the backbone network greatly improves the accuracy for Deepfake detection. In addition, the space-frequency interaction mechanism does benefit to capturing common artifact features, thus achieving better results in cross-dataset evaluation. Our code will be available at https://github.com/EricGzq/SFIConv.","1556-6021","","10.1109/TIFS.2023.3324739","Xinjiang Uygur Autonomous Region Tianshan Excellence Project(grant numbers:2022TSYCLJ0036); Scientific and Technological Innovation 2030 Major Project(grant numbers:2022ZD0115800); National Natural Science Foundation of China(grant numbers:62302427,62261053,61972143,61972142,62372164,U1903213); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10286083","Deepfake detection;space-frequency interactive convolution;backbone network;manipulation traces","Deepfakes;Convolution;Faces;Feature extraction;Forgery;Deep learning;Task analysis","","33","","52","IEEE","16 Oct 2023","2024","","IEEE","IEEE Journals"
"Deepfake detection based on Spatio-Temporal Fusion","T. Chen; J. Hu; S. Yang","College of Computer Science & Technology, Chengdu University of Information Technology, Chengdu, China; College of Computer Science & Technology, Chengdu University of Information Technology, Chengdu, China; College of Computer Science & Technology, Chengdu University of Information Technology, Chengdu, China",2025 International Conference on Information Management and Computing Technology (ICIMCT),"8 Oct 2025","2025","","","77","82","To address the limitations of existing detection algorithms that utilize temporal information but are weak in extracting local information of forged traces, this paper introduces a detection algorithm for forged faces which based on spatiotemporal feature fusion. The algorithm comprises a spatial-frequency domain hybrid feature enhancement module and a frequency-aware dynamic gating unit module. Through the frequency domain, the high-frequency components of forged traces are enhanced to capture the global spatial and local frequency-domain cues. Subsequently, the frequency-aware dynamic gating unit is employed to amplify subtle cues in the temporal dimension that are difficult to discern. These cues from both dimensions are then integrated through an information fusion module to obtain a more comprehensive feature representation. Experimental results demonstrate that the proposed algorithm exhibits superior generalization performance on datasets in the forged domain.","","979-8-3315-8501-3","10.1109/ICIMCT.2025.00024","China Meteorological Administration; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11185707","deepfake detection;Feature Enhancement;Spatiotemporal Feature Fusion","Deepfakes;Heuristic algorithms;Frequency-domain analysis;Computational modeling;Logic gates;Feature extraction;Robustness;Spatiotemporal phenomena;Information management;Detection algorithms","","","","46","IEEE","8 Oct 2025","9-11 May 2025","9-11 May 2025","IEEE","IEEE Conferences"
"ADD 2022: the first Audio Deep Synthesis Detection Challenge","J. Yi; R. Fu; J. Tao; S. Nie; H. Ma; C. Wang; T. Wang; Z. Tian; Y. Bai; C. Fan; S. Liang; S. Wang; S. Zhang; X. Yan; L. Xu; Z. Wen; H. Li","National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; Department of Electrical and Computer Engineering, National University of Singapore","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","9216","9220","Audio deepfake detection is an emerging topic, which was included in the ASVspoof 2021. However, the recent shared tasks have not covered many real-life and challenging scenarios. The first Audio Deep synthesis Detection challenge (ADD) was motivated to fill in the gap. The ADD 2022 includes three tracks: low-quality fake audio detection (LF), partially fake audio detection (PF) and audio fake game (FG). The LF track focuses on dealing with bona fide and fully fake utterances with various real-world noises etc. The PF track aims to distinguish the partially fake audio from the real. The FG track is a rivalry game, which includes two tasks: an audio generation task and an audio fake detection task. In this paper, we describe the datasets, evaluation metrics, and protocols. We also report major findings that reflect the recent advances in audio deepfake detection tasks.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9746939","Research and Development; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9746939","audio deepfake;fake detection;low-quality fake;partially fake;audio fake game","Measurement;Protocols;Conferences;Games;Signal processing;Acoustics;Task analysis","","104","","20","IEEE","27 Apr 2022","23-27 May 2022","23-27 May 2022","IEEE","IEEE Conferences"
"Boosting Deepfake Detection Generalizability via Expansive Learning and Confidence Judgement","K. Zhang; Z. Hou; Z. Hua; Y. Zheng; L. Yu Zhang","School of Computer Science and Technology, Harbin Institute of Technology at Shenzhen, Shenzhen, China; School of Computer Science and Technology, Harbin Institute of Technology at Shenzhen, Shenzhen, China; School of Computer Science and Technology, Harbin Institute of Technology at Shenzhen, Shenzhen, China; School of Computer Science and Technology, Harbin Institute of Technology at Shenzhen, Shenzhen, China; School of Information and Communication Technology, Griffith University, Gold Coast Campus, Southport, QLD, Australia",IEEE Transactions on Circuits and Systems for Video Technology,"29 Jan 2025","2025","35","1","953","966","As deepfake technology poses severe threats to information security, significant efforts have been devoted to deepfake detection. To enable model generalization for detecting new types of deepfakes, it is required that the existing models should learn knowledge about new types of deepfakes without losing prior knowledge, a challenge known as catastrophic forgetting (CF). Existing methods mainly utilize domain adaptation to learn about the new deepfakes for addressing this issue. However, these methods are constrained to utilizing a small portion of data samples from the new deepfakes, and they suffer from CF when the size of the data samples used for domain adaptation increases. This resulted in poor average performance in source and target domains. In this paper, we introduce a novel approach to boost the generalizability of deepfake detection. Our approach follows a two-stage training process: training in the source domain (prior deepfakes that have been used for training) and domain adaptation to the target domain (new types of deepfakes). In the first stage, we employ expansive learning to train our expanded model from a well-trained teacher model. In the second stage, we transfer the expanded model to the target domain while removing assistant components. For model architecture, we propose the frequency extraction module to extract frequency features as complementary to spatial features and introduce spatial-frequency contrastive loss to enhance feature learning ability. Moreover, we develop a confidence judgement module to eliminate conflicts between new and prior knowledge. Experimental results demonstrate that our method can achieve better average accuracy in source and target domains even when using large-scale data samples of the target domain, and it exhibits superior generalizability compared to state-of-the-art methods.","1558-2205","","10.1109/TCSVT.2024.3462985","National Natural Science Foundation of China(grant numbers:62071142); Guangdong Basic and Applied Basic Research Foundation(grant numbers:2024A1515012299,2023A1515010714); Guangdong Provincial Key Laboratory of Novel Security Intelligence Technologies(grant numbers:2022B1212010005); Shenzhen Science and Technology Program(grant numbers:ZDSYS20210623091809029); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10684474","Deepfake detection;generalizability;domain adaptation;catastrophic forgetting","Deepfakes;Feature extraction;Adaptation models;Training;Data mining;Frequency-domain analysis;Finite element analysis","","2","","64","IEEE","19 Sep 2024","Jan. 2025","","IEEE","IEEE Journals"
"Diffusion-Aware Deepfake Detection via Kernel PCA on Noise Residuals for Semantic Communication","B. Chen","College of Information and Electrical Engineering, China Agriculture University, Beijing, China",2025 IEEE 101st Vehicular Technology Conference (VTC2025-Spring),"30 Sep 2025","2025","","","1","7","Deepfake creation relies on advanced deep learning models enabling hyper-realistic synthetic media with applications in industrial and social semantic communication. However, these advancements pose severe threats to digital security and semantic communication, where preserving content integrity is critical. Traditional detection methods fail against diffusion-generated content due to diminishing distributional gaps between real and synthetic samples. We propose a novel Deepfake Detection Pipeline that leverages the inherent noise-prediction mechanism of Denoising Diffusion Probabilistic Models (DDPMs) to extract discriminative distributional features. By fine-tuning a DDPM noise predictor, we capture subtle artifacts in synthetic images that are imperceptible to conventional detectors. These features are then analyzed through a kernel-based normative compliance detector, combining Kernel PCA (KPCA) with out-of-distribution detection to isolate deepfakes by measuring deviations from natural image manifolds. The proposed approach addresses the key challenge of detecting fine-grained distributional differences in high-quality synthetic media. Experiments demonstrate state-of-the-art performance on diffusion-generated deepfakes, outperforming existing methods on CREMA-D and Remote Sensing DeepFake Detection Dataset. The pipeline allows integration with existing detection frameworks, offering a scalable solution for evolving threats.","2577-2465","979-8-3315-3147-8","10.1109/VTC2025-Spring65109.2025.11174885","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11174885","Deepfake Detection;Diffusion Models;Noise Predictor;Distribution Features;Generative Models;Semantic Communication;High-Resolution Imaging","Deepfakes;Noise;Pipelines;Media;Predictive models;Feature extraction;Semantic communication;Diffusion models;Security;Principal component analysis","","","","33","IEEE","30 Sep 2025","17-20 June 2025","17-20 June 2025","IEEE","IEEE Conferences"
"A Novel Unified Approach to Deepfake Detection of Images","L. Sen; S. Mukherjee","Computer Science and Engineering, NIT Rourkela, Rourkela, Odisha; Computer Science and Engineering, NIT Rourkela, Rourkela, Odisha",2024 12th International Conference on Intelligent Systems and Embedded Design (ISED),"15 Apr 2025","2024","","","1","6","The advancements in the field of AI is increasingly giving rise to various threats. One of the most prominent of them is the synthesis and misuse of Deep Fakes. To sustain trust in this digital age, detection and tagging of deepfakes is very necessary. In this paper, a novel architecture for Deepfake detection in images is presented. The architecture uses cross-attention between spatial and frequency domain features along with a blood detection module to classify an image as real or fake. This paper aims to develop a unified architecture and provide insights into each step. It is trained on two small datasets with 200 and 400 images respectively. On comparative analysis, our model was better than the other possibilities. Further, there was an increment in accuracy of 4.29% and 4.60% upon adding 200 images to the dataset. This shows that, if trained on a large dataset and hyper-parameters optimized, the performance will increase significantly.","","979-8-3315-2261-2","10.1109/ISED63599.2024.10957205","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10957205","DeepFake detection;Cross Attention;Fourier Transform etc","Deepfakes;Image segmentation;Accuracy;Frequency-domain analysis;Tagging;Information age;Skin;Intelligent systems;Blood;Tuning","","","","16","IEEE","15 Apr 2025","20-22 Dec. 2024","20-22 Dec. 2024","IEEE","IEEE Conferences"
"GASGM-GFT: Gaussian Attenuation Singing Graph Model and Graph Fourier Transform for Singing Voice Deepfake Detection","B. Wu; Q. Qian; L. Ran; H. Wang","School of Information, Guizhou University of Finance and Economics, Guiyang, China; School of Information, Guizhou University of Finance and Economics, Guiyang, China; School of Information, Guizhou University of Finance and Economics, Guiyang, China; School of Information, Guizhou University of Finance and Economics, Guiyang, China",2025 International Joint Conference on Neural Networks (IJCNN),"14 Nov 2025","2025","","","1","8","Singing voice synthesis and singing voice conversion technologies have raised significant concerns regarding music copyright and authenticity. While extant research has predominantly focused on detecting spoofing speech, much less attention has been given to deepfake singing voice. Moreover, conventional techniques frequently prove incapable of capturing the intricate temporal relationships inherent in vocalisation, thus impeding their capacity to effectively extract both local and global characteristics. To address these challenges, this paper introduces a novel deepfake detection method of singing voice called GASGM-GFT (Gaussian Attenuation Singing Graph Model and Graph Fourier Transform). In this approach, a singing graph model between sampling points of the original singing is creatively constructed using a Gaussian attenuation function. This model captures the complex temporal relationships of the singing signal. Next, the Graph Fourier Transform (GFT) is applied to map the singing signal into the graph frequency domain. This helps capture both local and global frequency features within the singing graph model, revealing hidden deepfake properties of the signal. The one-dimensional graph frequency domain signals are then expanded into two dimensions and processed through residual blocks for feature enhancement. Finally, the graph attention module is utilized to model node relationships, compute attention weights, and aggregate features through graph pooling layers to produce the final discrimination result. The experimental results demonstrate that GASGM-GFT outperforms existing advanced methods for spoofing speech detection and singing voice deepfake detection on the CtrSVDD dataset. It achieves an equal error rate (EER) of only 2.53% on the Vocals test set and surpasses other systems on the Mixture test set.","2161-4407","979-8-3315-1042-8","10.1109/IJCNN64981.2025.11228680","National Natural Science Foundation of China; Department of Education of Guizhou Province; Guizhou Normal University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11228680","Graph Signal Processing;Singing Voice Deepfake Detection;Graph Neural Network","Voice activity detection;Deepfakes;Fourier transforms;Frequency-domain analysis;Computational modeling;Signal processing;Attenuation;Feature extraction;Robustness;Graph neural networks","","","","22","IEEE","14 Nov 2025","30 June-5 July 2025","30 June-5 July 2025","IEEE","IEEE Conferences"
"WaveGuard: Robust Deepfake Detection and Source Tracing via Dual-Tree Complex Wavelet and Graph Neural Networks","Z. He; Z. Guo; L. Wang; G. Yang; Y. Diao; D. Ma","College of Computer Science and Technology, Xinjiang University, Urumqi, China; College of Computer Science and Technology, Xinjiang University, Urumqi, China; College of Computer Science and Technology, Xinjiang University, Urumqi, China; College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; School of Computer Science, Hefei University of Technology, Hefei, China; College of Computer Science and Technology, Xinjiang University, Urumqi, China",IEEE Transactions on Circuits and Systems for Video Technology,"","2025","PP","99","1","1","Deepfake technology has great potential in the field of media and entertainment, but it also brings serious risks, including privacy disclosure and identity fraud. To counter these threats, proactive forensic methods have become a research hotspot by embedding invisible watermark signals to build active protection schemes. However, existing methods are vulnerable to watermark destruction under malicious distortions, which leads to insufficient robustness. Moreover, embedding strong signals may degrade image quality, making it challenging to balance robustness and imperceptibility. Although watermarked images look natural, their underlying structures are often different from the original images, which is ignored by traditional watermarking methods. To address these issues, this paper proposes a proactive watermarking framework called WaveGuard, which explores frequency domain embedding and graph-based structural consistency optimization. In this framework, the watermark is embedded into the high-frequency sub-bands by dual-tree complex wavelet transform (DT-CWT) to enhance the robustness against distortions and deepfake forgeries. By leveraging joint sub-band correlations and selected sub-band combinations, the framework enables robust source tracing and semi-robust deepfake detection. To enhance imperceptibility, we propose a Structural Consistency Graph Neural Network (SC-GNN) that constructs graph representations of the original and watermarked images to ensure structural consistency and reduce perceptual artifacts. Experimental results show that the proposed method performs exceptionally well in face swap and face replay tasks. The code has been published at https://github.com/vpsg-research/WaveGuard.","1558-2205","","10.1109/TCSVT.2025.3628951","National Natural Science Foundation of China(grant numbers:62302427,62462060); Natural Science Foundation of Xinjiang Uygur Autonomous Region(grant numbers:2023D01C175); Tianshan Talent Training Program(grant numbers:2022TSYCLJ0036); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11224900","Deepfake Detection;Source Tracing;Frequency-domain Embedding;Graph Neural Network (GNN)","Watermarking;Deepfakes;Robustness;Distortion;Faces;Feature extraction;Perturbation methods;Graph neural networks;Training;Frequency-domain analysis","","1","","","IEEE","4 Nov 2025","","","IEEE","IEEE Early Access Articles"
"End-to-end Audio Deepfake Detection from RAW Waveforms: a RawNet-Based Approach with Cross-Dataset Evaluation","A. Di Pierno; L. Guarnera; D. Allegra; S. Battiato","IMT School of Advanced Studies Lucca, Lucca, Italy; Department of Mathematics and Computer Science, University of Catania, Catania, Italy; Department of Mathematics and Computer Science, University of Catania, Catania, Italy; Department of Mathematics and Computer Science, University of Catania, Catania, Italy",2025 International Joint Conference on Neural Networks (IJCNN),"14 Nov 2025","2025","","","1","8","Audio deepfakes represent a growing threat to digital security and trust, leveraging advanced generative models to produce synthetic speech that closely mimics real human voices. Detecting such manipulations is especially challenging under open-world conditions, where spoofing methods encountered during testing may differ from those seen during training. In this work, we propose an end-to-end deep learning framework for audio deepfake detection that operates directly on raw waveforms. Our model, RawNetLite, is a lightweight convolutional-recurrent architecture designed to capture both spectral and temporal features without handcrafted preprocessing. To enhance robustness, we introduce a training strategy that combines data from multiple domains and adopts Focal Loss to emphasize difficult or ambiguous samples. We further demonstrate that incorporating codec-based manipulations and applying waveform-level audio augmentations (e.g., pitch shifting, noise, and time stretching) leads to significant generalization improvements under realistic acoustic conditions. The proposed model achieves over 99.7% F1 and 0.25% EER on in-domain data (FakeOrReal), and up to 83.4% F1 with 16.4% EER on a challenging out-of-distribution test set (AVSpoof2021 + CodecFake). These findings highlight the importance of diverse training data, tailored objective functions and audio augmentations in building resilient and generalizable audio forgery detectors. Code and pretrained models are available at https://iplab.dmi.unict.it/mfs/Deepfakes/PaperRawNet2025/.","2161-4407","979-8-3315-1042-8","10.1109/IJCNN64981.2025.11229087","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11229087","Audio deepfake detection;synthetic speech recognition;raw audio classification;end-to-end learning;convolutional neural networks;RawNet;digital media forensics","Training;Deepfakes;Noise;Neural networks;Training data;Speech recognition;Robustness;Speech synthesis;Security;Testing","","1","","29","IEEE","14 Nov 2025","30 June-5 July 2025","30 June-5 July 2025","IEEE","IEEE Conferences"
"Generalizable Deepfake Detection With Phase-Based Motion Analysis","E. Prashnani; M. Goebel; B. S. Manjunath","Department of Electrical and Computer Engineering, University of California at Santa Barbara, Santa Barbara, CA, USA; Department of Electrical and Computer Engineering, University of California at Santa Barbara, Santa Barbara, CA, USA; Department of Electrical and Computer Engineering, University of California at Santa Barbara, Santa Barbara, CA, USA",IEEE Transactions on Image Processing,"12 Dec 2024","2025","34","","100","112","We propose PhaseForensics, a DeepFake (DF) video detection method that uses a phase-based motion representation of facial temporal dynamics. Existing methods that rely on temporal information across video frames for DF detection have many advantages over the methods that only utilize the per-frame features. However, these temporal DF detection methods still show limited cross-dataset generalization and robustness to common distortions due to factors such as error-prone motion estimation, inaccurate landmark tracking, or the susceptibility of the pixel intensity-based features to adversarial distortions and the cross-dataset domain shifts. Our key insight to overcome these issues is to leverage the temporal phase variations in the band-pass frequency components of a face region across video frames. This not only enables a robust estimate of the temporal dynamics in the facial regions, but is also less prone to cross-dataset variations. Furthermore, we show that the band-pass filters used to compute the local per-frame phase form an effective defense against the perturbations commonly seen in gradient-based adversarial attacks. Overall, with PhaseForensics, we show improved distortion and adversarial robustness, and state-of-the-art cross-dataset generalization, with 92.4% video-level AUC on the challenging CelebDFv2 benchmark (a recent state of-the-art method, FTCN, compares at 86.9%).","1941-0042","","10.1109/TIP.2024.3441821","NSF(grant numbers:1664172); Computational Facilities Purchased under NSF(grant numbers:1925717); Dissertation Fellowship funded by the Department of Electrical and Computer Engineering at UC Santa Barbara; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10685029","Deepfake detection;deep learning;video analysis;video forensics","Feature extraction;Deepfakes;Faces;Robustness;Detectors;Dynamics;Generators","","12","","85","IEEE","20 Sep 2024","2025","","IEEE","IEEE Journals"
"Quantitative Dissection of Spatial, Temporal, and Frequency Features in Deepfake Detection","Y. Tiwari; D. Saxena; F. -R. Hsu; A. Yadav","Department of Computer Science and Engineering, IET, DSMNRU, Lucknow, U.P, India; Department of Computer Science and Engineering, Chandigarh University, Mohali, Punjab, India; Department of Computer Science and Information Engineering, Feng Chia University, Taichung, Taiwan; Department of Computer Science and Engineering, IET, DSMNRU, Lucknow, U.P, India","2025 IEEE International Conference on Computer, Electronics, Electrical Engineering & their Applications (IC2E3)","24 Sep 2025","2025","","","1","6","Deepfake detection models have achieved remarkable accuracies yet remain opaque in their decision processes. In this study, we dissect the feature hierarchies exploited by four state-of-the-art deepfake detectors—Xception, ResNet50, EfficientNet-B4, and Vision Transformer (ViT), using advanced explainability methods (Grad-CAM, LIME, SHAP) on the FaceForensics++ dataset across various compression levels. Our experiments demonstrate that localized spatial artifacts, temporal discontinuities, and frequency-based anomalies are critical for discrimination. For instance, occluding the mouth region reduces Xception’s accuracy from 92.5% to 55.3% (a 37.2% drop), while blurring the eye region induces a 28% accuracy reduction for Xception and 35% for EfficientNet-B4. Temporal perturbation via inter-frame Gaussian smoothing decreases EfficientNet-B4’s performance from 95.2% to 64.7% (a 30.5% drop), underscoring its reliance on micro-motion cues. Moreover, Fourier analysis reveals that real videos exhibit 31.2% high-pass energy in the forehead region versus 22.8% in deepfakes, and filtering these features lowers EfficientNet-B4’s accuracy from 94.1% to 66.4%. These quantifiable metrics confirm that deepfake models integrate spatial, temporal, and frequency-domain features for classification. Our work provides a reproducible framework for interpretable deepfake detection, paving the way for more robust cross-dataset generalization and enhanced trustworthiness in media forensics.","","979-8-3315-2439-5","10.1109/IC2E365635.2025.11166815","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11166815","Deepfake Detection;Explainable AI;Grad-CAM;LIME;SHAP;Xception;ResNet50;EfficientNet-B4;Vision Transformer;Feature Attribution","Deepfakes;Computer vision;Accuracy;Smoothing methods;Perturbation methods;Mouth;Media;Feature extraction;Transformers;Residual neural networks","","","","21","IEEE","24 Sep 2025","15-16 May 2025","15-16 May 2025","IEEE","IEEE Conferences"
"Exploring the Impact of Moire Pattern on Deepfake Detectors","R. Tariq; S. Tariq; S. S. Woo","Computer Science & Engineering Department, Sungkyunkwan University, South Korea; CSIRO’s Data61, Australia; Computer Science & Engineering Department, Sungkyunkwan University, South Korea",2024 IEEE International Conference on Image Processing (ICIP),"27 Sep 2024","2024","","","3813","3819","Deepfake detection is critical in mitigating the societal threats posed by manipulated videos. While various algorithms have been developed for this purpose, challenges arise when detectors operate externally, such as on smartphones, when users take a photo of deepfake images and upload on the Internet. One significant challenge in such scenarios is the presence of Moiré patterns, which degrade image quality and confound conventional classification algorithms, including deep neural networks (DNNs). The impact of Moiré patterns remains largely unexplored for deepfake detectors. In this study, we investigate how camera-captured deepfake videos from digital screens affect detector performance. We conducted experiments using two prominent datasets, CelebDF and FF++, comparing the performance of four state-of-theart detectors on camera-captured deepfake videos with introduced Moiré patterns. Our findings reveal a significant decline in detector accuracy, with none achieving above 68% on average. This underscores the critical need to address Moiré pattern challenges in real-world deepfake detection scenarios.","2381-8549","979-8-3503-4939-9","10.1109/ICIP51287.2024.10647902","Sungkyunkwan University; Sungkyunkwan University; Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10647902","Moire Pattern;Deepfakes Detection;Video Manipulation;Digital Screen Capture Analysis","Resistance;Image quality;Deepfakes;Image processing;Noise;Detectors;Classification algorithms","","1","","21","IEEE","27 Sep 2024","27-30 Oct. 2024","27-30 Oct. 2024","IEEE","IEEE Conferences"
"Deepfake Detection Based on LSTM Networks with Facial Geometric Features","D. Xiong; Z. Wen; C. Zhang; P. Xiao; M. Wu","School of Communication Engineering, Chengdu University of Information Technology, Chengdu, China; School of Communication Engineering, Chengdu University of Information Technology, Chengdu, China; School of Communication Engineering, Chengdu University of Information Technology, Chengdu, China; School of Communication Engineering, Chengdu University of Information Technology, Chengdu, China; School of Communication Engineering, Chengdu University of Information Technology, Chengdu, China","2025 4th International Conference on Electronics, Integrated Circuits and Communication Technology (EICCT)","6 Aug 2025","2025","","","627","630","The increasing sophistication of Deepfake technology necessitates robust detection methods. This paper proposes a Deepfake detection approach utilizing Long ShortTerm Memory (LSTM) networks to analyze temporal variations in facial geometric features. By extracting precise facial landmark coordinates over video frames, we capture subtle dynamic inconsistencies characteristic of manipulated content. These landmark sequences are transformed into feature vectors, which are then fed into an LSTM network designed to model temporal patterns and distinguish between genuine and forged videos. The efficacy of our method is demonstrated through experiments on publicly available datasets. On the UADFV dataset, our approach achieves an accuracy of 90.45%, and on the FaceForensics++ (FF++) dataset, it reaches 93.50% accuracy, highlighting its potential for effective Deepfake detection.","","979-8-3315-3594-0","10.1109/EICCT65471.2025.11099876","Sichuan Province Science and Technology Department, Sichuan Province(grant numbers:24JBGS0050); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11099876","Long Short-Term Memory;deepfake video detection;facial geometric features;Deepfake","Integrated circuits;Deepfakes;Accuracy;Dynamics;Feature extraction;Vectors;Robustness;Real-time systems;Long short term memory;Manipulator dynamics","","","","11","IEEE","6 Aug 2025","11-13 July 2025","11-13 July 2025","IEEE","IEEE Conferences"
"DDL: Effective and Comprehensible Interpretation Framework for Diverse Deepfake Detectors","Z. Sun; N. Ruan; J. Li","Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China",IEEE Transactions on Information Forensics and Security,"2 Apr 2025","2025","20","","3601","3615","In the context of escalating advancements in AI generative technologies, Deepfakes, the sophisticated face forgeries created using deep learning methods, have emerged as a significant security threat. The predominant countermeasures are Deepfake detectors based on deep learning (DL). However, due to the opaque nature of DL-model, they struggle to offer understandable explanations for their predictive decisions, which undermines their reliability and effectiveness in real-world applications. Existing mainstream DL-oriented interpretation approaches, the feature attribution methods, struggle to work on Deepfake detectors due to issues of low interpretation fidelity, poor intelligibility, and limited applicability across different types of detectors. This paper addresses these critical challenges by proposing the Deepfake Detector Lens (DDL), a novel framework designed to enhance the interpretability of diverse architectural Deepfake detectors, encompassing those based on image, frequency domain, and video. DDL employs a heuristic algorithm to enhance interpretation efficacy and incorporates image segmentation and face parsing techniques to bridge the gap between the machine-generated interpretation saliency map and human understanding. Comprehensive evaluations of DDL demonstrate its superiority over existing feature attribution methods in terms of fidelity, intelligibility, and applicability. The proposed DDL significantly advances the interpretability of Deepfake detection technology, offering a more reliable and understandable tool for combating AI-generated face forgeries.","1556-6021","","10.1109/TIFS.2025.3553803","National Key Research and Development Program of China(grant numbers:2023YFB2704700); National Natural Science Foundation of China(grant numbers:62472276); Shanghai Committee of Science and Technology, China(grant numbers:23511101000,24BC3200400); Science and Technology Project of State Grid Corporation of China(grant numbers:5700-202321603A-3-2-ZN); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10937201","Interpretable deepfake detection;feature attribution","Detectors;Deepfakes;Faces;Frequency-domain analysis;Security;Feature extraction;Deep learning;Lenses;Data mining;Training","","4","","52","IEEE","21 Mar 2025","2025","","IEEE","IEEE Journals"
"DiffSeg: Towards Detecting Diffusion-Based Inpainting Attacks Using Multi-Feature Segmentation","R. A. Frick; M. Steinebach","Fraunhofer SIT — ATHENE Center, Darmstadt, Germany; Fraunhofer SIT — ATHENE Center, Darmstadt, Germany",2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW),"27 Sep 2024","2024","","","3802","3808","With the advancements made in deep learning over the past years, creating convincing media manipulations has become easy and accessible than ever before. In particular, diffusion models such as Stable-Diffusion allow users to synthesize realistic images based on a given text input. Apart from synthesizing entirely new images, diffusion models can also be used to make edits to images using inpainting. To combat the spread of disinformation and illegal content created with diffusion-based inpainting, this paper presents a new detection method based on multi-feature segmentation. Apart from information derived from the raw pixel values, noise, and frequency information are also exploited to detect and localize regions that have been subject to editing. Evaluation results strongly suggest that the proposed method can achieve high mIoU and AUC scores, outperforming state-of-the-art methods, even for syntheses generated by unseen diffusion models, or highly compressed images.","2160-7516","979-8-3503-6547-4","10.1109/CVPRW63382.2024.00384","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10678308","Deepfake Detection;Inpainting Detection;Diffusion Models;Media Forensics","Deep learning;Image segmentation;Computer vision;Image coding;Conferences;Noise;Diffusion models","","2","","23","IEEE","27 Sep 2024","17-18 June 2024","17-18 June 2024","IEEE","IEEE Conferences"
"Real-Time Deepfake Video Detection using Machine Learning: A CNN-based Authentication Framework","S. Babitha; Y. K; D. H. J. V; H. J","Information Technology, Hindustan Institute of Technology and Science, Chennai; Information Technology, Hindustan Institute of Technology and Science, Chennai; Information Technology, Hindustan Institute of Technology and Science, Chennai; Information Technology, Hindustan Institute of Technology and Science, Chennai",2025 Third International Conference on Augmented Intelligence and Sustainable Systems (ICAISS),"24 Jun 2025","2025","","","134","138","Deepfake technology presents significant threats to digital security, misinformation, and privacy. A Convolutional Neural network-based deepfake video detection in real time using optimization techniques to increase the accuracy and computational efficiency is proposed in this paper. The model is trained on the dataset of 15,000 images and uses feature extraction, adaptive loss function, and real-time processing optimization to achieve better performance. The experimental results give competitive results in terms of accuracy, precision, and recall compared to state-of-the-art models like EfficientNet and Xception. The framework is tolerant to adversarial attacks and compression effects. The work done in this direction will be further extended in the future to build transformer-based models for better generalization and adversarial resilience in deepfake detection.","","979-8-3315-0724-4","10.1109/ICAISS61471.2025.11041947","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11041947","Deepfake Detection;Convolutional Neural Networks (CNNs);Real-Time Video Authentication;Optimization Techniques;Adversarial Robustness","Deepfakes;Accuracy;Computational modeling;Streaming media;Feature extraction;Transformers;Real-time systems;Robustness;Convolutional neural networks;Optimization","","","","13","IEEE","24 Jun 2025","21-23 May 2025","21-23 May 2025","IEEE","IEEE Conferences"
"DDEM: Deepfake Detection Enhanced Model for Image Forgery Detection Combat Academic Misconduct","J. Ding; J. Liu; J. Shi; X. Hu; X. Qiao; H. E","School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China; Beijing Wanfang Data Co., Ltd., Beijing, China; School of Artificial Intelligence, Beijing University of Posts and Telecommunications, Beijing, China; School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China; Beijing Wanfang Data Co., Ltd., Beijing, China; School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China",2024 11th International Conference on Behavioural and Social Computing (BESC),"12 Dec 2024","2024","","","1","6","Image forgery, as a classic form of academic mis-conduct, has garnered increasing interest from researchers in the field of research integrity. Concurrently, automated detection and localization methods for image forgery have been making steady progress. However, the rapid advancement of image generation and image inpainting methods based on diffusion models presents new threats to the task of image forgery detection. Existing approaches are finding it difficult to identify forgery images that have been spliced by deepfake images and authentic photographs. To tackle this challenge, we propose the Deepfake Detection Enhanced Model (DDEM), which learns image features from both the RGB domain and frequency domain using the HRNet backbone. Furthermore, we introduce diffusion reconstruction error to enhance deepfake detection capabilities in our model. Fi-nally, we conduct experiments on public datasets and a self-made dataset generated by the image inpainting model, demonstrating that our proposed method outperforms the state-of-the-art in terms of image tampering detection and localization.","2689-8284","979-8-3315-3190-4","10.1109/BESC64747.2024.10780724","Ministry of Science and Technology(grant numbers:GXCZ-D-21070106); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10780724","Research Integrity;Image Forgery Detection;Deepfake Detection;Image Splicing Detection","Location awareness;Deepfakes;Visualization;Social computing;Image synthesis;Frequency-domain analysis;Splicing;Feature extraction;Forgery;Image reconstruction","","1","","41","IEEE","12 Dec 2024","16-18 Aug. 2024","16-18 Aug. 2024","IEEE","IEEE Conferences"
"Disruptive Attacks on Face Swapping via Low-Frequency Perceptual Perturbations","M. Huang; M. Shu; S. Zhou; Z. Liu","Department of Mathematics and Artificial Intelligence, Qilu University of Technology, Jinan, China; Department of Mathematics and Artificial Intelligence, Qilu University of Technology, Jinan, China; Department of Mathematics and Artificial Intelligence, Qilu University of Technology, Jinan, China; Department of Mathematics and Artificial Intelligence, Qilu University of Technology, Jinan, China",2025 International Joint Conference on Neural Networks (IJCNN),"14 Nov 2025","2025","","","1","9","Deepfake technology, driven by Generative Adversarial Networks (GANs), poses significant risks to privacy and societal security. Existing detection methods are predominantly passive, focusing on post-event analysis without preventing attacks. To address this, we propose an active defense method based on low-frequency perceptual perturbations to disrupt face-swapping manipulation, reducing the performance and naturalness of generated content. Unlike prior approaches that used low-frequency perturbations to impact classification accuracy, our method directly targets the generative process of deepfake techniques.We combine frequency and spatial domain features to strengthen defenses. By introducing artifacts through low-frequency perturbations while preserving high-frequency details, we ensure the output remains visually plausible. Additionally, we design a complete architecture featuring an encoder, a perturbation generator, and a decoder, leveraging discrete wavelet transform (DWT) to extract low-frequency components and generate perturbations that disrupt facial manipulation models. Experiments on CelebA-HQ and LFW demonstrate significant reductions in face-swapping effectiveness, improved defense success rates, and preservation of visual quality.","2161-4407","979-8-3315-1042-8","10.1109/IJCNN64981.2025.11228245","Shandong Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11228245","deepfake detection;privacy protection;adversarial defense;low-frequency perturbations","Deepfakes;Privacy;Visualization;Perturbation methods;Focusing;Feature extraction;Generators;Discrete wavelet transforms;Decoding;Faces","","","","42","IEEE","14 Nov 2025","30 June-5 July 2025","30 June-5 July 2025","IEEE","IEEE Conferences"
"Synthetic Voice Detection and Audio Splicing Detection using SE-Res2Net-Conformer Architecture","L. Wang; B. Yeoh; J. W. Ng",KLASS Engineering and Solutions Pte Ltd; KLASS Engineering and Solutions Pte Ltd; KLASS Engineering and Solutions Pte Ltd,2022 13th International Symposium on Chinese Spoken Language Processing (ISCSLP),"8 Feb 2023","2022","","","115","119","Synthetic voice and splicing audio clips have been generated to spoof Intemet users and artificial intelligence (AI) technologies such as voice authentication. Existing research work treats spoofing countermeasures as a binary classification problem: bonafide vs. spoof. This paper extends the existing Res2Net by involving the recent Conformer block to further exploit the local patterns on acoustic features. Experimental results on ASVspoof 2019 database show that the proposed SE-Res2Net-Conformer architecture is able to improve the spoofing countermeasures performance for the logical access scenario. In addition, this paper also proposes to re-formulate the existing audio splicing detection problem. Instead of identifying the complete splicing segments, it is more useful to detect the boundaries of the spliced segments. Moreover, a deep learning approach can be used to solve the problem, which is different from the previous signal processing techniques.","","979-8-3503-9796-3","10.1109/ISCSLP57327.2022.10037999","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10037999","spoofing countermeasures;audio splicing detection;Res2Net;synthetic voice detection;deepfake","Deep learning;Databases;Splicing;System performance;Authentication;Acoustics;Artificial intelligence","","5","","30","IEEE","8 Feb 2023","11-14 Dec. 2022","11-14 Dec. 2022","IEEE","IEEE Conferences"
"Evading Deepfake Detectors via Adversarially Degrading and Restoring Forged Images","Z. Shi; C. Lin; Z. Zhao; P. Peer; C. Shen","School of Cyber Science and Engineering, Xi’an Jiaotong University, Xi’an, China; School of Cyber Science and Engineering, Xi’an Jiaotong University, Xi’an, China; School of Cyber Science and Engineering, Xi’an Jiaotong University, Xi’an, China; Computer Vision Laboratory, University of Ljubljana, Ljubljana, Slovenia; School of Cyber Science and Engineering, Xi’an Jiaotong University, Xi’an, China",2025 IEEE International Conference on Multimedia and Expo (ICME),"30 Oct 2025","2025","","","1","6","Deepfake detection can prevent the misuse of deep generative techniques but is known to be vulnerable to adversarial attacks. However, most existing attacks introduce noticeable noise, resulting in an unsatisfactory trade-off between attack effectiveness and imperceptibility. In this paper, we propose a new generative attack based on adversarially Degrading and Restoring (DR) fake images, eliminating the use of noisy perturbations. Specifically, degradation works by removing high-frequency deepfake artifacts with the guidance of adversarial loss from the detector, and the subsequent restoration aims to maintain the image quality by restoring high-frequency details of natural images. Our analysis confirms that combining degradation and restoration effectively aligns the distribution of adversarial (fake) images and real images in both frequency and pixel domains. Our experimental results across eight popular detectors and three popular deep-fake datasets prove the effectiveness of our method compared with several state-of-the-art methods. Our code is available at https://github.com/fanoflck/DR_attack.","1945-788X","979-8-3315-9495-4","10.1109/ICME59968.2025.11210143","National Key Research and Development Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11210143","Adversarial attack;Deepfake detection;Image degradation and restoration","Degradation;Image quality;Deepfakes;Visualization;Perturbation methods;Frequency-domain analysis;Noise;Detectors;Image restoration;Noise measurement","","","","28","IEEE","30 Oct 2025","30 June-4 July 2025","30 June-4 July 2025","IEEE","IEEE Conferences"
"Visual Deepfake Detection: Review of Techniques, Tools, Limitations, and Future Prospects","N. Ur Rehman Ahmed; A. Badshah; H. Adeel; A. Tajammul; A. Daud; T. Alsahfi","Department of Computing, Hamdard University, Islamabad Campus, Islamabad, Pakistan; Department of Software Engineering, University of Sargodha, Sargodha, Pakistan; Department of Computing, Hamdard University, Islamabad Campus, Islamabad, Pakistan; U.S.-Pakistan Center for Advanced Studies in Water, Mehran University of Engineering and Technology, Jamshoro, Sindh, Pakistan; Faculty of Resilience, Rabdan Academy, Abu Dhabi, United Arab Emirates; Department of Information Systems and Technology, College of Computer Science and Engineering, University of Jeddah, Jeddah, Saudi Arabia",IEEE Access,"3 Jan 2025","2025","13","","1923","1961","In recent years, rapid advancements in deepfakes (incorporating Artificial Intelligence (AI), machine, and deep learning) have updated tools and techniques for manipulating multimedia. Though technology has primarily been utilized for beneficial purposes, such as education and entertainment, it is also used for malicious or unethical tasks to spread disinformation or ruin someone’s dignity, even if it encompasses harassing and blackmailing victims. Deepfakes refer to high-quality and realistic multimedia-manipulated content that has been digitally modified or synthetically generated. We conducted a systematic literature review of deepfake detection to offer an updated overview of existing research work that initially describes the widely accessible deepfake generation tools, classifications, and detection process. We highlighted recent techniques in visual deepfake detection based on the feature representations, grouped into four domains: spatial, temporal, frequency, and spatio-temporal, including their key features and limitations by providing details of existing datasets, together with the potentials of deepfake and its future directions. This study tried to add an updated repository of technological change in deepfake, which could help researchers to develop robust deepfake models.","2169-3536","","10.1109/ACCESS.2024.3523288","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10816641","Deepfake detection;machine learning;deep learning;deepfake applications;deepfake datasets;deepfake generation tools","Deepfakes;Face recognition;Deep learning;Faces;Training;Generators;Decoding;Social networking (online);Generative adversarial networks;Feature extraction","","9","","282","CCBY","27 Dec 2024","2025","","IEEE","IEEE Journals"
"FA3-CLIP: Frequency-Aware Cues Fusion and Attack-Agnostic Prompt Learning for Unified Face Attack Detection","Y. Li; N. Li; A. Liu; H. Ma; L. Yang; X. Chen; Z. Liang; Y. Liang; J. Wan; Z. Lei","School of Computer Science and Engineering, Faculty of Innovation Engineering, Macau University of Science and Technology, Macau, China; School of Computer Science and Engineering, Faculty of Innovation Engineering, Macau University of Science and Technology, Macau, China; School of Computer Science and Engineering, Faculty of Innovation Engineering, Macau University of Science and Technology, Macau, China; School of Computer Science and Engineering, Faculty of Innovation Engineering, Macau University of Science and Technology, Macau, China; School of Computer Science and Engineering, Faculty of Innovation Engineering, Macau University of Science and Technology, Macau, China; School of Software Engineering, Beijing Jiaotong University (BJTU), Beijing, China; School of Computer Science and Engineering, Faculty of Innovation Engineering, Macau University of Science and Technology, Macau, China; School of Computer Science and Engineering, Faculty of Innovation Engineering, Macau University of Science and Technology, Macau, China; School of Computer Science and Engineering, Faculty of Innovation Engineering, Macau University of Science and Technology, Macau, China; School of Computer Science and Engineering, Faculty of Innovation Engineering, Macau University of Science and Technology, Macau, China",IEEE Transactions on Information Forensics and Security,"12 Aug 2025","2025","20","","8167","8177","Facial recognition systems are vulnerable to physical (e.g., printed photos) and digital (e.g., DeepFake) face attacks. Existing methods struggle to simultaneously detect physical and digital attacks due to: 1) significant intra-class variations between these attack types, and 2) the inadequacy of spatial information alone to comprehensively capture live and fake cues. To address these issues, we propose a unified attack detection model termed Frequency-Aware and Attack-Agnostic CLIP (FA3-CLIP), which introduces attack-agnostic prompt learning to express generic live and fake cues derived from the fusion of spatial and frequency features, enabling unified detection of live faces and all categories of attacks. Specifically, the attack-agnostic prompt module generates generic live and fake prompts within the language branch to extract corresponding generic representations from both live and fake faces, guiding the model to learn a unified feature space for unified attack detection. Meanwhile, the module adaptively generates the live/fake conditional bias from the original spatial and frequency information to optimize the generic prompts accordingly, reducing the impact of intra-class variations. We further propose a dual-stream cues fusion framework in the vision branch, which leverages frequency information to complement subtle cues that are difficult to capture in the spatial domain. In addition, a frequency compression block is utilized in the frequency stream, which reduces redundancy in frequency features while preserving the diversity of crucial cues. We also establish new challenging protocols to facilitate unified face attack detection effectiveness. Experimental results on multiple benchmarks demonstrate that FA3-CLIP significantly improves performance, reducing ACER by over 1.2% on UniAttackData, and increasing AUC by more than 3% as well as reducing EER by over 4% on the JFSFDB dataset. The source code is available at https://github.com/YongzeLi/FA3-CLIP","1556-6021","","10.1109/TIFS.2025.3593167","Science and Technology Development Fund of Macau(grant numbers:0140/2024/AGJ,0096/2023/RIA2,0123/2022/A3,0044/2024/AGJ,0084/2024/RIB2); Beijing Natural Science Foundation(grant numbers:JQ23016); National Natural Science Foundation of China(grant numbers:62476273,62406320,U23B2054,62276254); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11097296","Face anti-spoofing;deepfake detection;unified feature space;frequency-aware;cues fusion","Feature extraction;Faces;Face recognition;Visualization;Frequency diversity;Training;Deepfakes;Data mining;Protocols;Noise","","","","62","IEEE","28 Jul 2025","2025","","IEEE","IEEE Journals"
"A Preliminary Case Study on Long-Form In-the-Wild Audio Spoofing Detection","X. Liu; X. Wang; J. Yamagishi","National Institute of Informatics 2-1-2 Hitotsubashi, Tokyo, Japan; National Institute of Informatics 2-1-2 Hitotsubashi, Tokyo, Japan; National Institute of Informatics 2-1-2 Hitotsubashi, Tokyo, Japan",2024 International Conference of the Biometrics Special Interest Group (BIOSIG),"11 Dec 2024","2024","","","1","6","Audio spoofing detection has become increasingly important due to the rise in real-world cases. Current spoofing detectors, referred to as spoofing countermeasures (CM), are mainly trained and focused on audio waveforms with a single speaker and short duration. This study explores spoofing detection in more realistic scenarios, where the audio is long in duration and features multiple speakers and complex acoustic conditions. We test the widely-acquired AASIST under this challenging scenario, looking at the impact of multiple variations such as duration, speaker presence, and acoustic complexities on CM performance. Our work reveals key issues with current methods and suggests preliminary ways to improve them. We aim to make spoofing detection more applicable in more in-the-wild scenarios. This research is served as an important step towards developing detection systems that can handle the challenges of audio spoofing in real-world applications.","1617-5468","979-8-3503-7371-4","10.1109/BIOSIG61931.2024.10786724","Ministry of Internal Affairs and Communications; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10786724","Long-form Audio;Audio DeepFake;Spoof Detection","Training;Location awareness;Biometrics;Deepfakes;Detectors;Feature extraction;Acoustics;Complexity theory","","","","23","IEEE","11 Dec 2024","25-27 Sept. 2024","25-27 Sept. 2024","IEEE","IEEE Conferences"
"Detection of Diffusion Model-Generated Faces by Assessing Smoothness and Noise Tolerance","B. Liu; B. Liu; M. Ding; T. Zhu","School of Computer Science, University of Technology Sydney, NSW, Australia; School of Computer Science, University of Technology Sydney, NSW, Australia; Data61, CSIRO, NSW, Australia; Faculty of Data Science, City University of Macau, Macau, China",2024 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB),"31 Jul 2024","2024","","","1","6","The fast growth of artificial intelligence (AI) raises much concern about the misinformation brought by AI-generated content (AIGC), especially Deepfake techniques that generate fake human faces. The recent development of Diffusion Models (DMs) moves another critical step forward to generate high-resolution and realistic human faces, which has become a challenge for existing Deepfake detectors. In this paper, we propose a DM-generated image detector by looking into the generation pipeline of DMs and the details of DM-generated images. The detector is based on the observation that DM-generated human faces show over-smooth textures and do not contain details as real human faces. Through a comprehensive analysis of DM-generated faces in spatial and frequency domains, we noticed that the over-smoothness improves the tolerance of Gaussian noise since excessive smoothness mitigates some of the impact of noise. Inspired by the observations, we propose a Deepfake detector capable of recognizing challenging DM-generated faces. We mainly propose the Noise Residual Unit (NRD) in our framework to collect the frequency response of images to Gaussian noise as distinctive features for classification. In detail, for an input face image, we add Gaussian noise to it and get the noise-degraded image. Then, the NRU generates the Noise Residual Image (NRI) by calculating the residual of the high-pass-filtered original image and the high-pass-filtered degraded image. The NRI indicates the high-frequency impact brought by the Gaussian noise and, therefore, suggests the tolerance of the original image to noise degradation. The original image and NRI are encoded and fused to obtain the joint representation, which is then fed to a classifier to predict the binary label. We conducted comprehensive experiments to evaluate the effectiveness of the proposed detector. The results indicate that our proposed detector achieves state-of-the-art detection performance on DM-generated faces and generalizes well to unseen DM-generated and GAN-generated face datasets.","2155-5052","979-8-3503-6426-2","10.1109/BMSB62888.2024.10608232","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10608232","Deepfake detection;diffusion models;frequency analysis","Deepfakes;Analytical models;Gaussian noise;Frequency-domain analysis;Pipelines;Detectors;Frequency response","","2","","37","IEEE","31 Jul 2024","19-21 June 2024","19-21 June 2024","IEEE","IEEE Conferences"
"A Computer Vision Model to Identify Deepfakes to Combat Misinformation During Political Events","A. Narayan; S. Fox","Computer Vision Research Concentration, Pioneer Academics, Bengaluru, India; Mathematics, Statistics, and Computer Science, Macalester College, St Paul, USA","2024 IEEE 11th Uttar Pradesh Section International Conference on Electrical, Electronics and Computer Engineering (UPCON)","12 May 2025","2024","","","1","11","With rampant use of technology, deepfake videos have emerged as a critical issue in today's global landscape of rapid information dissemination, leading to new dimensions of influence and power. Political events frequently fall victim to misinformation; emphasizing that the authenticity of such propagated media is paramount. The aim of this paper is to utilize advanced AI and ML algorithms to combat the rising challenge of deepfakes - hyper-realistic videos that appear convincingly genuine to the human eye. This work utilizes Error Level Analysis to detect compression inconsistencies between frames and compares this approach with a modified CNN architecture. The modified InceptionResnetVl model that was created achieved a training accuracy of 78% and a validation accuracy of 75% when tested on the DeepFake Detection Challenge dataset. This was also tested with the Presidential Deepfake Dataset. A potential extension of this paper would be the integration of ELA with the modified CNN model significantly improving training efficiency and achieving a higher accuracy while also increasing computational simplicity.","2687-7767","979-8-3503-7872-6","10.1109/UPCON62832.2024.10983603","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10983603","Deepfake Detection;CNN;Error-Level Analysis;Hyper-realistic frame detection;Media authenticity verification;Political Misinformation","Training;Deepfakes;Visualization;Accuracy;Image analysis;Computational modeling;Lighting;Computer architecture;Optimization;Context modeling","","","","27","IEEE","12 May 2025","29 Nov.-1 Dec. 2024","29 Nov.-1 Dec. 2024","IEEE","IEEE Conferences"
"Frame-to-Utterance Convergence: A Spectra-Temporal Approach for Unified Spoofing Detection","A. Khan; K. M. Malik; S. Nawaz","Department of Computer Science and Engineering, Oakland University, Rochester, Michigan, USA; Department of Computer Science and Engineering, Oakland University, Rochester, Michigan, USA; Johannes Kepler University, Linz, Austria","ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","18 Mar 2024","2024","","","10761","10765","Voice spoofing attacks pose a significant threat to automated speaker verification systems. Existing anti-spoofing methods often simulate specific attack types, such as synthetic or replay attacks. However, in real-world scenarios, the countermeasures are unaware of the generation schema of the attack, necessitating a unified solution. Current unified solutions struggle to detect spoofing artefacts, especially with recent spoofing mechanisms. For instance, the spoofing algorithms inject spectral or temporal anomalies, which are challenging to identify. To this end, we present a spectra-temporal fusion leveraging frame-level and utterance-level coefficients. We introduce a novel local spectral deviation coefficient (SDC) for frame-level inconsistencies and employ a bi-LSTM-based network for sequential temporal coefficients (STC), which capture utterance-level artifacts. Our spectra-temporal fusion strategy combines these coefficients, and an auto-encoder generates spectra-temporal deviated coefficients (STDC) to enhance robustness. Our proposed approach addresses multiple spoofing categories, including synthetic, replay, and partial deepfake attacks. Extensive evaluation on diverse datasets (ASVspoof2019, ASVspoof2021, VSDC, partial spoofs, and in-the-wild deepfakes) demonstrated its robustness for a wide range of voice applications.","2379-190X","979-8-3503-4485-1","10.1109/ICASSP48485.2024.10447500","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10447500","Voice Spoofing Detection;Spectral Temporal;Audio Deepfake Detection;Unified spoofing detection","Deepfakes;Signal processing algorithms;Signal processing;Robustness;Acoustics;Speech processing;Convergence","","6","","20","IEEE","18 Mar 2024","14-19 April 2024","14-19 April 2024","IEEE","IEEE Conferences"
"Interactive Two-Stream Network Across Modalities for Deepfake Detection","J. Wu; B. Zhang; Z. Li; G. Pang; Z. Teng; J. Fan","School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; AI Laboratory, Lenovo Research, Beijing, China",IEEE Transactions on Circuits and Systems for Video Technology,"26 Oct 2023","2023","33","11","6418","6430","As face forgery techniques have become more mature, the proliferation of deepfakes may threaten the security of human society. Although existing deepfake detection methods achieve good performance for in-dataset evaluation, it remains to be improved in the generalization ability, where the representation of the imperceptible artifacts plays a significant role. In this paper, we propose an Interactive Two-Stream Network (ITSNet) to explore the discriminant inconsistency representation from the perspective of cross-modality. In particular, the patch-wise Decomposable Discrete Cosine Transform (DDCT) is adopted to extract fine-grained high-frequency clues, and information from different modalities communicates with each other via a designed interaction module. To perceive the temporal inconsistency, we first develop a Short-term Embedding Module (SEM) to refine subtle local inconsistency representation between adjacent frames, and then a Long-term Embedding Module (LEM) is designed to further refine the erratic temporal inconsistency representation from the long-range perspective. Extensive experimental results conducted on three public datasets show that ITSNet outperforms the state-of-the-art methods both in terms of in-dataset and cross-dataset evaluations.","1558-2205","","10.1109/TCSVT.2023.3269841","Fundamental Research Funds for the Central Universities of China(grant numbers:2022JBMC009); National Natural Science Foundation of China(grant numbers:61972027); Beijing Municipal Natural Science Foundation(grant numbers:42120411); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10107603","Deepfake detection;inconsistency representation;cross-modality learning","Forgery;Faces;Frequency-domain analysis;Feature extraction;Deepfakes;Convolution;Discrete cosine transforms","","22","","53","IEEE","24 Apr 2023","Nov. 2023","","IEEE","IEEE Journals"
"Deepfake Detection and Localization Using Multi-View Inconsistency Measurement","B. Zhang; Q. Yin; W. Lu; X. Luo","School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; School of Computer Science and Engineering, Ministry of Education Key Laboratory of Information Technology, Guangdong Province Key Laboratory of Information Security Technology, Sun Yat-sen University, Guangzhou, China; School of Computer Science and Engineering, Ministry of Education Key Laboratory of Information Technology, Guangdong Province Key Laboratory of Information Security Technology, Sun Yat-sen University, Guangzhou, China; State Key Laboratory of Mathematical Engineering and Advanced Computing, Zhengzhou, China",IEEE Transactions on Dependable and Secure Computing,"13 Mar 2025","2025","22","2","1796","1809","As deepfake technology advances, forgery detection techniques have evolved beyond simple classification to include fine-grained localization. However, existing deepfake localization methods struggle with with real-world deepfake videos, which are often multi-face scenarios with only some parts manipulated. To address the above-mentioned problems, we propose a Multi-View Inconsistency Measurement (MVIM) network that simultaneously measures inconsistencies from noise and temporal view to detect and locate tampered regions. Specifically, considering the noise inconsistencies in multi-face scenarios where fake faces have inconsistent noise patterns compared to real faces and backgrounds, we design a Noise Inconsistency Measurement (Noise-IM) module that measures noise similarity among faces and between faces and backgrounds using a masked attention mechanism to identify suspected tampered regions in noise domain. Since facial jitter of tampered regions in deepfake videos is observed to be more intense than that of real regions, we design a Temporal Inconsistency Measurement (Temporal-IM) module which adopts self-attention mechanism and fine-grained bi-direction convolutions to capture tampering traces between frames in temporal domain. Inconsistency features obtained by the two modules are fused for detecting and locating tampered regions. The superiority of our MVIM network is verified by extensive experiments with many state-of-the-art methods in different benchmark datasets.","1941-0018","","10.1109/TDSC.2024.3472064","National Natural Science Foundation of China(grant numbers:U2001202,62072480,U23A20305,62172435); Guangdong Provincial Key Laboratory of Information Security Technology(grant numbers:2023B1212060026); Communication University of China(grant numbers:SKLMCC2022KF003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10702428","Deepfake detection;face forgery localization;multi-face forensics;inconsistency measurement","Noise;Faces;Noise measurement;Deepfakes;Location awareness;Forgery;Feature extraction;Attention mechanisms;Forensics;Decoding","","7","","62","IEEE","1 Oct 2024","March-April 2025","","IEEE","IEEE Journals"
"STC-CapsNet: Detecting Audio Deepfakes with Spatio-Temporal Convolutions and Capsule Networks","T. M. Wani; S. A. A. Qadri; I. Amerini","Sapienza University of Rome, Italy; National Tsing Hua University, Taiwan; Sapienza University of Rome, Italy","2025 IEEE Symposium on Computational Intelligence in Image, Signal Processing and Synthetic Media (CISM)","8 Jul 2025","2025","","","1","7","Capsule networks are a powerful architecture designed to capture hierarchical relationships in data, making them effective for complex classification tasks. In audio deepfake detection, these networks effectively distinguish between real and synthetic audio by capturing subtle time and frequency patterns. Their ability to model intricate dependencies across both domains makes capsule networks especially suited for this challenging task. This study introduces the novel Spatio-Temporal Convolutional Capsule Network (STC-CapsNet), which utilizes mel-spectrograms and grayscale spectrograms for feature extraction. After preprocessing steps like noise reduction and segmentation, temporal and spectral convolutions are applied, followed by capsule layers with dynamic routing to enhance feature representation. The model is evaluated on the FoR dataset, achieving an F1-Score of 98.4% and a low EER of 2.8% using mel-spectrograms, outperforming grayscale spectrograms in both accuracy and error rate.","","979-8-3315-0835-7","10.1109/CISM64958.2025.11060861","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11060861","Audio Deepfake Detection;Mel-spectrograms;Grayscale spectrogram;Spatio-Temporal Convolutional Capsule Network","Deepfakes;Time-frequency analysis;Accuracy;Convolution;Noise reduction;Gray-scale;Media;Routing;Feature extraction;Spectrogram","","","","22","IEEE","8 Jul 2025","17-20 March 2025","17-20 March 2025","IEEE","IEEE Conferences"
"Integrating GLCM Texture Analysis for Improved Deepfake Detection on CelebDF(v2) Dataset","K. Joshi; A. Sinha","School of Computer Science Engineering, Manipal University Jaipur, Jaipur, India; School of Computer Science Engineering, Manipal University Jaipur, Jaipur, India",2024 Asian Conference on Intelligent Technologies (ACOIT),"2 Apr 2025","2024","","","1","6","The rapid growth in deep learning and artificial intelligence has led to the proliferation of deepfake technology, posing significant challenges in digital media authentication. This paper presents a comprehensive study on deepfake detection, utilizing Grey Level Co-occurrence Matrix (GLCM) texture analysis to enhance detection accuracy. GLCM provides critical texture features, specifically ‘Contrast’ and ‘Dissimilarity’, which offer valuable insights into the texture inconsistencies often present in deepfake images. By quantifying these inconsistencies, we aim to distinguish between authentic and manipulated images. The results from our experiments indicate that GLCM texture analysis is a powerful method for identifying deepfakes. The proposed method is evaluated on benchmark dataset, showcasing significant improvements in detection accuracy compared to existing techniques. This study adds valuable insights in the development of robust and reliable deepfake detection frameworks, offering valuable tools for protecting the integrity of digital media.","","979-8-3503-7495-7","10.1109/ACOIT62457.2024.10939531","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10939531","Deepfake Detection;GLCM;Contrast;Dissimilarity;Texture Analysis;Digital Media Authentication","Deep learning;Deepfakes;Accuracy;Authentication;Media;Benchmark testing;Feature extraction;Reliability;Artificial intelligence","","1","","17","IEEE","2 Apr 2025","6-7 Sept. 2024","6-7 Sept. 2024","IEEE","IEEE Conferences"
"Representation Alignment For Deepfake Detection","Z. Li; W. Tang; S. Gao; Y. Wang; S. Wang","School of Computer Science & Engineering, Beihang University, Beijing, China; School of Computer Science & Engineering, Beihang University, Beijing, China; School of Computer Science & Engineering, Beihang University, Beijing, China; School of Aeronautic Science & Engineering, Beihang University, Beijing, China; School of Computer Science & Engineering, Beihang University, Beijing, China",2025 11th International Conference on Computing and Artificial Intelligence (ICCAI),"11 Aug 2025","2025","","","677","686","DeepFake detection faces growing challenges with the rapid advancement of generative models, enabling the creation of increasingly sophisticated forgeries. Existing methods often rely on heuristic features from spatial or frequency domains without effectively integrating them into backbone architectures to capture general forgery representations. To address this, we propose the Representation Alignment (RA) technique to enhance backbone design by incorporating high-quality external semantic features. By aligning intermediate representations, RA enables the detector to capture robust spatial attributes and discriminative frequency features, improving its ability to generalize across diverse forgery types. The proposed RA-enhanced Xception detector demonstrates superior performance in both within-domain and cross-domain evaluations. These results validate the effectiveness of RA in enhancing generalization and robustness, offering a lightweight and efficient approach for advancing DeepFake detection.","","979-8-3315-2491-3","10.1109/ICCAI66501.2025.00109","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11105862","DeepFake Detection;Representation Alignment;Forgery generalization;Xception detector","Training;Deepfakes;Adaptation models;Frequency-domain analysis;Semantics;Detectors;Self-supervised learning;Feature extraction;Forgery;Robustness","","","","79","IEEE","11 Aug 2025","28-31 March 2025","28-31 March 2025","IEEE","IEEE Conferences"
"A Review on Deepfake Image Detection Approaches, Techniques and Methods","J. C. Ng; M. B. Jasser; B. Issa; S. -S. M. Ajibade; H. N. Chua","School of Computing and Artificial Intelligence, Faculty of Engineering and Technology, Sunway University, No. 5, Jalan Universiti, Bandar Sunway, Selangor Darul Ehsan, Malaysia; School of Computing and Artificial Intelligence, Faculty of Engineering and Technology, Sunway University, No. 5, Jalan Universiti, Bandar Sunway, Selangor Darul Ehsan, Malaysia; Faculty of Informatics Engineering, University of Aleppo, Syria; School of Computing and Artificial Intelligence, Faculty of Engineering and Technology, Sunway University, No. 5, Jalan Universiti, Bandar Sunway, Selangor Darul Ehsan, Malaysia; School of Computing and Artificial Intelligence, Faculty of Engineering and Technology, Sunway University, No. 5, Jalan Universiti, Bandar Sunway, Selangor Darul Ehsan, Malaysia",2025 IEEE International Conference on Automatic Control and Intelligent Systems (I2CACIS),"7 Aug 2025","2025","1","","512","517","Deepfake technology has been increasingly advanced and highly capable of generating and modifying media contents. Deepfake technologies like automated generation of scripts and avatars creation are applicable on many distinct fields and industries, helping in improving and enhancing the visuals and media contents to be published and shared with the public. However, Deepfake technologies also, being widely used in various malicious activities and crime cases, like financial frauds and scams, as well as sexual abuse and harassment. Hence, Deepfake detection is essential, to reduce the problems and avoid the consequences brought by Deepfake technologies. In this work, several existing Deepfake detection approaches, techniques and methods are explored and discussed. To understand better the effects and consequences caused by Deepfake, this work includes cases studies on real-world Deepfake incidents, conducted by searching through the news information accessible through internet. In addition, a thorough survey is conducted by searching for related articles and papers via Google Scholar using a suitable set of keywords. Results are presented via taxonomy. Some comparisons are presented to give some insights on the deepfake image detection approaches.","2995-2859","979-8-3315-4294-8","10.1109/I2CACIS65476.2025.11100461","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11100461","Deepfake detection;Neural Network;Texture Analysis;Frequency Analysis and Biological Analysis","Surveys;Deepfakes;Automatic frequency control;Visualization;Reviews;Taxonomy;Neural networks;Media;Internet;Intelligent systems","","","","40","IEEE","7 Aug 2025","27-28 June 2025","27-28 June 2025","IEEE","IEEE Conferences"
"Benchmarking Audio Deepfake Detection Robustness in Real-World Communication Scenarios","H. Shi; X. Shi; S. Dogan; S. Alzubi; T. Huang; Y. Zhang","Institute for Digital Technologies, Loughborough University London, London, UK; Institute for Digital Technologies, Loughborough University London, London, UK; Institute for Digital Technologies, Loughborough University London, London, UK; Department of Computer Science, University of Exeter, Exeter, UK; Department of Computer Science, University of Exeter, Exeter, UK; Department of Computer Science, University of Exeter, Exeter, UK",2025 33rd European Signal Processing Conference (EUSIPCO),"17 Nov 2025","2025","","","566","570","Existing Audio Deepfake Detection (ADD) systems often struggle to generalise effectively due to the significantly degraded audio quality caused by audio codec compression and channel transmission effects in real-world communication scenarios. To address this challenge, we developed a rigorous benchmark to evaluate the performance of the ADD system under such scenarios. We introduced ADD-C, a new test dataset to evaluate the robustness of ADD systems under diverse communication conditions, including different combinations of audio codecs for compression and packet loss rates. Benchmarking three baseline ADD models on the ADD-C dataset demonstrated a significant decline in robustness under such conditions. A novel Data Augmentation (DA) strategy was proposed to improve the robustness of ADD systems. Experimental results demonstrated that the proposed approach significantly enhances the performance of ADD systems on the proposed ADD-C dataset. Our benchmark can assist future efforts towards building practical and robustly generalisable ADD systems.","","978-9-4645-9362-4","10.23919/EUSIPCO63237.2025.11226601","Loughborough University(grant numbers:GS1016); China Scholarship Council(grant numbers:202208060237); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11226601","Audio Deepfake Detection;Audio Signal Processing;Audio Codec;Robustness;Wireless Communication","Wireless communication;Deepfakes;Codecs;Packet loss;Europe;Benchmark testing;Signal processing;Solids;Robustness;Machine listening","","","","43","","17 Nov 2025","8-12 Sept. 2025","8-12 Sept. 2025","IEEE","IEEE Conferences"
"A Robust and Lightweight CNN-Transformer Model for Audio Deepfake Detection in Indian Languages","M. Gaikawad; S. Ghosh","Computer Science and Engineering, COEP Technological University, Pune, India; Computer Science and Engineering, COEP Technological University, Pune, India","2025 7th International Conference on Signal Processing, Computing and Control (ISPCC)","24 Jun 2025","2025","","","382","387","The proliferation of audio deepfake technology poses significant threats to digital security, particularly in multilingual contexts such as India, where diverse languages are widely used. This paper presents a robust and lightweight CNN-Transformer hybrid model designed for audio deepfake detection in major Indian languages, including Marathi, Hindi, Tamil, Telugu, Malayalam, and Kannada. The proposed model addresses two critical challenges in deepfake detection: domain generalization and computational efficiency. By integrating multiple feature types—Mel spectrograms, LFCC, and Wav2Vec—and leveraging Convolutional Neural Networks (CNNs) for spatial feature extraction, Transformer layers with multi-scale attention for temporal dependencies, and a spectral-temporal gating mechanism for feature fusion, the model achieves superior performance across diverse audio environments, including low-quality and noisy data. Additionally, the model is optimized for edge devices using pretraining, quantization, knowledge distillation, and pruning, ensuring real-time performance with minimal accuracy loss. Evaluated on a novel dataset of nearly 10,000 samples per language, alongside ASVspoof 2021 and in-the-wild datasets, the model achieves a test accuracy of 98.07% (validation accuracy of 98.62%) with precision and recall scores of 0.98 and 0.98 on the test set, respectively. The study also analyzes trade-offs between model size, inference speed, and detection accuracy, offering insights into practical deployment. This work advances audio forensics by providing a scalable, efficient, and language-agnostic solution to counter audio deepfakes in resource-constrained settings.","2643-8615","979-8-3315-3893-4","10.1109/ISPCC66872.2025.11039572","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11039572","Audio Deepfake Detection;CNN-Transformer Hybrid Model;Indian Languages;Domain Generalization;Edge Device Optimization;Multilingual Datasets","Performance evaluation;Deepfakes;Accuracy;Quantization (signal);Computational modeling;Feature extraction;Transformers;Real-time systems;Multilingual;Security","","","","16","IEEE","24 Jun 2025","6-8 March 2025","6-8 March 2025","IEEE","IEEE Conferences"
"Identification of Deepfakes using Strategic Models and Architectures","S. R. Nallapati; D. Dommeti; S. Medhalavalasa; K. K. Bonku; P. V. V. S. Srinivas; D. Bhattacharyya","Department of CSE, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India; Department of CSE, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India; Department of CSE, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India; Department of CSE, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India; Department of CSE, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India; Department of CSE, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India",2023 International Conference on Sustainable Computing and Data Communication Systems (ICSCDS),"25 Apr 2023","2023","","","75","82","Deepfake technology has been rapidly evolving and expanding in recent years. It has become increasingly easy to manipulate multimedia content, making it harder to detect what is real and what is manipulated. The research aims to explore how neural networks can be used to detect deepfake in multimedia, helping to protect users from potentially malicious and deceptive content. The aim is to explore what neural networks are, how they can be used to detect deepfakes and the potential implications of this technology. The research also aims to evaluate the advantages and disadvantages of using neural networks for deepfake detection. As the world of deepfake technology continues to evolve, this research will provide an overview of the latest developments in deepfake detection and their potential impact. The goal of this research is to use neural networks to detect deepfakes and to identify suspicious content to alert users. This could help protect users from being exposed to malicious content and help content producers ensure the integrity of their work. As deepfake technology continues to evolve, neural networks may become an essential tool for quickly and accurately detecting deepfakes in multimedia. The research explores topics like, CNN, 3D CNN, GATED RECURRENT UNIT and Architectures like Xception, VGG16, InceptionV3 and ResNet50V2. The outcomes are graphically represented and analyzed. the comparative stratification of the approach is done to analyze and detect deepfakes.","","978-1-6654-9199-0","10.1109/ICSCDS56580.2023.10104880","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10104880","Deepfake Detection;Deep Learning;Convolutional Neural Network;Gated Recurrent Unit;Image Noise Patterns","Deepfakes;Visualization;Three-dimensional displays;Neural networks;Computer architecture;Media;Logic gates","","1","","18","IEEE","25 Apr 2023","23-25 March 2023","23-25 March 2023","IEEE","IEEE Conferences"
"MRE-Net: Multi-Rate Excitation Network for Deepfake Video Detection","G. Pang; B. Zhang; Z. Teng; Z. Qi; J. Fan","School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; AI Laboratory, Lenovo Research, Beijing, China",IEEE Transactions on Circuits and Systems for Video Technology,"3 Aug 2023","2023","33","8","3663","3676","The current social media is flooded with hyper realistic face-synthetic videos due to the explosion of DeepFake technology that has brought a serious impact on human society security, which calls for further exploring on deepfake video detection methods. Existing methods attempt to isolated capture spatial artifacts or extract the homogeneous temporal inconsistency to detect deepfake video, but little attention has been paid to the exploitation of dynamic spatial-temporal inconsistency. To mitigate this issue, in this paper, we propose a novel Multi-Rate Excitation Network (MRE-Net) to effectively excite dynamic spatial-temporal inconsistency from the perspective of multiple rates for deepfake video detection. The proposed MRE-Net is composed of two components: Bipartite Group Sampling (BGS) and multiple rate branches. The BGS draws the entire video into multiple bipartite groups with different rates to cover various face motion dynamic evolution. We further design multiple rate branches to capture both short-term and long-term spatial-temporal inconsistency from corresponding bipartite groups of BGS. Concretely, for the early stages of the multi-rate branches, Momentary Inconsistency Excitation (MIE) module is developed to encode the spatial artifacts and intra-group short-term temporal inconsistency. Meanwhile, for the last stages of the multi-rate branches, Longstanding Inconsistency Excitation (LIE) module is constructed to perceive inter-group long-term temporal dynamics. Extensive experiments and visualizations conducted on four popular datasets demonstrate the effectiveness of the proposed method against state-of-the-art deepfake detection methods.","1558-2205","","10.1109/TCSVT.2023.3239607","Fundamental Research Funds for the Central Universities of China(grant numbers:2022JBMC009); Natural Science Foundation of China(grant numbers:61972027); Beijing Municipal Natural Science Foundation(grant numbers:4212041); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10025759","Deepfake detection;momentary inconsistency;longstanding inconsistency","Deepfakes;Faces;Forgery;Feature extraction;Social networking (online);Three-dimensional displays;Frequency-domain analysis","","50","","60","IEEE","25 Jan 2023","Aug. 2023","","IEEE","IEEE Journals"
"AI-Powered Deepfake Detection in Biometric Systems","U. M. Atasoy; M. Altıntaş; T. İnan","Department of Artificial Intelligence Engineering, TOBB University of Economics and Technology, Ankara, Türkiye; Department of Artificial Intelligence Engineering, TOBB University of Economics and Technology, Ankara, Türkiye; Department of Artificial Intelligence Engineering, TOBB University of Economics and Technology, Ankara, Türkiye",2025 Innovations in Intelligent Systems and Applications Conference (ASYU),"30 Oct 2025","2025","","","1","6","Deepfake technologies pose a growing threat to biometric systems by enabling the creation of highly realistic forged facial content. This study proposes a deepfake detection framework based on the XceptionNet architecture, aiming to enhance detection robustness under both familiar and unseen conditions. To achieve this, we leverage two widely adopted datasets-Celeb-DF-v2 and FaceForensics++-and construct a hybrid dataset to improve domain generalization. The pipeline includes Dlib-based face detection and alignment, consistent preprocessing, and efficient feature extraction using XceptionNet. We evaluate the system across six test settings, including unseen samples from different videos, and report high accuracy and F1 scores, even under domain shifts. Our findings show that training on diverse datasets significantly boosts generalization, and the proposed system outperforms several existing baselines on unseen Celeb-DF-v2. This work demonstrates the potential of combining architectural efficiency with dataset diversity to build deployable deepfake detection models for biometric security applications.","2770-7946","979-8-3315-9727-6","10.1109/ASYU67174.2025.11208454","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11208454","Deepfake Detection;Biometric Security;Deep Neural Networks;Dataset Generalization;Face Manipulation Forensics","Biometrics;Training;Deepfakes;Technological innovation;Biological system modeling;Diversity reception;Pipelines;Robustness;Security;Standards","","","","15","IEEE","30 Oct 2025","10-12 Sept. 2025","10-12 Sept. 2025","IEEE","IEEE Conferences"
"Enhancing Deepfake Detection Through Dynamics of Facial Expressions","V. K. Sharma; S. Rawat","Amity School of Engineering & Technology, Amity University, Noida, Uttar Pradesh, India; Amity School of Engineering & Technology, Amity University, Noida, Uttar Pradesh, India",2025 6th International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV),"25 Jul 2025","2025","","","70","79","The rapid evolution of deepfake technology poses significant threats to digital security, media integrity, and public trust, necessitating the development of robust detection frame-works. Traditional deepfake detection methods primarily rely on pixel inconsistencies, frequency-domain analysis, or handcrafted features, but these approaches are increasingly vulnerable to advanced generative models that produce high-fidelity manipulations. In this study, we introduce MADDM, a Masked Autoencoder-based deepfake detection model that leverages facial expression dynamics to identify inconsistencies in muscle coordination—an aspect that remains challenging for deepfake generators to replicate accurately. Our model is trained in a self-supervised manner, first learning natural facial expressions from real datasets and then detecting anomalies in synthetic videos by reconstructing masked facial regions. Evaluations on Celeb-DF, DFDC, and FaceForensics++ datasets demonstrate that MADDM significantly outperforms existing detection methods, achieving an average accuracy of 81.1%, with state-of-the-art performance on Celeb-DF (86.3%). Further analysis through intra-dataset and cross-dataset testing confirms the model’s superior generalization capabilities. The results highlight the potential of expression-based deepfake detection as a powerful and scalable solution for digital forensics and misinformation control. Future research should explore real-time implementation, transformer-based optimizations, and adversarial training strategies to enhance detection efficiency against evolving deepfake techniques.","","979-8-3315-1175-3","10.1109/ICICV64824.2025.11085942","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11085942","deepfake detection;facial expressions analysis;spatio temporal;convolutional neural network;masked auto encoders","Training;Deepfakes;Frequency-domain analysis;Autoencoders;Transformers;Feature extraction;Generators;Facial muscles;Security;Optimization","","","","24","IEEE","25 Jul 2025","17-19 June 2025","17-19 June 2025","IEEE","IEEE Conferences"
"Recalibrated Bandpass Filtering On Temporal Waveform For Audio Spoof Detection","Y. Ren; W. Liu; D. Liu; L. Wang","Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education; School of Cyber Science and Engineering, Wuhan University; School of Cyber Science and Engineering, Wuhan University; Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education",2021 IEEE International Conference on Image Processing (ICIP),"23 Aug 2021","2021","","","3907","3911","Deepfake techniques mislead people’s cognition with high-quality fake videos and audios, and speech synthesis is an important tool to implement cognitive attacks, which mainly include Text-To-Speech (TTS) and Voice Conversion (VC). In this paper, we propose a method for audio spoof detection based on frequency band recalibration via sinc convolution and squeeze-excitation module, extracting features from the temporal waveform and emphasizing the frequency bands that are more useful on this task. Experimental results show that the proposed method outperforms other similar methods by 18.6% with an average EER of 7.23%, and achieve better generalizability on the detection of unseen spoofing methods, while the size of the model is reduced by 30.8%.","2381-8549","978-1-6654-4115-5","10.1109/ICIP42928.2021.9506427","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9506427","Audio spoof detection;Deepfake;Presentation attack detection;Speaker verification;ASVspoof","Filtering;Convolution;Conferences;Tools;Feature extraction;Cognition;Speech synthesis","","5","","25","IEEE","23 Aug 2021","19-22 Sept. 2021","19-22 Sept. 2021","IEEE","IEEE Conferences"
"Mdff-Net: A Multi-Domain Feature-Fusion Network for Robust Deepfake Video Detection","S. Thota; R. Prakash","School of Computer Science and Artificial Intelligence, SR University, Warangal, India; School of Computer Science and Artificial Intelligence, SR University, Warangal, India",2025 IEEE International Conference on Advances in Computing Research On Science Engineering and Technology (ACROSET),"16 Dec 2025","2025","","","1","7","The rapid evolution of generative adversarial and diffusion models has made it effortless to fabricate photorealistic ""deepfake"" videos, undermining public trust and posing serious social, political, and security risks. Existing detectors largely focus on spatial artifacts in individual frames, rendering them brittle when post-processed or confronted with newer generation methods that conceal pixel-level cues. We propose Multi-Domain Feature-Fusion Network (MDFF-Net), the first real-time framework that learns and fuses complementary spatial, temporal, and frequency evidence within a single, end-to-end architecture. MDFF-Net employs three specialized encoders Swin-V2 for RGB textures, TimeSformer Lite for motion dynamics, and a lightweight ResNet for log-magnitude Fourier spectra whose tokens are aggregated via a lightweight multi-head cross-attention module that adaptively re-weights each modality per clip. To improve reproducibility, we additionally provide a concise pseudo-code summary of the training and fusion algorithm within the paper, beyond releasing code and pre-trained weights. To train the model, we introduce a two stage strategy are modality specific pre training followed by joint fine-tuning on a diverse union of FaceForensics++, DFDC, Celeb-DF, DeepfakeBench, and an in-the-wild 2024 compilation. Extensive experiments show that MDFF-Net achieves 98.7% AUC on FaceForensics++ and 95.2%, AUC on DeepfakeBench, surpassing state of the art fusion baselines by up to 7.4 percentage points while sustaining 41 fps on a single RTX 4090 GPU. Ablation studies confirm that removing any branch degrades accuracy, and replacing cross-attention with concatenation reduces mean AUC by 2.9 points. Grad-CAM visualizations demonstrate interpretable, modality-specific focus on blending boundaries, physiological motion, and spectral artifacts. MDFF-Net’s code, pre-trained weights, and evaluation scripts will be released to foster practical adoption and stimulate future research on holistic deepfake forensics.","","978-1-6654-5810-8","10.1109/ACROSET66531.2025.11281048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11281048","Deepfake detection;multi-modal fusion;spatial-temporal-frequency features;cross-attention;video forensics;GAN artifacts;real-time inference","Training;Deepfakes;Visualization;Codes;Forensics;Feature extraction;Rendering (computer graphics);Real-time systems;Reproducibility of results;Security","","","","15","IEEE","16 Dec 2025","27-28 Sept. 2025","27-28 Sept. 2025","IEEE","IEEE Conferences"
"SFSimNet: An Efficient Spatial-Frequency Multi-Scale Intra-Feature Similarity Measurement Network for Deepfake Detection","J. Fang; X. Ding; J. Feng; Y. Yu; L. He","Shenzhen Research Institute of Northwestern Polytechnical University, Shenzhen, Guangdong; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, Hubei, China; Shenzhen Research Institute of Northwestern Polytechnical University, Shenzhen, Guangdong; College of Artificial Intelligence, Nanjing University of Aeronautics and Astronautics, Nanjing, Jiangsu; School of Software, Northwestern Polytechnical University, Xi’an, Shaanxi, China",IEEE Transactions on Consumer Electronics,"","2025","PP","99","1","1","The rapid evolution of face synthesis technology, powered by AIGC (AI-generated content), has facilitated its widespread misuse, posing substantial security risks in consumer electronics applications. The core principle of deepfake technology involves manipulating or forgery of facial data using advanced AI/ML algorithms. However, such tampered or forged content inherently exhibits discrepancies from the original, creating opportunities for detection. In this paper, we exploit these discrepancies by employing intra-feature similarity measurements to distinguish between content for deepfake detection. We introduce a computationally efficient and low-complexity deepfake detection framework based on a multi-scale similarity measurement mechanism that operates in both the spatial and frequency domains. This approach effectively captures subtle traces of manipulation across diverse feature scales and domains. Comprehensive experimental results demonstrate our method’s exceptional performance, surpassing state-of-the-art deepfake detection techniques while requiring fewer parameters and lower computational costs (FLOPs), making it suitable for real-time consumer electronics applications. The code is available at.","1558-4127","","10.1109/TCE.2025.3580624","National Natural Science Foundation of China(grant numbers:62202387); the Guangdong Basic and Applied Basic Research Foundation(grant numbers:2025A1515011112); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11039045","Deepfake detection;multi-domain feature extraction;deep learning;intra-feature similarity","Deepfakes;Faces;Feature extraction;Accuracy;Frequency-domain analysis;Forgery;Computational efficiency;Computational modeling;Transformers;Training","","1","","","IEEE","17 Jun 2025","","","IEEE","IEEE Early Access Articles"
"DeePhyNet: Toward Detecting Phylogeny in Deepfakes","K. Thakral; H. Agarwal; K. Narayan; S. Mittal; M. Vatsa; R. Singh","Department of Computer Science and Engineering, Indian Institute of Technology Jodhpur, Jodhpur, India; Department of Electrical Engineering, Indian Institute of Technology Jodhpur, Jodhpur, India; Department of Computer Science and Engineering, Indian Institute of Technology Jodhpur, Jodhpur, India; Department of Computer Science and Engineering, Indian Institute of Technology Jodhpur, Jodhpur, India; Department of Computer Science and Engineering, Indian Institute of Technology Jodhpur, Jodhpur, India; Department of Computer Science and Engineering, Indian Institute of Technology Jodhpur, Jodhpur, India","IEEE Transactions on Biometrics, Behavior, and Identity Science","27 Dec 2024","2025","7","1","132","145","Deepfakes have rapidly evolved from their inception as a niche technology into a formidable tool for creating hyper-realistic manipulated content. With the ability to convincingly manipulate videos, images, and audio, deepfake technology can be used to create fake news, impersonate individuals, or even fabricate events, posing significant threats to public trust and societal stability. The technology has already been used to generate deepfakes for a number of the above-listed applications. Extending the complexities, this paper introduces the concept of deepfake phylogeny. Currently, multiple deepfake generation algorithms can also be used sequentially to create deepfakes in a phylogenetic manner. In such a scenario, deepfake detection, ingredient model signature detection, and phylogeny sequence detection performances have to be optimized. To address the challenge of detecting such deepfakes, we propose DeePhyNet, which performs three tasks: it first differentiates between real and fake content; it next determines the signature of the generative algorithm used for deepfake creation to determine which algorithm has been used for generation, and finally, it also predicts the phylogeny of algorithms used for generation. To the best of our knowledge, this is the first algorithm that performs all three tasks together for deepfake media analysis. Another contribution of this research is the DeePhyV2 database to incorporate multiple deepfake generation algorithms including recently proposed diffusion models and longer phylogenetic sequences. It consists of 8960 deepfake videos generated using four different generation techniques. The results on multiple protocols and comparisons with state-of-the-art algorithms demonstrate that the proposed algorithm yields the highest overall classification results across all three tasks.","2637-6407","","10.1109/TBIOM.2024.3487482","Ministry of Electronics and Information Technology, Government of India; Prime Ministers Research Fellowship; IBM PhD Fellowship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10737137","Deepfakes;phylogeny;deepfake detection","Deepfakes;Phylogeny;Faces;Face recognition;Feature extraction;Prediction algorithms;Generative adversarial networks;Forgery;Fingerprint recognition","","","","77","IEEE","28 Oct 2024","Jan. 2025","","IEEE","IEEE Journals"
"Revisiting Generalizability in Deepfake Detection: Improving Metrics and Stabilizing Transfer","S. Kamat; S. Agarwal; T. Darrell; A. Rohrbach","University of California, Berkeley; Adobe Research; University of California, Berkeley; University of California, Berkeley",2023 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW),"25 Dec 2023","2023","","","426","435","""Generalizability"" is seen as the hallmark quality of a good deepfake detection model. However, standard out-of-domain evaluation datasets are very similar in form to the training data and lag behind the advancements in modern synthesis methods, making them highly insufficient metrics for robustness. We extend the study of transfer performance of three state-of-the-art methods (that use spatial, temporal, and lip-reading features respectively) on four newer fake types released within the last year. Depending on the artifact modes they were trained on, detection methods fail in different scenarios. On diffusion fakes, the aforementioned methods get 96%, 75%, and 51% AUC respectively, whereas on talking-head fakes, the same methods get 80%, 99%, and 92% AUC. We compare various methods of combining spatial and temporal modalities through joint training and feature fusion in order to stabilize generalization performance.We also propose a new, randomized algorithm to synthesize videos that emulate diverse, visually apparent artifacts with implausibilities in human facial-structure. By testing deepfake detectors on highly randomized artifacts, we can measure the level to which detection networks have learned a strong model for ""reality"", as opposed to memorizing subtle artifact patterns.","2473-9944","979-8-3503-0744-3","10.1109/ICCVW60793.2023.00049","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10350675","Computer Vision;Deepfake Detection;Deepfakes","Measurement;Training;Deepfakes;Conferences;Diversity reception;Training data;Detectors","","6","","62","IEEE","25 Dec 2023","2-6 Oct. 2023","2-6 Oct. 2023","IEEE","IEEE Conferences"
"Guardian AI: Synthetic Media Forensics through Multimodal Fusion and Advanced Machine Learning","K. K; S. R; D. S; D. S","Department of Computer Science and Business Systems, K.S.Rangasamy College of Technology, Namakkal, Tamil Nadu, India; Department of Computer Science and Business Systems, K.S.Rangasamy College of Technology, Namakkal, Tamil Nadu, India; Department of Computer Science and Business Systems, K.S.Rangasamy College of Technology, Namakkal, Tamil Nadu, India; Department of Computer Science and Business Systems, K.S.Rangasamy College of Technology, Namakkal, Tamil Nadu, India",2024 International Conference on Cognitive Robotics and Intelligent Systems (ICC - ROBINS),"21 May 2024","2024","","","226","232","The burgeoning spread of synthetic media disrupts content verification and threatens online trust. This research proposes Guardian AI, a robust deepfake detection system achieving 93% accuracy by harnessing the synergistic power of facial recognition, image forensics, and machine learning. Guardian AI extracts diverse features from videos: facial recognition models analyze landmarks, expressions, and lip-syncing for inconsistencies; image forensics algorithms detect manipulated pixels, lighting patterns, and compression artifacts; and temporal analysis captures unnatural head movements and frame-to-frame motion discrepancies. These multifaceted features are then fused and fed into a rigorously trained deep learning model on multi-modal datasets of real and deepfake videos. Guardian AI classifies video inputs as real or fake, providing a confidence score for its prediction. By leveraging facial recognition's subtle inconsistency detection, image forensics' manipulation artifact identification, and machine learning's robust multi-cue integration, Guardian AI achieves exceptional accuracy and generalizability, adapting to evolving deepfake creation techniques with its diverse training data. This study signifies a significant contribution to content verification by delivering a high accuracy deepfake detection system, paving the way for a more reliable and trustworthy online environment.","","979-8-3503-7274-8","10.1109/ICC-ROBINS60238.2024.10533980","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10533980","Deepfake Detection;Facial Recognition;Image Forensics;Machine Learning;Multimodal Fusion;Content Verification","Deepfakes;Image forensics;Ethics;Explainable AI;Face recognition;Feature extraction;Real-time systems","","1","","10","IEEE","21 May 2024","17-19 April 2024","17-19 April 2024","IEEE","IEEE Conferences"
"MFCC vs. LFCC for Audio Deepfake Detection: The Role of Delta Features and Input Length","K. Schäfer; M. Steinebach","Fraunhofer SIT, ATHENE, Darmstadt, Germany; Fraunhofer SIT, ATHENE, Darmstadt, Germany",2025 33rd European Signal Processing Conference (EUSIPCO),"17 Nov 2025","2025","","","576","580","Basic feature representations like MFCCs and LFCCs allow resource efficient and explainable feature extraction for e.g. audio deepfake detection. Despite the frequent utilisation of these feature representations, a comprehensive examination of the number of coefficients employed and the impact of delta and double delta values remains to be undertaken. We analysed MFCCs and LFCCs combined with four classifiers, using in-domain and out-of-domain test sets. MFCCs performed superior on out-of-domain data, LFCC on the in-domain test set. The combination of lower amounts of coefficients with longer audio inputs, in conjunction with the utilisation of delta and double delta features, yielded enhanced generalisable results. For instance, for ResNet34 with 128 coefficients we calculated an EER of 65.15% on the out-of-domain test set, with 20 coefficients we calculated an EER of 29.71%. Furthermore, we identified specific patterns in the MFCCs when employed with various classifiers. For all classifiers, lower MFCCs (0, 1) were identified as contributing to a classification as bona-fide, whereby higher MFCCs contributed to a classification as spoof for all detectors.","","978-9-4645-9362-4","10.23919/EUSIPCO63237.2025.11226775","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11226775","audio deepfakes;detection;LFCC;MFCC;explainability","Deepfakes;Europe;Detectors;Signal processing;Feature extraction;Mel frequency cepstral coefficient","","","","16","","17 Nov 2025","8-12 Sept. 2025","8-12 Sept. 2025","IEEE","IEEE Conferences"
"AIM-Bone: Texture Discrepancy Generation and Localization for Generalized Deepfake Detection","B. Liu; X. Zhang; H. Ling; Z. Li; R. Wang; H. Zhang; P. Li","School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China","IEEE Transactions on Biometrics, Behavior, and Identity Science","26 Jun 2025","2025","7","3","422","431","Deep synthesis multimedia content, especially human face manipulation poses a risk of visual and auditory confusion, highlighting the call for generalized face forgery detection methods. In this paper, we propose a novel method for fake sample synthesis, along with a dual auto-encoder network for generalized deepfake detection. First, we delve into the texture discrepancy between tampered and unperturbed regions within forged images and impose models to learn such features by adopting Augmentation Inside Masks (AIM). It is capable of sabotaging the texture consistency within a single real image and generating textures that are commonly seen in fake images. It is realized by exhibiting forgery clues of discrepancy in noise patterns, colors, resolutions, and especially the existence of GAN (Generative Adversarial Network) features, including GAN textures, deconvolution traces, GAN distribution, etc. To the best of our knowledge, this work is the first to incorporate GAN features in fake sample synthesizing. The second is that we design a Bone-shaped dual auto-encoder with a powerful image texture filter bridged in between to aid forgery detection and localization in two streams. Reconstruction learning in the color stream avoids over-fitting in specific textures and imposes learning color-related features. Moreover, the GAN fingerprints harbored within the output image can be in furtherance of AIM and produce texture-discrepant samples for further training. The noise stream takes input processed by the proposed texture filter to focus on noise perspective and predict forgery region localization, subjecting to the constraint of mask label produced by AIM. We conduct extensive experiments on multiple benchmark datasets and the superior performance has proven the effectiveness of AIM-Bone and its advantage against current state-of-the-art methods. Our source code is available at https://github.com/heart74/AIM-Bone.git.","2637-6407","","10.1109/TBIOM.2025.3526655","National Natural Science Foundation of China(grant numbers:62372203,62302186); Major Scientific and Technological Project of Shenzhen(grant numbers:202316021); National Key Research and Development Program of China(grant numbers:2022YFB2601802); Major Scientific and Technological Project of Hubei Province(grant numbers:2022BAA046,2022BAA042); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10829837","Deepfake detection;forgery detection generalization;fake textures;adversarial learning;data augmentation","Forgery;Generative adversarial networks;Faces;Deepfakes;Training;Image color analysis;Image reconstruction;Feature extraction;Adversarial machine learning;Data augmentation","","","","60","IEEE","6 Jan 2025","July 2025","","IEEE","IEEE Journals"
"Detection Of Deepfake Images","M. M. Biddappa; M. Hamsaveni; M. Himalatha; M. K. Manoj; M. Ashok","Computer Science And Engineering Vidyavardhaka College Of Engineering, Mysore, India; Computer Science And Engineering Vidyavardhaka College Of Engineering, Mysore, India; Computer Science And Engineering Vidyavardhaka College Of Engineering, Mysore, India; Computer Science And Engineering Vidyavardhaka College Of Engineering, Mysore, India; Computer Science And Engineering Vidyavardhaka College Of Engineering, Mysore, India","2025 Annual International Conference on Data Science, Machine Learning and Blockchain Technology (AICDMB)","12 Dec 2025","2025","","","1","8","In this paper, an extensive evaluation of two recent state-of-the-art deepfake detectors: the Deep Convolutional Neural Network (D-CNN) and Frequency Convolutional Neural Network(fCNN). These models are supposed to counter the issue of deepfakes or adversarial attacks in technologically driven and fast pace media manipulations, especially image and video tampering. The fCNN to detect concealed deception artifacts that remained in frequency-domain features and D-CNN focused on the spatial feature extraction by convolution layer itself. Accuracy, efficiency and adversarial robustness: evaluate both models with respect to the factors. To make a groundwork for future enhancements in media forensics, this study presents an analysis of various models best suited to the goal and points out their pros and cons by justifying scalability, flexibility towards compressed media as well utilization that can further improvise resilience & reliability.","","979-8-3315-4216-0","10.1109/AICDMB64359.2025.11277531","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11277531","Deepfake detection;D-CNN;fCNN;frequency-domain analysis;adversarial robustness;real-time","Biometrics;Deepfakes;Technological innovation;Biological system modeling;Frequency-domain analysis;Media;Feature extraction;Robustness;Convolutional neural networks;Protection","","","","15","IEEE","12 Dec 2025","27-28 June 2025","27-28 June 2025","IEEE","IEEE Conferences"
"DIP: Diffusion Learning of Inconsistency Pattern for General DeepFake Detection","F. Nie; J. Ni; J. Zhang; B. Zhang; W. Zhang","School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; School of Cyber Science and Technology, Sun Yat-sen University, Shenzhen, China; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; Department of Networks, Pengcheng Laboratory, Shenzhen, China; School of Cyberspace Science, Harbin Institute of Technology, Harbin, China",IEEE Transactions on Multimedia,"4 Apr 2025","2025","27","","2155","2167","With the advancement of deepfake generation techniques, the importance of deepfake detection in protecting multimedia content integrity has become increasingly obvious. Recently, temporal inconsistency clues have been explored to improve the generalizability of deepfake video detection. According to our observation, the temporal artifacts of forged videos in terms of motion information usually exhibits quite distinct inconsistency patterns along horizontal and vertical directions, which could be leveraged to improve the generalizability of detectors. In this paper, a transformer-based framework for Diffusion Learning of Inconsistency Pattern (DIP) is proposed, which exploits directional inconsistencies for deepfake video detection. Specifically, DIP begins with a spatiotemporal encoder to represent spatiotemporal information. A directional inconsistency decoder is adopted accordingly, where direction-aware attention and inconsistency diffusion are incorporated to explore potential inconsistency patterns and jointly learn the inherent relationships. In addition, the SpatioTemporal Invariant Loss (STI Loss) is introduced to contrast spatiotemporally augmented sample pairs and prevent the model from overfitting nonessential forgery artifacts. Extensive experiments on several public datasets demonstrate that our method could effectively identify directional forgery clues and achieve state-of-the-art performance.","1941-0077","","10.1109/TMM.2024.3521766","National Natural Science Foundation of China(grant numbers:U23B2022,U22A2030); Guangdong Major Project of Basic and Applied Basic Research(grant numbers:2023B0303000010); Major Key Project of PCL(grant numbers:PCL2023A05); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10814697","Deepfake detection;vision transformer;graph diffusion learning","Deepfakes;Spatiotemporal phenomena;Forgery;Electronics packaging;Transformers;Feature extraction;Optical flow;Robustness;Nickel;Image color analysis","","1","","61","IEEE","25 Dec 2024","2025","","IEEE","IEEE Journals"
"Review of Deepfake Detection Techniques and Challenges","N. S. Ahmad Sharawardi; S. -H. Liew; P. Turumugon; A. Subramaniam","Faculty of Computing and Information Technology, Tunku Abdul Rahman University of Management and Technology Tanjung Bungah, Pulau Pinang, Malaysia; Faculty of Computer Science and Information Technology, Universiti Malaysia Sarawak (UNIMAS), Kota Samarahan, Sarawak, Malaysia; Faculty of Computing and Information Technology, Tunku Abdul Rahman University of Management and Technology Tanjung Bungah, Pulau Pinang, Malaysia; Faculty of Computing and Information Technology, Tunku Abdul Rahman University of Management and Technology Tanjung Bungah, Pulau Pinang, Malaysia","2025 IEEE International Conference on Computation, Big-Data and Engineering (ICCBE)","28 Nov 2025","2025","","","867","872","The proliferation of deepfake technology, powered by advanced generative models such as generative adversarial networks (GANs), presents challenges in digital media authenticity, public trust, and cybersecurity. We reviewed recent advancements in deepfake detection across multiple modalities, including image, video, and audio. Benchmark datasets, such as FaceForensics++, the deepfake detection challenge (DFDC), and Celeb-deepfake (Celeb-DF), have been used to develop diverse detection models. These models encompass approaches based on EfficientNet-driven transfer learning, convolutional neural network-long short-term memory (CNN-LSTM) hybrids for temporal feature extraction, graph-based neural architectures, and ensemble methods that integrate deep learning with handcrafted features. Although certain models report detection accuracies as high as 99.99% on specific datasets, many exhibit limited generalizability across different benchmarks, particularly when confronted with compression artifacts. Additionally, real-time deployment remains constrained by substantial computational demands. Emerging threats, including adversarial perturbations and diffusion-based synthetic media, necessitate the development of more resilient detection strategies. Proactive countermeasures such as blockchain-based timestamping, digital watermarking, and cryptographic hashing have been adopted to enhance media integrity. The results of the review underscore the need for lightweight, interpretable, and multimodal detection frameworks to generalize the models' applicability across diverse domains, thereby supporting reliable and scalable media verification in increasingly complex digital environments.ion.","","979-8-3315-3244-4","10.1109/ICCBE65177.2025.11255645","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11255645","deepfake detection;generative adversarial networks (GANs);convolutional neural networks (CNNs);hybrid models;spatial-temporal models","Training;Deep learning;Deepfakes;Adaptation models;Accuracy;Computational modeling;Biological system modeling;Media;Benchmark testing;Real-time systems","","","","35","IEEE","28 Nov 2025","27-29 June 2025","27-29 June 2025","IEEE","IEEE Conferences"
"Exploring the Adversarial Robustness of CLIP for AI-generated Image Detection","V. De Rosa; F. Guillaro; G. Poggi; D. Cozzolino; L. Verdoliva","University Federico II of Naples, Italy; University Federico II of Naples, Italy; University Federico II of Naples, Italy; University Federico II of Naples, Italy; University Federico II of Naples, Italy",2024 IEEE International Workshop on Information Forensics and Security (WIFS),"27 Dec 2024","2024","","","1","6","In recent years, many forensic detectors have been proposed to detect AI-generated images and prevent their use for malicious purposes. Convolutional neural networks (CNNs) have long been the dominant architecture in this field and have been the subject of intense study. However, recently proposed Transformer-based detectors have been shown to match or even outperform CNN-based detectors, especially in terms of generalization. In this paper, we study the adversarial robustness of AI-generated image detectors, focusing on Contrastive LanguageImage Pretraining (CLIP)-based methods that rely on Visual Transformer (ViT) backbones and comparing their performance with CNN-based methods. We study the robustness to different adversarial attacks under a variety of conditions and analyze both numerical results and frequency-domain patterns. CLIPbased detectors are found to be vulnerable to white-box attacks justlike CNN-based detectors. However, attacks do not easily transfer between CNN-based and CLIP-based methods. This is also confirmed by the different distribution of the adversarial noise patterns in the frequency domain. Overall, this analysis provides new insights into the properties of forensic detectors that can help to develop more effective strategies.","2157-4774","979-8-3503-6442-2","10.1109/WIFS61860.2024.10810719","Google; Horizon Europe; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10810719","Deepfakes;AI-generated image detection;adversarial robustness","Visualization;Forensics;Frequency-domain analysis;Noise;Focusing;Detectors;Transformers;Robustness;Security;Glass box","","6","","31","IEEE","27 Dec 2024","2-5 Dec. 2024","2-5 Dec. 2024","IEEE","IEEE Conferences"
"Attention Guided Multi-attribute Architecture For Deepfake Detection","R. Sharma; B. Jawade; A. Agarwal; S. Setlur; N. Ratha","University at Buffalo, USA; University at Buffalo, USA; IISER Bhopal, India; University at Buffalo, USA; University at Buffalo, USA",2023 IEEE Western New York Image and Signal Processing Workshop (WNYISPW),"13 Dec 2023","2023","","","1","4","Deepfake content generated through visual and audio manipulations is speculated to become one of the most threatening artificial intelligence (AI) technologies capable of grave negative impact on society through identity fraud, reputation damage, and undermining of trust in large-scale political campaigns and criminal investigation procedures. A significant measure of the efforts towards solving this problem fails to generalize beyond the training data. We hypothesize that the primary reason behind the drawback is the dearth of efforts toward the exploitation of multiple channels of information from the data. Towards this goal, we investigate a multimodal paradigm exploiting an attention-informed feature generation procedure through a deep network. We further augment the supervisory signal using camera sensor fingerprints which contain additional corroboratory information for the decision-making process. We demonstrate that a non-linear transformation of the decision space augmented through multiple channels allows for a significant boost in the generalization capacity over unseen datasets or attacks. We illustrate the applicability of our framework on the widely known datasets of FaceForensics++ and CelebDF.","2471-9242","979-8-3503-2969-8","10.1109/WNYISPW60588.2023.10349650","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10349650","Deepfake detection;Multimodal fusion;Multi-scale attention;Camera Fingerprint/Noiseprint","Image quality;Deepfakes;Visualization;Perturbation methods;Signal processing algorithms;Training data;Fingerprint recognition","","","","33","IEEE","13 Dec 2023","3-3 Nov. 2023","3-3 Nov. 2023","IEEE","IEEE Conferences"
"A Comprehensive Comparative Analysis of Deepfake Detection Techniques in Visual, Audio, and Audio-Visual Domains","A. A. Bekheet; A. Ghoneim; G. Khoriba","Computer Science Department, Faculty of Computers and Artificial Intelligence, Helwan University, Cairo, Egypt; Computer Science Department, Faculty of Computers and Artificial Intelligence, Helwan University, Cairo, Egypt; Centre for Informatics Science (CIS), School of Information Technology and Computer Science (ITCS), Nile University, Giza, Egypt","2024 Intelligent Methods, Systems, and Applications (IMSA)","5 Sep 2024","2024","","","122","129","In recent years, the rise of social media platforms has made them vital channels for sharing news, where audio and visual content play a crucial role in enhancing the credibility of news content. However, significant Artificial Intelligence (AI) progress has introduced new techniques and tools for manipulating multimedia content. These advancements have made it easier to create fabricated digital media, leading to a harmful impact on sharing misinformation, especially in fake news. Consequently, an urgent need arises to explore prevailing methodologies for detecting fake images, audio, and videos, accompanied by a comprehensive exposition of their strengths and limitations. Our survey addresses these methodologies and conducts a rigorous comparative analysis of diverse approaches using various metrics and datasets. We categorize these approaches into visual-based, audio-based, and audio-visual-based deepfake detection methods, encompassing techniques employed across domains. Additionally, we examine notable datasets utilized in detecting image, video, and audio deepfakes, offering insights into their attributes and appropriateness for evaluation purposes. Our findings highlight the effectiveness and limitations of current detection methods, providing a roadmap for future research in multimodal deepfake detection. This includes exploring emerging facets of video manipulation, such as text overlays and motion patterns, investigating advanced deep learning architectures like Transformers, and emphasizing the need for extensive, diverse, and publicly accessible datasets to enhance the robustness and validation of detection methods.","","979-8-3503-6263-3","10.1109/IMSA61967.2024.10652683","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10652683","Audio-visual Deepfake Detection;Convolutional Neural Networks (CNNs);Recurrent Neural Networks (RNNs);Transformers;Mel Frequency Cepstral Coefficients (MFCC);Mel-spectrogram;Text-to-Speech Synthesis (TTS) Voice Conversion (VC)","Surveys;Measurement;Deepfakes;Visualization;Social networking (online);Neural networks;Streaming media","","1","","68","IEEE","5 Sep 2024","13-14 July 2024","13-14 July 2024","IEEE","IEEE Conferences"
"Spatiotemporal Deepfake Video Detection: A Hybrid CNN-Transformer Approach with Frequency Analysis","N. Celebi; Q. Liu","Department of Computer Science, Sam Houston State University, Huntsville, TX, USA; Department of Computer Science, Sam Houston State University, Huntsville, TX, USA",2025 IEEE International Conference on Information Reuse and Integration and Data Science (IRI),"12 Sep 2025","2025","","","216","221","Deepfakes are AI-generated manipulated videos that closely mimic real individuals, posing significant risks to privacy, digital security, and information authenticity. To address these threats, we propose DFD-V, a novel deepfake detection framework that combines spatial, frequency, and temporal analysis to capture diverse forgery artifacts. The model extracts per-frame features using an EfficientNet-B0 backbone for spatial cues and a custom CNN operating on 2D FFT spectra to detect frequency-domain anomalies. A Motion-Aware Frequency Attention (MAF) module further emphasizes temporal inconsistencies in spectral patterns. These dual features are fused via Selective Cross-Domain Attention Fusion (SCDAF), aligning complementary evidence. The fused representations are then modeled over time using a Bidirectional LSTM, enabling detection of frame-level inconsistencies such as flicker or jitter. We preprocess videos by extracting aligned facial regions and apply standard augmentations to improve robustness. The model is trained using binary cross-entropy loss, with optional adversarial domain adaptation to enhance cross-dataset generalization. Experimental results demonstrate that DFD-V achieves strong performance on multiple benchmarks, offering a reliable and interpretable framework for robust deepfake video detection.","2835-5776","979-8-3315-9944-7","10.1109/IRI66576.2025.00048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11153098","DeepFake video detection;deep learning;digital forensics;machine learning;multimedia security","Deepfakes;Adaptation models;Privacy;Streaming media;Feature extraction;Robustness;Spatiotemporal phenomena;Rough surfaces;Security;Standards","","","","26","IEEE","12 Sep 2025","6-8 Aug. 2025","6-8 Aug. 2025","IEEE","IEEE Conferences"
"A Dual-Stream CNN-LSTM Framework with ELA Preprocessing for Deepfake Detection","N. N. Nadarajan; A. R. Trivedi; S. K; M. M; G. Kolagatla; S. Rana; N. M","SCOPE, VIT-AP University, Amaravati, India; SCOPE, VIT-AP University, Amaravati, India; SCOPE, VIT-AP University, Amaravati, India; School of Electronics Engineering, VIT-AP University, Amaravati, India; SCOPE, VIT-AP University, Amaravati, India; SCOPE, VIT-AP University, Amaravati, India; School of Electronics Engineering, VIT-AP University, Amaravati, India",2025 International Conference on Sensors and Related Networks (SENNET) Special Focus on Digital Healthcare(64220),"29 Aug 2025","2025","","","1","6","The proliferation of deepfake content presents critical threats to digital authenticity, privacy, and information integrity. This paper proposes a hybrid deepfake detection framework that integrates Error Level Analysis (ELA) with the ResNet-50 convolutional neural network to identify manipulated images. The system employs a dual-stream architecture that processes both raw frames and ELA-transformed inputs, enhancing spatial and temporal feature extraction through Long Short-Term Memory (LSTM) layers. Evaluated on both general-purpose and celebrity-based datasets, the proposed model demonstrates superior classification accuracy and robust generalization, particularly in detecting forgeries involving high-profile individuals. Experimental results affirm the model’s effectiveness in capturing compression inconsistencies and subtle manipulations, positioning it as a scalable and reliable solution for deepfake detection in real-world scenarios.","","979-8-3315-9746-7","10.1109/SENNET64220.2025.11135952","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11135952","Deepfake detection;Error Level Analysis (ELA);ResNet-50;LSTM;image forensics;digital media authenticity;deep learning;multimedia security","Deepfakes;Accuracy;Sensitivity;Media;Feature extraction;Sensors;Convolutional neural networks;Security;Reliability;Long short term memory","","","","17","IEEE","29 Aug 2025","24-27 July 2025","24-27 July 2025","IEEE","IEEE Conferences"
"Pandora's Black or White Box: Are AI Tools Undermining Evidence?","E. Williams; J. Rodgers; S. Chandler-Crnigoj; K. Jones; C. Robinson","Faculty of Engineering Technology, Liverpool John Moores University, Liverpool, England; Police Service of Scotland, Edinburgh, Scotland; Faculty of Engineering Technology, Liverpool John Moores University, Liverpool, England; Faculty of Engineering Technology, Liverpool John Moores University, Liverpool, England; Faculty of Engineering Technology, Liverpool John Moores University, Liverpool, England",2025 International Conference on Computer Systems and Technologies (CompSysTech),"2 Sep 2025","2025","","","1","6","The proliferation of synthetic media, particularly deepfakes, is having a significant impact on society in general and the criminal justice system in particular. The increase in deepfake audio and video evidence presents significant challenges to digital forensics, where accurate detection is essential for maintaining the integrity of evidence. With limited manual methods available for identifying manipulated content, forensic professionals are increasingly turning to AI-enabled detection tools. This research examines whether the application of professional-grade AI tools for deepfake detection introduces changes to original files, such as modifications to metadata, compression artefacts, or structural alterations, that could compromise their integrity and admissibility in legal contexts. The investigation has focused on 2 professional tools currently widely employed within audio and video forensic units of UK police forces. The work undertaken employs controlled testing to assess the extent and nature of such changes. It evaluates whether these tools adhere to ethical and procedural standards, particularly regarding the chain of custody and evidentiary reliability. The findings aim to inform the integration of AI tools into audio/video forensic workflows, addressing critical concerns about balancing advanced detection capabilities with the preservation of file authenticity. Through identifying potential risks and challenges, the study seeks to support policymakers, forensic practitioners, and legal professionals in ensuring that advancements in synthetic media detection uphold the foundational principles of evidence handling and judicial integrity.","","979-8-3315-4322-8","10.1109/CompSysTech65493.2025.11137140","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11137140","Artificial Intelligence;Forensics;Digital Forensics;Deepfake Detection;Policing","Deepfakes;Ethics;Magnetic resonance imaging;Digital forensics;Media;Metadata;Turning;Artificial intelligence;Standards;Testing","","","","23","IEEE","2 Sep 2025","27-28 June 2025","27-28 June 2025","IEEE","IEEE Conferences"
"ViT-Xplain: A Transparent Deepfake Detector for Consumer Electronics Based on Attention and Explainable AI","G. Husnain; A. B. M. Ali; A. Khan; A. Junaid; M. Usman; E. M. Awwad; A. A. Telba","Department of Computer Science, CECOS University of IT and Emerging Sciences, Peshawar, Pakistan; Air Conditioning Engineering Department, College of Engineering, University of Warith Al-Anbiyaa, Karbala, Iraq; Department of Computer Science, CECOS University of IT and Emerging Sciences, Peshawar, Pakistan; Department of Computer Science, CECOS University of IT and Emerging Sciences, Peshawar, Pakistan; Department of Public Health, National Health Services, Wales, UK; Department of Electrical Engineering, College of Engineering, King Saud University, P.O. Box 800, Riyadh, Saudi Arabia; Department of Electrical Engineering, College of Engineering, King Saud University, P.O. Box 800, Riyadh, Saudi Arabia",IEEE Transactions on Consumer Electronics,"","2025","PP","99","1","1","Consumer electronics platforms like social media, mobile apps and smart devices are becoming more vulnerable to deepfake videos, which can seriously harm content authenticity, user trust and legal safety. Many existing deepfake detection systems use deep neural networks that only give a final score, without explaining how the decision was made. This makes it difficult to use these systems in the real world, where people need clear reasons to trust what the model says. Problems like shortcut learning, video compression issues and background distractions also make these models less reliable. While some researchers have used convolutional and hybrid models to improve detection accuracy, they often ignore the need for explainable results. In this work, we introduce an explainable Vision Transformer (ViT) system that combines strong detection ability with clear, easy-to-understand explanations. The framework consists of five phases: dataset analysis and frame sampling, model training, evaluation and error analysis, attention roll-out and aggregation and explainability and trust scoring. Alongside predictions, the system produces attention-based visual overlays and quantitative metrics such as attention-to-face overlap, entropy concentration, clarity index and a trust score. Evaluated on the FaceForensics++ benchmark, our ViT model achieves 74.4% accuracy, 66.0% precision, 90.7% recall, 76.4% F1-score, 81.8 ROC AUC and 72.3 PR AUC. Attention maps consistently highlight facial regions with an average overlap score of 0.575 and higher alignment correlates with classifier confidence. The framework is lightweight, Python-based and deployable on standard hardware, making it practical for consumer platforms that require explainability, trust calibration and compliance-friendly audit features.","1558-4127","","10.1109/TCE.2025.3643884","King Saud University(grant numbers:ORF-2025-1108); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11300282","Deepfake Detection;Vision Transformer;Explainability;Attention-to-face Overlap;Trust Scoring","","","","","","IEEE","15 Dec 2025","","","IEEE","IEEE Early Access Articles"
"Deepfake Detection using XAI based Deep Fusion Models","A. Anitha; L. M. Saju; B. Kamaraj","School of Computer Science Engineering and Information Systems, Vellore Institute of Technology, Vellore, Tamil Nadu, India; School of Computer Science Engineering and Information Systems, Vellore Institute of Technology, Vellore, Tamil Nadu, India; Madurai Medical College, Madurai, Tamilnadu, India","2025 2nd International Conference on Computational Intelligence, Communication Technology and Networking (CICTN)","26 Mar 2025","2025","","","526","531","Deepfake technology has rapidly evolved, posing a serious threat to the authenticity of digital media and contributing to the spread of misinformation. The manipulation of media content raises significant concerns across sectors like politics, entertainment, and social media, undermining public trust in digital information. In response, this research proposes an advanced deepfake detection model that integrates Explainable Artificial Intelligence (XAI) techniques within a hybrid deep learning architecture. The proposed model combines ResNet50 and Vision Transformer (ViT) to capture spatial and contextual features effectively. While exploring additional methods such as facial landmark detection and frequency domain analysis, the final model focuses on the ResNet50-ViT combination for its superior performance to fusion model. To ensure transparency, the model employs XAI techniques such as LIME (Local Interpretable Model-agnostic Explanations) and SHAP (SHapley Additive exPlanations), offering interpretability by revealing the key factors that influence its predictions. This dual focus on high detection accuracy and interpretability ensures that the model not only detects deepfakes effectively but also builds trust in automated decision-making processes. By leveraging cutting-edge deep learning and XAI methods, this framework offers a more reliable, transparent, and adaptable solution for preserving digital media authenticity across various applications, ultimately contributing to combating misinformation and fostering trust in digital content.","","979-8-3315-3038-9","10.1109/CICTN64563.2025.10932587","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10932587","Deepfake Detection;Deep Learning;ResNet50;Vision Transformer (ViT);Explainable Artificial Intelligence (XAI)","Deep learning;Deepfakes;Computer vision;Analytical models;Adaptation models;Explainable AI;Frequency-domain analysis;Predictive models;Transformers;Residual neural networks","","","","18","IEEE","26 Mar 2025","6-7 Feb. 2025","6-7 Feb. 2025","IEEE","IEEE Conferences"
"AI-Based Image Forgery Detection (AI-IFD)","N. Yadav; S. Sheoran","Dept. of Computer Science and Engg., Indira Gandhi University, Meerpur, Rewari, India; Dept. of Computer Science and Engg., Indira Gandhi University, Meerpur, Rewari, India","2025 12th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)","27 Nov 2025","2025","","","1","7","Digital image manipulation has reached unprecedented sophistication with the advent of generative adversarial networks (GANs) and diffusion models, creating significant challenges for digital forensics and media verification. This paper presents AI-IFD (AI-based Image Forgery Detection), a novel multi-domain ensemble framework that combines spatial, frequency, and error-level analysis through attention-guided fusion mechanisms. Our approach integrates ResNet-50, VGG-16, EfficientNet-B0, and a custom JPEG-aware convolutional neural network using Bayesian-optimized soft weighting strategies. Enhanced with a four-layer Vision Transformer (ViT) neck for global context modeling, the system achieves robust detection capabilities while maintaining real-time processing speeds. Comprehensive evaluation on FaceForensics++, DFDC, CelebDF, and a custom 38k-image dataset demonstrates superior performance with $\text{9 0. 8 \%}$ accuracy, $\text{0. 9 5 2}$ AUC-ROC, and $\text{1 8. 1 m s}$ inference time on $224 \times 224$ images. The framework exhibits exceptional adversarial robustness, maintaining 72.3 % accuracy under FGSM attacks and 55.6 % under PGD attacks, representing significant improvements over existing approaches. These results validate multi-domain fusion coupled with attention mechanisms as a promising direction for real-time, adversary-aware image forgery detection.","2769-2884","979-8-3315-5421-7","10.1109/ICRITO66076.2025.11241973","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11241973","Image forgery detection;deepfake detection;ensemble learning;attention mechanisms;adversarial robustness;computer vision;digital forensics","Training;Computer vision;Accuracy;Digital forensics;Media;Transformers;Forgery;Robustness;Real-time systems;Bayes methods","","","","20","IEEE","27 Nov 2025","18-19 Sept. 2025","18-19 Sept. 2025","IEEE","IEEE Conferences"
"Deepfake Detection Using Graph Representation with Multi-dimensional Features","J. Chen; W. Lin; J. Xu","School of Computer and Cyber Sciences Communication University of China, Beijing, China; School of Computer and Cyber Sciences Communication University of China, Beijing, China; School of Computer and Cyber Sciences Communication University of China, Beijing, China",2023 IEEE Smart World Congress (SWC),"1 Mar 2024","2023","","","717","722","The proliferation of fake video poses a significant threat to the authority and authenticity of news across multiple domains. The most existing methods of deepfake detection primarily focus on identifying the face as a whole in a video, ignoring the correlation between the facial components. However, our investigation indicates that constituent potions of a face have different effects in deepfake detection. To address this issue, we divided the face in a video frame into several regions and explored the relationship between these regions. Our approach involves constructing a feature graph of this correlation, aiming to make use of the relationship and temporal characteristics between regions of a face in a deepfake video. To begin with, the features of each facial region are extracted through CNN. Subsequently, the feature graph of the entire video is constructed with these features being the vertices and the correlation being the edge. A graph neural network is finally utilized to determine whether the video has been tampered with. Our experiments on several publicly accessible datasets demonstrate that the proposed approach outperforms other state-of-the-art deepfake detection techniques in most scenarios.","","979-8-3503-1980-4","10.1109/SWC57546.2023.10449093","Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10449093","graph representation;deepfake detection;temporal characteristics","Deepfakes;Correlation;Image edge detection;Logic gates;Feature extraction;Graph neural networks;Faces","","3","","28","IEEE","1 Mar 2024","28-31 Aug. 2023","28-31 Aug. 2023","IEEE","IEEE Conferences"
"Rethinking the Up-Sampling Operations in CNN-Based Generative Network for Generalizable Deepfake Detection","C. Tan; H. Liu; Y. Zhao; S. Wei; G. Gu; P. Liu; Y. Wei","Institute of Information Science, Beijing Jiaotong University; Institute of Information Science, Beijing Jiaotong University; Institute of Information Science, Beijing Jiaotong University; Institute of Information Science, Beijing Jiaotong University; School of Information Science and Engineering, Yanshan University; CSE department, University of Nevada, Reno, USA; Institute of Information Science, Beijing Jiaotong University",2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),"16 Sep 2024","2024","","","28130","28139","Recently, the proliferation of highly realistic synthetic images, facilitated through a variety of GANs and Diffusions, has significantly heightened the susceptibility to misuse. While the primary focus of deepfake detection has traditionally centered on the design of detection algorithms, an investigative inquiry into the generator architectures has remained conspicuously absent in recent years. This paper contributes to this lacuna by rethinking the architectures of CNN-based generator, thereby establishing a generalized representation of synthetic artifacts. Our findings illuminate that the up-sampling operator can, beyond frequency-based artifacts, produce generalized forgery artifacts. In particular, the local interdependence among image pixels caused by upsampling operators is significantly demon-strated in synthetic images generated by GAN or diffusion. Building upon this observation, we introduce the concept of Neighboring Pixel Relationships(NPR) as a means to capture and characterize the generalized structural artifacts stemming from up-sampling operations. A comprehensive analysis is conducted on an open-world dataset, comprising samples generated by 28 distinct generative models. This analysis culminates in the establishment of a novel state-of-the-art performance, showcasing a remarkable 12.8% im-provement over existing methods. The code is available at https://github.com/chuangchuangtan/NPR-DeepfakeDetection.","2575-7075","979-8-3503-5300-6","10.1109/CVPR52733.2024.02657","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10658459","Deepfake Detection;Up-Sampling Operations;Neighboring Pixel Relationships","Deepfakes;Computer vision;Frequency-domain analysis;Computer architecture;Detectors;Generative adversarial networks;Generators","","83","","73","IEEE","16 Sep 2024","16-22 June 2024","16-22 June 2024","IEEE","IEEE Conferences"
"SwinGAN: A Synergistic Approach Combining Swin Transformers and GANs for DeepFake Detection","V. Kumar; P. Chaudhary; A. K. Singh; A. Srivastava; P. Diswar; H. Singh","Dept. of Computer Science and Engineering, Noida Institute of Engineering and Technology, Uttar Pradesh, India; Dept. of Computer Science and Engineering, Noida Institute of Engineering and Technology, Uttar Pradesh, India; Dept. of Computer Science and Engineering, Noida Institute of Engineering and Technology, Uttar Pradesh, India; Dept. of Computer Science and Engineering, Noida Institute of Engineering and Technology, Uttar Pradesh, India; Dept. of Computer Science and Engineering, Noida Institute of Engineering and Technology, Uttar Pradesh, India; Dept. of Computer Science and Engineering, Noida Institute of Engineering and Technology, Uttar Pradesh, India",2025 2nd International Conference On Multidisciplinary Research and Innovations in Engineering (MRIE),"19 Sep 2025","2025","","","652","657","With rapid progress comes deepfake technology concerns for an unreliable media. This calls for robust detection mechanisms protection against misinformation and deception. In this paper, we provided a framework for deepfake detection with GAN-based data augmentation and Swin transformer. The Swin Transformer is the hierarchical vision transformer based application. The model was validated on CelebDF, FaceForensics++, and DFDC benchmark datasets providing accuracies of 97.50%, 98.20, and 96.10%, respectively. With Area Under the Curve (AUC) scores edges of 0.995 and low Equal Error Rates (EER), the model validated for generalization. Comparison of results with other industry-leading model such as ResNet3D and Xception was favorable. GAN augmentation generated the synthetic frames dataset, which improved the robustness of the model while minimizing class imbalance, thereby improving generalization on different datasets. The findings of this study indicated the transformers-based architecture will be viable in deepfake detection and could serve as a catalyst for future research in media forensics.","","979-8-3315-8673-7","10.1109/MRIE66930.2025.11156622","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11156622","Deepfake Detection;Swin Transformer;Generative Adversarial Networks (GANs);Media Forensics;Computer Vision;Data Augmentation;FaceForensics++;Celeb-DFv2;DFDC","Deepfakes;Computer vision;Technological innovation;Accuracy;Forensics;Transformers;Generative adversarial networks;Data augmentation;Solids;Video recording","","","","25","IEEE","19 Sep 2025","30-31 July 2025","30-31 July 2025","IEEE","IEEE Conferences"
"Deepfake Detection and Cybersecurity Index: The Role of Computer Vision as a Digital Forensic Tool","T. O. Modupeola; V. Ayodeji Oluwasusi; N. A. Nobari Azar; A. Peter Ichull","Computer Information Systems, Near East University, Mersin, Turkey; Computer Information Systems Research and Technology Centre, Mersin, Turkey; Computer Information Systems, Near East University, Mersin, Turkey; Management Information Systems, Girne American University, Mersin, Turkey",2025 9th International Symposium on Multidisciplinary Studies and Innovative Technologies (ISMSIT),"5 Dec 2025","2025","","","1","7","This literature review investigates the growing threat that deepfake technologies raise concerns for digital trust, national security, and forensic integrity. However, detection models are becoming increasingly advanced, there is still a considerable gap between existing capabilities and the integration of detection into national cybersecurity frameworks. This study has attempted to address that gap by providing a conceptual framework that associates computer vision-based deepfake detection capability with measurable cyber readiness performance indicators. Two original constructs the Synthetic Media Threat Index (SMTI) and the AI Forensics Readiness Score (AIFR) are introduced to relate detection systems and global policy measures such as the Global Cybersecurity Index (GCI) and National Cyber Security Index (NCSI). The framework is developed through a theoretical literature synthesis and conceptual mapping, and is analyzed across three dimensions-technology, operation, and policy. This study positions deepfake detection as a strategic pillar in cybersecurity governance, and suggests a methodology to formulate for future empirical testing, standards for policy formulation, and for an AI forensics built environment infrastructure. The review provides academic, technical, and institutional stakeholders unique insights that are relevant to policy.","2770-7962","979-8-3315-9753-5","10.1109/ISMSIT67332.2025.11268234","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11268234","Deepfake Detection;Computer vision;Cybersecurity index;Digital forensics;Synthetic media threat index (SMTI);AIforensics readiness score (AIFR)","Deepfakes;Computer vision;Digital forensics;Media;Indexes;Computer security;Artificial intelligence;Standards;Testing;Systematic literature review","","","","30","IEEE","5 Dec 2025","14-16 Nov. 2025","14-16 Nov. 2025","IEEE","IEEE Conferences"
"From Deepfakes to Digital Truths: The Role of Watermarking in AI-Generated Image Verification","J. J. Thakkar; A. Kaur","Dept of Computer Science, New Jersey Institute of Technology, New Jersey, USA; Dept of Computer Science, New Jersey Institute of Technology, New Jersey, USA",2024 47th International Conference on Telecommunications and Signal Processing (TSP),"30 Jul 2024","2024","","","216","222","The evolution of Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL) has introduced deepfake technology. Deepfake technology is a form of digital manipulation that alters video, image, and audio content with the help of Generative AI. Those deepfakes have increased concerns in various fields, including education, art, and they also raise ethical and security concerns due to their potential for deceptive content. Reviewing the increasing challenge of identifying high-quality deepfakes, there's a pressing need for robust measures to counter them. This review explores various watermarking techniques and their use to protect content authenticity and origin. Watermarking embeds a subtle watermark and provides a strong defense against deepfake technologies and similar AI-driven tools. The paper discusses current watermarking methods, their strengths and weaknesses, and potential improvements to verify AI-generated content.","2768-3311","979-8-3503-6559-7","10.1109/TSP63128.2024.10605975","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10605975","Artificial Intelligence;Content Authentication;Deepfake Detection;Digital Media Integrity;Digital Watermarking;Generative AI;Machine Learning","Deepfakes;Ethics;Reviews;Watermarking;Pressing;Learning (artificial intelligence);Media","","1","","29","IEEE","30 Jul 2024","10-12 July 2024","10-12 July 2024","IEEE","IEEE Conferences"
"Detecting Deepfakes in Alternative Color Spaces to Withstand Unseen Corruptions","K. Zeng; X. Yu; B. Liu; Y. Guan; Y. Hu","School of Electronics and Engineering, South China University of Technology, Guangzhou, China; School of Electronics and Engineering, South China University of Technology, Guangzhou, China; School of Electronics and Engineering, South China University of Technology, Guangzhou, China; Department of computer science, University of Warwick, Coventry, UK; School of Electronics and Engineering, South China University of Technology, Guangzhou, China",2023 11th International Workshop on Biometrics and Forensics (IWBF),"26 Jun 2023","2023","","","1","6","The adverse impact of deepfakes has recently raised world-wide concerns. Many ways of deepfake detection are published in the literature. The reported results of existing methods are generally good under known settings. However, the robustness challenge in deepfake detection is not well addressed. Most detectors fail to identify deepfakes that have undergone post-processing. Observing that the conventionally adopted RGB space does not guarantee the best performance, we propose other color spaces that prove to be more effective in detecting corrupted deepfake videos. We design a robust detection approach that leverages an adaptive manipulation trace extraction network to reveal artifacts from two color spaces. To mimic practical scenarios, we conduct experiments to detect images with post-processings that are not seen in the training stage. The results demonstrate that our approach outperforms state-of-the-art methods, boosting the average detection accuracy by 7% ~ 17%.","","979-8-3503-3607-8","10.1109/IWBF57495.2023.10157416","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10157416","Deepfake detection;Color spaces;Robustness","Training;Deepfakes;Adaptive systems;Image color analysis;Biometrics (access control);Forensics;Conferences","","2","","25","IEEE","26 Jun 2023","19-20 April 2023","19-20 April 2023","IEEE","IEEE Conferences"
"AdvShadow: Evading DeepFake Detection via Adversarial Shadow Attack","J. Liu; M. Zhang; J. Ke; L. Wang","Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, Wuhan, China; Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, Wuhan, China; Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, Wuhan, China; Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, Wuhan, China","ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","18 Mar 2024","2024","","","4640","4644","With the emergence of techniques called DeepFakes, there has been a notable proliferation of DeepFake detectors rooted in deep learning. These detectors aim to expose subtle distinctions between genuine and counterfeit facial images across spatial, frequency, and physiological domains. Unfortunately, these detectors are susceptible to adversarial attacks. In this study, we introduce a novel transferable adversarial attack named AdvShadow, designed to attack DeepFake detectors by leveraging natural shadows in real-life. The proposed AdvShadow comprises three components: random shadow generator, shadow overlay network, and adversarial shadow generation. Initially, we construct a random shadowed facial dataset, utilizing additional shadow overlay network to produce adversarial samples for training. Then we generate adversarial shadows for DeepFake datasets, mitigating the disparities of luminance between real and synthesized images. Through extensive experiments, we demonstrate the effectiveness and transferability of AdvShadow for attacking under black-box settings.","2379-190X","979-8-3503-4485-1","10.1109/ICASSP48485.2024.10448251","National Natural Science Foundation of China; Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10448251","DeepFakes;DeepFake detection;transferable adversarial shadows","Training;Deepfakes;Overlay networks;Perturbation methods;Closed box;Lighting;Detectors","","4","","25","IEEE","18 Mar 2024","14-19 April 2024","14-19 April 2024","IEEE","IEEE Conferences"
"LGDF-Net: Local and Global Feature-Based Dual-Branch Fusion Networks for Deepfake Detection","M. Long; Z. Liu; L. -B. Zhang; F. Peng","School of Electronics and Communication Engineering, Guangzhou University, Guangzhou, Guangdong, China; School of Computer and Communication Engineering, Changsha University of Science and Technology, Changsha, China; School of Computer and Artificial Intelligence, Huaihua University, Huaihua, China; School of Artificial Intelligence, Guangzhou University, Guangzhou, Guangdong, China",IEEE Transactions on Circuits and Systems for Video Technology,"9 Jun 2025","2025","35","6","5489","5500","With the rapid development of Deepfake technology, social security is facing great challenges. Although numerous Deepfake detection algorithms based on traditional CNN frameworks perform well on specific datasets, they still suffer from overfitting due to an over-reliance on localized artifact information. This limitation leads to degraded detection performance across diverse datasets. To address this issue, this study proposes a dual-branch fusion network called LGDF-Net. LGDF-Net uses a dual-branch structure to process the local artifact features and global texture features generated by Deepfake separately, preserving their unique characteristics. Specifically, the local compression branch utilizes a specially designed local compression module (LCM) that allows the network to focus more accurately on key regions of localized artifacts in Deepfake faces. The global expansion branch enhances the analysis of the global facial context through a global expansion module (GEM), which captures image context information and subtle texture features more comprehensively. Additionally, the proposed multi-scale feature extraction module (MSFE) delves into image features at various scales, enriching the extraction of detailed information. Finally, the multi-level feature fusion strategy (MLFF) improves the integration of local and global features through multiple layers, enabling the network to learn the intrinsic connections between these two types of features. A series of experimental validations demonstrate that the proposed scheme outperforms many existing detection networks in terms of accuracy and generalization ability.","1558-2205","","10.1109/TCSVT.2025.3530402","Guangzhou Municipal Science and Technology Project(grant numbers:2025A03J3122); National Natural Science Foundation of China(grant numbers:62072055); Key Laboratory of Intelligent Control Technology for Wuling-Mountain Ecological Agriculture(grant numbers:ZNKZD2024-5); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10843307","Deepfake detection;dual-branching framework;multi-scale feature extraction;multi-level feature fusion","Feature extraction;Deepfakes;Forgery;Faces;Accuracy;Image color analysis;Electronic mail;Data mining;Visualization;Facial features","","4","","54","IEEE","16 Jan 2025","June 2025","","IEEE","IEEE Journals"
"FCD-Net: Learning to Detect Multiple Types of Homologous Deepfake Face Images","R. Han; X. Wang; N. Bai; Q. Wang; Z. Liu; J. Xue","School of Computer Science and Engineering, Xi’an University of Technology, Xi’an, China; School of Computer Science and Engineering, Xi’an University of Technology, Xi’an, China; Department of Mathematics, Xi’an University of Technology, Xi’an, China; School of Computer Science and Engineering, Xi’an University of Technology, Xi’an, China; School of Computer Science and Engineering, Xi’an University of Technology, Xi’an, China; Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China",IEEE Transactions on Information Forensics and Security,"1 May 2023","2023","18","","2653","2666","With the rapid development of artificial intelligence technology, a variety of GAN generated deepfake face images/videos have emerged endlessly. The abuse of deepfake has brought serious negative effects to many industries. Therefore, there is an urgent need to develop advanced methods to combat the abuse of deepfake. As far as we know, there are almost no techniques that can distinguish multiple types of homologous deepfake face images. In this study, we propose a method based on the multi-classification task to address this issue. The proposed method relies on a novel network framework named FCD-Net that consists of the facial synaptic saliency module (FSS), the contour detail feature extraction module (CDFE), and the distinguishing feature fusion module (DFF). Utilizing this method, the imperceptible features introduced by deepfake can be exposed, and the differences caused by different types of deepfake can be distinguished, even if deepfake images are homologous. To test the proposed method and compare it with other SOTA methods, we establish a new homologous dataset named HDFD that contains real face images, entire face synthesis images, face swap images, and facial attribute manipulation images. Among them, the three types of deepfake images are all generated from the same real face images through different deepfake techniques. Abundant experiment results demonstrate that the proposed method has a high-level detection accuracy and relatively strong robustness against content-preserving manipulations. Moreover, the generalization of our method is superior to other SOTA methods.","1556-6021","","10.1109/TIFS.2023.3269152","National Natural Science Foundation of China(grant numbers:61772416); Shaanxi Science Foundation of China(grant numbers:2022GY-087); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10106503","Deepfake detection;homologous face images;facial synaptic saliency (FSS);contour detail feature extraction;distinguishable feature fusion (DFF)","Deepfakes;Faces;Feature extraction;Face recognition;Generative adversarial networks;Image color analysis;Frequency-domain analysis","","19","","57","IEEE","21 Apr 2023","2023","","IEEE","IEEE Journals"
"AEROBLADE: Training-Free Detection of Latent Diffusion Images Using Autoencoder Reconstruction Error","J. Ricker; D. Lukovnikov; A. Fischer",Ruhr University Bochum; Ruhr University Bochum; Ruhr University Bochum,2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),"16 Sep 2024","2024","","","9130","9140","With recent text-to-image models, anyone can generate deceptively realistic images with arbitrary contents, fueling the growing threat of visual disinformation. A key enabler for generating high-resolution images with low com-putational cost has been the development of latent diffusion models (LDMs). In contrast to conventional diffusion models, LDMs perform the denoising process in the low-dimensional latent space of a pretrained autoencoder (AE) instead of the high-dimensional image space. Despite their relevance, the forensic analysis of LDMs is still in its infancy. In this work we propose AEROBLADE, a novel detection method which exploits an inherent component of LDMs: the AE used to transform images between image and latent space. We find that generated images can be more accurately reconstructed by the AE than real images, allowing for a simple detection approach based on the reconstruction error. Most importantly, our method is easy to imple-ment and does not require any training, yet nearly matches the performance of detectors that rely on extensive training. We empirically demonstrate that AEROBLADE is effective against state-of-the-art LDMs, including Stable Diffusion and Midjourney. Beyond detection, our approach allows for the qualitative analysis of images, which can be leveraged for identifying inpainted regions. We release our code and data at https://github.com/jonasricker/aeroblade.","2575-7075","979-8-3503-5300-6","10.1109/CVPR52733.2024.00872","Deutsche Forschungsgemeinschaft(grant numbers:EXC 2092 CASA - 390781972); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10656214","diffusion models;deepfake detection;latent diffusion models;stable diffusion;autoencoder;fake image detection","Training;Visualization;Forensics;Noise reduction;Text to image;Transforms;Diffusion models","","26","","60","IEEE","16 Sep 2024","16-22 June 2024","16-22 June 2024","IEEE","IEEE Conferences"
"Deepfake Video Authentication Based on Blockchain","U. Patil; P. M. Chouragade","Department of Computer Science and Engineering, Government College of Engineering, Amravati, Amravati, India; Department of Computer Science and Engineering, Government College of Engineering, Amravati, Amravati, India",2021 Second International Conference on Electronics and Sustainable Communication Systems (ICESC),"23 Sep 2021","2021","","","1110","1113","Nowadays, it is difficult to predict the information such as news and videos on the internet is real or not and people are increasingly sharing it on social media without thinking of fake. As soon as they verify the authenticity of a video, they start expressing their concerns and sharing the opinions of others. Therefore, such videos spread rapidly and help in sharing fake videos or unverified information. The need today is to focus on building a strong fake video detection system as soon as possible to avoid the consequences of such unverified information. This paper analyzes the recent research articles to detect the deep fake videos on social media.","","978-1-6654-2867-5","10.1109/ICESC51422.2021.9532725","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9532725","Blockchain;Deepfake Video;Fake Video;Fake Video Detection System;Video Authentication;Video Integrity;Video Tampering","Deep learning;Social networking (online);Communication systems;Buildings;Authentication;Blockchains;Reliability","","6","","17","IEEE","23 Sep 2021","4-6 Aug. 2021","4-6 Aug. 2021","IEEE","IEEE Conferences"
"AVSecure: An Audio-Visual Watermarking Framework for Proactive Deepfake Detection","B. Guo; H. Tai; G. Luo; Y. Zhu","School of Electronic and Computer Engineering, Shenzhen Graduate School Peking University, Shenzhen, China; School of Electronic and Computer Engineering, Shenzhen Graduate School Peking University, Shenzhen, China; School of Electronic and Computer Engineering, Shenzhen Graduate School Peking University, Shenzhen, China; School of Electronic and Computer Engineering, Shenzhen Graduate School Peking University, Shenzhen, China",2024 IEEE 14th International Conference on Electronics Information and Emergency Communication (ICEIEC),"20 Jun 2024","2024","","","1","4","The rise of Deepfake technology presents a significant challenge to the integrity of information. Most existing Deepfake detection methods rely on visual artifacts to distinguish between the authentic and manipulated content, but they are unable to cope with unseen tampering method and easily affected by post-processing. Although recent investigations have tried to proactively protect facial images using deep watermarking techniques, more deceptive Deepfakes often incorporate both visual and audio modalities. To address this issue, we propose a novel proactive Deepfake detection framework for both audio and visual modalities by utilizing a unified encoder-decoder architecture to embed audio-visual watermarks. Also, an audiovisual feature encoder is developed to align the audio and visual information. The multi-modal watermarking is designed to embed a watermark as the detection clue in each modality respectively and conduct verification of both modalities together to detect Deepfaked multimedia. By adding a distortion layer between embedding and extracting during training, the embedded watermark is able to be robust against common post-processing operations (e.g., JPEG compression) while remaining sensitive to Deepfake manipulations (e.g., SimSwap) in the water-mark verification. Our experimental results on VidTIMIT have demonstrated that the proposed watermarking framework can effectively detect various advanced Deepfake manipulations and achieve good robustness to different kinds of common distortions compared with passive uni-modal and multi-modal Deepfake detection methods.","2377-844X","979-8-3503-6189-6","10.1109/ICEIEC61773.2024.10561738","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10561738","Deepfake Detection;Watermarking;Multi-modal","Training;Deepfakes;Visualization;Ecosystems;Transform coding;Watermarking;Feature extraction","","1","","18","IEEE","20 Jun 2024","24-25 May 2024","24-25 May 2024","IEEE","IEEE Conferences"
"Face Forgery Detection Algorithm Based on Improved MobileViT Network","T. Wang; X. Lu","School of Information Engineering, Inner Mongolia University of Science and Technology, Baotou, China; School of Information Engineering, Inner Mongolia University of Science and Technology, Baotou, China",2023 8th International Conference on Intelligent Computing and Signal Processing (ICSP),"19 Sep 2023","2023","","","1396","1400","DeepFakes blur the boundaries between reality and forgery, resulting in the collapse of exiting credit system, causing immeasurable consequences for national security and social order. Through analysis of existing face forgery techniques, it is found that most generation techniques rely on random noise distribution, and global information will be lost after up sampling. Therefore, we propose a deepfake detection algorithm based on improved MobileViT, which uses CNN local space biasing and the global space representation of the Transformer network to learn the local features and global representation of forged faces, respectively. Coordinate attention is introduced to obtain directional perception and position sensitive information, making the model locate synthetic traces of fake faces better and fusion local and global representation more effectively. For the improved generalization of the model, with the GELU activation function to solve the problem of neuron death. Our model achieved 96.2% on FF++(C23) datasets, and 93.7%,94.1%,96.3%,87.9% on DF, F2F, FS, and NT datasets, respectively. Comparing with previous methods, our model has shown detection robustness and better generalization.","","979-8-3503-0245-5","10.1109/ICSP58490.2023.10248802","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10248802","Deepfake Detection;MobileViT;Coordinate Attention;GELU","Deepfakes;Computational modeling;Neurons;Signal processing;Transformers;Forgery;Robustness","","5","","20","IEEE","19 Sep 2023","21-23 April 2023","21-23 April 2023","IEEE","IEEE Conferences"
"Face forgery detection with a fused attention mechanism","J. Wang; Y. Qi; J. Hu; J. Hu","Northwest Normal University, Lanzhou City, Gansu Province, China; Northwest Normal University, Lanzhou City, Gansu Province, China; Northwest Normal University, Lanzhou City, Gansu Province, China; Northwest Normal University, Lanzhou City, Gansu Province, China","2022 3rd International Conference on Computer Vision, Image and Deep Learning & International Conference on Computer Engineering and Applications (CVIDL & ICCEA)","18 Jul 2022","2022","","","722","725","In recent years, the technology of forged faces has become more and more sophisticated, and the human eye cannot even distinguish these forged products. The fake face images or videos generated by this series of technologies are widely disseminated on the Internet, causing a serious impact on society, thus drawing attention to DeepFake detection, and more research is also inclined to this, but The current research has the problem that the extracted artifact features are relatively single, which leads to the relatively low performance of the artifact detection algorithm. To solve the limitations of the existing methods, the DeepFake detection method fused with attention mechanism is proposed, which extracts the global and local features of the face respectively. Artifact features are found in multiple regions of the face. The method is trained on the FaceForensics++ dataset, and the detection accuracy is improved in different network structures.","","978-1-6654-5911-2","10.1109/CVIDLICCEA56201.2022.9824499","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9824499","DeepFake Detection;attention mechanism;feature fusion","Deepfakes;Privacy;Focusing;Feature extraction;Forgery;Internet;Security","","6","","23","IEEE","18 Jul 2022","20-22 May 2022","20-22 May 2022","IEEE","IEEE Conferences"
"FairSSD: Understanding Bias in Synthetic Speech Detectors","A. K. Singh Yadav; K. Bhagtani; D. Salvi; P. Bestagini; E. J. Delp","Video and Image Processing Lab (VIPER), Purdue University, West Lafayette, Indiana, USA; Video and Image Processing Lab (VIPER), Purdue University, West Lafayette, Indiana, USA; Dipartimento di Elettronica, Informazione e Bioingegneria, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Milano, Italy; Video and Image Processing Lab (VIPER), Purdue University, West Lafayette, Indiana, USA",2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW),"27 Sep 2024","2024","","","4418","4428","Methods that can generate synthetic speech which is perceptually indistinguishable from speech recorded by a human speaker, are easily available. Several incidents report misuse of synthetic speech generated from these methods to commit fraud. To counter such misuse, many methods have been proposed to detect synthetic speech. Some of these detectors are more interpretable, can generalize to detect synthetic speech in the wild and are robust to noise. However, limited work has been done on understanding bias in these detectors. In this work, we examine bias in existing synthetic speech detectors to determine if they will unfairly target a particular gender, age and accent group. We also inspect whether these detectors will have a higher misclassification rate for bona fide speech from speech-impaired speakers w.r.t fluent speakers. Extensive experiments on 6 existing synthetic speech detectors using more than 0.9 million speech signals demonstrate that most detectors are gender, age and accent biased, and future work is needed to ensure fairness. To support future research, we release our evaluation dataset, models used in our study and source code at https://gitlab.com/viper-purdue/fairssd.","2160-7516","979-8-3503-6547-4","10.1109/CVPRW63382.2024.00445","Air Force Research Laboratory; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10677928","Deepfake Detection;AntiSpoofing;Media Forensics;Fairness;Bias Study;Synthetic Speech Detectors","Computer vision;Source coding;Conferences;Noise;Detectors;Pattern recognition;Fraud","","4","","75","IEEE","27 Sep 2024","17-18 June 2024","17-18 June 2024","IEEE","IEEE Conferences"
"A Robust Audio Deepfake Detection System via Multi-View Feature","Y. Yang; H. Qin; H. Zhou; C. Wang; T. Guo; K. Han; Y. Wang",Huawei Noah’s Ark Lab; Huawei Noah’s Ark Lab; Huawei Noah’s Ark Lab; Huawei Noah’s Ark Lab; Huawei Noah’s Ark Lab; Huawei Noah’s Ark Lab; Huawei Noah’s Ark Lab,"ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","18 Mar 2024","2024","","","13131","13135","With the advancement of generative modeling techniques, synthetic human speech becomes increasingly indistinguishable from real, and tricky challenges are elicited for the audio deepfake detection (ADD) system. In this paper, we exploit audio features to improve the generalizability of ADD systems. Investigation of the ADD task performance is conducted over a broad range of audio features, including various handcrafted features and learning-based features. Experiments show that learning-based audio features pretrained on a large amount of data generalize better than hand-crafted features on out-of-domain scenarios. Subsequently, we further improve the generalizability of the ADD system using proposed multi-feature approaches to incorporate complimentary information from features of different views. The model trained on ASV2019 data achieves an equal error rate of 24.27% on the In-the-Wild dataset. The code will be released as soon 1.","2379-190X","979-8-3503-4485-1","10.1109/ICASSP48485.2024.10446560","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10446560","Audio deepfake detection;anti-spoofing;feature incorporation","Deepfakes;Analytical models;Speech coding;Error analysis;Speech recognition;Signal processing;Feature extraction","","30","","20","IEEE","18 Mar 2024","14-19 April 2024","14-19 April 2024","IEEE","IEEE Conferences"
"A Dual-Branch CNN for Robust Detection of AI-Generated Facial Forgeries","X. Zhang; Y. Song; F. Zuo","Computer Science Department, University of Southern Maine, Portland, United States; Computer Science Department, University of Southern Maine, Portland, United States; The Department of Computer Science, University of Central Oklahoma, Edmond, United States",2025 IEEE 12th International Conference on Cyber Security and Cloud Computing (CSCloud),"2 Dec 2025","2025","","","1","6","The rapid advancement of generative AI has enabled the creation of highly realistic forged facial images, posing significant threats to AI security, digital media integrity, and public trust. Face forgery techniques-ranging from face swapping and attribute editing to powerful diffusion-based image synthesis-are increasingly being used for malicious purposes such as misinformation, identity fraud, and defamation. This growing challenge underscores the urgent need for robust and generalizable face forgery detection methods as a critical component of AI security infrastructure. In this work, we propose a novel dual-branch convolutional neural network for face forgery detection that leverages complementary cues from both spatial and frequency domains. The RGB branch captures semantic information, while the frequency branch focuses on high-frequency artifacts that are difficult for generative models to suppress. A channel attention module is introduced to adaptively fuse these heterogeneous features, highlighting the most informative channels for forgery discrimination. To guide the network's learning process, we design a unified loss function-FSC Loss-that combines focal loss, supervised contrastive loss, and a frequency center margin loss to enhance class separability and robustness. We evaluate our model on the DiFF benchmark, which includes forged images generated from four representative methods: text-to-image, image-to-image, face swap, and face edit. Our method achieves strong performance across all categories and outperforms average human accuracy. These results demonstrate the model's effectiveness and its potential contribution to safeguarding AI ecosystems against visual forgery attacks.","2693-8928","979-8-3315-8781-9","10.1109/CSCloud66326.2025.00023","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11261496","AI Security;Multimedia Forensics;Computer Vision;Face Forgery Detection;Deepfake Detection","Visualization;Adaptation models;Biological system modeling;Semantics;Text to image;Forgery;Robustness;Security;Convolutional neural networks;Faces","","","","30","IEEE","2 Dec 2025","7-9 Nov. 2025","7-9 Nov. 2025","IEEE","IEEE Conferences"
"Leveraging Deep Learning Methods for Detecting Deepfake Speeches","R. A. Samiha; M. T. Alom; R. Hossain; R. Islam; A. Sultana","Dept. of Computer Science & Eng., World University of Bangladesh, Dhaka, Bangladesh; Dept. of Computer Science & Eng., World University of Bangladesh, Dhaka, Bangladesh; Dept. of Computer Science & Eng., World University of Bangladesh, Dhaka, Bangladesh; Dept. of Software Eng., Daffodil International University, Dhaka, Bangladesh; School of Computer Science & Technology, Algoma University, Brampton, ON, Canada",2025 IEEE 4th International Conference on Computing and Machine Intelligence (ICMI),"8 Sep 2025","2025","","","1","5","Synthetic speeches, infamously known as Audio Deepfakes (AD), can easily become a menacing tool if they fall into the wrong hands. Moreover, social networks, which are highly vulnerable to deepfake attacks, can potentially cause social chaos. In order to tackle any potential harm, the misuse of deepfakes needs to be prevented. Especially for deepfake audio, detection methods are crucial to tackling the spread of deepfake speeches. In this study, we proposed a deep learning (DL) framework, the Convolutional Neural Network (CNN), to detect deepfake Bengali speeches. Through this study, we contributed to the resolution of certain research gaps, such as the limited number of dedicated researches and the scarcity of Bengali audio datasets comprising the Bengali domain in this field. The proposed model was applied on a set of primary self-created Bengali audio data. As a result, the CNN framework achieved the highest score of 98.24%, compared to a one-dimensional representation foundational CNN model.","","979-8-3315-0913-2","10.1109/ICMI65310.2025.11141035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11141035","deepfake;audio classification;artificial intelligence;deep learning;synthetic speech;deepfake detection","Deep learning;Training;Deepfakes;Accuracy;Recurrent neural networks;Social networking (online);Computer architecture;Feature extraction;Convolutional neural networks;Speech synthesis","","","","15","IEEE","8 Sep 2025","5-6 April 2025","5-6 April 2025","IEEE","IEEE Conferences"
"A Novel Multi-Scale Spectral-Guided Graph Attention Network for DeepFake Video Detection","M. Irfan; M. J. Lee; A. Neyaz; D. Nobayashi","Department of Electrical Engineering, City College of New York, New York, NY, USA; Department of Electrical Engineering, City College of New York, New York, NY, USA; School of Computing and Data Science, Wentworth Institute of Technology, Boston, MA, USA; Department of Electrical and Electronic Engineering, Kyushu Institute of Technology, Fukuoka, Japan",2025 13th International Symposium on Digital Forensics and Security (ISDFS),"2 Jun 2025","2025","","","1","7","The rapid advancement of deepfake technology presents significant challenges for video authenticity verification, necessitating robust detection mechanisms. This paper introduces a novel framework for deepfake video detection that integrates the Multi-Scale Spectral-Guided Graph Attention Network (MSG-GAT) with the Lightweight Assimilation-Elimination (Lite-ASEL) algorithm. By representing video frames as graphs, the framework effectively captures intricate pixel relationships, enabling the detection of subtle manipulations with enhanced precision. Additionally, the Lite-ASEL algorithm is employed for feature selection, balancing reduced computational complexity with high detection performance. Experimental results demonstrate the superiority of the proposed framework, achieving state-of-the-art performance with an AUC of 99.1 % and a detection accuracy of 99.3%. Furthermore, hyperparameter tuning confirms the framework's robustness and efficiency, consistently achieving an optimal objective score of 98.54%, validating its effectiveness for optimal feature selection and deepfake detection.","2768-1831","979-8-3315-0993-4","10.1109/ISDFS65363.2025.11011972","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11011972","Graph Neural Network;Convolutional Neural Network;Content Manipulation;Deepfake Video Detection;Feature Selection","Deepfakes;Accuracy;Scalability;Image edge detection;Feature extraction;Robustness;Graph neural networks;Synchronization;Security;Tuning","","1","","24","IEEE","2 Jun 2025","24-25 April 2025","24-25 April 2025","IEEE","IEEE Conferences"
"Deepfake Voice Detection: Countering Deepfake Audio with Deep Learning Architectures","K. K. Ko; S. Wai Wai Tun; M. T. Kyaw; T. Thet Zin","University of Information Technology, Yangon, Myanmar; University of Information Technology, Yangon, Myanmar; University of Information Technology, Yangon, Myanmar; Faculty of Computer Science, University of Information Technology, Yangon, Myanmar",2025 6th International Conference on Advanced Information Technologies (ICAIT),"18 Nov 2025","2025","","","1","6","The active development of the Text-to-Speech (TTS) technology as well as the Voice Conversion (VC) has posed an outstanding danger to the digital security. To overcome this obstacle, this paper will compare and contrast systematically three different deep learning structures, a hybrid CNN-RNN framework that aims to conduct both spectral and temporal artifact processing, a CNN-LSTM ensemble framework exploring the distinctive capabilities of the spatial and temporal processing, and a state-of-the-art system with Wav2Vec2 as a pre-trained feature extractor and as a Light Convolutional Neural Network (LCNN) to make predictions. Although all these architectures operate on the basis of known elements, they are new in the way that they specifically aim at deepfake detection and also they are assessed and evaluated in an unprecedented way in parallel. With experiments on a wide variety of benchmark datasets, such as ASVspoof 2019, WaveFake and FoR, this paper compares the trade-offs between feature-engineered and self-supervised methods. As the results show, CNN + LSTM-based platform can deliver better results, its analysis accuracy is 99.81, because it is able to get deep, context-sensitive representations of unprocessed audio. The present study highlights the symbiosis of organizing various deep learning techniques and establishes a complete reference in future studies in resilient equipment of deepfake voice detecting.","","979-8-3315-7272-3","10.1109/ICAIT68809.2025.11236771","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11236771","Deepfake;Voice Detection;Wav2Vec2;CNN-RNN;Ensemble Learning","Deep learning;Deepfakes;Accuracy;Computational modeling;Computer architecture;Feature extraction;Transformers;Data models;Convolutional neural networks;Security","","1","","21","IEEE","18 Nov 2025","3-3 Nov. 2025","3-3 Nov. 2025","IEEE","IEEE Conferences"
"GC-ConsFlow: Leveraging Optical Flow Residuals and Global Context for Robust Deepfake Detection","J. Chen; M. Hu; D. Zhang; J. Meng","School of Computer Science and Technology, Changsha University of Science and Technology, Changsha, China; School of Computer Science and Technology, Changsha University of Science and Technology, Changsha, China; School of Computer Science and Technology, Changsha University of Science and Technology, Changsha, China; School of Computer Science and Technology, Changsha University of Science and Technology, Changsha, China",2025 IEEE International Conference on Multimedia and Expo (ICME),"30 Oct 2025","2025","","","1","6","The rapid development of Deepfake technology has enabled the generation of highly realistic manipulated videos, posing severe social and ethical challenges. Existing Deepfake detection methods primarily focused on either spatial or temporal inconsistencies, often neglecting the interplay between the two or suffering from interference caused by natural facial motions. To address these challenges, we propose the global context consistency flow (GC-ConsFlow), a novel dual-stream framework that effectively integrates spatial and temporal features for robust Deepfake detection. The global grouped context aggregation module (GGCA), integrated into the global context-aware frame flow stream (GCAF), enhances spatial feature extraction by aggregating grouped global context information, enabling the detection of subtle, spatial artifacts within frames. The flow-gradient temporal consistency stream (FGTC), rather than directly modeling the residuals, it is used to improve the robustness of temporal feature extraction against the inconsistency introduced by unnatural facial motion using optical flow residuals and gradient-based features. By combining these two streams, GC-ConsFlow demonstrates the effectiveness and robustness in capturing complementary spatiotemporal forgery traces. Extensive experiments show that GC-ConsFlow outperforms existing state-of-the-art methods in detecting Deepfake videos under various compression scenarios.","1945-788X","979-8-3315-9495-4","10.1109/ICME59968.2025.11209351","National Natural Science Foundation of China; Research and Development; Natural Science Foundation of Hunan Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11209351","Deepfake Detection;Spatiotemporal Features;Optical Flow Residuals;Global Context Analysis","Deepfakes;Ethics;Noise;Interference;Feature extraction;Robustness;Forgery;Spatiotemporal phenomena;Optical flow;Context modeling","","1","","21","IEEE","30 Oct 2025","30 June-4 July 2025","30 June-4 July 2025","IEEE","IEEE Conferences"
"Hybrid CNN–Transformer Ensemble for Robust Deepfake Video Detection","K. Saksham; A. Agrawal","Indian Institute of Information Technology Allahabad, Prayagraj, Uttar Pradesh, India; Indian Institute of Information Technology Allahabad, Prayagraj, Uttar Pradesh, India",2025 IEEE 6th India Council International Subsections Conference (INDISCON),"2 Dec 2025","2025","","","1","6","The advent of deepfake videos, driven by generative models like GANs, poses an increasingly formidable threat to media integrity and digital security. These manipulations can be detected using models capable of identifying local visual artifacts as well as contextual inconsistencies at a larger scale. In this paper, we introduce a two-level ensemble model based on Convolutional Neural Networks and Vision Transformers to effectively process spatial and temporal patterns in video data. The system proposed here performs $98.97 \%$ on the AVLips dataset and 95.19% on DFDC, showing robust performance across datasets with different compression and manipulation levels. By combining the complementary strengths of CNNs and Transformers, the ensemble enhances reliability and generalization across different conditions. This work is part of building reliable deepfake detection tools for practical use in media verification and forensic analysis.","","979-8-3315-1504-1","10.1109/INDISCON66021.2025.11251858","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11251858","Deepfake Detection;Ensemble Learning;Convolutional Neural Networks (CNNs);Vision Transformers (ViT;CvT);Transfer Learning;Xception Network;Temporal and Spatial Features;ResNet;Cross-Dataset Generalization;Video Forensics","Deepfakes;Computer vision;Visualization;Forensics;Transfer learning;Media;Video compression;Transformers;Convolutional neural networks;Ensemble learning","","","","18","IEEE","2 Dec 2025","21-23 Aug. 2025","21-23 Aug. 2025","IEEE","IEEE Conferences"
"Improving Generalization in Facial Manipulation Detection Using Image Noise Residuals and Temporal Features","M. Atamna; I. Tkachenko; S. Miguet","CNRS, INSA Lyon, UCBL, Centrale Lyon, LIRIS, UMR5205, Univ Lyon, Univ Lyon 2, Bron, France; CNRS, INSA Lyon, UCBL, Centrale Lyon, LIRIS, UMR5205, Univ Lyon, Univ Lyon 2, Bron, France; CNRS, INSA Lyon, UCBL, Centrale Lyon, LIRIS, UMR5205, Univ Lyon, Univ Lyon 2, Bron, France",2023 IEEE International Conference on Image Processing (ICIP),"11 Sep 2023","2023","","","3424","3428","The high visual quality of modern deepfakes raises significant concerns about the trustworthiness of digital media and makes facial tampering detection more challenging. Although current deep learning-based deepfake detectors achieve excellent results when tested on deepfake images or image sequences generated using known methods, generalization—where a trained model is tasked with detecting deepfakes created with previously unseen manipulation techniques—is still a major challenge. In this paper, we investigate the impact of training spatial and spatio-temporal deep learning network architectures in the image noise residual domain using spatial rich model (SRM) filters on generalization performance. To this end, we conduct a series of tests on the manipulation methods of the FaceForensics++, DeeperForensics-1.0 and Celeb-DF datasets, demonstrating the value of image noise residuals and temporal feature exploitation in tackling the generalization task.","","978-1-7281-9835-4","10.1109/ICIP49359.2023.10222043","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10222043","Deepfake detection;video manipulation detection;image forensics;steganalysis features","Training;Deep learning;Deepfakes;Visualization;Sensitivity;Video compression;Feature extraction","","5","","19","IEEE","11 Sep 2023","8-11 Oct. 2023","8-11 Oct. 2023","IEEE","IEEE Conferences"
"Anomaly Detection and Localization for Speech Deepfakes via Feature Pyramid Matching","E. Coletta; D. Salvi; V. Negroni; D. U. Leonzio; P. Bestagini","Dipartimento di Elettronica, Informazione e Bioingegneria (DEIB), Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria (DEIB), Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria (DEIB), Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria (DEIB), Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria (DEIB), Politecnico di Milano, Milano, Italy",2025 33rd European Signal Processing Conference (EUSIPCO),"17 Nov 2025","2025","","","820","824","The rise of AI-driven generative models has enabled the creation of highly realistic speech deepfakes-synthetic audio signals that can imitate target speakers' voices-raising critical security concerns. Existing methods for detecting speech deepfakes primarily rely on supervised learning, which suffers from two critical limitations: limited generalization to unseen synthesis techniques and a lack of explainability. In this paper, we address these issues by introducing a novel interpretable one-class detection framework, which reframes speech deepfake detection as an anomaly detection task. Our model is trained exclusively on real speech to characterize its distribution, enabling the classification of out-of-distribution samples as synthetically generated. Additionally, our framework produces interpretable anomaly maps during inference, highlighting anomalous regions across both time and frequency domains. This is done through a Student-Teacher Feature Pyramid Matching system, enhanced with Discrepancy Scaling to improve generalization capabilities across unseen data distributions. Extensive evaluations demonstrate the superior performance of our approach compared to the considered baselines, validating the effectiveness of framing speech deepfake detection as an anomaly detection problem.","","978-9-4645-9362-4","10.23919/EUSIPCO63237.2025.11226156","Italian Ministry of Education, University, and Research; European Union(grant numbers:CUP D43C22003080001,PE00000001,CUP D43C22003050001,PE00000014); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11226156","Multimedia Forensics;Audio Forensics;Speech Deepfake;Explainability;Anomaly Detection","Location awareness;Deepfakes;Time-frequency analysis;Forensics;Supervised learning;Statistical distributions;Signal processing;Security;Speech processing;Anomaly detection","","","","30","","17 Nov 2025","8-12 Sept. 2025","8-12 Sept. 2025","IEEE","IEEE Conferences"
"Preserving Visual Authenticity: Block chain-Augmented AI Frameworks for Advanced Digital Deception Recognition and Mitigation","M. Priya; J. Murugesan; P. Bhuvaneswari; M. Rubigha; S. Lalithambikai; B. Mohanraj","Department of Information Technology, Knowledge Institute of Technology, Salem, India; Department of Information Technology, Knowledge Institute of Technology, Salem, India; Department of Computer Science and Engineering, Sona College of Technology, Salem, India; Department of Information Technology, Knowledge Institute of Technology, Salem, India; Department of Information Technology, Knowledge Institute of Technology, Salem, India; Department of Information Technology, Sona College of Technology, Salem, India",2024 5th International Conference on Smart Electronics and Communication (ICOSEC),"24 Oct 2024","2024","","","707","713","The rapid advancements in deep learning have given rise to sophisticated DeepFake technologies, posing significant threats to visual integrity and authenticity in digital media. This paper presents an innovative approach to DeepFake detection and mitigation by integrating blockchain technology with artificial intelligence frameworks. The proposed Blockchain-Augmented AI (BAAI) framework utilizes the immutability and decentralized nature of block chain to enhance the security and reliability of the detection process. Our method involves the development of advanced AI models for detecting DeepFakes, which are then integrated with a blockchain-based ledger to ensure the verifiability and traceability of detection results. In this proposed work, a novel integration of blockchain technology and AI designed to enhance DeepFake detection capabilities. The framework achieves a $97 \%$ accuracy rate, ensuring reliable identification of manipulated media, while maintaining a low false positive rate of 3%. These results highlight the BAAI framework’s effectiveness in minimizing erroneous detections and its robustness in safeguarding digital visual content. In the face of increasingly sophisticated DeepFake technologies, this framework offers a crucial advancement in combating digital deception.","","979-8-3315-0440-3","10.1109/ICOSEC61587.2024.10722740","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10722740","DeepFake Detection;Visual Integrity;Blockchain-Augmented AI (BAAI);Detection Accuracy;False Positives;Detection Precision;Media Authenticity","Deep learning;Deepfakes;Visualization;Prevention and mitigation;Face recognition;Media;Robustness;Blockchains;Security;Artificial intelligence","","2","","20","IEEE","24 Oct 2024","18-20 Sept. 2024","18-20 Sept. 2024","IEEE","IEEE Conferences"
"RLGC: Reconstruction Learning Fusing Gradient and Content Features for Efficient Deepfake Detection","K. Xu; X. Hu; X. Zhou; X. Xu; L. Qi; C. Chen","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; Faculty of Business Data Science, Kansai University, Osaka, Japan; School of Computer and Software, Nanjing University of Information Science and Technology, Nanjing, China; College of Computer Science and Technology, China University of Petroleum (East China), Qingdao, China; State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China",IEEE Transactions on Consumer Electronics,"13 Dec 2024","2024","70","3","6084","6094","Current deepfake detection methods, which utilize noise features, localized textures, or frequency statistics, may perform well in special domains or forgery methods. But the generalization performance of these methods is often unsatisfactory because of the ignorance of mining intrinsic facial features. To address this problem, we re-evaluated the fusion of image gradient features in neural networks and delved deeper into the intrinsic structure of input images. Consequently, we propose a reconstruction-classification network that initially learns face content and gradient separately from a reconstruction perspective and then detects forged faces by fusing them together. This paper introduces three well-designed components: 1) a dual-branch feature extraction module to excite distributional inconsistencies between real and forged faces; 2) a content-gradient feature fusion module to investigate the relationship between face content and image gradient; 3) a reconstruction disparity based Bi-Directional attention module that guides the model in efficiently categorizing the fused features. Extensive experiments on large-scale benchmark datasets demonstrate that our method significantly enhances performance, especially for generalization ability, compared to state-of-the-art methods.","1558-4127","","10.1109/TCE.2024.3435032","National Natural Science Foundation of China(grant numbers:62172227); National Key Research and Development Program(grant numbers:2021YFF0602101); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10612835","Deepfake detection;deep generative model;multi-scale feature fusion;reconstruction learning","Image reconstruction;Feature extraction;Forgery;Faces;Face recognition;Deepfakes;Generative adversarial networks","","11","","58","IEEE","29 Jul 2024","Aug. 2024","","IEEE","IEEE Journals"
"ISTVT: Interpretable Spatial-Temporal Video Transformer for Deepfake Detection","C. Zhao; C. Wang; G. Hu; H. Chen; C. Liu; J. Tang","Department of Computer Science and Technology, Tongji University, Shanghai, China; Department of Computer Science and Technology, Tongji University, Shanghai, China; Oosto, Belfast, U.K; Alibaba Group, Hangzhou, China; College of Surveying and Geo-Informatics, Tongji University, Shanghai, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China",IEEE Transactions on Information Forensics and Security,"1 Feb 2023","2023","18","","1335","1348","With the rapid development of Deepfake synthesis technology, our information security and personal privacy have been severely threatened in recent years. To achieve a robust Deepfake detection, researchers attempt to exploit the joint spatial-temporal information in the videos, like using recurrent networks and 3D convolutional networks. However, these spatial-temporal models remain room to improve. Another general challenge for spatial-temporal models is that people do not clearly understand what these spatial-temporal models really learn. To address these two challenges, in this paper, we propose an Interpretable Spatial-Temporal Video Transformer (ISTVT), which consists of a novel decomposed spatial-temporal self-attention and a self-subtract mechanism to capture spatial artifacts and temporal inconsistency for robust Deepfake detection. Thanks to this decomposition, we propose to interpret ISTVT by visualizing the discriminative regions for both spatial and temporal dimensions via the relevance (the pixel-wise importance on the input) propagation algorithm. We conduct extensive experiments on large-scale datasets, including FaceForensics++, FaceShifter, DeeperForensics, Celeb-DF, and DFDC datasets. Our strong performance of intra-dataset and cross-dataset Deepfake detection demonstrates the effectiveness and robustness of our method, and our visualization-based interpretability offers people insights into our model.","1556-6021","","10.1109/TIFS.2023.3239223","National Natural Science Fund of China(grant numbers:62076184,61976158,61976160,62076182); Shanghai Innovation Action Project of Science and Technology(grant numbers:20511100700); Shanghai Natural Science Foundation(grant numbers:22ZR1466700); Fundamental Research Funds for the Central Universities and the State Key Laboratory of Integrated Services Networks, Xidian University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10024806","Deepfake detection;video transformer;deep learning interpretability","Deepfakes;Transformers;Visualization;Task analysis;Electronic mail;Shape;Robustness","","111","","59","IEEE","23 Jan 2023","2023","","IEEE","IEEE Journals"
"Masked Relation Learning for DeepFake Detection","Z. Yang; J. Liang; Y. Xu; X. -Y. Zhang; R. He","Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Center for Research on Intelligent Perception and Computing, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Center for Research on Intelligent Perception and Computing, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Center for Research on Intelligent Perception and Computing, Institute of Automation, Chinese Academy of Sciences, Beijing, China",IEEE Transactions on Information Forensics and Security,"6 Mar 2023","2023","18","","1696","1708","DeepFake detection aims to differentiate falsified faces from real ones. Most approaches formulate it as a binary classification problem by solely mining the local artifacts and inconsistencies of face forgery, which neglect the relation across local regions. Although several recent works explore local relation learning for DeepFake detection, they overlook the propagation of relational information and lead to limited performance gains. To address these issues, this paper provides a new perspective by formulating DeepFake detection as a graph classification problem, in which each facial region corresponds to a vertex. But relational information with large redundancy hinders the expressiveness of graphs. Inspired by the success of masked modeling, we propose Masked Relation Learning which decreases the redundancy to learn informative relational features. Specifically, a spatiotemporal attention module is exploited to learn the attention features of multiple facial regions. A relation learning module masks partial correlations between regions to reduce redundancy and then propagates the relational information across regions to capture the irregularity from a global view of the graph. We empirically discover that a moderate masking rate (e.g., 50%) brings the best performance gain. Experiments verify the effectiveness of Masked Relation Learning and demonstrate that our approach outperforms the state of the art by 2% AUC on the cross-dataset DeepFake video detection. Code will be available at https://github.com/zimyang/MaskRelation.","1556-6021","","10.1109/TIFS.2023.3249566","National Natural Science Foundation of China(grant numbers:U2003111,U21B2045,62276256); Beijing Nova Program(grant numbers:Z211100002121108); Chinese Association for Artificial Intelligence (CAAI)-Huawei MindSpore Open Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10054130","Multimedia forensics;DeepFake detection;masked learning;relation feature","Deepfakes;Faces;Feature extraction;Forgery;Image edge detection;Correlation;Visualization","","93","","94","IEEE","27 Feb 2023","2023","","IEEE","IEEE Journals"
"Deepfake Forensics Leveraging MobileNetV2 for High Precision Detection","P. Singh; S. Sasikumar; R. S. Geddam; K. Tharun; M. Kavitha; T. Bhuvaneswari","Dept. of Electronics and Communication Engineering, Hindustan Institute of Technology & Science, Chennai, India; Dept. of Electronics and Communication Engineering, Rajalakshmi Institute of Technolog, Chennai, India; Dept. of Electronics and Communication Engineering, Hindustan Institute of Technology & Science, Chennai, India; Dept. of Electronics and Communication Engineering, Hindustan Institute of Technology & Science, Chennai, India; Dept. of Electronics and Communication Engineering, Hindustan Institute of Technology & Science, Chennai, India; Faculty of Engineering and Technology, Multimedia University, Melaka, Malaysia",2025 Multimedia University Engineering Conference (MECON),"10 Dec 2025","2025","","","1","6","This Deepfake technology has emerged as a powerful tool for generating synthetic media, leveraging advancements in artificial intelligence and deep learning to create highly realistic fake images and videos. While deepfakes offer potential benefits in fields such as entertainment, media production, and virtual reality, they also present serious threats, including misinformation, identity fraud, and privacy violations. The ability to detect deepfake content accurately and efficiently is critical in safeguarding digital authenticity and preventing misuse. This research focuses on the development of deepfake detection models using Convolutional Neural Networks (CNNs) and MobileNetV2. Three primary detection methods— handcrafted feature analysis, machine learning-based classification, and artifact detection—were implemented and evaluated. A dataset consisting of 20,000 images, equally split between real and fake, was used for model training and testing, and optimized using dropout regularization, learning rate tuning, and early stopping. The CNN model achieved an accuracy of 90%, while an optimized MobileNetV2 Subtraction model improved detection accuracy to 97% by reducing overfitting and refining hyperparameters. The study underscores the importance of robust deepfake detection frameworks, particularly in an era where manipulated content is becoming increasingly difficult to differentiate from real media. Future enhancements will explore real-time detection solutions and adversarial training techniques to further improve detection accuracy and resilience.","","979-8-3315-5549-8","10.1109/MECON67253.2025.11277038","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11277038","Deepfake detection;Convolutional Neural Networks (CNN);MobileNetV2;artificial intelligence;misinformation","Training;Deep learning;Deepfakes;Solid modeling;Accuracy;Computational modeling;Feature extraction;Real-time systems;Convolutional neural networks;Testing","","","","20","IEEE","10 Dec 2025","21-23 July 2025","21-23 July 2025","IEEE","IEEE Conferences"
"Beyond Deepfake Images: Detecting AI-Generated Videos","D. S. Vahdati; T. D. Nguyen; A. Azizpour; M. C. Stamm","Drexel University, Philadelphia, PA, USA; Drexel University, Philadelphia, PA, USA; Drexel University, Philadelphia, PA, USA; Drexel University, Philadelphia, PA, USA",2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW),"27 Sep 2024","2024","","","4397","4408","Recent advances in generative AI have led to the development of techniques to generate visually realistic synthetic video. While a number of techniques have been developed to detect AI-generated synthetic images, in this paper we show that synthetic image detectors are unable to detect synthetic videos. We demonstrate that this is because synthetic video generators introduce substantially different traces than those left by image generators. Despite this, we show that synthetic video traces can be learned, and used to perform reliable synthetic video detection or generator source attribution even after H.264 re-compression. Furthermore, we demonstrate that while detecting videos from new generators through zero-shot transferability is challenging, accurate detection of videos from a new generator can be achieved through few-shot learning.","2160-7516","979-8-3503-6547-4","10.1109/CVPRW63382.2024.00443","Air Force Research Laboratory; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10678510","Generative AI;Synthetic images;Synthetic Videos;Media Forensics;Deep Neural Networks;Deep Learning;synthetic image detection;synthetic video detection;video forensics;image forensics;Deepfake","Training;Deepfakes;Generative AI;Forensics;Conferences;Detectors;Generators","","7","","98","IEEE","27 Sep 2024","17-18 June 2024","17-18 June 2024","IEEE","IEEE Conferences"
"Deepfake Audio Detection: a Multi Model, Multi Dataset Performance Study Using Deep Learning Architectures","A. Bhardwaj","Dept. of EECE, SSES Sharda University, Greater Noida, India",2025 International Conference on Intelligent Communication Networks and Computational Techniques (ICICNCT),"18 Nov 2025","2025","","","1","6","As AI-generated content rapidly increases, deepfake audio presents a significant risk to digital security and reliability. To address this issue, a hybrid deep learning approach is implemented by integrating convolutional neural networks (CNN) with long short-term memory (LSTM) networks. The framework utilizes both Mel spectrogram and MFCC features to capture intricate spectral and temporal patterns in audio. The model is trained and evaluated on various iterations of a publicly available deepfake audio dataset, which included genuine, normalized, short-length, and re-recorded samples, to guarantee strong performance across different scenarios. The results demonstrate that the CNN+LSTM model reliably exceeds the performance of individual CNN, RNN, LSTM and Transformer models, attaining improved accuracy and reduced error rates. This underscores the advantages of hybrid models in real-world audio forensics and suggests directions for future research focused on enhancing generalization, resilience to noise, and defense against adversarial attacks.","","979-8-3315-8623-2","10.1109/ICICNCT66124.2025.11232782","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11232782","deepfake audio;deep learning;fake speech detection;CNN;RNN;LSTM;transformers","Deep learning;Deepfakes;Accuracy;Error analysis;Transformers;Convolutional neural networks;Reliability;Security;Long short term memory;Spectrogram","","","","15","IEEE","18 Nov 2025","5-6 Sept. 2025","5-6 Sept. 2025","IEEE","IEEE Conferences"
"Robust AI-Synthesized Speech Detection Using Feature Decomposition Learning and Synthesizer Feature Augmentation","K. Zhang; Z. Hua; Y. Zhang; Y. Guo; T. Xiang","School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, Guangdong, China; School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, Guangdong, China; School of Computing and Artificial Intelligence, Jiangxi University of Finance and Economics, Nanchang, Jiangsu, China; Alibaba Group, Hangzhou, Zhejiang, China; College of Computer Science, Chongqing University, Chongqing, China",IEEE Transactions on Information Forensics and Security,"10 Jan 2025","2025","20","","871","885","AI-synthesized speech, also known as deepfake speech, has recently raised significant concerns due to the rapid advancement of speech synthesis and speech conversion techniques. Previous works often rely on distinguishing synthesizer artifacts to identify deepfake speech. However, excessive reliance on these specific synthesizer artifacts may result in unsatisfactory performance when addressing speech signals created by unseen synthesizers. In this paper, we propose a robust deepfake speech detection method that employs feature decomposition to learn synthesizer-independent content features as complementary for detection. Specifically, we propose a dual-stream feature decomposition learning strategy that decomposes the learned speech representation using a synthesizer stream and a content stream. The synthesizer stream specializes in learning synthesizer features through supervised training with synthesizer labels. Meanwhile, the content stream focuses on learning synthesizer-independent content features, enabled by a pseudo-labeling-based supervised learning method. This method randomly transforms speech to generate speed and compression labels for training. Additionally, we employ an adversarial learning technique to reduce the synthesizer-related components in the content stream. The final classification is determined by concatenating the synthesizer and content features. To enhance the model’s robustness to different synthesizer characteristics, we further propose a synthesizer feature augmentation strategy that randomly blends the characteristic styles within real and fake audio features and randomly shuffles the synthesizer features with the content features. This strategy effectively enhances the feature diversity and simulates more feature combinations. Experimental results on four deepfake speech benchmark datasets demonstrate that our model achieves state-of-the-art robust detection performance across various evaluation scenarios, including cross-method, cross-dataset, and cross-language evaluations.","1556-6021","","10.1109/TIFS.2024.3520001","National Key Research and Development Program of China(grant numbers:2022YFB3103500); National Natural Science Foundation of China(grant numbers:62071142); Guangdong Basic and Applied Basic Research Foundation(grant numbers:2024A1515012299); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10806877","Deepfake speech detection;feature decomposition;feature augmentation;robust detection","Synthesizers;Deepfakes;Feature extraction;Voice activity detection;Vocoders;Training;Robustness;Spectrogram;Multitasking;Transformers","","5","","61","IEEE","18 Dec 2024","2025","","IEEE","IEEE Journals"
"Open Challenges in Synthetic Speech Detection","L. Cuccovillo; C. Papastergiopoulos; A. Vafeiadis; A. Yaroshchuk; P. Aichroth; K. Votis; D. Tzovaras","Fraunhofer Institute for Digital Media Technology, Ilmenau, Germany; Centre for Research and Technology Hellas, Thessaloniki, Greece; Centre for Research and Technology Hellas, Thessaloniki, Greece; Fraunhofer Institute for Digital Media Technology, Ilmenau, Germany; Fraunhofer Institute for Digital Media Technology, Ilmenau, Germany; Centre for Research and Technology Hellas, Thessaloniki, Greece; Centre for Research and Technology Hellas, Thessaloniki, Greece",2022 IEEE International Workshop on Information Forensics and Security (WIFS),"14 Dec 2022","2022","","","1","6","In this paper the current status and open challenges of synthetic speech detection are addressed. The work comprises an initial analysis of available open datasets and of existing detection methods, a description of the requirements for new research datasets compliant with regulations and better representing real-case scenarios, and a discussion of the desired characteristics of future trustworthy detection methods in terms of both functional and non-functional requirements. Compared to other works, based on specific detection solutions or presenting single dataset of synthetic speeches, our paper is meant to orient future state-of-the-art research in the domain, to quickly lessen the current gap between synthesis and detection approaches.","2157-4774","979-8-3503-0967-6","10.1109/WIFS55849.2022.9975433","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9975433","deepfake;synthetic speech;spoofing detection","Technical requirements;Forensics;Collaboration;Training data;Solids;Regulation;Recording","","21","","46","IEEE","14 Dec 2022","12-16 Dec. 2022","12-16 Dec. 2022","IEEE","IEEE Conferences"
"Fighting Deepfake by Exposing the Convolutional Traces on Images","L. Guarnera; O. Giudice; S. Battiato","Department of Mathematics and Computer Science, University of Catania, Catania, Italy; Department of Mathematics and Computer Science, University of Catania, Catania, Italy; Department of Mathematics and Computer Science, University of Catania, Catania, Italy",IEEE Access,"18 Sep 2020","2020","8","","165085","165098","Advances in Artificial Intelligence and Image Processing are changing the way people interacts with digital images and video. Widespread mobile apps like FACEAPP make use of the most advanced Generative Adversarial Networks (GAN) to produce extreme transformations on human face photos such gender swap, aging, etc. The results are utterly realistic and extremely easy to be exploited even for non-experienced users. This kind of media object took the name of Deepfake and raised a new challenge in the multimedia forensics field: the Deepfake detection challenge. Indeed, discriminating a Deepfake from a real image could be a difficult task even for human eyes but recent works are trying to apply the same technology used for generating images for discriminating them with preliminary good results but with many limitations: employed Convolutional Neural Networks are not so robust, demonstrate to be specific to the context and tend to extract semantics from images. In this paper, a new approach aimed to extract a Deepfake fingerprint from images is proposed. The method is based on the Expectation-Maximization algorithm trained to detect and extract a fingerprint that represents the Convolutional Traces (CT) left by GANs during image generation. The CT demonstrates to have high discriminative power achieving better results than state-of-the-art in the Deepfake detection task also proving to be robust to different attacks. Achieving an overall classification accuracy of over 98%, considering Deepfakes from 10 different GAN architectures not only involved in images of faces, the CT demonstrates to be reliable and without any dependence on image semantic. Finally, tests carried out on Deepfakes generated by FACEAPP achieving 93% of accuracy in the fake detection task, demonstrated the effectiveness of the proposed technique on a real-case scenario.","2169-3536","","10.1109/ACCESS.2020.3023037","iCTLab s.r.l. - Spin-off of University of Catania; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9189772","Deepfake detection;generative adversarial networks;multimedia forensics;image forensics","Information integrity;Videos;Generative adversarial networks;Faces;Task analysis;Computer architecture;Gallium nitride","","101","","31","CCBY","9 Sep 2020","2020","","IEEE","IEEE Journals"
"D3: Scaling Up Deepfake Detection by Learning from Discrepancy","Y. Yang; Z. Qian; Y. Zhu; O. Russakovsky; Y. Wu","School of Computer Science, Wuhan University; School of Computer Science, Wuhan University; Department of Computer Science, Princeton University; Department of Computer Science, Princeton University; School of Computer Science, Wuhan University",2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),"13 Aug 2025","2025","","","23850","23859","The boom of Generative AI brings opportunities entangled with risks and concerns. Existing literature emphasizes the generalization capability of deepfake detection on unseen generators, significantly promoting the detector’s ability to identify more universal artifacts. This work seeks a step toward a universal deepfake detection system with better generalization and robustness. We do so by first scaling up the existing detection task setup from the one-generator to multiple-generators in training, during which we disclose two challenges presented in prior methodological designs and demonstrate the divergence of detectors’ performance. Specifically, we reveal that the current methods tailored for training on one specific generator either struggle to learn comprehensive artifacts from multiple generators or sacrifice their fitting ability for seen generators (i.e., In-Domain (ID) performance) to exchange the generalization for unseen generators (i.e., Out-Of-Domain (OOD) performance). To tackle the above challenges, we propose our Discrepancy Deepfake Detector (D3) framework, whose core idea is to deconstruct the universal artifacts from multiple generators by introducing a parallel network branch that takes a distorted image feature as an extra discrepancy signal and supplement its original counterpart. Extensive scaled-up experiments demonstrate the effectiveness of D3, achieving 5.3% accuracy improvement in the OOD testing compared to the current SOTA methods while maintaining the ID performance. The source code will be updated in our GitHub repository: https://github.com/BigAandSmallq/D3.","2575-7075","979-8-3315-4364-8","10.1109/CVPR52734.2025.02221","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11095242","deepfake detection;fake image detection","Training;Deepfakes;Generative AI;Source coding;Fitting;Generators;Robustness;Pattern recognition;Testing;Software development management","","1","","53","IEEE","13 Aug 2025","10-17 June 2025","10-17 June 2025","IEEE","IEEE Conferences"
"Hubert-Derived SSL Features and ECAPA-TDNN Matching for Robust Audio Deepfake Detection","G. Tahaoglu","Department of Computer Engineering, Karadeniz Technical University, Trabon, Turkey",2025 IEEE 35th International Workshop on Machine Learning for Signal Processing (MLSP),"24 Oct 2025","2025","","","1","6","The rapid advancement and growing accessibility of deepfake audio technologies have prompted substantial concerns, particularly in domains such as politics and media, regarding the reliability of distinguishing between authentic and manipulated audio recordings. This study proposes a robust deepfake audio detection framework combining selfsupervised learning (SSL) features extracted using HuBERT models and a powerful ECAPA-TDNN classifier enhanced with One-Class Softmax (OC-Softmax). Three HuBERT variants-Base, Large, and XLarge-were assessed, along with various fusion strategies. Experiments were conducted on the ASVspoof 2019 LA dataset and demonstrated that the proposed system significantly outperforms existing state-of-the-art approaches. The best configuration, based on score level fusion of HuBERT-Large and HuBERT-XLarge with ECAPA-TDNN, achieved an EER of 0.20 % and a minimum t-DCF of 0.006. Available at: https://github.com/gultahaoglu/Hubertderiveredfeatures_deepfakeaudiodetection","2161-0371","979-8-3315-7029-3","10.1109/MLSP62443.2025.11204297","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11204297","deepfake audio;audio spoofing detection;HuBERT-based features;ECAPA-TDNN","Deepfakes;Accuracy;Conferences;Machine learning;Signal processing;Media;Benchmark testing;Feature extraction;Audio recording;Robustness","","","","34","IEEE","24 Oct 2025","31 Aug.-3 Sept. 2025","31 Aug.-3 Sept. 2025","IEEE","IEEE Conferences"
"CIPHER: Counterfeit Image Pattern High-level Examination via Representation for GAN and Diffusion Discriminator Learning","K. Kim; Y. Han; S. Ju; Y. Jean; Y. Kim; M. Choi; S. Lim; K. Park; S. Baek; S. Hyeon; N. -J. Kim; H. -J. Lee",OUTTA; OUTTA; OUTTA; OUTTA; OUTTA; OUTTA; OUTTA; OUTTA; OUTTA; OUTTA; Seoul National University; Seoul National University,2025 IEEE/IEIE International Conference on Consumer Electronics-Asia (ICCE-Asia),"4 Dec 2025","2025","","","1","6","The rapid progress of generative adversarial networks (GANs) and diffusion models has enabled the creation of synthetic faces that are increasingly difficult to distinguish from real images. This progress, however, has also amplified the risks of misinformation, fraud, and identity abuse, underscoring the urgent need for detectors that remain robust across diverse generative models. In this work, we introduce Counterfeit Image Pattern High-level Examination via Representation(CIPHER), a deepfake detection framework that systematically reuses and fine-tunes discriminators originally trained for image generation. By extracting scale-adaptive features from ProGAN discriminators and temporal-consistency features from diffusion models, CIPHER captures generation-agnostic artifacts that conventional detectors often overlook. Through extensive experiments across nine state-of-the-art generative models, CIPHER demonstrates superior cross-model detection performance, achieving up to 74.33% F1-score and outperforming existing ViT-based detectors by over 30% in F1-score on average. Notably, our approach maintains robust performance on challenging datasets where baseline methods fail, with up to 88% F1-score on CIFAKE compared to near-zero performance from conventional detectors. These results validate the effectiveness of discriminator reuse and cross-model fine-tuning, establishing CIPHER as a promising approach toward building more generalizable and robust deep-fake detection systems in an era of rapidly evolving generative technologies.","","979-8-3315-7402-4","10.1109/ICCE-Asia67487.2025.11263770","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11263770","Deepfake detection;GAN;Diffusion;Discriminator learning;Representation learning","Representation learning;Ciphers;Deepfakes;Social networking (online);Image synthesis;Detectors;Feature extraction;Diffusion models;Generative adversarial networks;Robustness","","","","48","IEEE","4 Dec 2025","27-29 Oct. 2025","27-29 Oct. 2025","IEEE","IEEE Conferences"
"Multi branch deepfake detection based on double attention mechanism","D. Du; H. Cai; G. Chen; H. Shi","School of Electronic and Information Engineering, Changchun University of Science and Technology, Changchun, China; School of Electronic and Information Engineering, Changchun University of Science and Technology, Changchun, China; School of Electronic and Information Engineering, Changchun University of Science and Technology, Changchun, China; School of Opto-Electronic Engineering, Changchun University of Science and Technology, Changchun, China",2021 International Conference on Electronic Information Engineering and Computer Science (EIECS),"9 Nov 2021","2021","","","746","749","With the continuous development of artificial face technology, it is more and more difficult to distinguish true and false faces with naked eyes. This paper proposes a multi branch artifact detection algorithm based on double attention mechanism, which can detect subtle artifacts. Firstly, dlib is used for face detection, and the local images of eyes, nose and mouth are segmented. A multi branch detection network model based on double attention mechanism is proposed. The model fully learns the context semantic information of local artifacts and global artifacts. The performance of the proposed method is evaluated on the deepfake data set, and the experimental results show that the test accuracy of the proposed method reaches 96.45%. At the same time, compared with other methods, this method also has a good performance in anti compression test.","","978-1-6654-1674-0","10.1109/EIECS53707.2021.9587946","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9587946","Deepfake;Attention mechanism;Face detection","Image segmentation;Computational modeling;Semantics;Nose;Mouth;Feature extraction;Security","","3","","13","IEEE","9 Nov 2021","23-26 Sept. 2021","23-26 Sept. 2021","IEEE","IEEE Conferences"
"RE-Mark: An Identity-Recovery Watermarking Method for Undoing Deepfake Face-Swap","T. Walczyna; J. M. Zurada; Z. Piotrowski","Electronics and Telecommunications Faculty, Military University of Technology, Warsaw, Poland; Electrical and Computer Eng. Department, University of Louisville, 2301 S 3rd St, Louisville, KY, USA; Electronics and Telecommunications Faculty, Military University of Technology, Warsaw, Poland",IEEE Access,"","2025","PP","99","1","1","In response to the growing threat of face‑swap deepfakes, we introduced RE‑Mark. This active zero-bit watermark embeds a compact neural identity signature directly within a facial image and later reconstructs the pre-swap appearance from a single image. The scheme employs a pair of symmetric, attention-enhanced U-Nets acting as an embedder and extractor. It is trained with a specific training pipeline that mixes five different face-swap engines with classical degradations such as noise and blur. This diversity forces the network to learn robust, high-level cues rather than brittle artifact patterns, yielding transparent watermarks that remain visually imperceptible at a peak signal-to-noise ratio (PSNR) of approximately 36 dB. Unlike previous active defenses that only flag manipulations, RE-Mark hides enough semantic redundancy to recover an authentic face without any external reference gallery, closing the gap between fragile detectors and robust—but non-restorative—watermarks. Therefore, the method equips platforms and investigators with a practical tool for both tamper verification and post‑factum identity restoration.","2169-3536","","10.1109/ACCESS.2025.3638457","Wojskowa Akademia Techniczna(grant numbers:UGB 22-054/2025); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11271225","Deepfake detection;Face‑swap robustness;Identity recovery;Image watermarking;Neural networks","Deepfakes;Watermarking;Faces;Image reconstruction;Visualization;Image restoration;Feature extraction;Robustness;Pipelines;Engines","","","","","CCBY","28 Nov 2025","","","IEEE","IEEE Early Access Articles"
"Within 3DMM Space: Exploring Inherent 3D Artifact for Video Forgery Detection","C. Peng; T. Xu; D. Liu; N. Wang; X. Gao","State Key Laboratory of Integrated Services Networks, School of Cyber Engineering, Xidian University, Xi’an, Shaanxi, China; State Key Laboratory of Integrated Services Networks, School of Cyber Engineering, Xidian University, Xi’an, Shaanxi, China; State Key Laboratory of Integrated Services Networks, School of Cyber Engineering, Xidian University, Xi’an, Shaanxi, China; State Key Laboratory of Integrated Services Networks, School of Telecommunications Engineering, Xidian University, Xi’an, Shaanxi, China; State Key Laboratory of Integrated Services Networks, School of Electronic Engineering, Xidian University, Xi’an, Shaanxi, China",IEEE Transactions on Information Forensics and Security,"4 Aug 2025","2025","20","","7954","7965","Recently, the breathtaking development and potential misuse of deepfake technology has raised numerous privacy and security concerns, triggering widespread apprehension. Existing deepfake detection methods focus on the analysis of local regions for faces, such as mouth movement, eye blinking frequency, etc., which, however, are limited in their ability to capture the global inconsistencies present in forged faces. Some researchers attempt to seize 3D artifacts related to facial global information, but typically treat the 3D information as mere input, lacking the in-depth analysis. To address these shortcomings and mine the inherent and delicate 3D artifacts in the forged faces, this paper innovatively proposes the 3D Artifact Detector (3DAD) method, which leverages the spatio-temporal inconsistency on the 3D semantic space in the forgery videos to uncover the deepfake clues. Specifically, we employ 3D Analysis Unit (3DAU) to pre-train the face reconstruction task within 3D Morphable Model (3DMM) space, thereby obtaining the high-level inherent 3d representation. Concurrently, for the multi-levels of information in the face, we utilize the Texture Perception Unit (TPU) to extract the texture information in the low-level semantic space of the images. Ultimately we feed the two distinct modalities into the spatiotemporal fusion model for final detection. Through extensive intra- and cross-dataset experiments on publicly available datasets, we demonstrate the effectiveness and generalizability of the proposed method. The source code is available at https://github.com/Cookie-XT/3DAD","1556-6021","","10.1109/TIFS.2025.3592557","National Natural Science Foundation of China(grant numbers:62276198,U22A2035,U22A2096,62036007,62306227); Innovation Capability Support Plan in Shaanxi Province(grant numbers:2025ZC-KJXX-22); Scientific and Technological Innovation Teams in Shaanxi Province(grant numbers:2025RS-CXTD-011); Young Elite Scientists Sponsorship Program by CAST(grant numbers:2022QNRC001); Shaanxi Province Core Technology Research and Development Project(grant numbers:2024QY2-GJHX-11); Open Research Project of Key Laboratory of Artificial Intelligence Ministry of Education(grant numbers:AI202401); Overseas Expertise Introduction Center for Discipline Innovation of Food Nutrition and Human Health (111 Center)(grant numbers:B16037); CCF-Baidu Open Fund; Fundamental Research Funds for the Central Universities(grant numbers:QTZX23083,QTZX23042,ZYTS24142); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11095790","Video forgery detection;Deepfake;3D information","Three-dimensional displays;Forgery;Faces;Deepfakes;Feature extraction;Data mining;Semantics;Frequency-domain analysis;Visualization;Spatiotemporal phenomena","","","","79","IEEE","24 Jul 2025","2025","","IEEE","IEEE Journals"
"Exploiting Facial Relationships and Feature Aggregation for Multi-Face Forgery Detection","C. Lin; F. Yi; H. Wang; J. Deng; Z. Zhao; Q. Li; C. Shen","School of Cyber Science and Engineering, Xi’an Jiaotong University, Xi’an, China; School of Software Engineering, Xi’an Jiaotong University, Xi’an, China; School of Cyber Science and Engineering, Xi’an Jiaotong University, Xi’an, China; School of Cyber Science and Engineering, Xi’an Jiaotong University, Xi’an, China; School of Cyber Science and Engineering, Xi’an Jiaotong University, Xi’an, China; School of Cyber Science and Engineering, Xi’an Jiaotong University, Xi’an, China; School of Cyber Science and Engineering, Xi’an Jiaotong University, Xi’an, China",IEEE Transactions on Information Forensics and Security,"30 Sep 2024","2024","19","","8832","8844","The emergence of advanced Deepfake technologies has gradually raised concerns in society, prompting significant attention to Deepfake detection. However, in real-world scenarios, Deepfakes often involve multiple faces. Despite this, most existing detection methods still detect these faces individually, overlooking the informative correlation between them and the relationship between the global information of the image and the local information of the faces. In this paper, we address this limitation by proposing FILTER, a novel framework for multi-face forgery detection that explicitly captures underlying correlations. FILTER consists of two main modules: Multi-face Relationship Learning (MRL) and Global Feature Aggregation (GFA). Specifically, MRL learns the correlation of local facial features in multi-face images, and GFA constructs the relationship between image-level labels and individual facial features to enhance performance from a global perspective. In particular, a contrastive learning loss function is used to better discriminate between real and fake faces. Extensive experiments on two publicly available multi-face forgery datasets demonstrate the state-of-the-art performance of FILTER in multi-face forgery detection. For example, on Openforensics Test-Challenge dataset, FILTER outperforms the previous state-of-the-art methods with a higher AUC score (0.980) and higher detection accuracy (92.04%).","1556-6021","","10.1109/TIFS.2024.3461469","National Key Research and Development Program of China(grant numbers:2021YFB3100700); National Natural Science Foundation of China(grant numbers:T2341003,62376210,62161160337,62132011,U21B2018,U20A20177,62206217); Shaanxi Province Key Industry Innovation Program(grant numbers:2023-ZDLGY-38); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10689267","Deepfake detection;multi-face relationship learning;global feature aggregation","Forgery;Faces;Feature extraction;Deepfakes;Facial features;Information filters;Frequency-domain analysis","","7","","61","IEEE","23 Sep 2024","2024","","IEEE","IEEE Journals"
"Leveraging Pixel Difference Feature for Deepfake Detection","M. Mao; C. Yan; J. Wang; J. Yang","Key Laboratory of the Ministry of Education for Embedded System and Service Computing, and National (Province Ministry Joint) Collaborative Innovation Center for Financial Network Security, Tongji University, Shanghai, China; Key Laboratory of the Ministry of Education for Embedded System and Service Computing, and National (Province Ministry Joint) Collaborative Innovation Center for Financial Network Security, Tongji University, Shanghai, China; Key Laboratory of the Ministry of Education for Embedded System and Service Computing, and National (Province Ministry Joint) Collaborative Innovation Center for Financial Network Security, Tongji University, Shanghai, China; Department of Computer Science and Technology, Tongji University, Shanghai, China",IEEE Transactions on Emerging Topics in Computational Intelligence,"23 Jul 2025","2025","9","4","3178","3188","The rise of Deepfake technology poses a formidable threat to the credibility of both judicial evidence and intellectual property safeguards. Current methods lack the ability to integrate the texture information of facial features into CNNs, despite the fact that fake contents are subtle and pixel-level. Due to the fixed grid kernel structure, CNNs are limited in their ability to describe detailed fine-grained information, making it challenging to achieve accurate image detection through pixel-level fine-grained features. To mitigate this problem, we propose a Pixel Difference Convolution (PDC) to capture local intrinsic detailed patterns via aggregating both intensity and gradient information. To avoid the redundant feature computations generated by PDC and explicitly enhance the representational power of a standard convolutional kernel, we separate PDC into vertical/horizontal and diagonal parts. Furthermore, we propose an Ensemble Dilated Convolution (EDC) to explore long-range contextual dependencies and further boost performance. We introduce a novel network, Pixel Difference Convolutional Network (PDCNet), which is built with PDC and EDC to expose Deepfake by capturing faint traces of tampering hidden in portrait images. By leveraging PDC and EDC in the information propagation process, PDCNet seamlessly incorporates both local and global pixel differences. Comprehensive experiments are performed on three databases, FF++, Celeb-DF, and DFDC to confirm that our PDCNet outperforms existing approaches. Our approach achieves accuracies of 0.9634, 0.9614, and 0.8819 in FF++, Celeb-DF, and DFDC, respectively.","2471-285X","","10.1109/TETCI.2025.3548803","China Scholarship Council CSC(grant numbers:202206260081); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10937061","Deepfake detection;pixel difference feature;ensemble dilated convolution","Faces;Deepfakes;Feature extraction;Convolution;Frequency-domain analysis;Forgery;Convolutional neural networks;Accuracy;Kernel;Biomedical monitoring","","1","","79","IEEE","21 Mar 2025","Aug. 2025","","IEEE","IEEE Journals"
"GTA-Net: A Robust Method for Deepfake Face Image Detection","Q. Yu; X. Wang; M. Jia; N. Bai; J. Hou; D. Liu","Xi'an University of Technology, Xi'an, China; Xi'an University of Technology, Xi'an, China; Xi'an University of Technology, Xi'an, China; Xi'an University of Technology, Xi'an, China; Xi'an University of Technology, Xi'an, China; Xi'an University of Technology, Xi'an, China",2023 China Automation Congress (CAC),"19 Mar 2024","2023","","","4576","4581","The rapid advancement of artificial intelligence technology has resulted in the emergence of deepfake, which has had a significant impact on various fields due to its realistic effects. Addressing the challenges posed by deepfake has become a crucial area of research. In this study, we propose a two-stream network framework, GTA-Net, for the detection of deepfake face images. The framework comprises a Global Residual Attention module (GRA), a Texture Feature Saliency module (TFS), and an Attention Feature Fusion module (AFF). We incorporate Local Binary Patterns (LBP) features into the network input to guide the decision-making process of the model towards prominent texture features, thereby enhancing detection accuracy. Additionally, we employ a residual attention mechanism to focus on specific deepfake-generated features and improve robustness by avoiding interference from content-preserving manipulations. Experimen-tal results show that the proposed method has high detection accuracy and strong robustness against degraded datasets, and generalization for cross-dataset detection.","2688-0938","979-8-3503-0375-9","10.1109/CAC59555.2023.10451644","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10451644","deepfake detection;texture feature saliency;robustness;generalization","Deepfakes;Adaptation models;Decision making;Focusing;Interference;Feature extraction;Robustness","","1","","28","IEEE","19 Mar 2024","17-19 Nov. 2023","17-19 Nov. 2023","IEEE","IEEE Conferences"
"RAW Data: A Key Component for Effective Deepfake Detection","S. Husseinil; J. -L. Dugelay","Department of Digital Security, EURECOM, Biot, France; Department of Digital Security, EURECOM, Biot, France","ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","7 Mar 2025","2025","","","1","5","Current deepfake detection methods are prone to overfitting to specific deepfake artifacts and often struggle with genuine images that have undergone compression and other image processing operations. These processes can obscure indicators of forgery, leading to inaccurate decisions. This paper aims to redefine the boundary between real and fake images by narrowing the definition of authentic samples to a stage closer to the radiance of the scene as captured by the sensor, prior to any transformations by an Image Signal Processor (ISP). Our proposed method bypasses ISP processing steps, such as denoising, white balance, and demosaicing, which are embedded in camera hardware. This unaltered preservation makes raw data an ideal starting point for deepfake detection. Given the scarcity of large-scale datasets designed for training on raw images, we propose a methodological approach to train our model on raw image data. Our method demonstrated state-of-the-art performance on the CDF dataset and showed competitive results across other RGB domain deepfake detection datasets. The model developed in this study is available at https://github.com/DeepFaux/Deepfake-Detection-with-RAW-Data.","2379-190X","979-8-3503-6874-1","10.1109/ICASSP49660.2025.10887800","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10887800","deepfake detection;image manipulation;ISP","Training;Deepfakes;Image coding;Noise reduction;Signal processing;Hardware;Forgery;Data models;Speech processing;Overfitting","","1","","38","IEEE","7 Mar 2025","6-11 April 2025","6-11 April 2025","IEEE","IEEE Conferences"
"HiTAL: Hierarchical Thumbnail and Latent Augmentation for Deepfake Detection","S. Tang; P. Zhang","School of Electronics and Communication Engineering, Sun Yat-sen University, Shenzhen Campus, Shenzhen, China; School of Electronics and Communication Engineering, Sun Yat-sen University, Shenzhen Campus, Shenzhen, China",IEEE Signal Processing Letters,"20 Nov 2025","2025","32","","4339","4343","Deepfake technology poses serious threats to privacy and information authenticity. Existing detection methods often suffer from limited cross-dataset generalization and robustness, and insufficient consideration of balanced modeling between temporal and spatial features in forged media. This paper proposes a hierarchical deepfake detection framework. At the input level, we introduce a perturbation-enhanced thumbnail layout that not only simulates real-world degradations caused by noise and compression but also explicitly balances inter-frame temporal features and intra-frame spatial features, thereby improving the effectiveness and robustness of spatiotemporal joint modeling. At the feature level, we employ intra-domain and cross-domain latent space augmentation to expand the forgery manifold and mitigate overfitting to manipulation-specific artifacts. Extensive experiments under cross-dataset and various perturbation settings demonstrate that the proposed method achieves superior generalization and robustness compared with state-of-the-art approaches.","1558-2361","","10.1109/LSP.2025.3627532","Shenzhen Science and Technology Program(grant numbers:KQTD20190929172704911); Science and Technology Planning Project of Guangdong Science and Technology Department; Guangdong Key Laboratory of Advanced IntelliSense Technology(grant numbers:2023B1212060024); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11222699","Cooperative augmentation;deepfake detection;latent space adaptation;perturbed thumbnails","Forgery;Robustness;Deepfakes;Spatiotemporal phenomena;Perturbation methods;Feature extraction;Manifolds;Layout;Media;Degradation","","","","42","IEEE","30 Oct 2025","2025","","IEEE","IEEE Journals"
"AI Model for Deepfake Detection – A Hybrid Deep Learning and Statistical Approach for GANGenerated Visuals","U. F. Zaidi; R. Kumar; M. I. Khan","Dept of Computer Science Engineering, RNTU, Bhopal; Dept of Computer Science Engineering, RNTU, Bhopal; Computer Science Engineering, PIMR, Bhopal",2025 International Conference on Engineering Innovations and Technologies (ICoEIT),"31 Oct 2025","2025","","","131","137","With the rapid advancement of Generative Adversarial Networks (GANs), there has been a sharp rise in hyper-realistic deepfake content, posing serious risks to digital security (DGTS), the spread of misinformation, and identity fraud (IDF). This study proposes an advanced AI-driven deepfake detection model (DDM), integrating a Hybrid Deep Learning and Statistical Approach (HDLSA) for robust GANgenerated visual analysis. The framework leverages Convolutional Neural Networks (CNNs) and Transformerbased architectures (TBA) for feature extraction, while employing statistical anomaly detection techniques to enhance interpretability and detection accuracy. A comprehensive dataset comprising diverse deepfake samples was utilized to train and simulates the model, achieving superior performance metrics compared to previously used benchmarks techniques. Experimental results demonstrate a notable improvement in detection precision (DP), recall (RCAL), and F1-score, reinforcing the model's efficacy in real-world deepfake identification. Furthermore, the study integrates Explainable AI (XAI) techniques, ensuring model transparency and interpretability. The proposed hybrid approach establishes a scalable, high-fidelity (SHF), and computationally efficient solution for combating deepfake threats across various domains, including cybersecurity, forensic analysis, and media authentication. The article is structured to provide a comprehensive review of deepfake detection challenges, a detailed explanation of the proposed hybrid model, and an extensive evaluation of experimental results. The key contribution of the study lies in the fusion of deep learning and statistical methodologies, significantly enhancing the robustness and generalizability of deepfake detection application.","","979-8-3315-2595-8","10.1109/ICoEIT63558.2025.11211537","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11211537","Deepfake Detection;Generative Adversarial Networks (GANs);Hybrid Deep Learning;Statistical Analysis;Explainable AI (XAI);Convolutional Neural Networks (CNNs)","Deep learning;Deepfakes;Visualization;Statistical analysis;Explainable AI;Computational modeling;Feature extraction;Transformers;Generative adversarial networks;Computational efficiency","","","","15","IEEE","31 Oct 2025","4-5 July 2025","4-5 July 2025","IEEE","IEEE Conferences"
"Generalizable Audio Deepfake Detection via Latent Space Refinement and Augmentation","W. Huang; Y. Gu; Z. Wang; H. Zhu; Y. Qian","AI Institute Department of Computer Science and Engineering, Auditory Cognition and Computational Acoustics Lab, MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University, Shanghai, China; Ant Group, Shanghai, China; Ant Group, Shanghai, China; Ant Group, Shanghai, China; AI Institute Department of Computer Science and Engineering, Auditory Cognition and Computational Acoustics Lab, MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University, Shanghai, China","ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","7 Mar 2025","2025","","","1","5","Advances in speech synthesis technologies, like text-to-speech (TTS) and voice conversion (VC), have made detecting deepfake speech increasingly challenging. Spoofing countermeasures often struggle to generalize effectively, particularly when faced with unseen attacks. To address this, we propose a novel strategy that integrates Latent Space Refinement (LSR) and Latent Space Augmentation (LSA) to improve the generalization of deepfake detection systems. LSR introduces multiple learnable prototypes for the spoof class, refining the latent space to better capture the intricate variations within spoofed data. LSA further diversifies spoofed data representations by applying augmentation techniques directly in the latent space, enabling the model to learn a broader range of spoofing patterns. We evaluated our approach on four representative datasets, i.e. ASVspoof 2019 LA, ASVspoof 2021 LA and DF, and In-The-Wild. The results show that LSR and LSA perform well individually, and their integration achieves competitive results, matching or surpassing current state-of-the-art methods.","2379-190X","979-8-3503-6874-1","10.1109/ICASSP49660.2025.10888328","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10888328","audio deepfake detection;anti-spoofing;generalization","Deepfakes;Refining;Prototypes;Data visualization;Signal processing;Robustness;Data models;Acoustics;Text to speech","","4","","29","IEEE","7 Mar 2025","6-11 April 2025","6-11 April 2025","IEEE","IEEE Conferences"
"Cognitive Inspired Generalization Boosting for Face Forgery Detection","Y. Huang; H. Yang","Institute of Image Communication and Network Engineering School of Information Science and Electronic Engineering & School of Integrated Circuits, Shanghai Jiao Tong University, Shanghai, China; Institute of Image Communication and Network Engineering School of Information Science and Electronic Engineering & School of Integrated Circuits, Shanghai Jiao Tong University, Shanghai, China",2025 IEEE International Conference on Multimedia and Expo (ICME),"30 Oct 2025","2025","","","1","8","Current face forgery detection models struggle to generalize across diverse forgery types due to limitations in feature extraction and refinement. Drawing inspiration from cognitive psychology, we propose an end-to-end detection framework SFMM to boost generalization capabilities. Based on dual-process theory, human cognition involves two complementary learning processes. The Fast Learning process rapidly captures explicit forgery-specific features using the Spatial-Frequency Transformer. The Slow Learning process gradually formulates generalized patterns across various forgeries by continuously updating a Momentum Memory Bank with the extracted features. This generalized knowledge is then employed to refine the feature extraction process. The two reciprocal processes are jointly optimized to foster a comprehensive and robust face forgery detection capability. Extensive experiments on benchmark datasets demonstrate that SFMM surpasses state-of-the-art methods in generalization tasks, achieving 1.0% and 3.7% AUC improvement on GAN-based and diffusion-based forgery datasets respectively.","1945-788X","979-8-3315-9495-4","10.1109/ICME59968.2025.11209182","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11209182","Deepfakes;Contrastive Learning;Face forgery detection","Deepfakes;Psychology;Contrastive learning;Benchmark testing;Feature extraction;Transformers;Boosting;Forgery;Cognition;Faces","","","","34","IEEE","30 Oct 2025","30 June-4 July 2025","30 June-4 July 2025","IEEE","IEEE Conferences"
"Lightweight and Accurate: Deepfake Detection using Binary Neural Networks and Vision Transformer","D. Stephy Joy; R. T. Selvi","Government Arts College (Autonomus), (Affliated by University of Madras), Chennai, India; Government Arts College (Autonomus), (Affliated by University of Madras), Chennai, India",2025 11th International Conference on Smart Computing and Communications (ICSCC),"17 Nov 2025","2025","","","1","5","The challenge of defending digital media authenticity has become critical because deep learning methods continue to improve their production of realistic forgeries. Current state-of-the-art detection systems require deep architectures together with substantial parameter count but do not work well for real-time or resource-limited situations. This work presents an efficient deepfake detection system based on 1-bit Binary Neural Networks and DWT features together with HOG and ViT backbone features. The detection method draws from DWT frequency-domain and HOG texture-domain features to reveal artifact patterns that synthetic models fail to recognize. Globally distributed modifications require the ViT backbone to detect entire spatial patterns due to its ability to capture distant context. Our proposed system reaches near state-of-the-art or state-of-the-art detection accuracy on the DFDC and OpenForensics datasets using substantially less computational resources than standard full-precision neural networks. The system maintains excellent detection capabilities against complex forgeries because it merges quantized classification with enhanced multi-domain features. The obtained results demonstrate BNN-based quantization as an effective solution for deepfake detectors which enables real-time operation on regular consumer-grade devices.","","979-8-3315-2562-0","10.1109/ICSCC66177.2025.11233324","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11233324","Deepfake detection;Binary Neural Networks (BNNs);Vision Transformers (ViT);Discrete Wavelet Transform (DWT);Histogram of Oriented Gradients (HOG)","Deepfakes;Histograms;Computational modeling;Neural networks;Transforms;Feature extraction;Transformers;Real-time systems;Forgery;Discrete wavelet transforms","","","","20","IEEE","17 Nov 2025","3-5 July 2025","3-5 July 2025","IEEE","IEEE Conferences"
"Beyond Accuracy: Explainable Multimodal Deepfake Detection Through Cross-Modal Feature Analysis and Dynamic Attention Weighting","T. Rahman; R. Chakma; T. Mahmud","Department of Computer Science and Engineering, Rangamati Science and Technology University; Department of Computer Science and Engineering, Rangamati Science and Technology University; Department of Computer Science and Engineering, Rangamati Science and Technology University","2025 International Conference on Quantum Photonics, Artificial Intelligence, and Networking (QPAIN)","29 Sep 2025","2025","","","1","6","The advent of deepfake technology in recent years has significantly transformed the domain of video synthesis, facilitating the production of convincing synthetic films. The study explains a method for detecting deepfakes that uses both visual and sound analysis with special neural networks and a technique that combines the two types of information. We have a system that uses an EfficientNetB0- based CNN to analyze face images and a bidirectional LSTM to process audio features, showing that combining both types of data makes detection stronger than using just one type. Our research on the AVLips dataset shows that different types of data learn in different ways-visual features help with quick learning at first but are more likely to overfit, while audio features lead to a more consistent learning process. Using explainable AI methods, we find that visual deepfake signs are mainly seen around the eyes and mouth, while specific MFCC coefficients (specifically 2 and 9) offer important distinguishing information in the audio part. The fusion model attains an accuracy of 87.25 %, surpassing the visual-only model at 85.25 % and the audio-only model at 81 %. In addition to performance measurements, our study offers important information regarding feature relevance across modalities and illustrates how attention mechanisms may adjust modality contributions depending on the reliability of individual samples. This study improves the field by highlighting the benefits of understanding multimodal methods and identifying specific patterns across different types of data that characterize deepfake content.","","979-8-3315-9694-1","10.1109/QPAIN66474.2025.11171737","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11171737","CNN;EfficientNetBO;LSTM;MFCC;AVLips;Deepfake Detection;Multimodal","Deepfakes;Visualization;Accuracy;Attention mechanisms;Mouth;Production;Media;Feature extraction;Robustness;Mel frequency cepstral coefficient","","","","24","IEEE","29 Sep 2025","31 July-2 Aug. 2025","31 July-2 Aug. 2025","IEEE","IEEE Conferences"
"Security Strengthen and Detection of Deepfake Videos and Images Using Deep Learning Techniques","S. Talreja; A. Bindle; V. Kumar; I. Budhiraja; P. Bhattacharya","School of Computer Science Engineering and Technology, Bennett University, Greater Noida, India; Electronics and Communication Engineering, Maharishi Markandeswar University, Mullana-Ambala, Haryana; Computer Science and Engineering, Amity School of Engineering and Technology, Amity University, Kolkata, India; School of Computer Science Engineering and Technology, Bennett University, Greater Noida, India; Computer Science and Engineering, Amity School of Engineering and Technology, Amity University, Kolkata, India",2024 IEEE International Conference on Communications Workshops (ICC Workshops),"12 Aug 2024","2024","","","1834","1839","The identification of fraudulent movies or images created using deep learning algorithms is the subject of this research and attempts an in-depth investigation of Deepfake Detection. Deepfakes are created by manipulating or replacing certain parts of an original video or image using machine learning algorithms, usually concentrating on face features. Deepfake detection's main goal is to precisely recognize and distinguish these altered media from real movies and photos. This study looks at a number of deepfake detection techniques, including forensic methods, machine learning algorithms, and picture analysis. These approaches' efficiency and performance are assessed based on their capacity to accurately identify and categories deep-fakes. The paper also examines the difficulties and restrictions of deepfake detection, such as the development of more complex and convincing deepfakes. Further, prospective uses and future possibilities for deepfake detection research are examined, with an emphasis on improving detection skills and creating effective countermeasures. Overall, this research offers insightful information about cutting-edge methods and developments in Deepfake Detection, giving a greater comprehension of its importance in resolving the issues brought on by manipulated media in the current digital era.","2694-2941","979-8-3503-0405-3","10.1109/ICCWorkshops59551.2024.10615811","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10615811","DeepFake Detection;Deep Learning;Machine Learning","Deep learning;Deepfakes;Machine learning algorithms;Image resolution;Conferences;Forensics;Face recognition","","2","","20","IEEE","12 Aug 2024","9-13 June 2024","9-13 June 2024","IEEE","IEEE Conferences"
"Deepfake Detection Fighting Against Noisy Label Attack","T. Qiao; S. Xie; Y. Chen; F. Retraint; R. Shi; X. Luo","School of Cyberspace, Hangzhou Dianzi University, Hangzhou, China; School of Cyberspace, Hangzhou Dianzi University, Hangzhou, China; Cyberspace Institute of Advanced Technology, Guangzhou University, Guangzhou, China; Laboratory of Computer Science and Digital Society, University of Technology of Troyes, Troyes, France; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; State Key Laboratory of Mathematical Engineering and Advanced Computing, Zhengzhou Science and Technology Institute, Zhengzhou, China",IEEE Transactions on Multimedia,"21 Aug 2024","2024","26","","9047","9059","The face manipulation technique such as Deepfake has been widely used to create realistic faces, which raises growing concerns in the community. Based on the correct labeled data, the current Deepfake detectors are mostly trained on the clean dataset, usually resulting in the reliable high detection accuracy. However, in the real-world scenario, labelers possibly mislabel the data or malicious attackers always intend to poison the training data with incorrect label, namely noisy label attack, leading to poor detection results. To overcome the tough issue, we propose a Deepfake detection framework fighting against noisy label attack. Specifically, a Negative Sample Generator (NSG) utilizes the possibly-poisoned samples to generate label-reliable negative samples through simulating blending artifacts caused by Deepfake. Next, a Noise-immune Contrastive Learner (NiCL) takes both positive and negative samples as training data, exploring blending artifacts and intrinsic forgery clues to filtrate the noisy samples out. Moreover, relying on label purification, the filtrated noisy samples are further purified, which then are fed back to the feature extractor for the following model training. Extensive experiments on the benchmark datasets demonstrate the superiority of our proposed Deepfake detector. In particular, when fighting against noisy label attack, the high performance of the proposed detector is remarkably better than its competitors.","1941-0077","","10.1109/TMM.2024.3385286","Zhejiang Provincial Natural Science Foundation of China(grant numbers:LZ23F020006,LTGG24F020008); National Key R&D Project(grant numbers:2022YFB3102900); National Natural Science Foundation of China(grant numbers:62172435,U23A20305); Henan Province Key R&D Project of China(grant numbers:221111321200); vigideo; UTT's AMI O-SPAR; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10491334","Deepfake detection;noisy label attack;contrastive learning","Noise measurement;Deepfakes;Training;Faces;Data models;Training data;Forensics","","7","","71","IEEE","4 Apr 2024","2024","","IEEE","IEEE Journals"
"Audio Deepfake Detection: End-to-End training with powerful pretrained ASR","K. H. Mansoor; M. Alam","Fast School of Computing, National University of Computer and Emerging Sciences, Islamabad, Pakistan; Fast School of Computing, National University of Computer and Emerging Sciences, Islamabad, Pakistan",2024 26th International Multi-Topic Conference (INMIC),"16 May 2025","2024","","","1","6","The advancements in audio deepfake generation raise significant concerns about its potential misuse, with implications ranging from personal reputation damage to global repercussions. While efforts are being made to mitigate this threat, the results so far are not particularly impressive. Many proposed solutions falter when tested on datasets that differ substantially from the ones on which they were trained. In our approach, we utilize Meta's MMS-300m pretrained ASR model as a feature extractor and train it end-to-end (E2E) alongside various classifiers (ResNet-18, MesoNet, AASIST, MLP, and SLP). We train on a small subset of the widely recognized ASVSpoof2021 DF dataset and conduct cross-dataset evaluations on the In-The-Wild (ITW) dataset, a standard benchmark. The E2E training of the robust ASR model yields a significant improvement, with all our models surpassing the current state of the art. Our best-performing model achieves an Equal Error Rate (EER) of 0.0342%, representing an impressive 55.48% improvement.","2835-8864","979-8-3315-0721-3","10.1109/INMIC64792.2024.11004412","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11004412","audio deepfake detection;end-to-end;pretrained ASR;Meta MMS-300m","Training;Deepfakes;Error analysis;Benchmark testing;Feature extraction;Data models;Distance measurement;Standards","","","","39","IEEE","16 May 2025","30-31 Dec. 2024","30-31 Dec. 2024","IEEE","IEEE Conferences"
"Unlocking A New Paradigm In Robustness For Multi-Step Facial Forgery Detection","S. Luo; W. Guan; L. Zhou; J. Dong","Beijing University of Posts and Telecommunications, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China",2025 IEEE International Conference on Image Processing (ICIP),"18 Aug 2025","2025","","","779","784","With the rapid advancement of face forgery technologies, the quality of manipulated images has significantly improved, posing a severe threat to information security. In response, deepfake detection has emerged as an effective countermeasure against the misuse of these technologies. Sequential deepfake detection,as a specialized extension, targets face images with multi-step manipulation. However, a key challenge in this task is defending against unknown image degradation that occurs during transformation, which is not widely addressed in previous research. This paper introduces a robust detection framework named RSFDF, aimed at enhancing detection capabilities when images are subjected to degradation operations. RSFDF incorporates two critical modules:ATEM and ESCM. ATEM assists the network in focusing on important features while suppressing irrelevant information; ESCM refines the attention mechanism to increase the model’s focus on edge contours, aiding in the judgment of sequential forgeries. Experiments show that RSFDF exhibits significant improvements in robustness against unknown image degradations.","2381-8549","979-8-3315-2379-4","10.1109/ICIP55913.2025.11084694","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11084694","Multi-step Manipulation;Sequential Deepfake Detection;Robustness","Degradation;Deepfakes;Sensitivity;Image edge detection;Image processing;Information security;Robustness;Forgery;Stability analysis;Faces","","","","29","IEEE","18 Aug 2025","14-17 Sept. 2025","14-17 Sept. 2025","IEEE","IEEE Conferences"
"Unsupervised Learning-Based Framework for Deepfake Video Detection","L. Zhang; T. Qiao; M. Xu; N. Zheng; S. Xie","School of Cyberspace, Hangzhou Dianzi University, Hangzhou, China; School of Cyberspace, Hangzhou Dianzi University, Hangzhou, China; School of Cyberspace, Hangzhou Dianzi University, Hangzhou, China; School of Cyberspace, Hangzhou Dianzi University, Hangzhou, China; School of Cyberspace, Hangzhou Dianzi University, Hangzhou, China",IEEE Transactions on Multimedia,"31 Oct 2023","2023","25","","4785","4799","With the continuous development of computer hardware equipment and deep learning technology, it is easier for people to swap faces in videos by currently-emerging multimedia tampering tools, such as the most popular deepfake. It would bring a series of new threats of security. Although many forensic researches have focused on this new type of manipulation and achieved high detection accuracy, most of which are based on supervised learning mechanism with requiring a large number of labeled samples for training. In this paper, we first develop a novel unsupervised detection manner for identifying deepfake videos. The main fundamental behind our proposed method is that the face region in the real video is taken by the camera while its counterpart in the deepfake video is usually generated by the computer; the provenance of two videos is totally different. Specifically, our method includes two clustering stages based on Photo-Response Non-Uniformity (PRNU) and noiseprint feature. Firstly, the PRNU fingerprint of each video frame is extracted, which is used to cluster the full-size identical source video (regardless of its real or fake). Secondly, we extract the noiseprint from the face region of the video, which is used to identify (re-cluster for the task of binary classification) the deepfake sample in each cluster. Numerical experiments verify our proposed unsupervised method performs very well on our own dataset and the benchmark FF++ dataset. More importantly, its performance rivals that of the supervised-based state-of-the-art detectors.","1941-0077","","10.1109/TMM.2022.3182509","Fundamental Research Funds for the Provincial Universities of Zhejiang(grant numbers:GK219909299001-007); Open Projects Program of National Laboratory of Pattern Recognition; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9795231","Deepfake detection;unsupervised learning;video clustering;PRNU;noiseprint","Faces;Streaming media;Cameras;Feature extraction;Forensics;Cyberspace;Training","","41","","62","IEEE","13 Jun 2022","2023","","IEEE","IEEE Journals"
"The Growing Need for Deepfakes Detection in the Age of AI-Generated Media","P. Badoni; M. S. Dildar; M. N. Ahmed; A. S. Zamani; M. R. Hussain; M. Wadhwa","CSE, Chandigarh University, Mohali, India; Department of Business Informatics, King Khalid University, Abha, Saudi Arabia; CSE, King Khalid University, Abha, Saudi Arabia; Department of Computer & Self Development, Prince Sattam bin Abdulaziz University, AlKharj, Saudi Arabia; Department of Business Informatics, King Khalid University, Abha, Saudi Arabia; CSE, Chandigarh University, Mohali, India",2025 12th International Conference on Emerging Trends in Engineering & Technology - Signal and Information Processing (ICETET - SIP),"16 Sep 2025","2025","","","1","6","Deepfakes detection is now a necessity because deep learning methods for producing highly realistic synthetic media are advancing at an alarming rate. These doctored photos, videos, and audio files can mislead their audience, disseminate disinformation, and represent a major security risk. Detection techniques utilize convolutional neural networks, recurrent neural networks, and transformer models to detect minor artifacts, inconsistencies, and unnatural patterns in multimedia content. Methods such as frequency analysis, facial landmark tracking, and adversarial training are used to improve detection accuracy. The ongoing development of generative models requires constant research to create resilient and flexible detection systems that can counter the threats from synthetic media manipulation.","2157-0485","979-8-3315-0099-3","10.1109/ICETETSIP64213.2025.11156944","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11156944","Deepfakes detection;synthetic media;convolutional neural networks;misinformation;adversarial training;facial landmark tracking;generative models;multimedia forensics;digital security","Training;Deepfakes;Recurrent neural networks;Biological system modeling;Medical services;Media;Benchmark testing;Security;Convolutional neural networks;Biomedical monitoring","","","","37","IEEE","16 Sep 2025","1-2 Aug. 2025","1-2 Aug. 2025","IEEE","IEEE Conferences"
"UniForensics: Face Forgery Detection via General Facial Representation","Z. Fang; H. Zhao; T. Wei; W. Zhou; M. Wan; Z. Wang; W. Zhang; N. Yu","University of Science and Technology of China, Hefei, Anhui, China; University of Science and Technology of China, Hefei, Anhui, China; University of Science and Technology of China, Hefei, Anhui, China; University of Science and Technology of China, Hefei, Anhui, China; Qianxin Technology Group Co. Ltd, Beijing, China; Qianxin Technology Group Co. Ltd, Beijing, China; University of Science and Technology of China, Hefei, Anhui, China; University of Science and Technology of China, Hefei, Anhui, China",IEEE Transactions on Dependable and Secure Computing,"","2025","PP","99","1","15","The rise of deepfakes has significantly heightened concerns for privacy and the authenticity of digital media, bringing widespread attention to face forgery detection. Previous deepfake detection methods mostly depend on low-level textural features vulnerable to perturbations and fall short of detecting unseen forgery methods. In contrast, high-level semantic features are less susceptible to perturbations and not limited to forgery-specific artifacts, thus having stronger generalization. Motivated by this, we propose a detection method that utilizes high-level semantic features of faces to identify inconsistencies in temporal domain. We introduce UniForensics, a novel deepfake detection framework that leverages a transformer-based video classification network, initialized with a meta-functional face encoder for enriched facial representation. In this way, we can take advantage of both the powerful spatio-temporal model and the high-level semantic information of faces. Furthermore, to leverage easily accessible real face data and guide the model in focusing on spatio-temporal features, we design a Dynamic Video Self-Blending (DVSB) method to efficiently generate training samples with diverse spatio-temporal forgery traces using real facial videos. Based on this, we advance our framework with a two-stage training approach: The first stage employs a novel self-supervised contrastive learning, where we encourage the network to focus on forgery traces by impelling videos generated by the same forgery process to have similar representations. On the basis of the representation learned in the first stage, the second stage involves fine-tuning on face forgery detection dataset to build a deepfake detector. Extensive experiments validates that UniForensics outperforms existing face forgery detection methods in generalization ability and robustness. In particular, our method achieves 95.3% and 77.2% cross dataset AUC on the challenging Celeb-DFv2 and DFDC respectively. Code will be made publicly available.","1941-0018","","10.1109/TDSC.2025.3627420","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11250851","Deepfake detection;self-supervised contrastive learning;data synthesis","Forgery;Faces;Deepfakes;Semantics;Face recognition;Feature extraction;Training;Robustness;Data models;Contrastive learning","","","","","IEEE","17 Nov 2025","","","IEEE","IEEE Early Access Articles"
"EDL-Det: A Robust TTS Synthesis Detector Using VGG19-Based YAMNet and Ensemble Learning Block","R. Mahum; A. Irtaza; A. Javed","Computer Science Department, UET Taxila, Taxila, Pakistan; Computer Science Department, UET Taxila, Taxila, Pakistan; Software Engineering Department, UET Taxila, Taxila, Pakistan",IEEE Access,"5 Dec 2023","2023","11","","134701","134716","Various audio deep fake synthesis algorithms exist, such as deep voice, tacotron, fastspeech, and imitation techniques. Despite the existence of various spoofing speech detectors, they are not ready to distinguish unseen audio samples with high precision. In this study, we suggest a robust model, namely an Ensemble Deep Learning Detector (EDL-Det), to detect text-to-speech (TTS) and categorize it into spoofed and bonafide classes. Our proposed model is an improved method based on Yet Another Multi-scale Convolutional Neural Network (YAMNet) employing VGG19 as a base network combined with two other deep learning(DL) techniques. Our proposed system effectively analyzes the audio to extract better artifacts. We have added an ensemble learning block that consists of ResNet50 and InceptionNetv2. First, we convert speech into mel-spectrograms that consist of time-frequency representations. Second, we train our model using the ASVspoof-2019 dataset. Ultimately, we classified the audios, transforming them into mel-spectrograms using our trained binary classifier and a majority voting scheme by three networks. Due to ensemble architecture, our proposed model effectively extracts the most representative features from the mel-spectrograms. Furthermore, we have performed extensive experiments to assess the performance of the suggested model using the ASVspoof 2019 corpus. Additionally, our proposed model is robust enough to identify the unseen spoofed audios and accurately classify the attacks based on cloning algorithms.","2169-3536","","10.1109/ACCESS.2023.3332561","University of Engineering and Technology Taxila, Pakistan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10316278","Deep learning;DeepFake audios;fake speech;text-to-speech detection;VGG19;mel-spectrograms","Feature extraction;Hidden Markov models;Detectors;Deep learning;Convolutional neural networks;Training;Deepfakes;Electronic messaging;Text analysis;Speech recognition;Spectrogram","","18","","70","CCBYNCND","13 Nov 2023","2023","","IEEE","IEEE Journals"
"Learning Generalizable Representations for Deepfake Detection with Realistic Sample Generation and Dual Augmentation","Z. Gao; X. Zhu; H. Jia; Y. Zhao; C. Ma; C. Li","Key Laboratory of Computer Vision and System, Ministry of Education, Tianjin University of Technology, Tianjin, P.R China; Key Laboratory of Computer Vision and System, Ministry of Education, Tianjin University of Technology, Tianjin, P.R China; Key Laboratory of Computer Vision and System, Ministry of Education, Tianjin University of Technology, Tianjin, P.R China; Key Laboratory of Computer Vision and System, Ministry of Education, Tianjin University of Technology, Tianjin, P.R China; Shandong Artificial Intelligence Institute, Qilu University of Technology (Shandong Academy of Sciences), Jinan, P.R China; Key Laboratory of Computer Vision and System, Ministry of Education, Tianjin University of Technology, Tianjin, P.R China",IEEE Transactions on Dependable and Secure Computing,"","2025","PP","99","1","13","Deepfake detection aims to identify manipulated content generated by generative models such as GANs and diffusion models. Although many detection methods have been proposed in recent years, their performance often degrades significantly when the test data includes unknown images or novel forgery types. To address this challenge, we propose a Realistic Sample Generation and Dual Augmentation framework, abbreviated as RSG-DA, to enhance generalization in deepfake detection. The key idea is to explore and expand the forgery feature space in order to learn decision boundaries that can capture diverse forgery patterns. Specifically, we introduce a Dynamic Landmark Diffusion Generator (DLDG) that synthesizes hybrid forgery samples with high visual realism and structural diversity. Additionally, we design a Dual Data Augmentation (DDA) strategy composed of DW-Augmentation and Class-Augmentation, where DW-Augmentation strengthens the representation of authentic image features through multi-scale transformations, while Class-Augmentation enriches the forgery distribution by expanding it with varied manipulations. Finally, we present a Lightweight Generic Forgery Distillation (LGFD) module that integrates the above components into a unified encoder, enabling the learning of robust and transferable forgery representations. Extensive experiments show that our method consistently outperforms state-of-the-art approaches in both intra-dataset and cross-dataset evaluations.","1941-0018","","10.1109/TDSC.2025.3642980","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11297777","Deepfake Detection;Dynamic Landmark Diffusion Generator;Dual Data Augmentation;Lightweight Generic Forgery Distillation","Forgery;Deepfakes;Data augmentation;Visualization;Generators;Face recognition;Diffusion models;Robustness;Noise reduction;Feature extraction","","","","","IEEE","11 Dec 2025","","","IEEE","IEEE Early Access Articles"
"Voices of Deception - Detecting AI-Synthesized Speech Using Spectrotemporal Features and Hybrid Learning Models","K. Vaghchhipawala; P. Nadkarni; A. Pai; A. Trivedi; S. Bollavarapu","Department of Computer Engineering, NMIMS University, MPSTME, Mumbai, Maharashtra, India; Department of Computer Engineering, NMIMS University, MPSTME, Mumbai, Maharashtra, India; Department of Computer Engineering, NMIMS University, MPSTME, Mumbai, Maharashtra, India; Department of Computer Engineering, NMIMS University, MPSTME, Mumbai, Maharashtra, India; Department of Computer Engineering, NMIMS University, MPSTME, Mumbai, Maharashtra, India",2025 IEEE 6th India Council International Subsections Conference (INDISCON),"2 Dec 2025","2025","","","1","6","With the advent of highly realistic AIsynthesized voice, the risk of deepfake voices has increased immensely, giving rise to grave concerns in domains such as fraud, impersonation, and digital trust. There is a gap in reliable, real-time detection solutions since current detection systems typically fall short when faced with a variety of accents, speaker styles, or complex synthesis approaches. This work proposes a hybrid deepfake voice detection framework that merges both machine learning and deep learning techniques with spectrotemporal features. A tailor-made dataset was collected from three significant sources- actual speech from the Speech Accent Archive, artificially created samples using Google Text-to-Speech, and cloned voices from the DEEP-VOICE dataset. Mel-Frequency Cepstral Coefficients (MFCCs) were utilized to extract relevant features from each audio sample. Two models were created and tested: a Voting Classifier that merges SVM, Random Forest, and Gradient Boosting, and a CNN-LSTM deep learning model that is capable of learning spatial and temporal speech patterns. The two models were accurate and above $95 \%$ and were incorporated into a user-friendly Gradio web interface to test in real-time. The findings show that combining multiple approaches with robust audio features yields a scalable and efficient solution for AI-generated voice identification. The system is highly suitable for use in security, media authentication, voice-based verification, and fraud prevention online.","","979-8-3315-1504-1","10.1109/INDISCON66021.2025.11252158","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11252158","Deepfake audio;voice synthesis;CNN-LSTM;Voting Classifier;MFCC;real-time detection;audio forensics","Deep learning;Deepfakes;Feature extraction;Real-time systems;Fraud;Text to speech;Security;Reliability;Usability;Random forests","","","","25","IEEE","2 Dec 2025","21-23 Aug. 2025","21-23 Aug. 2025","IEEE","IEEE Conferences"
"HybridNet: Advancing Deepfake Detection Through Residual, SE, and Depthwise Convolutions","A. Kumar","University of Illinois Chicago, Chicago, IL, USA",IEEE Access,"15 Dec 2025","2025","13","","207541","207552","Deepfake media pose a significant threat to digital information integrity, necessitating robust detection strategies. We propose HybridNet, a convolutional network for deepfake detection that integrates residual connections (ResNet), depthwise separable convolutions (EfficientNet principles), and Squeeze–and–Excitation (SE) blocks to balance high accuracy with computational efficiency. HybridNet incorporates uncertainty quantification via softmax confidence thresholds and interpretability through Gradient–weighted Class Activation Mapping (Grad–CAM) visualizations. Enhanced by a Hybrid Frequency–Spatial Attention (HFSA) module, it improves generalization across datasets. We evaluate HybridNet on FaceForensics++ (HQ) (96% accuracy), Celeb-DF v2 (97%), and the DFDC-preview split, where performance improves from 89% (baseline) to 93.2% with data augmentation and PGD-based robustness enhancements. Unlike prior detectors that are either black–box CNNs or heavy transformer architectures, HybridNet offers a practical trade–off between interpretability, efficiency, and accuracy. Additional evaluations against transformer–based models, compression robustness, fairness across demographics, adversarial attacks, and deployment feasibility underscore HybridNet’s versatility and reliability. Ablations confirm the contribution of each architectural component. We report confidence intervals and stress–test under codec compression, noise, and blur to substantiate robustness claims.","2169-3536","","10.1109/ACCESS.2025.3640106","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11275676","Deepfake detection;convolutional neural networks;residual networks;depthwise separable convolution;Squeeze–and–Excitation;interpretability;Grad–CAM;transformers;fairness","Transformers;Deepfakes;Accuracy;Convolutional neural networks;Robustness;Feature extraction;Computer architecture;Noise;Detectors;Standards","","","","45","CCBY","3 Dec 2025","2025","","IEEE","IEEE Journals"
"Navigating Deepfakes with Data Science: A Multi-Modal Analysis and Blockchain-Based Detection Framework","S. Patil; A. Bhat; N. Jain; V. Javalkar","University of Texas at Dallas, Richardson, Texas, USA; EY(Ernst & Young), Dallas, Texas, USA; Oracle America Inc, Sterling, VA, USA; Independent Researcher, Frisco, Texas, USA",2025 International Conference on Pervasive Computational Technologies (ICPCT),"1 Apr 2025","2025","","","772","777","Deepfake technology, fueled by advancements in artificial intelligence, presents a dual-use phenomenon with innovative applications in entertainment, education, and communication alongside significant ethical and societal risks, such as misinformation, identity theft, and privacy violations. This paper proposes a novel framework combining multi-modal analysis and blockchain verification to enhance deepfake detection. The multi-modal approach employs audio-visual analysis, temporal and spatial inconsistencies, and advanced feature extraction techniques to identify manipulations, while blockchain provides a tamper-proof mechanism for authenticating digital content at its source. By addressing research gaps such as cross-domain adaptability and limited training datasets, the framework offers a holistic solution to escalating challenges. Moreover, the paper emphasizes the importance of transparency, privacy preservation, and global collaboration to align technological innovation with ethical accountability. This work contributes to building a trustworthy digital ecosystem, enabling responsible applications of deepfake technology while mitigating its risks.","","979-8-3315-0868-5","10.1109/ICPCT64145.2025.10940229","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10940229","Deepfake detection;multi-modal analysis;blockchain;audio-visual inconsistencies;temporal analysis;spatial analysis;feature extraction;content hashing;ethical AI;dataset augmentation;synthetic data generation","Deepfakes;Ethics;Technological innovation;Privacy;Ecosystems;Entertainment industry;Collaboration;Feature extraction;Blockchains;Artificial intelligence","","","","26","IEEE","1 Apr 2025","8-9 Feb. 2025","8-9 Feb. 2025","IEEE","IEEE Conferences"
"Multi-Scale Self-Supervised Learning for Efficient Audio Deepfake Detection","T. M. Wani; I. Amerini","Sapienza University of Rome, Italy; Sapienza University of Rome, Italy",IEEE Signal Processing Letters,"","2025","PP","99","1","5","Neural vocoders enable highly realistic synthetic speech that challenges multimedia authentication; however, existing detection approaches suffer from limited robustness to unseen synthesis methods and inadequate deployment readiness. We propose MASD (Multi-scale Artifact-aware Self-supervised Deepfake detector), combining multi-scale SSL with handcrafted features. MASD decomposes spectrograms into three frequency bands, processed through an encoder pretrained using masked reconstruction, contrastive predictive coding, and adversarial vocoder classification. Features fuse with phase coherence, spectral flux, and high-frequency energy through cross-attention, classified by temperature-scaled SVM. Evaluation on ASVspoof 2019 LA demonstrates state-of-the-art performance. Ablation studies confirm adversarial augmentation as the primary driver of robustness, improving EER from 1.52% to 0.39%, while zero-shot cross-dataset evaluation validates generalization effectiveness, establishing MASD as a practical solution.","1558-2361","","10.1109/LSP.2025.3634032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11250894","audio deepfake detection;adversarial augmentation;confidence calibration;self-supervised learning","Vocoders;Training;Feature extraction;Deepfakes;Spectrogram;Kernel;Accuracy;Calibration;Robustness;Natural languages","","","","","IEEE","17 Nov 2025","","","IEEE","IEEE Early Access Articles"
