
@inproceedings{afchar_mesonet_2018,
	address = {Hong Kong, Hong Kong},
	title = {{MesoNet}: a {Compact} {Facial} {Video} {Forgery} {Detection} {Network}},
	isbn = {9781538665367},
	shorttitle = {{MesoNet}},
	url = {https://ieeexplore.ieee.org/document/8630761/},
	doi = {10.1109/WIFS.2018.8630761},
	abstract = {This paper presents a method to automatically and efficiently detect face tampering in videos, and particularly focuses on two recent techniques used to generate hyper-realistic forged videos: Deepfake and Face2Face. Traditional image forensics techniques are usually not well suited to videos due to the compression that strongly degrades the data. Thus, this paper follows a deep learning approach and presents two networks, both with a low number of layers to focus on the mesoscopic properties of images. We evaluate those fast networks on both an existing dataset and a dataset we have constituted from online videos. The tests demonstrate a very successful detection rate with more than
98\% for Deepfake and 95\% for Face2Face.},
	urldate = {2025-10-27},
	booktitle = {2018 {IEEE} {International} {Workshop} on {Information} {Forensics} and {Security} ({WIFS})},
	publisher = {IEEE},
	author = {Afchar, Darius and Nozick, Vincent and Yamagishi, Junichi and Echizen, Isao},
	month = dec,
	year = {2018},
	pages = {1--7},
}

@article{verdoliva_media_2020,
	title = {Media {Forensics} and {DeepFakes}: {An} {Overview}},
	volume = {14},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {1932-4553, 1941-0484},
	shorttitle = {Media {Forensics} and {DeepFakes}},
	url = {https://ieeexplore.ieee.org/document/9115874/},
	doi = {10.1109/JSTSP.2020.3002101},
	abstract = {With the rapid progress in recent years, techniques that generate and manipulate multimedia content can now provide a very advanced level of realism. The boundary between real and synthetic media has become very thin. On the one hand, this opens the door to a series of exciting applications in different fields such as creative arts, advertising, film production, and video games. On the other hand, it poses enormous security threats. Software packages freely available on the web allow any individual, without special skills, to create very realistic fake images and videos. These can be used to manipulate public opinion during elections, commit fraud, discredit or blackmail people. Therefore, there is an urgent need for automated tools capable of detecting false multimedia content and avoiding the spread of dangerous false information. This review paper aims to present an analysis of the methods for visual media integrity verification, that is, the detection of manipulated images and videos. Special emphasis will be placed on the emerging phenomenon of deepfakes, fake media created through deep learning tools, and on modern data-driven forensic methods to fight them. The analysis will help highlight the limits of current forensic tools, the most relevant issues, the upcoming challenges, and suggest future directions for research.},
	number = {5},
	urldate = {2025-10-27},
	journal = {IEEE Journal of Selected Topics in Signal Processing},
	author = {Verdoliva, Luisa},
	month = aug,
	year = {2020},
	pages = {910--932},
}

@inproceedings{sabir_recurrent_2019,
	title = {Recurrent convolutional strategies for face manipulation detection in videos},
	abstract = {The spread of misinformation through synthetically generated yet realistic images and videos has become a significant problem, calling for robust manipulation detection methods. Despite the predominant effort of detecting face manipulation in still images, less attention has been paid to the identification of tampered faces in videos by taking advantage of the temporal information present in the stream. Recurrent convolutional models are a class of deep learning models which have proven effective at exploiting the temporal information from image streams across domains. We thereby distill the best strategy for combining variations in these models along with domain specific face preprocessing techniques through extensive experimentation to obtain state-of-the-art performance on publicly available video-based facial manipulation benchmarks. Specifically, we attempt to detect Deepfake, Face2Face and FaceSwap tampered faces in video streams. Evaluation is performed on the recently introduced FaceForensics++ dataset, improving the previous state-of-the-art by up to 4.55\% in accuracy.},
	booktitle = {Proceedings of the {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} {Workshops}},
	author = {Sabir, Essa and Cheng, Weidi and Jaiswal, Abhinav and AbdAlmageed, Wael and Masi, Iacopo and Natarajan, Prem},
	year = {2019},
	pages = {1--9},
}

@inproceedings{rossler_faceforensics_2019,
	address = {Seoul, Korea (South)},
	title = {{FaceForensics}++: {Learning} to {Detect} {Manipulated} {Facial} {Images}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	isbn = {9781728148038},
	shorttitle = {{FaceForensics}++},
	url = {https://ieeexplore.ieee.org/document/9010912/},
	doi = {10.1109/ICCV.2019.00009},
	abstract = {The rapid progress in synthetic image generation and manipulation has now come to a point where it raises significant concerns for the implications towards society. At best, this leads to a loss of trust in digital content, but could potentially cause further harm by spreading false information or fake news. This paper examines the realism of state-of-the-art image manipulations, and how difficult it is to detect them, either automatically or by humans. To standardize the evaluation of detection methods, wepropose an automated benchmark for facial manipulation detection. In particular, the benchmark is based on DeepFakes, Face2Face [59], FaceSwap and NeuralTextures as prominent representatives for facial manipulations at random compression level and size. The benchmark is publicly available and contains a hidden test set as well as a database of over 1.8 million manipulated images. This dataset is over an order of magnitude larger than comparable, publicly available, forgery datasets. Based on this data, we performed a thorough analysis of data-driven forgery detectors. We show that the use of additional domain-specific knowledge improves forgery detection to unprecedented accuracy, even in the presence of strong compression, and clearly outperforms human observers.},
	urldate = {2025-10-27},
	booktitle = {2019 {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	publisher = {IEEE},
	author = {Rössler, Andreas and Cozzolino, Davide and Verdoliva, Luisa and Riess, Christian and Thies, Justus and Nießner, Matthias},
	month = oct,
	year = {2019},
	pages = {1--11},
}

@incollection{novais_adaptive_2025,
	address = {Cham},
	title = {Adaptive {Vehicle} {Detection} in {Urban} {Environments}: {A} {Self}-learning {Approach}},
	volume = {1279},
	isbn = {9783031831164 9783031831171},
	shorttitle = {Adaptive {Vehicle} {Detection} in {Urban} {Environments}},
	url = {https://link.springer.com/10.1007/978-3-031-83117-1_3},
	abstract = {With increasing urbanization, efficient urban traffic management is a critical challenge that requires smarter and more adaptable systems. This paper introduces a self-learning algorithm designed to enhance the adaptability and effectiveness of vehicle detection models using urban camera infrastructures. By leveraging these ubiquitous devices, the study aims to capture and analyze real-time traffic data, a task traditionally limited by the need for extensive manual data labeling and the limitations of pre-trained models under varying urban conditions. Our self-learning algorithm addresses these challenges by reducing reliance on manual labeling and enabling continuous model adaptation to new conditions without direct human intervention. Implemented in the dynamic urban environment of the city of Madrid, Spain, this study evaluates the algorithm’s capacity to enhance vehicle detection, considering a diverse range of vehicle types. The core of the algorithm comprises an iterative self-training process that refines model performance using both labeled and unlabeled data, thus progressively enhancing detection accuracy. Our findings reveal significant improvements in the ability of the model to accurately identify and classify vehicles, highlighting the potential of self-learning algorithms in urban traffic management.},
	language = {en},
	urldate = {2025-10-27},
	booktitle = {Ambient {Intelligence} – {Software} and {Applications} – 15th {International} {Symposium} on {Ambient} {Intelligence}},
	publisher = {Springer Nature Switzerland},
	author = {Guerrero-Contreras, Gabriel and Balderas-Díaz, Sara and García-Pascual, Abel and Muñoz, Andrés},
	editor = {Novais, Paulo and B. D., Parameshachari and Satoh, Ichiro and Inglada, Vicente Julian and González, Sara Rodríguez and Jove Pérez, Esteban and Parra Domínguez, Javier and Chamoso, Pablo and Alonso, Ricardo S.},
	year = {2025},
	doi = {10.1007/978-3-031-83117-1_3},
	pages = {25--34},
}

@inproceedings{anshul_intra-modal_2025,
	title = {Intra-modal and {Cross}-modal {Synchronization} for {Audio}-visual {Deepfake} {Detection} and {Temporal} {Localization}},
	abstract = {Recent deepfake detection algorithms focus solely on
uni-modal or cross-modal inconsistencies. While the former disregards audio-visual correspondence entirely rendering them less effective against multimodal attacks, the latter overlooks inconsistencies in a particular modality. Moreover, many models are single-stage supervised frameworks, effective on specific training data but less generalizable to new manipulations. To address these gaps, we propose a two-stage multimodal framework that first learns intra-modal and cross-modal temporal synchronization on real videos, capturing audio-visual correspondences crucial for deepfake detection and localization. We introduce a Gaussian-targeted loss in our pretraining model to focus on learning relative synchronization patterns across multimodal pairs. Using pretrained features, our approach not only enables classification on fully manipulated videos but also supports a localization module for partial deepfakes with only specific segments spoofed. Moreover, the pretraining stage does not require fine-tuning, thus reducing complexity. Our model, tested on various benchmark datasets, demonstrates strong generalization and precise temporal localization.},
	booktitle = {Proceedings of the {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	author = {Anshul, Ashutosh and Gopal, Shreyas and Rajan, Deepu and Chng, Eng Siong},
	month = oct,
	year = {2025},
	pages = {13826--13836},
}

@inproceedings{guera_deepfake_2018,
	address = {Auckland, New Zealand},
	title = {Deepfake {Video} {Detection} {Using} {Recurrent} {Neural} {Networks}},
	isbn = {978-1-5386-9294-3},
	url = {https://ieeexplore.ieee.org/document/8639163/},
	doi = {10.1109/AVSS.2018.8639163},
	abstract = {In recent months a machine-learning-based free software tool has made it easy to create believable face swaps in videos that leave few traces of manipulation, in what are known as “deepfake” videos. Scenarios where these realistic fake videos are used to create political distress, blackmail someone, or fake terrorism events are easily envisioned. This paper proposes a temporal-aware pipeline to automatically detect deepfake videos. Our system uses a convolutional neural network (CNN) to extract frame-level features. These features are then used to train a recurrent neural network (RNN) that learns to classify whether a video has been subject to manipulation or not. We evaluate our method against a large set of deepfake videos collected from multiple video websites. We show how our system can achieve competitive results in this task while using a simple architecture.},
	urldate = {2025-06-10},
	booktitle = {2018 15th {IEEE} {International} {Conference} on {Advanced} {Video} and {Signal} {Based} {Surveillance} ({AVSS})},
	publisher = {IEEE},
	author = {Güera, David and Delp, Edward J.},
	month = nov,
	year = {2018},
	pages = {1--6},
}

@article{guerrero-contreras_self-learning_2024,
	title = {Self-{Learning} {Systems} for {Enhanced} {Traffic} {Management} in {Urban} {Settings}},
	copyright = {Creative Commons Attribution 4.0 International},
	url = {https://zenodo.org/doi/10.5281/zenodo.11917270},
	doi = {10.5281/ZENODO.11917270},
	abstract = {With increasing urbanization, efficient urban traffic management is a critical challenge that requires smarter and more adaptable systems. This paper introduces a self-learning algorithm designed to enhance the adaptability and effectiveness of vehicle detection models using urban camera infrastructures. By leveraging these ubiquitous devices, the study aims to capture and analyze real-time traffic data, a task traditionally limited by the need for extensive manual data labeling and the limitations of pre-trained models under varying urban conditions. Our self-learning algorithm addresses these challenges by reducing reliance on manual labeling and enabling continuous model adaptation to new conditions without direct human intervention. Implemented in the dynamic urban environment of the city of Madrid, Spain, this study evaluates the algorithm’s capacity to enhance vehicle detection, considering a diverse range of vehicle types. The core of the algorithm comprises an iterative self-training process that refines model performance using both labeled and unlabeled data, thus progressively enhancing detection accuracy. Our findings reveal significant improvements in the ability of the model to accurately identify and classify vehicles, highlighting the potential of self-learning algorithms in urban traffic management.},
	language = {enc},
	urldate = {2025-11-28},
	author = {Guerrero-Contreras, Gabriel and Balderas-Díaz, Sara and García-Pascual, Abel and Munõz, Andrés},
	month = jun,
	year = {2024},
}

@article{hazirbas_towards_2022,
	title = {Towards {Measuring} {Fairness} in {AI}: {The} {Casual} {Conversations} {Dataset}},
	volume = {4},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {2637-6407},
	shorttitle = {Towards {Measuring} {Fairness} in {AI}},
	url = {https://ieeexplore.ieee.org/document/9634168/},
	doi = {10.1109/TBIOM.2021.3132237},
	abstract = {This paper introduces a novel dataset to help researchers evaluate their computer vision and audio models for accuracy across a diverse set of ages, genders, apparent skin tones and ambient lighting conditions. Our dataset is composed of 3,011 subjects and contains over 45,000 videos, with an average of 15 videos per person. The videos were recorded in multiple U.S. states with a diverse set of adults in various age, gender and apparent skin tone groups. A key feature is that each subject agreed to participate for their likenesses to be used. Additionally, our age and gender annotations are provided by the subjects themselves. A group of trained annotators labeled the subjects’ apparent skin tone using the Fitzpatrick skin type scale. Moreover, annotations for videos recorded in low ambient lighting are also provided. As an application to measure robustness of predictions across certain attributes, we provide a comprehensive study on the top five winners of the DeepFake Detection Challenge (DFDC). Experimental evaluation shows that the winning models are less performant on some specific groups of people, such as subjects with darker skin tones, and thus may not generalize to all people. In addition, we also evaluate state-of-the-art apparent age and gender classification methods. Our experiments provide a thorough analysis on these models in terms of fair treatment of people from various backgrounds.},
	number = {3},
	urldate = {2025-12-17},
	journal = {IEEE Transactions on Biometrics, Behavior, and Identity Science},
	author = {Hazirbas, Caner and Bitton, Joanna and Dolhansky, Brian and Pan, Jacqueline and Gordo, Albert and Ferrer, Cristian Canton},
	month = jul,
	year = {2022},
	pages = {324--332},
}

@inproceedings{levi_age_2015,
	address = {Boston, MA, USA},
	title = {Age and gender classification using convolutional neural networks},
	isbn = {9781467367592},
	url = {http://ieeexplore.ieee.org/document/7301352/},
	doi = {10.1109/CVPRW.2015.7301352},
	abstract = {Automatic age and gender classification has become relevant to an increasing amount of applications, particularly since the rise of social platforms and social media. Nevertheless, performance of existing methods on real-world images is still significantly lacking, especially when compared to the tremendous leaps in performance recently reported for the related task of face recognition. In this paper we show that by learning representations through the use of deep-convolutional neural networks (CNN), a significant increase in performance can be obtained on these tasks. To this end, we propose a simple convolutional net architecture that can be used even when the amount of learning data is limited. We evaluate our method on the recent Adience benchmark for age and gender estimation and show it to dramatically outperform current state-of-the-art methods.},
	urldate = {2025-12-17},
	booktitle = {2015 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} {Workshops} ({CVPRW})},
	publisher = {IEEE},
	author = {Levi, Gil and Hassner, Tal},
	month = jun,
	year = {2015},
	pages = {34--42},
}

@inproceedings{li_ictu_2018,
	address = {Hong Kong, Hong Kong},
	title = {In {Ictu} {Oculi}: {Exposing} {AI} {Created} {Fake} {Videos} by {Detecting} {Eye} {Blinking}},
	isbn = {9781538665367},
	shorttitle = {In {Ictu} {Oculi}},
	url = {https://ieeexplore.ieee.org/document/8630787/},
	doi = {10.1109/WIFS.2018.8630787},
	abstract = {The new developments in deep generative networks have significantly improved the quality and efficiency in generating realistically looking fake face videos. In this work, we describe a new method to expose fake face videos generated with deep neural network models. Our method is based on detection of eye blinking in the videos, which is a physiological signal that is not well presented in the synthesized fake videos. Our method is evaluated over benchmarks of eye-blinking detection datasets and shows promising performance on detecting videos generated with DNN-based software DeepFake.},
	urldate = {2025-10-27},
	booktitle = {2018 {IEEE} {International} {Workshop} on {Information} {Forensics} and {Security} ({WIFS})},
	publisher = {IEEE},
	author = {Li, Yuezun and Chang, Ming-Ching and Lyu, Siwei},
	month = dec,
	year = {2018},
	pages = {1--7},
}

@inproceedings{neekhara_adversarial_2021,
	address = {Nashville, TN, USA},
	title = {Adversarial {Threats} to {DeepFake} {Detection}: {A} {Practical} {Perspective}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	isbn = {9781665448994},
	shorttitle = {Adversarial {Threats} to {DeepFake} {Detection}},
	url = {https://ieeexplore.ieee.org/document/9522903/},
	doi = {10.1109/CVPRW53098.2021.00103},
	abstract = {Facially manipulated images and videos or DeepFakes can be used maliciously to fuel misinformation or defame individuals. Therefore, detecting DeepFakes is crucial to increase the credibility of social media platforms and other media sharing web sites. State-of-the art DeepFake detection techniques rely on neural network based classification models which are known to be vulnerable to adversarial examples. In this work, we study the vulnerabilities of state-of-the-art DeepFake detection methods from a practical stand point. We perform adversarial attacks on DeepFake detectors in a black box setting where the adversary does not have complete knowledge of the classification models. We study the extent to which adversarial perturbations transfer across different models and propose techniques to improve the transferability of adversarial examples. We also create more accessible attacks using Universal Adversarial Perturbations which pose a very feasible attack scenario since they can be easily shared amongst attackers. We perform our evaluations on the winning entries of the DeepFake Detection Challenge (DFDC) and demonstrate that they can be easily bypassed in a practical attack scenario by designing transferable and accessible adversarial attacks.},
	urldate = {2025-12-17},
	booktitle = {2021 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} {Workshops} ({CVPRW})},
	publisher = {IEEE},
	author = {Neekhara, Paarth and Dolhansky, Brian and Bitton, Joanna and Ferrer, Cristian Canton},
	month = jun,
	year = {2021},
	pages = {923--932},
}

@article{rana_deepfake_2022,
	title = {Deepfake {Detection}: {A} {Systematic} {Literature} {Review}},
	volume = {10},
	copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2169-3536},
	shorttitle = {Deepfake {Detection}},
	url = {https://ieeexplore.ieee.org/document/9721302/},
	doi = {10.1109/ACCESS.2022.3154404},
	abstract = {Over the last few decades, rapid progress in AI, machine learning, and deep learning has resulted in new techniques and various tools for manipulating multimedia. Though the technology has been mostly used in legitimate applications such as for entertainment and education, etc., malicious users have also exploited them for unlawful or nefarious purposes. For example, high-quality and realistic fake videos, images, or audios have been created to spread misinformation and propaganda, foment political discord and hate, or even harass and blackmail people. The manipulated, high-quality and realistic videos have become known recently as Deepfake. Various approaches have since been described in the literature to deal with the problems raised by Deepfake. To provide an updated overview of the research works in Deepfake detection, we conduct a systematic literature review (SLR) in this paper, summarizing 112 relevant articles from 2018 to 2020 that presented a variety of methodologies. We analyze them by grouping them into four different categories: deep learning-based techniques, classical machine learning-based methods, statistical techniques, and blockchain-based techniques. We also evaluate the performance of the detection capability of the various methods with respect to different datasets and conclude that the deep learning-based methods outperform other methods in Deepfake detection.},
	urldate = {2025-12-17},
	journal = {IEEE Access},
	author = {Rana, Md Shohel and Nobi, Mohammad Nur and Murali, Beddhu and Sung, Andrew H.},
	year = {2022},
	pages = {25494--25513},
}

@article{tolosana_deepfakes_2020,
	title = {Deepfakes and beyond: {A} survey of face manipulation and fake detection},
	volume = {64},
	abstract = {The free access to large-scale public databases, together with the fast progress of deep learning techniques, in particular Generative Adversarial Networks, have led to the generation of very realistic fake content with its corresponding implications towards society in this era of fake news. This survey provides a thorough review of techniques for manipulating face images including DeepFake methods, and methods to detect such manipulations. In particular, four types of facial manipulation are reviewed: i) entire face synthesis, ii) identity swap (DeepFakes), iii) attribute manipulation, and iv) expression swap. For each manipulation group, we provide details regarding manipulation techniques, existing public databases, and key benchmarks for technology evaluation of fake detection methods, including a summary of results from those evaluations. Among all the aspects discussed in the survey, we pay special attention to the latest generation of DeepFakes, highlighting its improvements and challenges for fake detection. In addition to the survey information, we also discuss open issues and future trends that should be considered to advance in the field.},
	journal = {Information Fusion},
	author = {Tolosana, Ruben and Vera-Rodriguez, Ruben and Fierrez, Julian and Morales, Aythami and Ortega-Garcia, Javier},
	year = {2020},
	pages = {131--148},
}

@inproceedings{yang_exposing_2019,
	address = {Brighton, United Kingdom},
	title = {Exposing {Deep} {Fakes} {Using} {Inconsistent} {Head} {Poses}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	isbn = {9781479981311},
	url = {https://ieeexplore.ieee.org/document/8683164/},
	doi = {10.1109/ICASSP.2019.8683164},
	abstract = {In this paper, we propose a new method to expose AI-generated fake face images or videos (commonly known as the Deep Fakes). Our method is based on the observations that Deep Fakes are created by splicing synthesized face region into the original image, and in doing so, introducing errors that can be revealed when 3D head poses are estimated from the face images. We perform experiments to demonstrate this phenomenon and further develop a classification method based on this cue. Using features based on this cue, an SVM classifier is evaluated using a set of real face images and Deep Fakes.},
	urldate = {2025-10-27},
	booktitle = {{ICASSP} 2019 - 2019 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	publisher = {IEEE},
	author = {Yang, Xin and Li, Yuezun and Lyu, Siwei},
	month = may,
	year = {2019},
	pages = {8261--8265},
}

@inproceedings{zhang_panda_2014,
	title = {{PANDA}: {Pose} aligned networks for deep attribute modeling},
	abstract = {We propose a method for inferring human attributes
(such as gender, hair style, clothes style, expression, action) from images of people under large variation of viewpoint, pose, appearance, articulation and occlusion. Convolutional Neural Nets (CNN) have been shown to perform very well on large scale object recognition problems. In the context of attribute classification, however, the signal is often subtle and it may cover only a small part of the image, while the image is dominated by the effects of pose and viewpoint. Discounting for pose variation would require training on very large labeled datasets which are not presently available. Part-based models, such as poselets and DPM have been shown to perform well for this problem but they are limited by shallow low-level features. We propose a new method which combines part-based models and deep learning by training pose-normalized CNNs. We show substantial improvement vs. state-of-the-art methods on challenging attribute classification tasks in unconstrained settings. Experiments confirm that our method outperforms both the best part-based methods on this problem and conventional CNNs trained on the full bounding box of the person.},
	booktitle = {Proceedings of the {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Zhang, Ning and Paluri, Manohar and Ranzato, Marc'Aurelio and Darrell, Trevor and Bourdev, Lubomir},
	year = {2014},
	pages = {1637--1644},
}

@inproceedings{durall_watch_2020,
	title = {Watch {Your} {Up}-{Convolution}: {CNN} {Based} {Generative} {Deep} {Neural} {Networks} {Are} {Failing} to {Reproduce} {Spectral} {Distributions}},
	doi = {10.1109/CVPR42600.2020.00791},
	abstract = {Generative convolutional deep neural networks, e.g. popular GAN architectures, are relying on convolution based up-sampling methods to produce non-scalar outputs like images or video sequences. In this paper, we show that common up-sampling methods, i.e. known as up-convolution or transposed convolution, are causing the inability of such models to reproduce spectral distributions of natural training data correctly. This effect is independent of the underlying architecture and we show that it can be used to easily detect generated data like deepfakes with up to 100{\textbackslash}\% accuracy on public benchmarks. To overcome this drawback of current generative models, we propose to add a novel spectral regularization term to the training optimization objective. We show that this approach not only allows to train spectral consistent GANs that are avoiding high frequency errors. Also, we show that a correct approximation of the frequency spectrum has positive effects on the training stability and output quality of generative networks.},
	booktitle = {2020 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Durall, Ricard and Keuper, Margret and Keuper, Janis},
	year = {2020},
	keywords = {Convolution, Distortion, Gallium nitride, Generative adversarial networks, Neural networks, Training},
	pages = {7887--7896},
}

@misc{dolhansky_deepfake_2020,
	title = {The {DeepFake} {Detection} {Challenge} ({DFDC}) {Dataset}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2006.07397},
	doi = {10.48550/ARXIV.2006.07397},
	abstract = {Deepfakes are a recent off-the-shelf manipulation technique that allows anyone to swap two identities in a single video. In addition to Deepfakes, a variety of GAN-based face swapping methods have also been published with accompanying code. To counter this emerging threat, we have constructed an extremely large face swap video dataset to enable the training of detection models, and organized the accompanying DeepFake Detection Challenge (DFDC) Kaggle competition. Importantly, all recorded subjects agreed to participate in and have their likenesses modified during the construction of the face-swapped dataset. The DFDC dataset is by far the largest currently and publicly available face swap video dataset, with over 100,000 total clips sourced from 3,426 paid actors, produced with several Deepfake, GAN-based, and non-learned methods. In addition to describing the methods used to construct the dataset, we provide a detailed analysis of the top submissions from the Kaggle contest. We show although Deepfake detection is extremely difficult and still an unsolved problem, a Deepfake detection model trained only on the DFDC can generalize to real "in-the-wild" Deepfake videos, and such a model can be a valuable analysis tool when analyzing potentially Deepfaked videos. Training, validation and testing corpuses can be downloaded from https://ai.facebook.com/datasets/dfdc.},
	urldate = {2025-12-18},
	publisher = {arXiv},
	author = {Dolhansky, Brian and Bitton, Joanna and Pflaum, Ben and Lu, Jikuo and Howes, Russ and Wang, Menglin and Ferrer, Cristian Canton},
	year = {2020},
	keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, Machine Learning (cs.LG)},
}

@inproceedings{amerini_deepfake_2019,
	address = {Seoul, Korea (South)},
	title = {Deepfake {Video} {Detection} through {Optical} {Flow} {Based} {CNN}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	isbn = {9781728150239},
	url = {https://ieeexplore.ieee.org/document/9022558/},
	doi = {10.1109/ICCVW.2019.00152},
	abstract = {Recent advances in visual media technology have led to new tools for processing and, above all, generating multi-media contents. In particular, modern AI-based technologies have provided easy-to-use tools to create extremely realistic manipulated videos. Such synthetic videos, named Deep Fakes, may constitute a serious threat to attack the reputation of public subjects or to address the general opinion on a certain event. According to this, being able to individuate this kind of fake information becomes fundamental. In this work, a new forensic technique able to discern between fake and original video sequences is given; unlike other state-of-the-art methods which resorts at single video frames, we propose the adoption of optical flow fields to exploit possible inter-frame dissimilarities. Such a clue is then used as feature to be learned by CNN classifiers. Preliminary results obtained on FaceForensics++ dataset highlight very promising performances.},
	urldate = {2025-10-27},
	booktitle = {2019 {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision} {Workshop} ({ICCVW})},
	publisher = {IEEE},
	author = {Amerini, Irene and Galteri, Leonardo and Caldelli, Roberto and Del Bimbo, Alberto},
	month = oct,
	year = {2019},
	pages = {1205--1207},
}

@misc{korshunov_deepfakes_2018,
	title = {{DeepFakes}: a {New} {Threat} to {Face} {Recognition}? {Assessment} and {Detection}},
	shorttitle = {{DeepFakes}},
	url = {http://arxiv.org/abs/1812.08685},
	doi = {10.48550/arXiv.1812.08685},
	abstract = {It is becoming increasingly easy to automatically replace a face of one person in a video with the face of another person by using a pre-trained generative adversarial network (GAN). Recent public scandals, e.g., the faces of celebrities being swapped onto pornographic videos, call for automated ways to detect these Deepfake videos. To help developing such methods, in this paper, we present the first publicly available set of Deepfake videos generated from videos of VidTIMIT database. We used open source software based on GANs to create the Deepfakes, and we emphasize that training and blending parameters can significantly impact the quality of the resulted videos. To demonstrate this impact, we generated videos with low and high visual quality (320 videos each) using differently tuned parameter sets. We showed that the state of the art face recognition systems based on VGG and Facenet neural networks are vulnerable to Deepfake videos, with 85.62\% and 95.00\% false acceptance rates respectively, which means methods for detecting Deepfake videos are necessary. By considering several baseline approaches, we found that audio-visual approach based on lip-sync inconsistency detection was not able to distinguish Deepfake videos. The best performing method, which is based on visual quality metrics and is often used in presentation attack detection domain, resulted in 8.97\% equal error rate on high quality Deepfakes. Our experiments demonstrate that GAN-generated Deepfake videos are challenging for both face recognition systems and existing detection methods, and the further development of face swapping technology will make it even more so.},
	urldate = {2025-12-17},
	publisher = {arXiv},
	author = {Korshunov, Pavel and Marcel, Sebastien},
	month = dec,
	year = {2018},
	note = {arXiv:1812.08685},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@misc{katamneni_contextual_2024,
	title = {Contextual {Cross}-{Modal} {Attention} for {Audio}-{Visual} {Deepfake} {Detection} and {Localization}},
	url = {http://arxiv.org/abs/2408.01532},
	doi = {10.48550/arXiv.2408.01532},
	abstract = {In the digital age, the emergence of deepfakes and synthetic media presents a significant threat to societal and political integrity. Deepfakes based on multi-modal manipulation, such as audio-visual, are more realistic and pose a greater threat. Current multi-modal deepfake detectors are often based on the attention-based fusion of heterogeneous data streams from multiple modalities. However, the heterogeneous nature of the data (such as audio and visual signals) creates a distributional modality gap and poses a significant challenge in effective fusion and hence multi-modal deepfake detection. In this paper, we propose a novel multi-modal attention framework based on recurrent neural networks (RNNs) that leverages contextual information for audio-visual deepfake detection. The proposed approach applies attention to multi-modal multi-sequence representations and learns the contributing features among them for deepfake detection and localization. Thorough experimental validations on audio-visual deepfake datasets, namely FakeAVCeleb, AV-Deepfake1M, TVIL, and LAV-DF datasets, demonstrate the efficacy of our approach. Cross-comparison with the published studies demonstrates superior performance of our approach with an improved accuracy and precision by 3.47\% and 2.05\% in deepfake detection and localization, respectively. Thus, obtaining state-of-the-art performance. To facilitate reproducibility, the code and the datasets information is available at https://github.com/vcbsl/audiovisual-deepfake/.},
	urldate = {2025-12-17},
	publisher = {arXiv},
	author = {Katamneni, Vinaya Sree and Rattani, Ajita},
	month = aug,
	year = {2024},
	note = {arXiv:2408.01532},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Multimedia, Computer Science - Sound, Electrical Engineering and Systems Science - Audio and Speech Processing},
}

@misc{beckmann_fooling_2023,
	title = {Fooling {State}-of-the-{Art} {Deepfake} {Detection} with {High}-{Quality} {Deepfakes}},
	url = {http://arxiv.org/abs/2305.05282},
	doi = {10.48550/arXiv.2305.05282},
	abstract = {Due to the rising threat of deepfakes to security and privacy, it is most important to develop robust and reliable detectors. In this paper, we examine the need for high-quality samples in the training datasets of such detectors. Accordingly, we show that deepfake detectors proven to generalize well on multiple research datasets still struggle in real-world scenarios with well-crafted fakes. First, we propose a novel autoencoder for face swapping alongside an advanced face blending technique, which we utilize to generate 90 high-quality deepfakes. Second, we feed those fakes to a state-of-the-art detector, causing its performance to decrease drastically. Moreover, we fine-tune the detector on our fakes and demonstrate that they contain useful clues for the detection of manipulations. Overall, our results provide insights into the generalization of deepfake detectors and suggest that their training datasets should be complemented by high-quality fakes since training on mere research data is insufficient.},
	urldate = {2025-10-27},
	publisher = {arXiv},
	author = {Beckmann, Arian and Hilsmann, Anna and Eisert, Peter},
	month = may,
	year = {2023},
	note = {arXiv:2305.05282},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{li_celeb-df_2020,
	address = {Seattle, WA, USA},
	title = {Celeb-{DF}: {A} {Large}-{Scale} {Challenging} {Dataset} for {DeepFake} {Forensics}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	isbn = {9781728171685},
	shorttitle = {Celeb-{DF}},
	url = {https://ieeexplore.ieee.org/document/9156368/},
	doi = {10.1109/CVPR42600.2020.00327},
	abstract = {AI-synthesized face-swapping videos, commonly known as DeepFakes, is an emerging problem threatening the trustworthiness of online information. The need to develop and evaluate DeepFake detection algorithms calls for datasets of DeepFake videos. However, current DeepFake datasets suffer from low visual quality and do not resemble DeepFake videos circulated on the Internet. We present a new large-scale challenging DeepFake video dataset, Celeb-DF, which contains 5,639 high-quality DeepFake videos of celebrities generated using improved synthesis process. We conduct a comprehensive evaluation of DeepFake detection methods and datasets to demonstrate the escalated level of challenges posed by Celeb-DF.},
	urldate = {2025-10-27},
	booktitle = {2020 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Li, Yuezun and Yang, Xin and Sun, Pu and Qi, Honggang and Lyu, Siwei},
	month = jun,
	year = {2020},
	pages = {3204--3213},
}

@article{guarnera_face_2022,
	title = {The {Face} {Deepfake} {Detection} {Challenge}},
	volume = {8},
	issn = {2313-433X},
	url = {https://www.mdpi.com/2313-433X/8/10/263},
	doi = {10.3390/jimaging8100263},
	abstract = {Multimedia data manipulation and forgery has never been easier than today, thanks to the power of Artificial Intelligence (AI). AI-generated fake content, commonly called Deepfakes, have been raising new issues and concerns, but also new challenges for the research community. The Deepfake detection task has become widely addressed, but unfortunately, approaches in the literature suffer from generalization issues. In this paper, the Face Deepfake Detection and Reconstruction Challenge is described. Two different tasks were proposed to the participants: (i) creating a Deepfake detector capable of working in an “in the wild” scenario; (ii) creating a method capable of reconstructing original images from Deepfakes. Real images from CelebA and FFHQ and Deepfake images created by StarGAN, StarGAN-v2, StyleGAN, StyleGAN2, AttGAN and GDWCT were collected for the competition. The winning teams were chosen with respect to the highest classification accuracy value (Task I) and “minimum average distance to Manhattan” (Task II). Deep Learning algorithms, particularly those based on the EfficientNet architecture, achieved the best results in Task I. No winners were proclaimed for Task II. A detailed discussion of teams’ proposed methods with corresponding ranking is presented in this paper.},
	language = {en},
	number = {10},
	urldate = {2025-10-27},
	journal = {Journal of Imaging},
	author = {Guarnera, Luca and Giudice, Oliver and Guarnera, Francesco and Ortis, Alessandro and Puglisi, Giovanni and Paratore, Antonino and Bui, Linh M. Q. and Fontani, Marco and Coccomini, Davide Alessandro and Caldelli, Roberto and Falchi, Fabrizio and Gennaro, Claudio and Messina, Nicola and Amato, Giuseppe and Perelli, Gianpaolo and Concas, Sara and Cuccu, Carlo and Orrù, Giulia and Marcialis, Gian Luca and Battiato, Sebastiano},
	month = sep,
	year = {2022},
	pages = {263},
}
