"Authors","Author full names","Author(s) ID","Title","Year","Link","Abstract","Author Keywords"
"Wang, S.; Zhang, H.; Yang, G.","Wang, Shuai (57432133200); Zhang, Hanling (13611757700); Yang, Gaobo (8647279200)","57432133200; 13611757700; 8647279200","Face forgery detection via identification of evident tampered regions and multi-view analysis","2026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105021883734&partnerID=40&md5=9d04c8c03aded5c6962fd1c1552f566a","In AI-synthesized faces, there usually exist prominent natural features, which pose a huge challenge for face forgery detection. In this work, we propose a Region-Aware Deep Neural Network (RDNN). RDNN calculates the tampering possibility of each face region based on the features learned from each region and selects the region with the highest tampering possibility as the detection result. Then, a new Latent Cue Capture Loss (LCCL) is designed to train RDNN to capture those fake face features ignored by traditional loss functions. Besides, by leveraging RDNN to locate forgeries, we propose a deepfake detection strategy namely RDNN-based Multi-Perspective Deepfake Detection (RMDD), to keep the advantages of RDNN while improving the detection robustness. Specifically, RMDD uses RDNN to locate suspected forgeries in the original and horizontally flipped faces, and mines local features in the vicinity of these suspected forgeries. Finally, the detection result is acquired by integrating the above detection clues. Ablation experiments verify the ability of RDNN to locate manipulated traces and the contribution of each component in RMDD. Moreover, experimental results demonstrate that RMDD has excellent detection accuracy and generalization ability. © 2025 Elsevier B.V.","Deepfake detection; Face forgery detection; Face manipulation detection; Image forensics"
"Rajesh, T.; Maruthupermal, S.","Rajesh, Tirupathi (60055683100); Maruthupermal, S. (60054258400)","60055683100; 60054258400","Generalizable deepfake detection framework using hybrid convolution-based EfficientNetB7 with attention mechanism","2026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013740842&partnerID=40&md5=87fa8f1e12c720047e82ef8f0c904675","The highly realistic fake videos have been created by the deepfake technology in recent years. The political and societal consequences occurred because of the misinformation disseminated by the fake videos. To prevent these issues, automated approaches for deep fake detection are necessary. The deep fake video is detected in this work using hybrid deep learning. The main contribution of the proposed research is to determine deepfakes from videos, which aims to avoid the spread of malicious rumours. The differences between the real and deepfake videos are effectively identified through this developed approach, as they utilize the different features from the facial landmarks along with the eye blinks for determining the sophisticated fakes from the authenticated visual contents. The required videos are collected from the public databases. The frames are extracted from the collected videos. The attained video frames are given to the facial landmark detection process, where the coordinates of the eyes, lips, and nose are extracted. From these detected facial landmarks, the texture features, shape features, and the number of eye blinks are obtained for better detection purposes. The extracted features are integrated with the optimized weights for attaining the weighted fused feature, where the Updated Random Parameter-aided Fennec Fox Optimization (URP-FFO) is used for tuning the weights optimally. Each frame of 1-dimensional data forms 2-dimensional original video frames, which are taken as feature set 1 from the weighted fused features. The 3-dimensional data from the facial images is considered as feature set 2. The attained features are given to the Hybrid 2D-3D Convolution-based EfficientNetB7 with Attention Mechanism (HC-EB7AM) for differentiating the real and fake videos. The manipulated contents are easily identified by this approach. Finally, several measures are used for validating the performance. The potential strength of the proposed model is validated by the experimentation with the accuracy of 93.66% using dataset 1 and 94.38% using dataset 2, respectively. © 2025 Elsevier Ltd","Deepfake detection; EfficientNetB7 with attention mechanism; Facial landmark extraction; Hybrid convolution network; Updated random parameter-based Fennec fox optimization; Video frames"
"Hou, S.; Jiang, X.; Xu, K.; Xu, Q.; Meng, L.; Sun, T.","Hou, Shijie (60057769500); Jiang, Xinghao (13607511800); Xu, Ke (57089521400); Xu, Qiang (57218658921); Meng, Laijin (57210134140); Sun, Tanfeng (59651207700)","60057769500; 13607511800; 57089521400; 57218658921; 57210134140; 59651207700","Normalization-consistent data curation for generalizable deepfake detection","2026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105020666904&partnerID=40&md5=a2bd3994fd07690f43eac4b3c0e0898b","Deepfake has recently garnered considerable attention due to its potential threat. Recent detectors often struggle to generalize due to sensitivity to dataset-specific biases. We identify a key factor: their performance varies significantly with different normalization parameters, indicating reliance on preprocessing artifacts rather than authentic manipulation traces. To address this, we propose Normalization-Consistent Data Curation (NormCura), which selects training samples based on their prediction stability across normalization variations. NormCura first evaluates sample consistency under multiple normalization conditions, then trains only on stable samples. This filters out normalization-sensitive artifacts while retaining robust forensic patterns. Extensive cross-dataset evaluations on nine deepfake datasets demonstrate that this approach significantly improves generalization performance, including emerging diffusion-based synthetic faces, confirming that normalization consistency is an effective proxy for learning generalizable deepfake detection features. © 2025","Data curation; Deepfake detection; Face forgery detection"
"Chen, J.; Che, X.; Li, Q.; Zhao, Q.","Chen, Jingfei (59449491500); Che, Xun (58891358300); Li, Qianmu (59675111200); Zhao, Qian (57188569902)","59449491500; 58891358300; 59675111200; 57188569902","Boosting Video Deepfake Detection via Quality-Aware and Multi-scale Audio-Visual Alignment","2026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105022974819&partnerID=40&md5=2a170b5a811600fb8c04350a408dc62e","Advances in deep generative models have made realistic audio-visual deepfakes increasingly common, leading to growing concerns about media authenticity. Although recent methods utilize the synchrony between speech and facial motion for detection, they often fail in real-world conditions where visual quality is degraded or forgeries display highly accurate audio-visual alignment. In this paper, we propose QM-AVAlign, a novel quality-aware and multi-scale audio-visual alignment framework for robust video deepfake detection. QM-AVAlign employs a visual quality assessment module to dynamically generate spatial reliability masks for each frame, emphasizing high-confidence visual cues while suppressing unreliable regions. Leveraging these quality-weighted visual features, we introduce a multi-scale cross-modal fusion strategy to simultaneously model global synchrony and fine-grained, physiologically grounded relationships between speech and facial expressions. Additionally, an uncertainty calibration loss is introduced, guiding the model to produce higher uncertainty scores when faced with ambiguous or low-quality samples. Extensive experiments on multiple public benchmarks demonstrate that QM-AVAlign achieves superior robustness and generalization under challenging conditions with visual impairments and advanced forgery techniques. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2026.","Audio-visual; Cross modal; Deepfake detection"
"Echchkaf, A.; Idrissi, N.","Echchkaf, Abdelghani (60209241200); Idrissi, N. (13907793900)","60209241200; 13907793900","Enhancing Fake News Detection: A Comparative Analysis of YIX and AI Methodologies for Image Classification","2026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105022830281&partnerID=40&md5=e88ec354e101232093e2e4bb993e376f","This article presents a comparative analysis of two methodologies for Fake News detection based on YIX and Our proposed model (AI). The YIX methodology integrates YOLO v3 for object detection, InceptionResNetV2 for feature extraction, and XGBoost for classification. In contrast, the AI (InceptionResNetV2 AdaBoost) methodology enhances the YIX approach by eliminating YOLO v3 to mitigate potential feature concealment issues, incorporating modified InceptionResNetV2 architecture with additional dropout and dense layers, and substituting XGBoost with AdaBoost for improved binary classification performance. The evaluation is conducted on two datasets: CatsandDogs, comprising images of two animal types, and Caleb-DF, containing over 20,000 images classified into real and fake classes. Each dataset consists of 5,000 images for testing purposes. Results demonstrate that the AI methodology yields superior performance compared to YIX. For the CatsandDogs dataset, ours achieves an accuracy of 0.99, specificity of 1, and recall of 0.98, whereas YIX achieves an accuracy of 0.94, specificity of 0.94, and recall of 0.94. Similarly, on the Celeb-DF dataset, AI achieves an accuracy of 0.91, specificity of 0.93, and recall of 0.88, surpassing YIX with an accuracy of 0.84, specificity of 0.85, and recall of 0.81. Notably, the AI model achieves 91% higher accuracy than YIX, indicating significant improvement in positive prediction accuracy. These findings underscore the effectiveness of the AI methodology in enhancing object detection and classification performance, particularly in scenarios involving complex image datasets. The results highlight the importance of methodological enhancements and algorithmic modifications in advancing the capabilities of computer vision systems. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2026.","AdaBoost; CelebD-F; Classification; CNN; Computer vision; dataset; Deep learning; Deepfake detection; Face recognition; Image processing; InceptionResNetV2; Object detection; XGBoost; YOLO"
"Huang, C.; Yang, R.; Lan, R.; Wu, Z.; Li, J.; Hu, T.","Huang, Chaoyi (59710033000); Yang, Rui (57215216214); Lan, Rushi (35146229200); Wu, Zhanghui (60199310600); Li, Jiahao (59710397200); Hu, Tengjie (60200097600)","59710033000; 57215216214; 35146229200; 60199310600; 59710397200; 60200097600","Spatially-Aware Framework for Sequential Deepfake Detection","2026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105022162210&partnerID=40&md5=3df4cf4f709f8d7c687ca94da7388b0a","With the rapid advancements in facial editing technologies, deepfake detection for multi-step continuous facial manipulation has emerged as a crucial research area in computer vision and visual security. Current state-of-the-art detection methods typically rely on traditional convolutional neural network (CNN) feature extractors, which struggle to capture fine-grained local manipulation traces, thereby limiting their detection performance in complex, continuous forgery scenarios. To address this challenge, this paper introduces a coordinate-based multi-scale strategy, MSCP-SeqFakeFormer. By incorporating coordinate positioning between the CNN feature extraction and Transformer encoder, the approach leverages multiple scales and receptive fields to effectively enhance local detail features associated with facial forgeries. This enhancement significantly improves the model’s ability to recognize manipulation types and their sequences. Experimental results on the publicly available Seq-DeepFake dataset demonstrate that the proposed method outperforms the baseline model in both fixed-length (Fixed-Acc) and adaptive-length (Adaptive-Acc) evaluation metrics, and also achieves superior performance in the facial image recovery task. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2026.","Deepfake Detection; Feature Enhancement; Multi-step Forgery; Seq-DeepFake Dataset"
"Patil, V.; Bhende, B.; Jadhav, O.; Shinde, G.; Moholkar, K.","Patil, Vedant (60162391200); Bhende, Bhargavi (60162500800); Jadhav, Omkar (60103886500); Shinde, Gitanjali Rahul (57201552548); Moholkar, K. P. (57202970293)","60162391200; 60162500800; 60103886500; 57201552548; 57202970293","Differentiating Between AI-Generated Faces and Human Faces","2026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105020240832&partnerID=40&md5=ad49f8dfb5de766e8c769abd3b46992c","The increasing realism of AI-generated faces, driven by advancements in generative adversarial networks (GANs) like StyleGAN and ProGAN, poses significant challenges in security, identity verification, and digital forensics. Current detection methods, primarily relying on convolutional neural networks (CNNs), struggle to identify subtle artifacts in high-quality synthetic imagery. This paper proposes a hybrid model combining Vision Transformers (ViTs) and XceptionNet in a soft-voting ensemble framework. ViT captures global spatial patterns, while XceptionNet excels in detecting localized texture inconsistencies. The ensemble achieves 92.3% accuracy, 92.5% precision, and an F1-score of 0.922 on a dataset of 188,800 real and AI-generated faces. Extensive experiments demonstrate the model’s robustness against diverse deepfake architectures, including those with minimal artifacts. This approach offers a state-of-the-art solution for differentiating real and AI-generated faces, with significant implications for fraud prevention, content moderation, and digital forensics. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2026.","AI-generated faces; Deep fake; Deep learning; Deepfake detection; Generative adversarial networks (GANs); Vision Transformers (ViTs); XceptionNet"
"Tiwari, R.; Agarwal, H.; Pant, R.; Singh, P.; Yadav, N.K.","Tiwari, Ramakant (60161399900); Agarwal, Himanshu (60161184200); Pant, Raghav (60161444800); Singh, Prabhat (59395934400); Yadav, Nand Kishor (60161271000)","60161399900; 60161184200; 60161444800; 59395934400; 60161271000","Real vs Synthetic Face Detection Using AI And rPPG Technology","2026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105020168314&partnerID=40&md5=73a475aa5eff79feebe596d774730c8a","In recent years, we have seen an exponential increase in the exposure of synthetic face videos on the Internet. This surge poses several serious risks, including threats to the authenticity of digital content and the facilitation of misinformation and identity-related fraud. The currently existing methods to identify these deepfakes are significantly less effective against the newly developed synthetic faces implemented with advanced technologies. Therefore, we introduce this work, which will work flawlessly in identifying synthetic faces and differentiating the content as authentic or fake. Real humans exhibit synchronized biological rhythms. Utilizing this fact, we have trained a model that can extract these rhythms, and their absence can be used for identifying synthetic faces. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2026.","AI-generated Videos; Deepfake detection; Remote Photoplethysmography; Synthetic Face Detection; Synthetic Faces"
"Deng, L.; Wu, B.; Wang, J.","Deng, Liwei (51663261700); Wu, Boda (59654133600); Wang, Jiandong (58168684200)","51663261700; 59654133600; 58168684200","A multi-label classification method combined with texture enhancement for deepfake face detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105018575193&partnerID=40&md5=466e5f3cf3079fd8e4442da551f3edc8","As deepfake technology continues to evolve, existing techniques can manipulate specific regions such as facial components, and the small forgery area makes forgery more difficult to detect. Therefore, deepfake detection technology cannot be limited to real and fake face detection methods based on binary classification. To enable fine-grained detection of facial component forgeries, we propose a detection approach leveraging multi-label classification to simultaneously identify deepfake labels across various facial components. We first process the facial components manipulation dataset using a data augmentation method with information deletion to enrich the dataset with more varied samples. The texture feature enhancement module is also used to enhance the forged traces in the shallow features and enhance the network’s capability in identifying manipulation artifacts. We then apply Asymmetric Polynomial Loss (APL) to address the issue of label imbalance within the dataset. Experimental evaluation demonstrates that our method reaches a mAP of 92.08 and a mAUC of 89.23, effectively supporting precise detection of facial forgery traces. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2025.","Deepfake detection; Fine-grained detection; Multi-label classification; Texture feature enhancement"
"Singh, S.; Dhumane, A.","Singh, Sonam (57723967400); Dhumane, Amol V. (57190257788)","57723967400; 57190257788","Unmasking digital deceptions: An integrative review of deepfake detection, multimedia forensics, and cybersecurity challenges","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105017848056&partnerID=40&md5=5d76c7be8044417f71f33ae5decc4fd2","Deepfakes, which are driven by developments in generative AI, seriously jeopardize public trust, cybersecurity, and the veracity of information. This study offers a comprehensive analysis of the most recent methods for creating and detecting deepfakes in image, video, and audio modalities. With a focus on their advantages and disadvantages in cross-dataset and real-world scenarios, we compile the latest developments in transformer-based detection models, multimodal biometric defenses, and Generative Adversarial Networks (GANs). We provide implementation-level information such as pseudocode workflows, hyperparameter settings, and preprocessing pipelines for popular detection frameworks to improve reproducibility. We also examine the implications of cybersecurity, including identity theft and biometric spoofing, as well as policy-oriented solutions that incorporate federated learning, explainable AI, and ethical protections. By enriching technical insights with interdisciplinary perspectives, this review charts a roadmap for building robust, scalable, and trustworthy deepfake detection systems. © 2025 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license. http://creativecommons.org/licenses/by/4.0/","AI policy frameworks; Cross-dataset evaluation; Cyber security threats; Deepfake detection; Digital deception; Ethical AI; Explainable AI; Face synthesis; Federated learning; Generative adversarial networks (GANs); Identity theft; Multimedia forensics; Speech cloning; Synthetic media, biometric spoofing"
"Alkishri, W.; Yousif, J.H.; Al-Bahri, M.; Zakarya, M.; Khan, N.; Al-Maskari, S.S.; Gürhanli, A.","Alkishri, Wasin (57559807700); Yousif, Jabar H. (37035566000); Al-Bahri, Mahmood (57196049414); Zakarya, Muhammad (55546416300); Khan, Naveed (57026903700); Al-Maskari, Sanad (51664541900); Gürhanli, Ahmet (25824305200)","57559807700; 37035566000; 57196049414; 55546416300; 57026903700; 51664541900; 25824305200","A comparative study of deepfake facial manipulation technique using generative adversarial networks","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008207081&partnerID=40&md5=4a67c9defe7d2cd22945384cf6bc7b43","The manipulation of digital images has become a popular trend. Due to the development of image processing tools and visualization techniques integrating deep learning and artificial intelligence (AI) algorithms (in particular generative adversarial networks–GAN), this can pose serious threats to privacy and security. In recent years, Deepfake algorithms have been designed to exchange faces or modify facial features, potentially leading to more severe problems in this context. In this manuscript, we provide a comprehensive review of the two most important facial image processing technologies: (i) deepfake face manipulation; and (ii) face manipulation detection techniques. Furthermore, we explore the state-of-the-art of popular GAN techniques. In particular, three types of Deepfake face detection technologies are reviewed: (i) hand-crafted features (ii) artifacts; and (iii) learning-based features, while highlighting related improvements and challenges. Furthermore, this article discusses potential challenges and promising research directions for future investigation. We believe that this review has been organized to provide a structured analysis of important research papers and to discuss each study’s main findings and conclusions. Our investigation reveals shortcomings in manipulation detection benchmarks due to real-world scenario variations and biased dataset comparisons. Current research priorities revolve around enhancing GAN training stability, resolution, and manipulable facial features. Moreover, GANs have shown superior results in identifying fake images; however, their reliance prompts a systematic approach to detecting fakes. This dependency raises questions about detecting fake images with or without manipulated GAN architecture, urging the need for novel computational techniques to identify manipulations without GAN assistance. © Crown 2025.","Artifacts; Deepfake; Deepfake detection; Deepfake generation; GAN applications; GANs"
"Ghosh, T.","Ghosh, Tanusree (58722055200)","58722055200","Exploring the Janus Face of Synthetic Images: From Privacy-secure Biometrics Applications to Deepfake Detection for Misinformation-Free Social Networks","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105023873240&partnerID=40&md5=d85c52875f1026c91c91645fa9a52f0b","The rise of generative AI presents a profound duality, or a “Janus Face,” for digital society. On one hand, its ability to synthesize hyper-realistic faces offers a powerful solution to long-standing privacy and data scarcity challenges in biometric systems-a promising but underexplored application. On the other hand, this same technology is weaponized to create 'deepfakes' that fuel misinformation campaigns on Online Social Networks (OSNs), posing a significant threat to digital integrity. However, countering this threat is hampered by critical failures in existing deepfake detectors. They are often: (i) Brittle in the Wild: They prove vulnerable to the compression and post-processing artifacts introduced by OSNs. (ii) Poorly Generalizable: They fail to detect forgeries from new or unseen generative models. (iii) Computationally Inefficient: Many state-of-the-art models are too parameter-heavy for practical deployment on resource-constrained devices. This dissertation confronts this duality by addressing both sides of the coin. First, it examines the “substitutability” of synthetic face data, demonstrating that biometric classifiers (e.g., Age, Gender etc.) trained on AI-generated faces can match or even exceed the generalization performance of those trained on real face data. Second, to counter the malicious use of this technology, this dissertation develops a framework of deepfake detectors designed to be robust, generalizable, and efficient by construction. My work introduces novel, lightweight feature sets on different cues (e.g., colour cue-based Relative Chrominance Difference, Gradient features, Depth cues etc.) that are inherently resilient to OSN transformations and improve generalization to unseen forgeries. Preliminary results confirm state-of-the-art performance, achieving high accuracy in challenging real-world scenarios with a significant reduction in model complexity. © 2025 Copyright held by the owner/author(s).","biometric fairness; deepfake detection; diffusion models; synthetic media"
"Heo, M.; Woo, S.S.","Heo, Minji (59368326300); Woo, Simon S. (57202046772)","59368326300; 57202046772","FakeChain: Exposing Shallow Cues in Multi-Step Deepfake Detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105023141448&partnerID=40&md5=f2a36e491ff5d884564e8376b532530a","Multi-step or hybrid deepfakes, created by sequentially applying different deepfake creation methods such as Face-Swapping, GAN-based generation, and Diffusion methods, can pose an emerging and unforseen technical challenge for detection models trained on single-step forgeries. While prior studies have mainly focused on detecting isolated single manipulation, little is known about the detection model behavior under such compositional, hybrid, and complex manipulation pipelines. In this work, we introduce FakeChain, a large-scale benchmark comprising 1-, 2-, and 3-Step forgeries synthesized using five state-of-the-art representative generators. Using this approach, we analyze detection performance and spectral properties across hybrid manipulation at different step, along with varying generator combinations and quality settings. Surprisingly, our findings reveal that detection performance highly depends on the final manipulation type, with F1-score dropping by up to 58.83% when it differs from training distribution. This clearly demonstrates that detectors rely on last-stage artifacts rather than cumulative manipulation traces, limiting generalization. Such findings highlight the need for detection models to explicitly consider manipulation history and sequences. Our results highlight the importance of benchmarks such as FakeChain, reflecting growing synthesis complexity and diversity in real-world scenarios. Our sample code is available here. https://github.com/minjihh/FakeChain. © 2025 Copyright held by the owner/author(s).","deepfake detection; multi-step manipulation; multimedia forensics"
"Ghosh, T.; Naskar, R.","Ghosh, Tanusree (58722055200); Naskar, Ruchira (53866980700)","58722055200; 53866980700","Multi-level feature fusion for generalized face forgery detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013129555&partnerID=40&md5=2ffa5a0bd26566d13f338254db80d56e","With the meteoric rise of AI-based face forgery techniques, colloquially known as ‘Deepfakes’, the research community faces a huge challenge in designing detection tools that offer high detection accuracy, strong generalization and compact architectures for deployment on resource-constrained devices. In this paper, we introduce a novel Multi-Level Feature Fusion (MLFF) framework that employs a lightweight yet effective strategy for capturing artifacts across multiple resolutions, using a backbone network, enhanced by a Spatial Feature Selection Module (SFSM), and integrating these representations via a Feature Fusion Network (FFN), finally followed by a classification head for classification. We explore two pre-trained backbones—a CNN-based EfficientNet and a lightweight Swin Transformer, and demonstrate that our method not only surpasses SOTA approaches on the FaceForensics++ and FaceShifter benchmarks in terms of classification accuracy and AUC, but also exhibits superior generalization capabilities for cross-data set and cross-manipulation scenarios, while achieving more than 50 % model parameters reduction compared to current best-performing models, making it ideal for deployment in resource-limited environments. © 2025 Elsevier B.V.","AI-image; AI-video; Deepfake detection; Face forgery; Fake face; GAN image detection; Generalization; Image forensics"
"Bhuvaneswari, T.; Chandra Guru Sekar, R.; Shiva Raama Krishna, K.; Nishaal, S.R.; Arun Kumar, M.","Bhuvaneswari, T. (59692412000); Chandra Guru Sekar, R. (56938693000); Shiva Raama Krishna, K. (60110502300); Nishaal, S. R. (60110502400); Arun Kumar, M. (60110455300)","59692412000; 56938693000; 60110502300; 60110502400; 60110455300","Detection of Deepfake Videos in Social Networks","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016781434&partnerID=40&md5=aa4063b8019ffa90036c3c9361d8a91f","Now a days, Deepfake video is one of the major threats in social media platform. Deepfake videos of celebrities, politicians, and ordinary people spread false information, including of a devastating nature. Not only does it spoil their fame and sometimes leads to suicide. In order to save their good fame and life, developing detection methods is necessary. In the recent development of technology on communication systems, for reducing storage space, they are sharing compressed videos. Due to these advancements, video forensic departments find it more difficult to search for the originality of the videos. It cannot be stopped spreading of the information, but one can provide a solution to find the originality of the videos. To address this problem, a Robust Deepfake Video Detection (RDVD) method is proposed for compressive deepfake video detection using deep learning models such as Gated Recurrent Units (GRU) and Stochastic Gradient Descent (SGD), respectively. Additionally, we improve the detection by utilizing the Dempster-Shafer theory of fusion on outputs from the above two models. The FaceForensics++ dataset is utilized for experimentation. The dataset contains five kinds of Deepfake videos(Deepfake, Face2Face, FaceSwap, Neural Textures, FaceShifter) and original version of the Deepfake videos. The proposed model utilizes this dataset for model construction. The performance of the model is validated using various performance metrics. Our proposed method achieves promising detection results, with accuracies of 83.75% for Deepfake, 80.25% for Face2Face, 82.50% for FaceSwap, 81.66% for Neural Textures, and 79.75% for FaceShifter. In addition to accuracy, other evaluation metrics such as precision, recall, and F1-score were also measured, with the method consistently delivering better results compared to existing state-of-the-art techniques. © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2025.","Compressed Deepfake Videos; Deepfake detection; Dempster-Shafer Fusion; FaceForensics++; False Information; GRU; Identity Theft; SGD"
"Jiang, P.; Lei, B.; Sun, Y.; Yu, L.; Chen, Z.; Xie, H.; Zhang, Y.","Jiang, Peiqi (59184662300); Lei, Bohan (57202496239); Sun, Yuhao (59156296000); Yu, Lingyun (56879585300); Chen, Zhineng (36170296000); Xie, Hongtao (57215374594); Zhang, Yongdong (55902721000)","59184662300; 57202496239; 59156296000; 56879585300; 36170296000; 57215374594; 55902721000","Proactive Deepfake Detection via Self-Verifiable Semantic Watermarking","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105024074242&partnerID=40&md5=e2ba724cf9211d53c28e47d2d74dc2a1","Malicious Deepfakes pose serious security risks by producing highly realistic forged faces. While numerous countermeasures have been developed to train binary Deepfake classifiers, their limited generalization capacity restricts practical deployment. To proactively defend against Deepfakes, we propose SVS-WM, a Self-Verifiable Semantic Watermarking strategy. The core idea behind SVS-WM is to embed pairs of correlated watermarks within facial semantics, leveraging the inherent fragility of these features, i.e., any semantic modification will disrupt the watermark correlation, thereby enabling robust Deepfake detection. SVS-WM employs a facial semantic disentanglement and reconstruction network, allowing semi-fragile watermarks to be embedded concurrently across multiple semantic levels, including identity and multi-levels of attributes. Specifically, pairs of pseudo-random noise watermarks are adaptively injected into facial attribute and identity features. During propagation stage, the protected image may encounter identity or facial attributes manipulations, we then detect Deepfakes by verifying the correlation result between the decoded attribute watermark and the extracted identity vector. This unique cross-verification mechanism enables authentication without requiring original reference watermark, thereby realizing blind Deepfake detection. Extensive experiments validate the effectiveness of our approach, achieving an average detection accuracy of 98.19% across diverse Deepfake manipulations. © 2025 ACM.","deepfake detection; digital watermark"
"Wang, C.; Ma, W.; Zou, L.; Xia, Z.; Li, Q.; Ma, B.; Liu, Y.","Wang, Chunpeng (55318994100); Ma, Wenlong (60227582300); Zou, Li (15066308900); Xia, Zhiqiu (57188991071); Li, Qi (57204177824); Ma, Bin (57204589541); Liu, Yunan (56604552600)","55318994100; 60227582300; 15066308900; 57188991071; 57204177824; 57204589541; 56604552600","Toward Robust Deepfake Detection: A Proactive Method Based on Watermarking and Knowledge Distillation","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105024071370&partnerID=40&md5=4e5d8b9f7a86888832cc1be80477b5d4","Face deepfake detection is a critical technology for verifying the authenticity of facial media content and has long been a focal point in multimedia forensics. However, existing methods face significant challenges, primarily due to their limited ability to generalize across domains. Consequently, the growing variety of forgery techniques, combined with the degradation of visual quality in forged images, makes reliable detection even more difficult. To address these challenges, we propose WKD, a proactive deepfake detection framework based on Watermarking and Knowledge Distillation. The key insights of WKD are twofold: First, we embed watermark information into the Fractional-order Quaternion Radial Harmonic Fourier Moments (FrQRHFMs) space of the host image, achieving a robust balance between imperceptibility and robustness. Second, we design a dual-task learning framework consisting of a watermark extractor and a forgery discriminator, where learnable Low-Rank Adaptation (LoRA) layers are used to transfer knowledge from the extractor to the discriminator, thereby providing additional clues for deepfake detection. Specifically, the integrity of the watermark is compromised only when the host image undergoes a deepfake forgery, while it remains unaffected by conventional attacks. Experimental results on benchmark datasets demonstrate that WKD achieves state-of-the-art performance in both intra-domain and cross-domain deepfake detection, particularly when images are subjected to various conventional attacks. © 2025 ACM.","fractional-order quaternion radial harmonic fourier moments; low-rank adaptation; proactive deepfake detection"
"Lai, Y.; Wang, H.; Yang, J.; Kang, X.; Li, B.; Shen, L.; Yu, Z.","Lai, Yingxin (59438905900); Wang, Hongyang (58897793000); Yang, Jing (59639487600); Kang, Xiangui (7102354750); Li, Bin (57102112000); Shen, Linlin (7401704647); Yu, Zitong (57210955519)","59438905900; 58897793000; 59639487600; 7102354750; 57102112000; 7401704647; 57210955519","GM-DF: Generalized Multi-Scenario Deepfake Detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105024066491&partnerID=40&md5=64a8e7ecbf6b7208a52a882d44b9c78d","Recent advances in face forgery detection have shown strong in-domain performance but often fail to generalize to out-of-distribution data, especially when confronted with unseen manipulation techniques or domain shifts (e.g., lighting conditions, camera noise). We propose a novel Mixture-of-Experts framework, termed GM-DF, that decouples domain-specific and domain-invariant features to tackle cross-domain face forgery detection. Our method builds upon a foundation model (CLIP) and incorporates three key modules: (1) Dataset-Embedding Generator that leverages lightweight expert layers and database-aware feature normalization to adaptively modulate features at a per-domain level, capturing idiosyncratic cues without overfitting; (2) Multi-Dataset Representation mechanism that fuses these expert embeddings using scaled dot-product attention and integrates a mask image modeling (MIM) task to amplify local forgery artifacts; (3) Meta-Domain-Embedding Optimizer, inspired by MAML, which alternates between domain-specific (inner-loop) and domain-invariant (outer-loop) updates to facilitate rapid adaptation on new domains. Additionally, inspired by [13] (Yossi Gandelsman, Alexei A Efros, and Jacob Steinhardt. 2024. Interpreting the second-order effects of neurons in clip. arXiv preprint arXiv:2406.04341 (2024)) we introduce second-order feature propagation in the intermediate layers of CLIP to enhance fine-grained artifact cues and propose domain-class disentangled prompts to flexibly encode multi-domain text representations. Together, these strategies enable GM-DF to learn robust, shared forgery cues while preserving essential domain nuances. Our extensive experiments on multiple cross-domain benchmarks demonstrate that GM-DF significantly outperforms state-of-the-art approaches in both detection accuracy and domain transferability, reducing reliance on superficial artifacts and improving generalization to unseen forgeries. Importantly, our design requires minimal overhead beyond standard CLIP, making GM-DF both effective and computationally efficient for real-world face forgery detection. © 2025 ACM.","deepfake detection; moe"
"Mazzola, G.; Presti, L.L.; Cascia, M.L.","Mazzola, Giuseppe (24460695400); Presti, Liliana Lo (60118765000); Cascia, Marco La (60118694100)","24460695400; 60118765000; 60118694100","How Well Do Simple Features Detect Fake Faces? A Comparison with Deep Learning","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105021626886&partnerID=40&md5=2e5b5e38a3c5c6d6befc57c59618d595","The recent proliferation of highly realistic synthetic facial images, enabled by generative adversarial networks (GANs) and diffusion-based models, presents a growing challenge to digital media authenticity and visual forensics. This study investigates the problem of distinguishing real from AI-generated faces through a comparative evaluation of both traditional machine learning techniques and modern deep learning architectures. A custom dataset was constructed, combining real facial images from the FFHQ dataset with synthetic counterparts generated via the “This Person Does Not Exist” platform. We extracted local binary pattern (LBP) descriptors and trained multiple classifiers (including Random Forest, K-Nearest Neighbor, Support Vector Machine, Logistic Regression, and Naive Bayes) providing a robust baseline for interpretable face authenticity detection. In parallel, we evaluated convolutional neural networks and EfficientNet models, both with and without fine-tuning. Our results demonstrate that lightweight LBP-based approaches can yield competitive accuracy, offering interpretable and efficient alternatives to deep models in constrained settings. We further discuss the implications of these findings in light of current advances in generative models, and propose directions for enhancing detection robustness across unseen generative methods. © 2025 Copyright held by the owner/author(s).","Artificial Intelligence; Deepfake Detection; Image Forensics"
"Çiftçi, U.A.; Solar, N.; Greene, E.; Rhodes, A.; Demir, İ.","Çiftçi, Umur Aybars (57147959800); Solar, Nicholas (60192212600); Greene, Emily (60192827500); Rhodes, Anthony D. (57196020261); Demir, İlke (34975226700)","57147959800; 60192212600; 60192827500; 57196020261; 34975226700","Adversarial Reality for Frame-based Deepfake Detectors","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105021623017&partnerID=40&md5=ba0909417cde249d3a196acb5e67106e","Deepfake detection systems have shown remarkable success in identifying manipulated facial content by analyzing individual video frames. However, these systems remain vulnerable to adversarial attacks that can generate imperceptible perturbations to fool detection models. We present a novel adversarial attack specifically designed to target frame-based deepfake detectors across multiple face manipulation techniques. Our approach leverages a simple encoder-decoder network to generate adversarial examples that combine prediction loss optimization with perceptual reconstruction constraints, ensuring both attack effectiveness and visual quality preservation. Through comprehensive evaluation against 6 frame-based detectors on 8 manipulation methods, we demonstrate attack success rate of 83.40% while maintaining high perceptual and structural quality (1.248, 0.995, and 47.09 average RMSE, SSIM, and PSNR scores) over 35 transfer attack combinations. We report 97.43% and 93.15% misclassification accuracies on FaceForensics++ and FakeAVCeleb datasets, with a cross-dataset misclassification of 97.08%. Our method exhibits strong transferability across generation techniques, revealing fundamental vulnerabilities in current frame-based detectors and highlighting the need for more robust mechanisms. We further conduct ablation studies; analyze adversarial transformations per sample, per generator, and during formation; evaluate the impact of demographics; and perform comparisons to white- and black-box attacks. © 2025 Copyright held by the owner/author(s).","adversarial attacks; adversarial generation; adversarial reality; black-box attack; deepfake detection; Deepfakes; face manipulation"
"Zhang, Y.; Wang, C.; Zhou, X.","Zhang, Yupeng (60025190800); Wang, Chengyou (16551361300); Zhou, Xiao (57198477003)","60025190800; 16551361300; 57198477003","MSER-Net: Multi-stage edge refinement network for deepfake detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013635535&partnerID=40&md5=f82b78a65ddeda8120399d531873c04f","Today, the malicious creation and dissemination of deepfake content has reached a level that threatens personal privacy and even social stability. To address this issue, many researchers have focused on deepfake detection tasks. However, many approaches rely solely on single spatial domain information, with training models directly extracting global artefacts from images for detection. Such approaches frequently lack accuracy and are vulnerable to interference. Meanwhile, forgery traces typically appear at the edges of tampered regions, and these subtle edge inconsistencies serve as effective cues for detecting deepfakes. To address these issues, we propose the multi-stage edge refinement network (MSER-Net), which uses VMamba as its backbone network and incorporates channel residual image (CRI) to detect unnatural colour anomalies introduced during the deepfake process. First, the designed multiscale edge enhancement module (MSEEM) processes low-level features from both branches, obtaining multi-scale edge information using the Sobel operator and highlighting subtle forgery traces. In addition, we use the detail-aware interaction module (DAIM) to extract complementary information from spatial and residual features, which improves edge artefacts. Finally, we propose the multidimensional attention fusion module (MAFM), which improves dual-branch features from multiple perspectives using the attention mechanism, resulting in more effective fusion. Experimental results on multiple public datasets show that our method outperforms state-of-the-art detection approaches and exhibits the best robustness against most post-processing attacks. The code is available at: https://github.com/ypzhang123/MSER-Net. © 2025 The Author(s)","Deepfake detection; Edge refinement; Face forgery detection; Multimedia forensics"
"Thakur, U.; Khan, M.H.; Changlani, M.; Dotsinski, A.; Mahadevan, A.K.; Kechagias, I.; Najdenkoska, I.","Thakur, Udit (59960002900); Khan, Mohammad Hafeez (59959679300); Changlani, Meher (59959841000); Dotsinski, Asen (59959516500); Mahadevan, Aswin Krishna (59959841100); Kechagias, Ioannis (59960003000); Najdenkoska, Ivona (57226268751)","59960002900; 59959679300; 59959841000; 59959516500; 59959841100; 59960003000; 57226268751","CLaRE: CLIP with Latent Reconstruction Errors for Generated Face Detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105021465146&partnerID=40&md5=6e9525442171302eea04b161b5ce72fb","As generative models rapidly advance, detecting high-quality deepfakes becomes increasingly challenging, with existing methods struggling against modern diffusion-based generators. In this paper, we propose CLaRE, a deepfake detection framework that enhances CLIP by integrating Reconstruction Error (LaRE) through a novel cross-attention mechanism and Conditional Context Optimization (CoCoOp). Our key insight is that reconstruction errors from diffusion models provide discriminative signals that complement CLIP's semantic features, enabling better detection of subtle artifacts in synthetic content. To evaluate CLaRE, we conduct a comprehensive study on the DF40 deepfake dataset, training and testing four variations of our architecture using different training sizes (41k-410k samples). CLaRE achieves 78.3% mean accuracy - +1.5% over prompt-tuning baselines and competitive with recent SOTA - with notable gains on challenging datasets (+9.6% on MidJourney, +6.3% on StarGANv2). Crucially, our cross-attention fusion outperforms error-guided alternatives by +3.1-8.0% in cross-paradigm generalization while maintaining training stability at scale. Further, CLaRE retains strong performance on GAN-based content (75.4% on StyleCLIP), mitigating concerns about diffusion-centric design.1 © 2025 Copyright held by the owner/author(s).","CLIP; Deepfake detection; Diffusion models; Prompt tuning; Reconstruction error"
"Aldrees, A.; Abuzinadah, N.; Umer, M.; AlHammadi, D.A.; Alsubai, S.; Alharthi, R.","Aldrees, Asma (57369064400); Abuzinadah, Nihal Esam (58099302300); Umer, Muhammad Fahad (58255137000); AlHammadi, Dina Abdulaziz (59379042800); Alsubai, Shtwai (57194975731); Alharthi, Raed S. (57203659754)","57369064400; 58099302300; 58255137000; 59379042800; 57194975731; 57203659754","Deepfake detection using optimized VGG16-based framework enhanced with LIME for secure digital content","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105014802481&partnerID=40&md5=157fd9c45a18b5642a6146400bc52819","The rapid evolution of technologies to manipulate facial images, namely Generative Adversarial Networks (GANs) and those based on Stable Diffusion, has increased the need for effective deepfake detection mechanisms to mitigate their misuse. In this paper, the critical challenge of detecting deepfake images is addressed through a new deep learning-based approach that uses the VGG16 model after applying all necessary preprocessing steps. The VGG16 architecture was chosen for its deep structure and strong ability to capture intricate facial patterns when classifying facial images as real or manipulated. A robust preprocessing pipeline — including normalization, augmentation, facial alignment, and noise reduction — was implemented to optimize input data, improving the detection of subtle manipulations. Additionally, Explainable AI (XAI) techniques, such as the Local Interpretable Model-agnostic Explanations (LIME) framework, were integrated to provide transparent, visual explanations of the model's predictions, enhancing interpretability and user trust. To further assess generalizability, the evaluation was extended beyond the initial dataset by incorporating three additional benchmark datasets: FaceForensics++, Celeb-DF (v2), and the DFDC Preview Set. These datasets contain a range of manipulation techniques, allowing for comprehensive testing of the model's robustness across different scenarios. The proposed method outperformed baselines with exceptional performance metrics (accuracy, precision, recall, and F1-score up to 0.99), and maintained strong results across different datasets. These findings demonstrate that combining XAI approaches with a VGG16 model and thorough preprocessing effectively counters advanced deepfake generation techniques, such as StyleGAN2. This research contributes to a safer digital landscape by improving the detection and understanding of manipulated content, providing a practical way to confront the growing threat of deepfakes. © 2025 Elsevier B.V.","Deep learning; Deepfake detection; Explainable AI (XAI); Image processing; Local interpretable model-agnostic explanations (LIME); VGG16 model"
"Song, W.; Guo, S.; Gao, M.; Li, Q.; Zhu, X.; Rida, I.","Song, Weicheng (60027100400); Guo, Siyou (59173914500); Gao, Mingliang (26634962800); Li, Qilei (57202858223); Zhu, Xianxun (57211093174); Rida, Imad (56241583700)","60027100400; 59173914500; 26634962800; 57202858223; 57211093174; 56241583700","Deepfake detection via Feature Refinement and Enhancement Network","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012355188&partnerID=40&md5=876de9959f72e0603e63e299fdedfe0a","The rapid advancement of deepfake technology poses significant threats to the integrity and privacy of biometric systems, such as facial recognition and voice authentication. To address this issue, there is an urgent need for advanced forensic detection methods that can reliably safeguard biometric data from manipulation and unauthorized access. However, current methods mainly focus on shallow feature extraction and neglect feature refinement and enhancement, which leads to low detection accuracy and poor generalization performance. To address this problem, we propose Feature Refinement and Enhancement Network (FRENet) for deepfake detection by leveraging progressive refinement and enhanced mixed feature learning. Specifically, a Low Rank Projected Self-Attention (LPSA) module is introduced for the refinement and enhancement of features. Also, a Patch-based Focused (PatchFocus) module is proposed to highlight local texture inconsistencies in key regions. In addition, we propose a Refine Fusion (RefFus) module that integrates the refined features and associated noise information to enhance feature separability. Experimental results across five benchmark datasets demonstrate that the proposed FRENet outperforms state-of-the-art methods in terms of both accuracy and generalization. The code is available at https://github.com/weichengsong-code/FRENet. © 2025","Deepfake detection; Feature enhancement; Model generalization; Privacy preservation"
"Krasilnikov, M.; Nikitin, M.; Konushin, A.","Krasilnikov, Maksim (60116876300); Nikitin, Mikhail Yurievich (57199053672); Konushin, Anton S. (6506829728)","60116876300; 57199053672; 6506829728","VCF: A Real-World Video Conference Deepfake Benchmark for Face-Swap Detection and Robustness Evaluation","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105017233520&partnerID=40&md5=b7f78ac48f3d1d86dd90471a67b8d487","The rapid advancement of deepfake generation techniques poses significant security and privacy risks, particularly in video conferencing scenarios where variable resolutions, compression artifacts, and environmental factors complicate detection. Existing benchmarks often fail to address these context-specific challenges, limiting their applicability to real-world communication platforms. To bridge this gap, we introduce VCF (Video Conference DeepFakes) dataset, the first, to the best of our knowledge, specialized benchmark designed for evaluating deepfake detection in video conferencing contexts. VCF leverages the VCD dataset as target videos and the LaPa dataset as a set of source faces, algorithmically ranking sources by similarity in gender, ethnicity, age, and facial hair to select optimal matches for enhanced deepfake visual plausibility. The dataset incorporates multi-resolution videos, H.264 compression artifacts from different compression rates, and diverse backgrounds to simulate conditions specific to video conferences. Comprehensive evaluations of 14 detection methods reveal significant performance degradation under video quality variations. Our results emphasize the critical need for robust detection frameworks resilient to resolution shifts, compression artifacts, and diverse generation pipelines. VCF provides a standardized, scenario-specific benchmark to drive advancements in securing digital communication platforms against evolving deepfake threats. © © 2025 Maksim Krasilnikov et al.","Benchmark; Dataset; Deepfake detection; Face-swapping detection"
"Thabit, R.; Al-Askari, M.A.; Mohammed, D.Z.; Anaam, E.A.; Mahmood, Z.H.; Jabbar, D.J.; Salih, Z.A.","Thabit, Rasha (58046996400); Al-Askari, Mohanad A. (58034319000); Mohammed, Dunya Zeki (57191991496); Anaam, Elham Abdulwahab (57218162645); Mahmood, Zainab Hikmat (57207861976); Jabbar, Dina Jamal (57215964350); Salih, Zahraa Aqeel (57971298500)","58046996400; 58034319000; 57191991496; 57218162645; 57207861976; 57215964350; 57971298500","Face image authentication scheme based on MTCNN and SLT","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218684590&partnerID=40&md5=52fc07a009e59b45e6d4d20dc219b96b","DeepFakes and face image manipulation methods have been widely distributed in the last few years and several techniques have been presented to check the authenticity of the face image and detect manipulation if exists. Most of the available manipulation detection techniques have been successfully applied to reveal one type of manipulation under specific conditions, however, many limitations and challenges can be encountered in this field. To overcome some limitations and challenges, this paper presents a new face image authentication (FIA) scheme based on Multi-Task Cascaded Conventional Neural Networks (MTCNN) and watermarking in Slantlet transform (SLT) domain. The proposed FIA scheme has three main algorithms that are face detection and selection, embedding, and extraction algorithms. Different block sizes have been used to divide the image into non-overlapping blocks followed by classifying them into two groups that are blocks from face area (FA) and blocks from the remaining area (RA) of the image. In the embedding algorithms, the authentication information is generated from FA blocks and embedded in the RA blocks. In the extraction algorithms, the embedded information is extracted from RA blocks and compared with the calculated data from FA blocks to reveal manipulations and localize the manipulated blocks if exist. Extensive experiments have been conducted to evaluate the performance of the proposed FIA scheme for different face images. The experimental work included tests for payload, capacity, visual quality, time complexity, and localization of manipulations. The results proved the efficiency of the proposed scheme in detecting and localizing different face image manipulations such as attributes attacks, retouching attacks, expression swap, face swap, and morphing attacks. The proposed scheme overcomes many limitations and it is 100% accurate in localizing the tampered blocks which makes it a better candidate for practical applications. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2025.","DeepFakes detection; Face image security; Face manipulation detection; Face manipulation localization; Multimedia forensics"
"Li, J.; Hu, Y.; Liu, B.; She, H.; Li, C.-T.","Li, Jicheng (57201859261); Hu, Yongjian (35766130600); Liu, Beibei (55544736500); She, Huimin (58504567900); Li, Chang Tsun (26648782200)","57201859261; 35766130600; 55544736500; 58504567900; 26648782200","Deepfake detection with domain generalization and mask-guided supervision","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001820244&partnerID=40&md5=2408646640b4cb500f957119dc7edb98","Most existing deepfake (video face forgery) detectors work well in intra-dataset testing, but their performance degrades severely in cross-dataset testing. Cross-dataset generalization remains a major challenge. Since domain generalization (DG) aims to learn domain-invariant features while suppressing domain specific features, we propose a DG framework for improving face forgery detection in this study. Our detector consists of two modules. The first module learns both spatial and spectral features from frame images. The second one learns high-level feature patterns from the outputs of the first module, and constructs the classification features with the help of face mask-guided supervision. The classification result is fine-tuned by a confidence-based correction mechanism. The DG framework is realized through a bi-level optimization process. Extensive experiments demonstrate that our detector works effectively in both intra- and cross-dataset testing. Compared with 8 typical methods, it has the best overall performance and the highest robustness against common perturbations. © 2025 Elsevier Ltd","Deepfake detection; Domain generalization; Face mask supervision; Forged face detection; Generalization capability; Video face forgery detection"
"Le-Phan, M.-K.; Le, M.-H.; Tran, M.-T.; Do, T.-L.","Le-Phan, Minh Khoa (59932485900); Le, Minh Hoang (60020269800); Tran, Minh Triet (35176729700); Do, Trongle (57212828893)","59932485900; 60020269800; 35176729700; 57212828893","A Hybrid Model for Generalizable Deepfake Detection via Blending, Semantic, and General Artifacts","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016307809&partnerID=40&md5=e952939c20db621df0c8e3eeabb968cb","Deepfake can be a potential threat for fake information generation and distribution, making deepfake detection a helpful utility to prevent the widespread dissemination of fake content. However, deepfake detection models often struggle to perform well across different datasets because they rely on specific patterns present in the training data. To address this issue, we present a hybrid deepfake detection framework that integrates three complementary types of forgery clues: blending artifacts, semantic inconsistencies, and general deepfake artifacts. Our approach includes three specialized components: (1) a Blending Artifact Detector trained on self-blended images to detect visual inconsistencies from face blending, (2) a Semantic Feature Extractor that uses a pre-trained vision-language model to capture high-level facial features, and (3) a General Artifact Detector trained on diverse deepfake datasets to identify common manipulation traces. We propose a two-stage training strategy that allows each component to learn effectively without interfering with the others. Experiments on multiple benchmark datasets show that our method achieves strong cross-dataset performance, outperforming many existing approaches. Specifically, our model achieves an average frame-level AUC of 85.71% and video-level AUC of 90.8%, with the highest AUCs on DFD (96.7%) and DFDCP (92.5%), demonstrating improved generalization and state-of-the-art performance in deepfake detection. © 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM.","Blending Artifact; Deepfake Detection; General Deepfake Artifact; Hybrid Model; Semantic Feature"
"Xiao, Y.; Zhou, Y.; Cheng, P.; Ni, L.; Wu, X.; Zheng, T.","Xiao, Yinfei (59923826800); Zhou, Yanbing (59923294200); Cheng, Pengzhan (59251820900); Ni, Leqian (60076771900); Wu, Xusheng (59251971100); Zheng, Tianxiang (54901369300)","59923826800; 59923294200; 59251820900; 60076771900; 59251971100; 54901369300","An Attention-Based Framework for Detecting Face Forgeries: Integrating Efficient-ViT and Wavelet Transform","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105014506707&partnerID=40&md5=908623ad7d4b2b21b4b61fd4c9f1ab30","As face forgery techniques, particularly the DeepFake method, progress, the imperative for effective detection of manipulations that enable hyper-realistic facial representations to mitigate security threats is emphasized. Current spatial domain approaches commonly encounter difficulties in generalizing across various forgery methods and compression artifacts, whereas frequency-based analyses exhibit promise in identifying nuanced local cues; however, the absence of global contexts impedes the capacity of detection methods to improve generalization. This study introduces a hybrid architecture that integrates Efficient-ViT and multi-level wavelet transform to dynamically merge spatial and frequency features through a dynamic adaptive multi-branch attention (DAMA) mechanism, thereby improving the deep interaction between the two modalities. We innovatively devise a joint loss function and a training strategy to address the imbalanced data issue and improve the training process. Experimental results on the FaceForensics++ and Celeb-DF (V2) have validated the effectiveness of our approach, attaining 97.07% accuracy in intra-dataset evaluations and a 74.7% AUC score in cross-dataset assessments, surpassing our baseline Efficient-ViT by 14.1% and 7.7%, respectively. The findings indicate that our approach excels in generalization across various datasets and methodologies, while also effectively minimizing feature redundancy through an innovative orthogonal loss that regularizes the feature space, as evidenced by the ablation study and parameter analysis. © 2025 by the authors.","cross attention; deepfake detection; Efficient-ViT; face forgery; wavelet transform"
"Jin, X.; Kou, Y.; Xie, Y.; Zhao, Y.; Mat Kiah, M.L.; Jiang, Q.; Zhou, W.","Jin, Xin (56991832300); Kou, Yuru (58988680500); Xie, Yuhao (60074940000); Zhao, Yuying (60075106400); Mat Kiah, Miss Laiha (57214221751); Jiang, Qian (57194699462); Zhou, Wei (56857006600)","56991832300; 58988680500; 60074940000; 60075106400; 57214221751; 57194699462; 56857006600","Learning Local Texture and Global Frequency Clues for Face Forgery Detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105014369586&partnerID=40&md5=d888b821b13e9abbe0916488284c6a01","In recent years, the rapid advancement of deep learning techniques has significantly propelled the development of face forgery methods, drawing considerable attention to face forgery detection. However, existing detection methods still struggle with generalization across different datasets and forgery techniques. In this work, we address this challenge by leveraging both local texture cues and global frequency domain information in a complementary manner to enhance the robustness of face forgery detection. Specifically, we introduce a local texture mining and enhancement module. The input image is segmented into patches and a subset is strategically masked, then texture enhanced. This joint masking and enhancement strategy forces the model to focus on generalizable localized texture traces, mitigates overfitting to specific identity features and enabling the model to capture more meaningful subtle traces of forgery. Additionally, we extract multi-scale frequency domain features from the face image using wavelet transform, thereby preserving various frequency domain characteristics of the image. And we propose an innovative frequency-domain processing strategy to adjust the contributions of different frequency-domain components through frequency-domain selection and dynamic weighting. This Facilitates the model’s ability to uncover frequency-domain inconsistencies across various global frequency layers. Furthermore, we propose an integrated framework that combines these two feature modalities, enhanced with spatial attention and channel attention mechanisms, to foster a synergistic effect. Extensive experiments conducted on several benchmark datasets demonstrate that the proposed technique demonstrates superior performance and generalization capabilities compared to existing methods. © 2025 by the authors.","bioinformatics; deep learning; deepfake detection; face forgery detection; frequency domain"
"Vudayagiri, P.; Sana, R.; Abdallah, H.A.; Agarwal, N.; Agarwal, S.","Vudayagiri, Padmaja (60006901700); Sana, Rajeswari (60007035800); Abdallah, Hanaa A. (35776128600); Agarwal, Neha (57210697707); Agarwal, Saurabh (57190606444)","60006901700; 60007035800; 35776128600; 57210697707; 57190606444","Synthetic shadows: the interplay of forensic detection and anti-forensic techniques in GAN-generated images","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011189393&partnerID=40&md5=571aeb66b2aeba87f21f068f10b04504","Generative adversarial networks (GANs) have become a leading innovation in the synthesis of realistic face images. These images are typically unrecognizable to the naked eye and find application in entertainment, virtual reality, and media, greatly challenging digital forensics. Photorealistic yet fake face images generated by GANs raise questions concerning their use in identity impersonation, disinformation attacks, and other nefarious activities in society. Anti-forensic techniques, whose purpose is to conceal the digital trail of synthetic media, introduce additional challenges to detecting images generated by GANs. These include techniques such as adding noise, adversarial perturbations, and compression artifacts that can be used for concealing from cybersecurity and law enforcement solutions. This survey discusses the mechanisms and challenges of face image detection of GAN-generated images, highlighting the emergent interplay between evolving forensic detection and counteracting anti-forensic tactics. Current detection methods—ranging from machine learning classification to deep learning models and frequency domain-based approaches—are promising but generally insufficient owing to dependence on specific training sets and the versatility of state-of-the-art GAN models. This review discusses anti-forensic techniques, such as adaptive GANs and adversarial attacks, which function to reduce the detectability of synthetic media. Comparisons of detection methods versus anti-forensic techniques reveal critical gaps in robustness and generalizability and necessitate interdisciplinary investigations to confront the evolving threat landscape. Future studies will revolve around the explainability and adaptability of the frameworks to detect sophisticated tactics related to anti-forensic techniques. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2025.","Adversarial attacks; Anti-forensics; Deepfake detection; GAN detection techniques; GAN-generated face images"
"Qi, Y.; Xie, H.; Gao, Y.; Lin, Y.; Zhang, H.; Han, H.","Qi, Yongfeng (54893032200); Xie, Hongli (59462971900); Gao, Yajuan (59982470400); Lin, Yuanzhe (59463341200); Zhang, Heng (59463525100); Han, Haixi (59982611300)","54893032200; 59462971900; 59982470400; 59463341200; 59463525100; 59982611300","Generalizable face forgery detection based on adaptive spatial-frequency information mining","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010001788&partnerID=40&md5=545dd79d953a33794c6084c8b64b78f1","In the current field of face forgery detection, researchers are focused on recognizing forgery cues through the combination of frequency information and convolutional neural networks (CNN). However, existing methods often fail to capture spatial correlations with image content when extracting frequency features, making it difficult to accurately recognize highly simulated forged images. In addition, these methods perform well on homogeneous datasets, but their effectiveness decreases significantly when evaluated on cross-dataset samples. To address these issues, we propose a novel adaptive spatial-frequency information mining (ASFIM) method for generalizable face forgery detection. Specifically, the ASFIM method first processes the original RGB image through a frequency-aware learning module. This module extracts forgery frequency information closely related to the image content, which is subsequently used as input for frequency branching. Next, a spatial texture enhancement module is introduced to enable interaction between spatial and frequency features at an early stage. This approach not only strengthens the expressiveness of forgery features in the spatial domain but also provides an effective guide for recognizing forgery cues in the frequency domain. Finally, we designed the cross-domain interactive attention (CDIA) module to enhance forgery cues by deeply fusing spatial texture and frequency-aware features. Extensive experimental results demonstrate that the proposed ASFIM method outperforms various advanced methods in terms of generalization ability across challenging benchmark tests. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2025.","DCT; Deepfake detection; Face forgery detection; Frequency-aware learning; Spatial texture enhancement"
"Zhao, C.; Wang, C.; Song, Z.; Hu, G.; Wang, L.; Miao, D.","Zhao, Cairong (7403564629); Wang, Chutian (57884389600); Song, Zifan (58534498800); Hu, Guosheng (55925786500); Wang, Liang (55721263000); Miao, Duoqian (7006323434)","7403564629; 57884389600; 58534498800; 55925786500; 55721263000; 7006323434","Multi-definition Deepfake detection via semantics reduction and cross-domain training","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218451648&partnerID=40&md5=53a4d802ba672ba877236e5826f8af6d","The recent development of Deepfake videos directly threatens our information security and personal privacy. Although lots of previous works have made much progress on the Deepfake detection, we empirically find that the existing approaches do not perform well on the low definition (LD) and cross-definition (high and low) videos. To address this problem, in this paper, we follow two motivations: (1) high-level semantics reduction and (2) cross-domain training. For (1), we propose the Facial Structure Destruction and Adversarial Jigsaw Loss to reduce our model to learn high-level semantics and focus on learning low-level discriminative information; For (2), we propose an adversarial domain generalization method and a spatial attention distillation which uses the information of HD videos to guide LD videos. We conduct extensive experiments on public datasets, FaceForensics++ and Celeb-DF v2. Results show the great effectiveness of our method and we also achieve very competitive performance against state-of-the-art methods. Surprisingly, we empirically find that our method is also very effective on Face Anti-Spoofing (FAS) task, verified on OULU-NPU dataset. © 2025 Elsevier Ltd","Deep learning; Deepfake detection; Face Anti-Spoofing; Self-supervised learning"
"Yao, W.; Li, P.; Zhao, Y.; Wu, H.","Yao, Wenda (60042789100); Li, Panchi (16245350600); Zhao, Ya (60042679500); Wu, Hongchao (60042679600)","60042789100; 16245350600; 60042679500; 60042679600","Review of research on face deepfake detection methods; 人脸深度伪造检测方法研究综述","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013250991&partnerID=40&md5=2f1980f5956901189d7050a1b8a510b3","Deepfake technology refers to the synthesis of images，audio，and videos by using deep learning algorithms. This technology enables the precise mapping of facial features or other physical characteristics from one person onto a subject in another video，achieving highly realistic face-swapping effects. With advancements in algorithms and the increased accessibility of computational resources，the threshold for utilizing deepfake technology has gradually lowered，bringing convenience and numerous social and legal challenges. For example，deepfake technology is used to bring deceased actors back to the screen，providing a novel experience to the audience. Meanwhile，it is frequently exploited to impersonate citizens or leaders for fraudulent activities，produce pornographic content，or create fake news to influence public opinion. Consequently，the importance of deepfake detection technology is increasing，making it a significant focus of current research. To detect images and videos synthesized via deepfake technology，researchers must design models that can uncover subtle traces of manipulation within these media. However，accurately identifying these traces remains challenging due to several factors that complicate the detection process. First，rapid advancements in deepfake technology have made differentiating fake images and videos from authentic content increasingly difficult. As techniques such as generative adversarial networks（GANs）and diffusion models continue to evolve and improve，the texture，lighting，and motion within synthesized media become more seamlessly realistic，imposing significant challenges on detection models that seek to recognize subtle cues of manipulation. Second，forgers can employ a variety of countermeasures to obscure traces of manipulation，such as applying compression，cropping，or noise addition. Furthermore，forgers may create adversarial samples that are specifically crafted to exploit and bypass the vulnerability of detection models，making the identification of deepfake even more complex. Thirdly，the generalizability of deepfake detection methods remains a significant hurdle，because different generative techniques leave behind distinct forensic traces. For example，GAN-generated images frequently exhibit prominent grid-like artifacts in the frequency domain，while images produced through diffusion models typically leave only subtle，less detectable traces in this domain. Therefore，detection models that do not exclusively rely on low-level，technique-specific features but instead focus on capturing deep，generalized features that ensure robustness and applicability across diverse forgery types and detection scenarios are crucial. To address these multifaceted challenges，numerous scholars have proposed a variety of detection methods that are designed to capture nuanced traces left by deepfake manipulations. For example，certain approaches focus on identifying subtle forgery artifacts within the frequency domain of images，capitalizing on the distinct spectral anomalies that forgeries frequently introduce. Other methods prioritize assessing temporal consistency across video frames，because unnatural transitions or frame-level inconsistencies can indicate synthesized content. In addition，some detection strategies focus on evaluating synchronization among different modalities within videos，such as audio and visual elements，to detect inconsistencies that may reveal forgery. At present，several review papers in academia have summarized key research and developments within this domain. However，given the rapid advancements in generative artificial intelligence（AI），fake faces created with diffusion models have recently gained popularity，with scarcely any review that addresses the detection of such forgeries. Furthermore，as generative AI progresses continues advancing toward multimodal integration，deepfake detection methods are similarly evolving to incorporate features from multiple modalities. Nonetheless，the majority of existing reviews lack sufficient focus on multimodal detection approaches，underscoring a gap in the literature that this review seeks to address. To provide an up-to-date overview of face deepfake detection，this review first organizes commonly used datasets and evaluation metrics in the field. Then，it divides detection methods into image-level and video-level face deepfake detection. Based on feature selection approaches，image-level methods are categorized into spatial-domain and frequency-domain methods，while video-level methods are categorized into approaches based on spatiotemporal inconsistencies，biological features，and multimodal features. Each category is thoroughly analyzed with regard to its principles，strengths，weaknesses，and developmental trends. Finally，current research status and challenges in face deepfake detection are summarized，and future research directions are discussed. Compared with other related reviews，the novelty of this review lies in its summary of detection methods that specifically targets text-to-image/video generation and multimodal detection methods. This review is aligned with the latest trends in generative AI，offering a comprehensive and up-to-date summary of recent advancements in face deepfake detection. By examining the latest methodologies，including those developed to address forgeries created through advanced techniques，such as diffusion models and multimodal integration，this review reflects the ongoing evolution of detection technology. It highlights the progress made and the challenges that remain，positioning itself as a valuable resource for researchers who aim to navigate and contribute to the cutting-edge developments in this rapidly advancing field. A comprehensive analysis of face deepfake detection methods reveals that current techniques achieve nearly 100% accuracy within the training datasets，particularly those leveraging advanced models，such as Transformers. However，their performance frequently declines significantly in cross-dataset testing，particularly for spatial-domain and frequency-domain detection methods. This decline suggests that these approaches may fail to capture essential，generalizable features that are robust across varying datasets. By contrast，biological feature-based methods demonstrate superior generalization capabilities，successfully adapting to different contexts. However，they require carefully tailored training data and specific application conditions to reach optimal performance. Meanwhile，multimodal detection methods，which integrate features across multiple modalities，offer enhanced robustness and adaptability due to their layered approach. However，this added complexity frequently results in higher computational costs and increased model intricacy. Given the diversity in feature selection，along with the unique advantages and limitations inherent to each detection approach，no single method has yet provided a fully comprehensive solution to the deepfake detection challenge. This reality underscores the critical need for continued research in this evolving field and highlights the importance of this review in mapping current advancements and identifying future research directions. © 2025 Editorial and Publishing Board of JIG. All rights reserved.","deepfake detection; face forgery detection; face image; face video; frequency domain feature; multimodal features; spatial domain feature; temporal features"
"Budhiraja, R.; Kumar, M.; Das, M.K.; Bafila, A.S.; Pundir, A.; Singh, S.","Budhiraja, Rajat (57190491952); Kumar, Manish (57207935496); Das, Mrinal K. (57210523532); Bafila, Anil Singh (57222111714); Pundir, Amit (57206726943); Singh, Sanjeev (57216140046)","57190491952; 57207935496; 57210523532; 57222111714; 57206726943; 57216140046","MaD-CoRN: an efficient and lightweight deepfake detection approach using convolutional reservoir network","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011389939&partnerID=40&md5=307b4e5f1021a5d3902d32bc78f52274","In the modern digital era, human face lies at the core and forms the very basis of any social interaction and communication. It embeds highly precious information alongside facial identities and expressions, but at same time this very trait makes it vulnerable to manipulation attacks. The proliferation of large-scale public image databases alongside advancements in AI-driven image synthesis has heightened the prevalence of “DeepFakes”. While conventional fake detection classifiers suffer from low accuracies due to their susceptibility to manipulation techniques, state-of-the-art convolutional neural network (CNN) models offer high accuracies at the expense of extensive training and computational resources. To address these challenges, we introduce MaD-CoRN i.e. Manipulation detection by Convolutional Reservoir Networks. It is a novel and efficient combinatorial architecture that enhances the feature extraction capabilities using pre-trained convolutional networks with lightweight reservoir computing (RC), an improved form of RNN learning. This approach improves the separation and learning of facial features, resulting in notable speedups and a relative increase of over 15% in fake face detection accuracy, F1-score values when simulated using “Real and Fake Face Detection (RFFD)” and “100K-Generated fake image” public datasets. MaD-CoRN offers several advantages: (i) it is lightweight and cost-effective, (ii) leverages transfer learning and RC-based feature extraction, (iii) it achieves enhanced accuracies even with small input datasets (≈ 1900 samples) and it boasts a highly flexible and generic architecture. Additionally, we propose a unified framework based on various adaptations of the MaD-CoRN architecture. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.","Convolutional neural network; Convolutional reservoir network; Deepfake detection; Ensemble feature extraction; Face manipulation detection; Reservoir computing"
"Wang, G.; Han, Y.; Xu, F.; Gao, Y.; Sang, W.","Wang, Ge (56144355500); Han, Yue (59529224700); Xu, Fangqian (59529944800); Gao, Yuteng (59529224600); Sang, Wenjie (59529804700)","56144355500; 59529224700; 59529944800; 59529224600; 59529804700","The Detection Optimization of Low-Quality Fake Face Images: Feature Enhancement and Noise Suppression Strategies","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010341977&partnerID=40&md5=0943ffc42ec6d02b824a6ff00fd87f82","With the rapid advancement of deepfake technology, the detection of low-quality synthetic facial images has become increasingly challenging, particularly in cases involving low resolution, blurriness, or noise. Traditional detection methods often exhibit limited performance under such conditions. To address these limitations, this paper proposes a novel algorithm, YOLOv9-ARC, which is designed to enhance the accuracy of detecting low-quality fake facial images. The proposed algorithm introduces an innovative convolution module, Adaptive Kernel Convolution (AKConv), which dynamically adjusts kernel sizes to effectively extract image features, thereby mitigating the challenges posed by low resolution, blurriness, and noise. Furthermore, a hybrid attention mechanism, Convolutional Block Attention Module (CBAM), is integrated to amplify salient features while suppressing irrelevant information. Extensive experiments demonstrate that YOLOv9-ARC achieves a mean average precision (mAP) of 75.1% on the DFDC (DeepFake Detection Challenge) dataset, representing a 3.5% improvement over the baseline model. The proposed YOLOv9-ARC not only addresses the challenges of low-quality deepfake detection but also demonstrates significant improvements in accuracy within this domain. © 2025 by the authors.","Adaptive Kernel Convolution; Convolutional Block Attention Module; DeepFake Detection Challenge; low-quality synthetic facial images"
"Bunluesakdikul, P.; Mahanan, W.; Sungunnasil, P.; Sangamuang, S.","Bunluesakdikul, Patchraphon (59660232800); Mahanan, Waranya (56535353700); Sungunnasil, Prompong (59660421100); Sangamuang, Sumalee (38562159900)","59660232800; 56535353700; 59660421100; 38562159900","Deepfake Video Detection: A Novel Approach via NLP-Based Classification","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219095126&partnerID=40&md5=7e9bd710d49dc4d28160eff0eeb03f89","Nowadays, the Deepfake technology is mainly used to harm people’s reputations and can trick the face recognition system by swapping faces between people, raising significant security concerns. Thus, methods for detecting Deepfake are crucial. The recent methods for Deepfake detection have performed well in distinguishing real content from fake content. Some research employed the Transformer technique, commonly used in natural language processing (NLP), to enhance performance. Therefore, this paper proposes a novel deepfake detection method that transforms extracted features into words and utilizes NLP techniques for deepfake classification. We employed a fine-tuned pre-trained Convolutional Neural Network (CNN) model to extract features from the face images in the videos. These extracted features are labeled based on grouping methods, such as mean and standard deviation (SD). Tokenization and classification are then performed using Long Short-Term Memory (LSTM) and Recurrent Neural Network (RNN). Additionally, Bidirectional Encoder Representations from Transformers (BERT) is used as another tokenizer and classifier to compare the performance of deepfake detection between the traditional model and the NLP model. The result states that the method using BERT as a tokenizer and classifier with Mean and SD grouping method shows better efficiency, achieving 99.57% on the Roc Curve, 99.58% Accuracy, 99.18% Precision, 100.00% recall, and 99.59% F-measure. © 2025 World Scientific Publishing Europe Ltd.","Deepfake; deepfake detection; deepfake video; YOLO-face"
"Shao, R.; Wu, T.; Liu, Z.","Shao, Rui (57201860007); Wu, Tianxing (57815209400); Liu, Ziwei (56437024900)","57201860007; 57815209400; 56437024900","Robust Sequential DeepFake Detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214021905&partnerID=40&md5=a39d3bfea940f1243d114ba5d81221e2","Since photorealistic faces can be readily generated by facial manipulation technologies nowadays, potential malicious abuse of these technologies has drawn great concerns. Numerous deepfake detection methods are thus proposed. However, existing methods only focus on detecting one-step facial manipulation. As the emergence of easy-accessible facial editing applications, people can easily manipulate facial components using multi-step operations in a sequential manner. This new threat requires us to detect a sequence of facial manipulations, which is vital for both detecting deepfake media and recovering original faces afterwards. Motivated by this observation, we emphasize the need and propose a novel research problem called Detecting Sequential DeepFake Manipulation (Seq-DeepFake). Unlike the existing deepfake detection task only demanding a binary label prediction, detecting Seq-DeepFake manipulation requires correctly predicting a sequential vector of facial manipulation operations. To support a large-scale investigation, we construct the first Seq-DeepFake dataset, where face images are manipulated sequentially with corresponding annotations of sequential facial manipulation vectors. Based on this new dataset, we cast detecting Seq-DeepFake manipulation as a specific image-to-sequence (e.g., image captioning) task and propose a concise yet effective Seq-DeepFake Transformer (SeqFakeFormer). To better reflect real-world deepfake data distributions, we further apply various perturbations on the original Seq-DeepFake dataset and construct the more challenging Sequential DeepFake dataset with perturbations (Seq-DeepFake-P). To exploit deeper correlation between images and sequences when facing Seq-DeepFake-P, a dedicated Seq-DeepFake Transformer with Image-Sequence Reasoning (SeqFakeFormer++) is devised, which builds stronger correspondence between image-sequence pairs for more robust Seq-DeepFake detection. Moreover, we build a comprehensive benchmark and set up rigorous evaluation protocols and metrics for this new research problem. Extensive quantitative and qualitative experiments demonstrate the effectiveness of SeqFakeFormer and SeqFakeFormer++. Several valuable observations are also revealed to facilitate future research in broader deepfake detection problems. The code has been released at https://github.com/rshaojimmy/SeqDeepFake/. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2025.","DeepFake detection; Multimodal Learning; Sequential facial manipulation"
"Sharma, V.K.; Garg, R.; Caudron, Q.","Sharma, Vishal Kumar (57199918726); Garg, Rakesh (57205734819); Caudron, Quentin (56254835500)","57199918726; 57205734819; 56254835500","A systematic literature review on deepfake detection techniques","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200364938&partnerID=40&md5=fdb710b6e41c7a0c16c9eecbc25654e1","Big data analytics, computer vision, and human-level governance are key areas where deep learning has been impactful. However, its advancements have also led to concerns over privacy, democracy, and national security, particularly with the advent of deepfake technology. Deepfakes, a term coined in 2017, primarily involve face-swapping in videos. Initially easy to detect, rapid advancements in machine learning have made deepfakes increasingly realistic and challenging to distinguish from reality. Generative Adversarial Networks (GANs) and other deep learning methods are instrumental in creating deepfakes, leading to the development of applications like Faceapp and Fake App. These technological advancements, while impressive, pose significant risks to individual integrity and societal trust. Recognizing this, the necessity to develop systems capable of instantaneously identifying and assessing the authenticity of digital visual media has become paramount. This study aims to evaluate deepfake detection methods by discussing manipulations, optimizations, and enhancements of existing algorithms. It explores various datasets for image, video, and audio deepfake detection, including performance metrics to gauge detection algorithm effectiveness. Through a comprehensive review, this paper identifies gaps in current research, proposes future research directions, and provides a detailed quantitative and qualitative analysis of existing deepfake detection techniques. By consolidating existing literature and presenting new insights, this study serves as a valuable resource for researchers and practitioners aiming to advance the field of deepfake detection. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.","Deepfake datasets; Deepfake detection; Face manipulation; Generative adversarial network; Neural network; Perfomance metrics; Systemetic literature review"
"Choi, H.; Woo, S.S.","Choi, Hyeongjun (59916883000); Woo, Simon S. (57202046772)","59916883000; 57202046772","GAN or DM? In-depth Analysis and Evaluation of AI-generated Face Data for Generalizable Deepfake Detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006444643&partnerID=40&md5=09784ea77bbde49ad29136247768fb47","Deepfake detection remains challenging, particularly when identifying deepfakes generated by unseen forgery methods. Recent studies have shown that detectors trained on forgery data from Generative Adversarial Networks (GAN) cannot generalize well on data from Diffusion Models (DM) and vice versa. As generative methods such as GAN and DM are significantly advanced for creating highly photorealistic images, it becomes crucial to develop generalized methods to detect forgeries generated from different generation methods. While research on generalizable detectors is gaining momentum, the impact of training data on detectors' generalization ability has yet to be extensively studied, especially concerning synthetic human face images. In this work, we train popular deep neural networks using face data generated by various generative models and thoroughly analyze their generalizability. Our results reveal significant differences in model performance based on the forgery method used to generate the training data. Notably, we identify specific scenarios that significantly enhance model generalization, contradicting previous research finding that models trained on DM-generated data would achieve higher generalization performance than those trained on GAN-generated data. These findings emphasize the crucial role of training data selection in enhancing the generalization capabilities of deepfake detectors. By strategically selecting and combining datasets, we can develop more robust detection systems, laying a foundation for future research in creating reliable and universal deepfake detection methods. © © 2025 held by the owner/author(s).","deepfake detection; generalization; synthetic face data"
"Zhang, Y.; Li, Q.; Yu, Z.; Shen, L.","Zhang, Yaning (58026359800); Li, Qiufu (55429126700); Yu, Zitong (57210955519); Shen, Linlin (7401704647)","58026359800; 55429126700; 57210955519; 7401704647","Distilled transformers with locally enhanced global representations for face forgery detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211432197&partnerID=40&md5=cdb40bc9faa3ca79f3a25fce876c2f39","Face forgery detection (FFD) is devoted to detecting the authenticity of face images. Although current CNN-based works achieve outstanding performance in FFD, they are susceptible to capturing local forgery patterns generated by various manipulation methods. Though transformer-based detectors exhibit improvements in modeling global dependencies, they are not good at exploring local forgery artifacts. Hybrid transformer-based networks are designed to capture local and global manipulated traces, but they tend to suffer from the attention collapse issue as the transformer block goes deeper. Besides, soft labels are rarely available. In this paper, we propose a distilled transformer network (DTN) to capture both rich local and global forgery traces and learn general and common representations for different forgery faces. Specifically, we design a mixture of expert (MoE) module to mine various robust forgery embeddings. Moreover, a locally-enhanced vision transformer (LEVT) module is proposed to learn locally-enhanced global representations. We design a lightweight multi-attention scaling (MAS) module to avoid attention collapse, which can be plugged and played in any transformer-based models with only a slight increase in computational costs. In addition, we propose a deepfake self-distillation (DSD) scheme to provide the model with abundant soft label information. Extensive experiments show that the proposed method surpasses the state of the arts on five deepfake datasets. © 2024","Deepfake detection; Knowledge distillation; Mixture of expert; Multi-attention scaling; Transformer"
"Yang, H.; Li, X.; Hu, Z.","Yang, Hongyu (7406556789); Li, Xinghang (59758531800); Hu, Ze (58805739600)","7406556789; 59758531800; 58805739600","Survey of deepfake face generation and detection technologies; 深度伪造人脸生成与检测技术综述","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008819125&partnerID=40&md5=23e2de9e4742e4f6bddb362c4decf368","In the face of the serious threat posed by the application of deepfake technology in the field of face forgery to information security，the latest progress and main characteristics of deepfake face generation technology were first comprehensively reviewed and summarized．This technology has strong deceptiveness，low forgery cost，and high detection difficulty，making it difficult for the public and existing detection methods to effectively distinguish and detect．Secondly，according to the differences in forgery types，deepfake face generation technology was divided into four categories，which were complete face generation，attribute editing，identity replacement，and facial reenactment．For each type of technology，a detailed elaboration and analysis were carried out to clarify its technical principles and application scenarios． Thirdly，the datasets of real faces and deepfake faces involved in deepfake face detection technology were systematically summarized． Meanwhile，starting from feature selection，the existing deepfake face detection methods were classified，and a detailed analysis and comparison were made，including detection methods based on biometric features，identity information，image spatial features，image frequency-domain features，temporal features，and hybrid features．Finally，the challenges and future research directions in the fields of deepfake face generation and detection technology were deeply explored，respectively． © 2025 Huazhong University of Science and Technology. All rights reserved.","deepfake detection; deepfake technology; facial forgery; information security; media forensics"
"Mamarasulov, S.; Chen, L.; Chen, C.; Li, Y.; Wang, C.","Mamarasulov, Sardor (59399692800); Chen, Lianggangxu (57320560000); Chen, Changgu (58849527400); Li, Yang (59814621600); Wang, Changbo (59814882100)","59399692800; 57320560000; 58849527400; 59814621600; 59814882100","Data augmentation with attention framework for robust deepfake detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003593535&partnerID=40&md5=6f34dcf34febca6fde855a4c1e05ccd7","Deepfake detection has become an essential task in combating the proliferation of manipulated media. Current methods of deepfake detection typically use a Sequential DeepFake Manipulation Architecture to model the face features, which often suffer from overfitting. The main reason lies in the model becoming too specialized in recognizing a limited set of manipulated faces used in the training data. In this paper, a Data Augmentation with Attention Framework is proposed to address overfitting for robust deepfake detaction. Firstly, we advance the existing Sequential DeepFake Manipulation Architecture by integrating Grad-CAM to focus on critical facial regions, thereby enhancing the interpretive and optimization capabilities of the model. This sequence not only preserves the integrity of important facial features but also promotes robust feature learning and model generalization. Then, we incorporate CutMix augmentation, strategically applying it to the key areas identified by Grad-CAM. Finally, We hypothesize that incorporating these augmentations into the existing method can further enhance its ability to detect deepfake manipulations. By utilizing CutMix to blend image patches, we introduce additional perturbations that encourage the model to learn more discriminative features and generalize better to unseen data. Extensive evaluations are conducted to show that our approach significantly outperforms state-of-the-art methods by a large margin. The semantic meaning of our method is also verified by the visualization results. Significantly, our experiments conducted on the Seq-DeepFake dataset demonstrate the effectiveness of this approach. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2024.","CutMix augmentation; Data augmentation; Deepfake detection; Digital manipulation; Generalization; Manipulated media; Seq-DeepFake dataset; Sequential DeepFake manipulation architecture"
"Sun, Z.; Ruan, N.","Sun, Zekun (57223991663); Ruan, Na (54684943100)","57223991663; 54684943100","GANK: Dynamic Geometric and Appearance Features for Efficient and Robust Detection of Face Forgery","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003735268&partnerID=40&md5=c3dd6615003268518e2bc1c01798279d","Deepfakes refers to various deep-learning-based techniques that manipulate the face in videos. Maliciously manufactured face forgeries could result in serious problems such as portrait infringement, information confusion, or even public panic. Previous countermeasures focused mainly on promoting detection accuracy while relatively overlooking robustness and computational overhead. In this work, we propose an efficient and robust framework named GANK, which discriminates Deepfake videos through temporal modeling on decoupled geometric and appearance features. A temporal denoising technique featuring landmark tracking and Kalman filtering is introduced to optimize the feature sequences, and multi-stream Recurrent Neural Networks (RNN) are constructed for sufficient exploitation of dynamic features. Besides, we introduce two optimizations to alleviate overfitting and enhance the utilization of temporal information, including channel-wise dropout and temporal random cropping. Our framework achieves outstanding robustness using very lightweight network backbones, reaching state-of-the-art performance on multiple benchmarks. © 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM.","Deepfake detection; Face forgery; Facial landmarks; Multimodal learning; Video analysis"
"Li, B.; Zhao, H.; Li, L.","Li, Boyang (59758433000); Zhao, Huihuang (35200084000); Li, Leyi (59758463000)","59758433000; 35200084000; 59758463000","FDPNet: Deep forgery detection by leveraging multi-scale self-forgery images generating","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003796125&partnerID=40&md5=9d8f2d5c15c5951d489c37c8fa3dc9ae","With the continuous advancement of deep learning-based generation models, the problem of facial forgery has become increasingly prevalent. Therefore, deep forgery detection has become a major research focus, attracting widespread attention from scholars. However, the complex and diverse technologies employed in facial forgery and generation bring tremendous challenges for the generalization of detection models. For this, we propose a new forgery feature extraction network, FDPNet, with the goal of training a model that can effectively extract forgery traces from various media types and accurately predict the forgery regions to distinguish between genuine and fake content. To improve the model’s accuracy, this work also proposes an adversarial data augmentation technique, AMSM. This method aims to improve the detection model’s generalization ability by diversifying the types of forgery and strengthening self-supervised tasks that are sensitive to specific forgery configurations. Experimental results show that our model’s performance on the dataset was improved by 0.09%. The model’s generalization ability was significantly enhanced in cross-dataset testing, with improvements of 0.66%, 0.43%, and 1.15%. These innovations significantly enhance the accuracy and generalization of forgery detection. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2025.","Adversarial learning; Deepfake detection; Face forgery detection; Multi-scale feature extraction"
"Lipianina-Honcharenko, K.; Melnyk, N.; Ivasechko, A.; Telka, M.; Illiashenko, O.","Lipianina-Honcharenko, Khrystyna (59548850400); Melnyk, Nazar (59170782200); Ivasechko, Andrii (59171551200); Telka, Mykola (59220096000); Illiashenko, Oleg A. (55842633400)","59548850400; 59170782200; 59171551200; 59220096000; 55842633400","Neural Network Ensemble Method for Deepfake Classification Using Golden Frame Selection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003448186&partnerID=40&md5=645710d794b9bfd16b706ff97227b685","Deepfake technology poses significant threats in various domains, including politics, cybersecurity, and social media. This study uses the golden frame selection technique to present a neural network ensemble method for deepfake classification. The proposed approach optimizes computational resources by extracting the most informative video frames, improving detection accuracy. We integrate multiple deep learning models, including ResNet50, EfficientNetB0, Xception, InceptionV3, and Facenet, with an XGBoost meta-model for enhanced classification performance. Experimental results demonstrate a 91% accuracy rate, outperforming traditional deepfake detection models. Additionally, feature importance analysis using Grad-CAM highlights how different architectures focus on distinct facial regions, enhancing overall model interpretability. The findings contribute to of robust and efficient deepfake detection techniques, with potential applications in digital forensics, media verification, and cybersecurity. © 2025 by the authors.","deepfake detection; EfficientNetB0; Facenet; golden frame selection; Grad-CAM; InceptionV3; neural network ensemble; ResNet50; Xception; XGBoost"
"Shi, Z.; Liu, W.; Chen, H.","Shi, Zenan (57188923911); Liu, Wenyu (57202069905); Chen, Haipeng (35753222600)","57188923911; 57202069905; 35753222600","Face Reconstruction-Based Generalized Deepfake Detection Model with Residual Outlook Attention","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003712183&partnerID=40&md5=f0ba7a479cbbac29a8369fe09f85db71","With the continuous development of deep counterfeiting technology, the information security in our daily life is under serious threat. While existing face forgery detection methods exhibit impressive accuracy when applied to datasets such as FaceForensics++ and Celeb-DF, they falter significantly when confronted with out-of-domain scenarios. This causes specialization of learned representations to known forgery patterns presented in the training set, rendering it difficult to detect forgeries with unknown patterns. To address this challenge, we propose a novel end-to-end Face Reconstruction-Based Generalized Deepfake Detection (FRG2D) model with Residual Outlook Attention (ROA), which emphasizes the robust visual representations of genuine faces and discerns the subtle differences between authentic and manipulated facial images. Our methodology entails reconstructing authentic face images using an encoder-decoder architecture based on U-net, facilitating a deeper understanding of disparities between genuine and manipulated facial images. Furthermore, we integrate the convolutional block attention module (CBAM) and channel attention block (CAB) to selectively focus the network's attention on salient features within real face images. Furthermore, we employ ROA to guide the network's focus towards precise features within manipulated facial images. Simultaneously, the computed reconstruction differences obtained through ROA serves as the ultimate representation fed into the classifier for face forgery detection. Both the reconstruction and classification learning processes are optimized end-to-end. Through extensive experimentation, our model demonstrated a substantial improvement in deepfake detection across unknown domains, while maintaining a high accuracy within the known domain. © 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM.","cross-domain generalization; Deepfake detection; face reconstruction; residual outlook"
"Zhou, C.; Li, F.W.B.; Song, C.; Zheng, D.; Yang, B.","Zhou, Changshuang (59540773400); Li, Frederick W.B. (7406057098); Song, Chao (57199789791); Zheng, Dong (58745105000); Yang, Bailin (13105420500)","59540773400; 7406057098; 57199789791; 58745105000; 13105420500","3D data augmentation and dual-branch model for robust face forgery detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216862698&partnerID=40&md5=067bae7db56f20def336a5b09deafefb","We propose Dual-Branch Network (DBNet), a novel deepfake detection framework that addresses key limitations of existing works by jointly modeling 3D-temporal and fine-grained texture representations. Specifically, we aim to investigate how to (1) capture dynamic properties and spatial details in a unified model and (2) identify subtle inconsistencies beyond localized artifacts through temporally consistent modeling. To this end, DBNet extracts 3D landmarks from videos to construct temporal sequences for an RNN branch, while a Vision Transformer analyzes local patches. A Temporal Consistency-aware Loss is introduced to explicitly supervise the RNN. Additionally, a 3D generative model augments training data. Extensive experiments demonstrate our method achieves state-of-the-art performance on benchmarks, and ablation studies validate its effectiveness in generalizing to unseen data under various manipulations and compression. © 2025","3D data augmentation; Deepfake detection; Dual-branch network"
"Yang, G.; Zuo, B.; Fang, X.; Zhang, J.","Yang, Gaoming (36976637300); Zuo, Bang (59481984000); Fang, Xianjin (26423619800); Zhang, Ji (57225122203)","36976637300; 59481984000; 26423619800; 57225122203","Exploiting optimized forgery representation space for general fake face detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212711405&partnerID=40&md5=e7949f4f8637c8b81128b6517fe24f86","Face forgery has become more realistic with deep learning in computer vision, posing a significant challenge to trustworthy face identification. Existing works have achieved considerable accuracy within the dataset by formulating the detection as a binary classification problem. These methods attempt to amplify the category differences between real and fake faces but ignore the optimization of representation space for learning the specific forgery information within samples, which results in the intra-class distribution collapse and poor generalization in unseen domains. To mitigate this issue, we propose a novel forgery detection framework that combines contrastive learning with supervised learning, named Contrastive Learning Against face Forgery (CLAF). Specifically, a dual branch learning framework is involved in extracting the consistent forgery feature distribution first. Then, we consider the similarity, variance, and covariance constraint term for the representation space, which can better preserve the specific forgery information within each sample for generalization detection. The generalization performance is confirmed on FaceForensics++, Celeb-DF, and DFDC. Extensive experiment results demonstrate the effectiveness of our framework in improving generalization. © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2024.","Contrastive learning; Deep learning; Deepfake detection; Face forgery detection"
"Ge, J.-W.; Cao, J.-X.; Zhao, Z.-X.; Liu, B.","Ge, Jiawei (57988224500); Cao, Jiuxin (14618987100); Zhao, Zhixiang (59778576200); Liu, Bo (59151910800)","57988224500; 14618987100; 59778576200; 59151910800","FSD-GAN: Generative Adversarial Training for Face Swap Detection via the Latent Noise Fingerprint","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004416507&partnerID=40&md5=ec5b6cdf5379266415bb89e869f01cbb","Current studies against DeepFake attacks are mostly passive methods that detect specific defects of DeepFake algorithms, lacking generalization ability. Meanwhile, existing active defense methods only focus on defending against face attribute manipulations, and there remain enormous challenges to establishing an active and sustainable defense mechanism for face swap detection. Therefore, we propose a novel training framework called FSD-GAN (Face Swap Detection based on Generative Adversarial Network), immune to the evolution of face swap attacks. Specifically, FSD-GAN contains three modules: the data processing module, the attack module that generates fake faces only used in training, and the defense module that consists of a fingerprint generator and a fingerprint discriminator. We embed the latent noise fingerprints generated by the fingerprint generator into face images, unperceivable to attackers visually and statistically. Once an attacker uses these protected faces to perform face swap attacks, these fingerprints will be transferred from training data (protected faces) to generative models (real-world face swap models), and they also exist in generated results (swapped faces). Our discriminator can easily detect latent noise fingerprints embedded in face images, converting the problem of face swap detection to verifying if fingerprints exist in swapped face images or not. Moreover, we alternately train the attack and defense modules under an adversarial framework, making the defense module more robust. We illustrate the effectiveness and robustness of FSD-GAN through extensive experiments, demonstrating that it can confront various face images, mainstream face swap models, and JPEG compression under different qualities. © Institute of Computing Technology, Chinese Academy of Sciences 2025.","deep learning; DeepFake detection; generative adversarial network; latent noise fingerprint"
"Yang, H.; Li, X.; Cheng, X.; Hu, Z.","Yang, Hongyu (7406556789); Li, Xinghang (59758531800); Cheng, Xiang (57188721663); Hu, Ze (58805739600)","7406556789; 59758531800; 57188721663; 58805739600","Few-Shot Deepfake Face Detection Method Based on Vision-Language Model; 基于视觉 -语言模型的小样本深度伪造人脸检测方法","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003799474&partnerID=40&md5=2493b159f266d45e28a8ce3c4ac286a3","Aiming at the limitations of existing deepfake face detection methods in terms of model complexity, sample size requirements and adaptability to new deepfake techniques, a few-shot deepfake face detection method based on visual-language model(FDFD-VLM) is proposed. FDFD-VLM is built upon contrastive language-image pre-training(CLIP). Visual features are optimized through a face region extraction and high-frequency feature enhancement module. Prompt adaptability is improved by a classless differentiated prompt optimization module, while multimodal feature representation is strengthened by CLIP encoding attention optimization module. Additionally, a triplet loss function is introduced to improve the model discriminative capability. Experimental results demonstrate that FDFD-VLM outperforms existing methods on multiple deepfake face datasets and achieves efficient detection performance in few-shot deepfake face detection scenarios. © 2025 Science Press. All rights reserved.","Deepfake Detection; Few-Shot Detection; Prompt Engineering; Visual-Language Model"
"Jin, X.; Yu, W.; Chen, D.-W.; Shi, W.","Jin, Xiao (57193447375); Yu, Wen (58978691600); Chen, Daiwei (59477767100); Shi, Wei (59103810700)","57193447375; 58978691600; 59477767100; 59103810700","DFD-NAS: General deepfake detection via efficient neural architecture search","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212410143&partnerID=40&md5=5c6234648ccfceb75548b48ded459090","As the saying goes, “seeing is believing”. However, with the development of digital face editing tools, we can no longer trust what we can see. Though face forgery detection has made promising progress, most current methods are manually designed by human experts, which is labor-intensive. In this paper, we develop an end-to-end framework based on neural architecture search (NAS) for deepfake detection, which can automatically design network architectures without human intervention. First, a forgery-oriented search space is created to choose appropriate operations for this task, which facilitates the search process in finding the most valuable gradient information for face forgery detection. Second, inspired by the fact that the gap between training error and test error is a good indicator of generalization ability for a classification task, we propose a novel performance estimation metric. This metric encourages the error in the performance estimation phase to be close to the error in the search phase, which guides the search process to select more general models. The cross-dataset search is also considered to develop more general architectures. Eventually, we design a cell cascaded pyramid network (C2PN) for final detection, which aggregates multiscale features for performance improvements. Compared with state-of-the-art networks artificially designed, our method achieves competitive performance in both in-dataset and cross-dataset scenarios. © 2024 Elsevier B.V.","Deepfake detection; Face forgery detection; Neural Architecture Search (NAS); Video forensics"
"Ma, L.; Yang, P.; Xu, Y.; Yang, Z.; Li, P.; Huang, H.","Ma, Lixia (59203287900); Yang, Puning (58161052400); Xu, Yuting (57227677100); Yang, Ziming (57538382600); Li, Peipei (57205367971); Huang, Huaibo (57200614611)","59203287900; 58161052400; 57227677100; 57538382600; 57205367971; 57200614611","Deep learning technology for face forgery detection: A survey","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211107524&partnerID=40&md5=74e4b287421e1b4237cdcdf3b9d71966","Currently, the rapid development of computer vision and deep learning has enabled the creation or manipulation of high-fidelity facial images and videos via deep generative approaches. This technology, also known as deepfake, has achieved dramatic progress and become increasingly popular in social media. However, the technology can generate threats to personal privacy and national security by spreading misinformation. To diminish the risks of deepfake, it is desirable to develop powerful forgery detection methods to distinguish fake faces from real faces. This paper presents a comprehensive survey of recent deep learning-based approaches for facial forgery detection. We attempt to provide the reader with a deeper understanding of the current advances as well as the major challenges for deepfake detection based on deep learning. We present an overview of deepfake techniques and analyze the characteristics of various deepfake datasets. We then provide a systematic review of different categories of deepfake detection and state-of-the-art deepfake detection methods. The drawbacks of existing detection methods are analyzed, and future research directions are discussed to address the challenges in improving both the performance and generalization of deepfake detection. © 2024 Elsevier B.V.","Audio–visual detection; Deepfake detection; Face forgery detection"
"Zhang, J.; Xu, P.; Liu, W.; Guo, X.; Sun, F.","Zhang, Jing (56218503600); Xu, Pan (57368358700); Liu, Wenjun (59564488000); Guo, Xiaoxuan (59565000000); Sun, Fang (36678138100)","56218503600; 57368358700; 59564488000; 59565000000; 36678138100","Negative instance generation for cross-domain facial forgery detection; 多样性负实例生成的跨域人脸伪造检测","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218264019&partnerID=40&md5=77f85a40b88bc5dbda08410f1349c13d","Objective With the rapid development of multimedia，mobile internet，and artificial intelligence technologies，facial recognition has achieved tremendous success in areas such as identity verification and security monitoring. However，with its widespread application，the risk of facial forgery attacks is gradually increasing. These attacks leverage deep learning models to create fraudulent digital content，including images，videos，and audio，posing a potential threat to societal stability and national security. Therefore，achieving deepfake detection is crucial for maintaining individual and organizational interests，ensuring public safety，and promoting the sustainable development of innovative technologies. According to different modes of image representation，deepfake detection methods can generally be divided into two categories. First，methods based on traditional image feature description typically involve image processing and feature extraction based on signal transformation models. Second，methods based on deep learning strategies for forged facial detection employ complex deep neural networks to obtain more discriminative high-dimensional nonlinear facial feature descriptions，thereby improving forgery detection accuracy. Both of these methods have achieved satisfactory results in deepfake detection experiments. However，most training and testing samples for these models are collected from the same data domain，resulting in excellent performance under such conditions；subsequently，it becomes challenging to obtain testing samples that are consistent with the distribution of the original training samples in practical applications，which may limit the application of these models in free-scene forgery detection tasks and even lead to complete model failure. Therefore，some scholars have proposed a data augmentation framework based on structural feature mining to increase the performance of convolutional neural network detectors. However，when faces are seamlessly integrated with backgrounds at the pixel level，the recognition accuracy significantly decreases. Consequently，some scholars have utilized transformer network architectures to construct deep forgery detection frameworks. Although this model achieves satisfactory generalization by deeply understanding the manipulated regions，it lacks descriptions of local tampering representations，and its detection efficiency is also quite low. On this basis，the main challenges faced in constructing deepfake detection models in cross-domain scenarios can be summarized as follows：1）extracting discriminative representations of forged facial images. The forgery process of facial images typically involves tampering or replacing local features of the image，posing challenges for obtaining discriminative features. 2）Improving the generalizability of detection models. Overreliance on current domain data during model training reduces the generalizability of recognition to other domain data，and when facing more challenging free-forgery detection scenarios，model failure may occur. This study addresses these challenges by introducing a cross-domain detection model that is based on diverse negative instance generations. Method The model achieves feature augmentation of forged negative instances and enhances the cross-domain recognition accuracy and generalizability by constructing a Siamese autoencoder network architecture with multiview feature fusion. It consists of the following three parts：1）the model implements discriminative multiview feature fusion under contrastive constraints. First，a Siamese autoencoder network is constructed to extract different view features. Second，contrastive constraints are employed to achieve multiview feature fusion. Given that typical facial forgery image manipulation involves only small-scale replacements and tampering，the global features of forged facial images are remarkably similar to those of real faces. Contrastive loss enables the differentiation of weakly discriminative hard samples. It maximizes the similarity of intraclass features while minimizing the similarity of interclass features. Finally，comprehensive learning is facilitated by guiding the supervised feature extraction network to retain important feature information of the original input，an approach for emphasizing the learning of discriminative feature representations. This study proposes the use of reconstruction loss to constrain the feature network by computing the difference between the decoder output and the original input. 2）The model achieves diversity in negative instance feature augmentation to enhance model generalizability，ensuring satisfactory recognition performance on cross-domain datasets. First，the rules for generating the fused samples are defined. This study statistically visualizes the network output feature histograms of constructed samples with different labels via feature visualization，analyzes the statistical patterns of negative samples，and defines feature-level sample generation rules：except when both view features are from positive samples，all other combinations of feature samples are generated as negative samples. Second，diverse forged feature sets are constructed using selected samples to enable the network to learn more discriminative features. Finally，a global training sample set is obtained by connecting the original training samples and augmented samples. 3）The model implements a discriminator construction with importance sample weighting. When the abovementioned feature augmentation of negative instances is achieved，the number of original negative instances can be significantly increased. This study introduces an importance weighting mechanism to avoid model overfitting on negative samples and underfitting on positive samples. First，the matrix is initialized to set different weights for each class sample，allowing negative samples to be weighted according to their predicted probabilities while keeping positive samples unchanged，thereby approximately achieving class balance during the loss calculation. Through negative sample weighting，the model is guided to pay more attention to positive sample features and prevent the classification decision boundary from biasing toward negative samples. Second，the distance between the predicted probability distribution and the true probability distribution was measured via cross-entropy loss as the classification loss function to supervise the classification results. Finally，the total loss function for model training is obtained. Result Experiments were conducted on three publicly available datasets to verify the effectiveness of the proposed method in a cross-domain environment. The model was subsequently compared with other popular methods，namely，FaceForensics++（FF++），Celeb-DFv2，and the Deepfake Detection Challenge，and the results were analyzed. The FF++ dataset comprises three versions based on different compression levels：c0（original），c23（high quality），and c40（low quality）. This study utilized the c23 and c40 versions for experimentation. The Celeb-DFv2 dataset is widely employed to test the models’generalization capabilities，as its forged images lack obvious visual artifact characteristics of deepfake manipulation，posing significant challenges in generalization detection. In the experiments，100 genuine videos and 100 forged videos were randomly selected，with one image extracted every 30 frames. For the DFDC dataset，140 videos were randomly selected，with 20 frames extracted from each video for testing. According to the experimental results，the proposed model exhibited a 10% improvement in the area under the curve（AUC）of the receiver operating characteristics compared with other state-of-the-art methods. Additionally，the model’s detection results in the native domain environment were validated，showing an approximate 10% and 5% increase in the ACC（accuracy score）and AUC values，respectively，compared with those of the other methods. Conclusion The method proposed in this study achieves superior performance in both cross-domain and in-domain deepfake detection. © 2025 Editorial and Publishing Board of JIG. All rights reserved.","contrastive constrain; cross-domain face forgery detection; deepfake detection; feature generation; multi-view feature fusion"
"Lee, S.-H.; Yun, G.-E.; Park, S.H.; Lim, M.Y.; Lee, Y.K.","Lee, Soo-hyun (57414324500); Yun, Gyungeun (57415431700); Park, Seong-hee (57991653000); Lim, Min-young (57991652900); Lee, Younkyu (56241842600)","57414324500; 57415431700; 57991653000; 57991652900; 56241842600","Towards Robust Deepfake Detection Based on Heart Rate Analysis","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216644310&partnerID=40&md5=923e093be6921dfae62b34b5f25fdd9e","Remote photoplethysmography (rPPG)-based deepfake detection analyzes a target’s heart rate (HR) patterns in a video. However, existing studies on rPPG-based deepfake detection have primarily focused on detection algorithms that utilize extracted HR values, rather than on mechanisms for acquiring and analyzing informative HR patterns. To establish robust rPPG-based deepfake detection, it is required to clarify the impact of key factors that directly affect HR extraction and processing. We defined the key factors that directly affect the performance of rPPG-based deepfake detection, including the facial region, extraction interval, rPPG extraction method, and feature engineering method. Based on these defined key factors, we assessed the impact of each variable for the key factors on rPPG-based deepfake detection performance. Furthermore, we identified the optimal combination of variables, which maximizes the performance of rPPG-based deepfake detection. Through statistical validation of 164 real-world videos, we conducted experimental evaluations. The results revealed variables for each key factor that yielded significant differences in HR values between real and fake videos. Moreover, we identified the optimal combination of the variables, enabling a pronounced distinction between real and fake videos. This paper successfully confirms the impactful role of individual variables and their optimal combinations for each key factor in rPPG-based deepfake detection. © © 2025 KSII.","Deepfake; deepfake detection; face recognition; remote photoplethysmography; rPPG"
"Birla, L.; Saikia, T.; Gupta, P.","Birla, Lokendra (57204565494); Saikia, Trishna (57670378700); Gupta, Puneet (57207922785)","57204565494; 57670378700; 57207922785","AVENUE: A Novel Deepfake Detection Method Based on Temporal Convolutional Network and rPPG Information","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217837454&partnerID=40&md5=d039f9415e354e3d4706ea87cba84656","In Deep Learning (DL), an adversary creates Deepfakes by manipulating facial features to fool someone. The Deepfakes pose a security threat to anyone's privacy and a primary concern for our society. It can be detected by utilizing the texture and physiological properties of the face, like eye and lip movements; however, such methods are incompetent when Deepfakes are created using recent Generative Adversarial Networks (GAN). Alternatively, Remote Photoplethysmography (rPPG) information can be used for Deepfake detection because GANs neglect human physiological information for Deepfake generation. Such detection can be inaccurate when rPPG signals are affected by the noises induced by facial deformation and illumination variations. Furthermore, the exiting Deepfake detections are usually performed using sequential models, and such models fail to process the long sequence of temporal information. These issues are mitigated by our proposed method AVENUE, that is, noel depfake detectio method based on temporal convoltion ntwork and rPPG information. For mitigating the noise issues in the rPPG signals, the proposed method detects and employs relatively stable clips of the input video for Deepfake detection. The stable clips are those clips that are least affected by facial deformations. Also, we use a modified Temporal convolutional network to model the long sequence of Deepfake information rather than the sequential architectures. We performed the experimental result on publicly available datasets of Deepfake videos. It demonstrates that our proposed method performs better than the existing rPPG-based Deepfake detection methods. © 2025 Copyright held by the owner/author(s).","and Temporal Convolution Networks (TCN); Deep learning; Deepfake detection; remote-Photoplethysmography (rPPG)"
"Chen, Z.; Wang, X.; Li, Y.","Chen, Zengqiang (59661442400); Wang, Xudong (59648906400); Li, Yuezun (57188647738)","59661442400; 59648906400; 57188647738","Enhancing Deepfake Detection via Adversarial Generative Learning","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219199980&partnerID=40&md5=90f4deb61638eda8c888b84a396c1644","Deepfake technology generates highly realistic videos effortlessly, raising serious concerns about privacy violations, misinformation, and financial fraud. Detecting Deepfakes is the most effective solution to address these issues. While existing detection methods perform well on standard protocols, they struggle with real-world scenarios due to constantly emerging unknown forgery types. To enhance detection generalization, recent methods augment training images by synthesizing diverse forged faces (pseudo-fake faces) and identifying common forgery features. In this paper, we describe a new augmentation-based method to further improve the detection generalization. Our method leverages adversarial generative learning, which adaptively synthesizes effective pseudo-fake faces based on a generator network, a face synthesizer, a face reconstruction, and a discriminator. Extensive experiments on several public datasets demonstrate the efficacy of our method. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.","Adversarial Training; Deepfake Detection"
"Yang, S.; Qi, X.; Wang, H.; Wang, J.; Sun, Y.","Yang, Shaocong (59145070400); Qi, Xiaolong (59660890900); Wang, Huiling (57850819500); Wang, Jian (59661001500); Sun, Yunlian (55866644500)","59145070400; 59660890900; 57850819500; 59661001500; 55866644500","Exposing Deepfakes with Noise-Based Clues","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219177818&partnerID=40&md5=9bb2ee8414273c2e4b166fdcbfda1727","Current deepfake detection methods focus on learning specific forged traces, but they struggle with unknown forgery types. To address this issue, we propose a noise feature consistency-based approach. We utilize both spatial and noise features in face images, as noise features effectively capture forged traces. To achieve robust feature representations, we design a cross-attention module to interact between noise and spatial features. Additionally, we design a comprehensive consistency guidance module to consider both intra- and inter-instance feature consistency. Experiments prove that our proposed method has good robustness and generalization. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.","deepfake detection; deepfakes; noise feature"
"Mansoor, N.; Iliev, A.I.","Mansoor, Nazneen (58158572200); Iliev, Alexander I. (57207799868)","58158572200; 57207799868","Explainable AI for DeepFake Detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215775217&partnerID=40&md5=9c6478446f895ec44488e9360229e219","The surge in technological advancements has resulted in concerns over its misuse in politics and entertainment, making reliable detection methods essential. This study introduces a deepfake detection technique that enhances interpretability using the network dissection algorithm. This research consists of two stages: (1) detection of forged images using advanced convolutional neural networks such as ResNet-50, Inception V3, and VGG-16, and (2) applying the network dissection algorithm to understand the models’ internal decision-making processes. The CNNs’ performance is evaluated through F1-scores ranging from 0.8 to 0.9, demonstrating their effectiveness. By analyzing the facial features learned by the models, this study provides explainable results for classifying images as real or fake. This interpretability is crucial in understanding how deepfake detection models operate. Although numerous detection models exist, they often lack transparency in their decision-making processes. This research fills that gap by offering insights into how these models distinguish real from manipulated images. The findings highlight the importance of interpretability in deep neural networks, providing a better understanding of their hierarchical structures and decision processes. © 2025 by the authors.","convolutional neural network; deep learning; deepfake detection; explainability; explainable artificial intelligence; face dictionary; inception V3; model interpretability; network dissection; ResNet-50; VGG-16"
"Duan, H.; Jiang, Q.; Xu, X.; Wang, Y.; Yi, H.; Yao, S.; Jin, X.","Duan, Hanxian (58988964800); Jiang, Qian (57194699462); Xu, Xiaoyuan (59519548800); Wang, Yu (59518890500); Yi, Huasong (59519215600); Yao, Shaowen (24473851600); Jin, Xin (56991832300)","58988964800; 57194699462; 59519548800; 59518890500; 59519215600; 24473851600; 56991832300","Adversarial Samples Generated by Self-Forgery for Face Forgery Detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215439650&partnerID=40&md5=b5eea23177bf540c6b0f964ec219f331","As deep learning techniques continue to advance making face synthesis realistic and indistinguishable. Algorithms need to be continuously improved to cope with increasingly sophisticated forgery techniques. Current face forgery detectors achieve excellent results when detecting training and testing from the same dataset. However, the detector performance degrades when generalized to unknown forgery methods. One of the most effective ways to address this problem is to train the model using synthetic data. This helps the model learn a generic representation for deep forgery detection. In this article, we propose a new strategy for synthesis of training data. To improve the quality and sensitivity to forgeries, we include a Multi-scale Feature Aggregation Module and a Forgery Identification Module in the generator and discriminator. The Multi-scale Feature Aggregation Module captures finer details and textures while reducing forgery traces. The Forgery Identification Module more acutely detects traces and irregularities in the forgery images. It can better distinguish between real and fake images and improve overall detection accuracy. In addition, we employ an adversarial training strategy to dynamically construct the detector. This effectively explores the enhancement space of forgery samples. Through extensive experiments, we demonstrate the effectiveness of the proposed synthesis strategy. © 2019 IEEE.","adversarial samples; deep learning; Deepfake detection; face forgery detection"
"Guo, Z.; Zhang, B.; Fan, J.; Teng, Z.; Fan, J.","Guo, Zishuo (59506592800); Zhang, Baopeng (57211546343); Fan, Jack (58684184400); Teng, Zhu (36553668200); Fan, Jianping (57220794072)","59506592800; 57211546343; 58684184400; 36553668200; 57220794072","Modal-Guided Multi-Domain Inconsistency Learning for Face Forgery Detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214522636&partnerID=40&md5=305fe670469e77ad357cad3664391dbc","The remarkable development of deepfake models has facilitated the generation of fake content with various modalities, such as forged images, manipulated audio, and modified video with (or without) corresponding audio. However, many existing methods only analyze content with known and fixed modalities to identify deepfakes, which restricts their focus on intra-domain inconsistencies, and they fail to explore diverse modal and inter-domain hierarchical inconsistencies. In this work, we propose a novel unified neural network named MGDL-Net (Modal-Guided Domain Learning Network), which contains a spatial branch, a temporal branch, and a frequency branch. This diverse combination of branches endows our network with the ability to detect face-related input with flexible modalities and perceive both intra- and inter-domain inconsistencies, such as unimodal, bimodal, and trimodal modalities. To effectively and comprehensively capture the various inconsistencies, we propose implementing heterogeneous inconsistency learning (HIL) with a three-level joint extraction paradigm. In particular, HIL performs heterogeneous learning from spatial, temporal, and frequency perspectives to generate more generalized representations of forgery and eliminate the interference of static redundant information. Furthermore, a multi-modal deepfake dataset is also constructed. We have conducted extensive experiments, and our results have demonstrated that the proposed method can achieve an outstanding performance compared to that of numerous state-of-the-art methods, which implies that the cross-modal inconsistency learning we propose is beneficial for multi-modal face forgery detection. © 2024 by the authors.","anti-face forgery; domain inconsistency learning; multi-modal deepfake detection"
"Hu, J.; Liang, J.; Qin, Z.; Liao, X.; Zhou, W.; Lin, X.","Hu, Juan (57223045710); Liang, Jinwen (57201734723); Qin, Zheng (57198995944); Liao, Xin (26665606800); Zhou, Wenbo (57192111936); Lin, Xiaodong (17435253300)","57223045710; 57201734723; 57198995944; 26665606800; 57192111936; 17435253300","ADA-FInfer: Inferring Face Representations From Adaptive Select Frames for High-Visual-Quality Deepfake Detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214101311&partnerID=40&md5=958236d225129436b9b0ebeb94c606e9","Interpretable deepfake detection is gaining attentionfor providing explainable, trustworthy results, avoiding the limitations of ‘black-box’ models. Current interpretable methods focus on visible artifacts in low-visual-quality deepfakes, but theseartifacts become less apparent in high-visual-quality deepfakesgenerated by advanced models. With advancements in deep generative models, producing high-visual-quality deepfakes has become a strategy to evade detection. To address this, we proposeADA − FInfer, an adaptive frame selection and interpretable facerepresentation inference method for detecting high-visual-qualitydeepfakes. ADA − FInfer adaptively selects frames by analyzingoptical flow to reveal manipulations. We also introduce an adaptiveattack method that manipulates specific frames, and our adaptiveselection strategy shows resistance to such attacks. ADA − FInferuses an encoder to learn face representations from source and targetfaces, applying a representation-prediction loss to maximize the distinction between real and fake videos. To provide further insights,we employ the joint entropy, mutual information, and conditionalentropy analyses to explain the method’s effectiveness. Extensiveexperiments and ablation studies demonstrate that ADA − FInferachieves promising performance in detecting high-visual-qualitydeepfakes. © 2004-2012 IEEE.","Adaptive frame selection; deepfake detection; high-visual-quality deepfake videos; inferring face representations"
"Tian, J.; Yu, C.; Wang, X.; Chen, P.; Xiao, Z.; Dai, J.; Han, J.; Chai, Y.","Tian, Jiahe (58535569200); Yu, Cai (57223740043); Wang, Xi (57192624112); Chen, Peng (57216430660); Xiao, Zihao (57195693259); Dai, Jiao (37010322300); Han, Jizhong (23008759600); Chai, Yesheng (58115601000)","58535569200; 57223740043; 57192624112; 57216430660; 57195693259; 37010322300; 23008759600; 58115601000","Real Appearance Modeling for More General Deepfake Detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211348486&partnerID=40&md5=d9e0f51897d4315f1477886e994bc979","Recent studies in deepfake detection have shown promising results when detecting deepfakes of the same type as those present in training. However, their ability to generalize to unseen deepfakes remains limited. This work improves the generalizable deepfake detection from a simple principle: an ideal detector classifies any face that contains anomalies not found in real faces as fake. Namely, detectors should learn consistent real appearances rather than fake patterns in the training set that may not apply to unseen deepfakes. Guided by this principle, we propose a learning task named Real Appearance Modeling (RAM) that guides the model to learn real appearances by recovering original faces from slightly disturbed faces. We further propose Face Disturbance to produce disturbed faces while preserving original information that enables recovery, which aids the model in learning the fine-grained appearance of real faces. Extensive experiments demonstrate the effectiveness of modeling real appearances to spot richer deepfakes. Our method surpasses existing state-of-the-art methods by a large margin on multiple popular deepfake datasets. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.","Deepfake Detection; Face Forgery Detection; Multimedia Forensic"
"Xie, Y.; Xu, H.; Chen, X.; Huang, Y.","Xie, Yuying (59425508100); Xu, Huahu (55493978900); Chen, Xingyuan (59296679100); Huang, Yuzhe (57222574306)","59425508100; 55493978900; 59296679100; 57222574306","A Meta-learning Method for Generalizable Face Forgery Detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210264453&partnerID=40&md5=90c50b67f466b329b93f86797d70539e","Face forgery technology poses significant risks, highlighting the need for effective detection methods. However, existing approaches often focus on specific forgery types and lack generalization. We treat face forgery detection as a zero-shot learning problem, aiming to detect unseen forgery methods. We propose a meta-learning-based model that combines EfficientNet and the Vision Transformer (ViT). The model processes images through two branches: ViT detects global discrepancies, while EfficientNet captures local features. Cross-attention integrates these features, enhancing detection capabilities. And we employ quadruplet loss to enhance the compactness within classes and the separation between different classes. Our model, evaluated on FaceForensics++ and Celeb-DF datasets, shows improved generalization and performance. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.","Deepfake detection; Meta learning; Zero-shot learning"
"Duan, H.; Jiang, Q.; Jin, X.; Wozniak, M.; Zhao, Y.; Wu, L.; Yao, S.; Zhou, W.","Duan, Hanxian (58988964800); Jiang, Qian (57194699462); Jin, Xin (56991832300); Wozniak, Michal (35410703700); Zhao, Yi (58605259600); Wu, Liwen (57200984308); Yao, Shaowen (24473851600); Zhou, Wei (56857006600)","58988964800; 57194699462; 56991832300; 35410703700; 58605259600; 57200984308; 24473851600; 56857006600","Mf-net: multi-feature fusion network based on two-stream extraction and multi-scale enhancement for face forgery detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209823553&partnerID=40&md5=1ffea08f2a398fbbb78e9c9005a03ae2","Due to the increasing sophistication of face forgery techniques, the images generated are becoming more and more realistic and difficult for human eyes to distinguish. These face forgery techniques can cause problems such as fraud and social engineering attacks in facial recognition and identity verification areas. Therefore, researchers have worked on face forgery detection studies and have made significant progress. Current face forgery detection algorithms achieve high detection accuracy within-dataset. However, it is difficult to achieve satisfactory generalization performance in cross-dataset scenarios. In order to improve the cross-dataset detection performance of the model, this paper proposes a multi-feature fusion network based on two-stream extraction and multi-scale enhancement. First, we design a two-stream feature extraction module to obtain richer feature information. Secondly, the multi-scale feature enhancement module is proposed to focus the model more on information related to the current sub-region from different scales. Finally, the forgery detection module calculates the overlap between the features of the input image and real images during the training phase to determine the forgery regions. The method encourages the model to mine forgery features and learns generic and robust features not limited to a particular feature. Thus, the model achieves high detection accuracy and performance. We achieve the AUC of 99.70% and 90.71% on FaceForensics++ and WildDeepfake datasets. The generalization experiments on Celeb-DF-v2 and WildDeepfake datasets achieve the AUC of 80.16% and 65.15%. Comparison experiments with multiple methods on other benchmark datasets confirm the superior generalization performance of our proposed method while ensuring model detection accuracy. Our code can be found at: https://github.com/1241128239/MFNet. © The Author(s) 2024.","Attention mechanism; Deep learning; Deepfake detection; Face forgery detection; Feature enhancement; Feature extraction"
"Guan, W.; Wang, W.; Peng, B.; Dong, J.; Tan, T.","Guan, Weinan (57223755493); Wang, Wei (56948518500); Peng, Bo (57201594957); Dong, Jing (55477985000); Tan, Tieniu (7402022125)","57223755493; 56948518500; 57201594957; 55477985000; 7402022125","ST-SBV: Spatial-Temporal Self-Blended Videos for Deepfake Detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208173004&partnerID=40&md5=89dc5f0e3f95e2e9416f54430f47b9f3","The generalization ability to unseen forgery data is a critical concern in deepfake detection tasks. In this paper, we propose a novel spatial-temporal generation method for synthesizing forgery data, called spatial-temporal self-blended video (ST-SBV). ST-SBV is specifically designed to train deepfake detectors in a self-supervised manner. We utilize various image augmentation techniques on a genuine video to create pseudo source and target videos. Subsequently, ST-SBV is generated by blending them using face masks, following the generation process of a deepfake video. The key idea behind ST-SBV is to imitate the spatial and temporal artifacts in deepfake videos that are inherent and generalizable across deepfake generation methods. This encourages detectors to learn more general and effective representations. Specially, compared to existing data synthesis methods, ST-SBV addresses the gap in investigating spatial-temporal inconsistencies in forgery videos. Extensive experiments demonstrate that our method significantly improves the generalization performance of deepfake detectors on unknown forgery data. In particular, on the challenging datasets DFDCP and DFDC, our method outperforms the baselines by 5.20% and 4.94%, respectively. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.","Deepfake detection; Synthetic forgery data"
"Zhang, D.; Qi, F.; Chen, J.; Chen, J.; Gong, R.; Tian, Y.; Zhang, L.","Zhang, Dengyong (55318418900); Qi, Feifan (59553692900); Chen, Jiahao (58993567700); Chen, Jiaxin (57211874368); Gong, Rongrong (57204182451); Tian, Yuehong (59128471700); Zhang, Lebing (57192932172)","55318418900; 59553692900; 58993567700; 57211874368; 57204182451; 59128471700; 57192932172","Fake Face Detection Based on Fusion of Spatial Texture and High-Frequency Noise","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207949303&partnerID=40&md5=6ecfab7ba4d80263c4229e46490b3118","The rapid development of the Internet has led to the widespread dissemination of manipulated facial images, significantly impacting people's daily lives. With the continuous advancement of Deepfake technology, the generated counterfeit facial images have become increasingly challenging to distinguish. There is an urgent need for a more robust and convincing detection method. Current detection methods mainly operate in the spatial domain and transform the spatial domain into other domains for analysis. With the emergence of transformers, some researchers have also combined traditional convolutional networks with transformers for detection. This paper explores the artifacts left by Deepfakes in various domains and, based on this exploration, proposes a detection method that utilizes the steganalysis rich model to extract high-frequency noise to complement spatial features. We have designed two main modules to fully leverage the interaction between these two aspects based on traditional convolutional neural networks. The first is the multi-scale mixed feature attention module, which introduces artifacts from high-frequency noise into spatial textures, thereby enhancing the model's learning of spatial texture features. The second is the multiscale channel attention module, which reduces the impact of background noise by weighting the features. Our proposed method was experimentally evaluated on mainstream datasets, and a significant amount of experimental results demonstrate the effectiveness of our approach in detecting Deepfake forged faces, outperforming the majority of existing methods. © 2025 Chinese Institute of Electronics.","Deepfakes detection; Image forensics; Mix attention; Steganalysis rich model"
"Zhang, G.; Li, Q.; Gao, M.; Guo, S.; Jeon, G.","Zhang, Guisheng (57865198700); Li, Qilei (57202858223); Gao, Mingliang (26634962800); Guo, Siyou (59173914500); Jeon, Gwanggil (15022497800)","57865198700; 57202858223; 26634962800; 59173914500; 15022497800","Detecting Sequential Deepfake Manipulation via Spectral Transformer With Pyramid Attention in Consumer IoT","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196110283&partnerID=40&md5=6c7a49a65880330558c1958140609f4c","Recently, the Consumer Internet of Things (CIoT) has brought great convenience to people. In CIoT, face image information is indispensable for payment and checking the identity of the user in the transaction. However, the misuse of deepfake face information in CIoT transactions is a growing problem. It has seriously violated the property and privacy of individuals. Moreover, with the proliferation of easily accessible facial editing applications, individuals can effortlessly manipulate facial components through sequential multi-step manipulations. To solve this issue, we propose a Spectral Transformer with a Pyramid Attention (STPA) model to detect sequence permutations in manipulated facial images. Specifically, we introduce a pyramid attention module that integrates both spatial and channel attention mechanisms to prioritize the face region over the background region. Additionally, a spectral Transformer is employed concurrently to extract global and local features to facilitate the fine-grained extraction of the face forgery region. Comprehensive experiments prove that the proposed method can enhance the detection accuracy of the sequential deepfake manipulation task through the fine-grained extraction of features in the face forgery region. © 1975-2011 IEEE.","Consumer security; privacy preservation; pyramid attention; sequential deepfake detection; spectral transformer"
"Zhou, K.; Sun, G.; Wang, J.; Wang, J.; Yu, L.","Zhou, Kai (57219160695); Sun, Guanglu (46961469200); Wang, Jun (57203534543); Wang, Jiahui (58519282400); Yu, Linsen (13609451800)","57219160695; 46961469200; 57203534543; 58519282400; 13609451800","FLAG: frequency-based local and global network for face forgery detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188841097&partnerID=40&md5=6bb7914944d5f436b0a8c7440a05bdbd","Deepfake detection aims to mitigate the threat of manipulated content by identifying and exposing forgeries. However, previous methods primarily tend to perform poorly when confronted with cross-dataset scenarios. To address the above issue, we propose an innovative hybrid network called the Frequency-based Local and Global (FLAG) network to explore local and global information with the help of frequency-domain cues for better generalization capability. In consideration of the fact that forged faces often exhibit flaws in the frequency domain, we design a Frequency-based Attention Enhancement Module (FAEM) to enhance the aggregation of CNN and Vision Transformer (ViT). In this design, local features from CNN are attentively enhanced by selected frequency coefficients in FAEM, facilitating generalizable global features learning by the ViT module. The effectiveness of the proposed method is validated via numerous experiments and the generalization performance is improved under cross-dataset scenarios. Especially, the proposed method have obtained an AUC of 99.26% and an ACC of 96.56% using intra-dataset experimental results on FaceForensics++ (C23). © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.","Channel attention; Deepfake detection; Hybrid network; Multimedia forensics; Vision transformer"
"Gifariani; Soewito, B.","Gifariani (60221791700); Soewito, Benfano (24473788700)","60221791700; 24473788700","Explainable AI-Driven Deepfake Detection Using Gradient-Weighted Class Activation Mapping","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105023704210&partnerID=40&md5=d8bdb68adf14d58e51876c3ad1cdb4e7","The rapid rise of synthetic media technologies has made deepfake content a serious threat to digital security and authenticity. To address this challenge, this study proposes an integrated deepfake detection by combining YOLO for face detection, CNN-based classification, and XAI for interpretability. YOLO is utilized for rapid and precise localization of facial regions from video frames or images. These detected face regions are then classified as either real or deepfake using ResNet50V2, InceptionResNetV2, and Xception. To enhance transparency and trust in the model's decisions, Explainable AI (XAI) is integrated using Grad-CAM, providing visual insights into which regions influenced the classification. To improve demographic representation, we develop a custom dataset by combining CelebDFv2 with a primary dataset focused on Asian facial features. Experimental results show ResNet50V2 outperforms other models with 91.69% accuracy, 75.80% precision, and a 44.45% F1-score. The findings demonstrate the potential of integrating object detection, deep learning, and XAI to build interpretable and scalable deepfake detection systems. © 2025 IEEE.","CNN Models; Deepfake Detection; Explainable AI; Grad-CAM; YOLO"
"Khalid, F.; Haider, U.; Hanif, M.; Rashid, A.; Khalil, A.","Khalid, Fatima (58034449300); Haider, Usman (58086707800); Hanif, Muhammad Shehzad (57210377659); Rashid, Ahmar (56817948100); Khalil, Akhtar (57222485068)","58034449300; 58086707800; 57210377659; 56817948100; 57222485068","Sparse Prototype-Based Framework for Deepfake Detection Using Class-Specific Dictionary Learning","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105023329076&partnerID=40&md5=6a729f86dded7c28cd93f9898bcafa36","Deepfake detection remains a pressing challenge due to the rapid evolution of forgery techniques and the demand for robust, generalizable, and interpretable solutions. We present a sparse prototype-based framework for deepfake detection that integrates class-specific dictionary learning with high-capacity face embeddings from the InceptionResNetV2 backbone. Discriminative dictionaries for real and manipulated faces are learned, and Orthogonal Matching Pursuit is employed to encode sparse representations. Classification decisions are derived from reconstruction residuals and sparse coefficient patterns, enabling transparent, traceable predictions. The proposed method is evaluated on Celeb-DF and five FaceForensics++ manipulation subsets, including FaceShifter, NeuralTexture, DeepFakes, FaceSwap, and Face2Face. It achieves up to 98.21% accuracy on FaceSwap and 92.05% on Celeb-DF, demonstrating competitive performance with state-of-the-art deep architectures while maintaining moderate computational cost. Beyond accuracy, the framework offers intrinsic interpretability by linking predictions to semantically meaningful prototypes, making it particularly suitable for forensic and high-stakes verification scenarios. © 2025 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.","Deepfake detection; dictionary learning; face forensics; interpretable AI; prototype networks; sparse coding"
"Walczyna, T.; Żurada, J.M.; Piotrowski, Z.","Walczyna, Tomasz (57250166400); Żurada, Jacek M. (35593077400); Piotrowski, Z. (12795554600)","57250166400; 35593077400; 12795554600","RE-Mark: An Identity-Recovery Watermarking Method for Undoing Deepfake Face-Swap","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105023285566&partnerID=40&md5=776aeea685e533121c1c42f1f97243f0","In response to the growing threat of faceswap deepfakes, we introduced REMark. This active zero-bit watermark embeds a compact neural identity signature directly within a facial image and later reconstructs the pre-swap appearance from a single image. The scheme employs a pair of symmetric, attention-enhanced U-Nets acting as an embedder and extractor. It is trained with a specific training pipeline that mixes five different face-swap engines with classical degradations such as noise and blur. This diversity forces the network to learn robust, high-level cues rather than brittle artifact patterns, yielding transparent watermarks that remain visually imperceptible at a peak signal-to-noise ratio (PSNR) of approximately 36 dB. Unlike previous active defenses that only flag manipulations, RE-Mark hides enough semantic redundancy to recover an authentic face without any external reference gallery, closing the gap between fragile detectors and robust - but non-restorative - watermarks. Therefore, the method equips platforms and investigators with a practical tool for both tamper verification and postfactum identity restoration. © 2013 IEEE.","Deepfake detection; Face-swap robustness; Identity recovery; Image watermarking; Neural networks"
"Qiu, L.; Jiang, K.; Tan, X.","Qiu, Lingyu (58751895800); Jiang, Ke (58067935800); Tan, Xiaoyang (8876261800)","58751895800; 58067935800; 8876261800","RoGA: Towards Generalizable Deepfake Detection through Robust Gradient Alignment","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105022596894&partnerID=40&md5=c545d585be6975d19999b6ad55a4c0f2","Recent advancements in domain generalization for deepfake detection have attracted significant attention, with previous methods often incorporating additional modules to prevent overfitting to domain-specific patterns. However, such regularization can hinder the optimization of the empirical risk minimization (ERM) objective, ultimately degrading model performance. In this paper, we propose a novel learning objective that aligns generalization gradient updates with ERM gradient updates. The key innovation is the application of perturbations to model parameters, aligning the ascending points across domains, which specifically enhances the robustness of deepfake detection models to domain shifts. This approach effectively preserves domain-invariant features while managing domain-specific characteristics, without introducing additional regularization. Experimental results on multiple challenging deepfake detection datasets demonstrate that our gradient alignment strategy outperforms state-of-the-art domain generalization techniques, confirming the efficacy of our method. The code is available at https://github.com/Lynn0925/RoGA. © 2025 IEEE.","Deepfake Detection; Face Forgery Detection"
"Fang, Z.; Zhao, H.; Wei, T.; Zhou, W.; Wan, M.; Wang, Z.; Zhang, W.; Yu, N.","Fang, Ziyuan (58505872700); Zhao, Hanqing (57226043096); Wei, Tianyi (57221840182); Zhou, Wenbo (57192111936); Wan, Ming (58018076000); Wang, Zhanyi (58018076100); Zhang, Weiming (56459354100); Yu, Neng-Hai (7201981769)","58505872700; 57226043096; 57221840182; 57192111936; 58018076000; 58018076100; 56459354100; 7201981769","UniForensics: Face Forgery Detection via General Facial Representation","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105022594664&partnerID=40&md5=1cd3f7f6ae1936de0f2484504cfce669","The rise of deepfakes has significantly heightened concerns for privacy and the authenticity of digital media, bringing widespread attention to face forgery detection. Previous deepfake detection methods mostly depend on low-level textural features vulnerable to perturbations and fall short of detecting unseen forgery methods. In contrast, high-level semantic features are less susceptible to perturbations and not limited to forgery-specific artifacts, thus having stronger generalization. Motivated by this, we propose a detection method that utilizes high-level semantic features of faces to identify inconsistencies in temporal domain. We introduce UniForensics, a novel deepfake detection framework that leverages a transformer-based video classification network, initialized with a meta-functional face encoder for enriched facial representation. In this way, we can take advantage of both the powerful spatio-temporal model and the high-level semantic information of faces. Furthermore, to leverage easily accessible real face data and guide the model in focusing on spatio-temporal features, we design a Dynamic Video Self-Blending (DVSB) method to efficiently generate training samples with diverse spatio-temporal forgery traces using real facial videos. Based on this, we advance our framework with a two-stage training approach: The first stage employs a novel self-supervised contrastive learning, where we encourage the network to focus on forgery traces by impelling videos generated by the same forgery process to have similar representations. On the basis of the representation learned in the first stage, the second stage involves fine-tuning on face forgery detection dataset to build a deepfake detector. Extensive experiments validates that UniForensics outperforms existing face forgery detection methods in generalization ability and robustness. In particular, our method achieves 95.3% and 77.2% cross dataset AUC on the challenging Celeb-DFv2 and DFDC respectively. Code will be made publicly available. © 2004-2012 IEEE.","data synthesis; Deepfake detection; self-supervised contrastive learning"
"Atasoy, U.M.; Altintas, M.; Inan, T.","Atasoy, Utku Murat (60203438700); Altintas, Mehmet (60203200700); Inan, Tolga (25651564000)","60203438700; 60203200700; 25651564000","AI-Powered Deepfake Detection in Biometric Systems","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105022505576&partnerID=40&md5=23746c0d5dd7c3d41192515486b34c90","Deepfake technologies pose a growing threat to biometric systems by enabling the creation of highly realistic forged facial content. This study proposes a deepfake detection framework based on the XceptionNet architecture, aiming to enhance detection robustness under both familiar and unseen conditions. To achieve this, we leverage two widely adopted datasets-Celeb-DF-v2 and FaceForensics++-and construct a hybrid dataset to improve domain generalization. The pipeline includes Dlib-based face detection and alignment, consistent preprocessing, and efficient feature extraction using XceptionNet. We evaluate the system across six test settings, including unseen samples from different videos, and report high accuracy and F1 scores, even under domain shifts. Our findings show that training on diverse datasets significantly boosts generalization, and the proposed system outperforms several existing baselines on unseen Celeb-DF-v2. This work demonstrates the potential of combining architectural efficiency with dataset diversity to build deployable deepfake detection models for biometric security applications. © 2025 IEEE.","Biometric Security; Dataset Generalization; Deep Neural Networks; Deepfake Detection; Face Manipulation Forensics"
"Yadav, K.D.K.; Kavati, I.; Kurella, A.S.; Jain, S.; Katare, Y.","Yadav, Koyya Deepthi Krishna (58993087100); Kavati, Ilaiah (56286935100); Kurella, Abhihkeshav Santosh (60201287300); Jain, Savvy (60201287400); Katare, Yashsvini (60201891700)","58993087100; 56286935100; 60201287300; 60201287400; 60201891700","Context-Preserving and Sparsity-Aware Temporal Graph Network for Unified Face Forgery Detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105022297379&partnerID=40&md5=53cbf7620eada8fc8372b61c27be58f1","Deepfakes and face forgeries continue to evolve, posing significant threats to consumer privacy, reputation, and public security. Existing deep learning approaches often focus on spatial inconsistencies but fail to capture relational context across facial regions and long-term temporal anomalies such as unnatural blinking or lip synchronization errors. We propose EDRL, a lightweight model that effectively captures spatiotemporal relational dependencies for robust face forgery detection. The architecture incorporates a Spatio-Temporal Attention (STA) module built upon a lightweight MC318 3D convolutional backbone, enabling motion-aware feature extraction and region-specific attention mapping. A Sparsity-Aware Edge Dropping Relation Learner (EDRL) constructs adaptive facial graphs by pruning redundant and less informative edges. A Temporal Adaptive Aggregation Network (TAAN) then aggregates frame-level features, ensuring that temporally significant representations are preserved even after edge pruning. Extensive evaluations show that EDRL achieves 98.4% accuracy on CASIA-FASD and reduces HTER by 6.2% on Replay-Attack compared to state-of-the-art baselines, while maintaining competitive results on digital forgery datasets. By enhancing robustness to diverse manipulations while reducing computational overhead, EDRL contributes towards a secure, lightweight, and deployable framework suitable for real-world applications. © 2025 IEEE.","DeepFake detection; Face Forgery; graph convolution network; relation learning; Spatio-Temporal attention"
"Ou, F.-Z.; Guo, H.; Kwong, S.","Ou, Fuzhao (57212479525); Guo, Haifeng (57214089569); Kwong, Sam Tak Wu (7005601503)","57212479525; 57214089569; 7005601503","Towards Unified Face Verification Against Quality Variations and Deepfake","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105022134701&partnerID=40&md5=2040fd71e737198fbb604029584f12e5","Face verification aims to provide reliable biological verification results for applications in areas such as security biometric identification, judicial analysis, and digital identity platforms. However, low-quality and malicious deepfake samples caused by complex collection environments may lead to erroneous outcomes in face verification. This paper introduces a unified system for reliable face verification designed to counteract deepfakebased identity spoofing while ensuring input quality reliability. The system processes an input pair of face images or videos through a multi-module pipeline. Specifically, a face detection module crops and aligns firstly the facial regions of input sample pairs. Then, in order to measure and reject low-quality samples, we design a dual metric-driven quality assessment module via class-centric deviation and embedding uncertainty fusion. Sequentially, the deepfake detection module will filter out the input of illegally synthetic face-swapping samples for anti-spoofing. For genuine samples, a quality-aware verification module trained by self-distillation is proposed for the final face verification. Herein, during the training process, low-quality samples are guided by high-quality samples to converge toward class centroids by minimizing the Wasserstein distance between their feature distributions, thereby enhancing model accuracy without increasing spatial complexity. Extensive experiments verify the reliability of our system. © 2025 IEEE.","and face verification; deepfake detection; Face detection and alignment; face quality assessment"
"Asiri, A.; Chen, L.; Tian, Z.; Ding, X.; Yu, S.","Asiri, Ahmed Abdullah (58253671100); Chen, Luoyu (59668318700); Tian, Zhiyi (57216726214); Ding, Xiaoyu (58897205100); Yu, Shui (55741361200)","58253671100; 59668318700; 57216726214; 58897205100; 55741361200","MG-Det: Deepfake Detection with Multi-granularity","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105022014964&partnerID=40&md5=964cb961a5b9fe17ce465c2951e2008f","With the rapid advancement of generative models, deepfake creation has become increasingly sophisticated, posing serious security and privacy threats as it can be exploited for malicious purposes such as spreading misinformation, facilitating identity theft, and enabling other malicious activities. This highlights the urgent need for robust deepfake detection methods to identify manipulated content, particularly human faces. Existing deepfake detection methods primarily rely on encoder-decoder architectures, where image backbone models process visual information for classification while focusing on global features, resulting in inadequate detection accuracy and limiting their ability to capture fine-grained deepfake artifacts and localized forgeries. As generative models continue to advance, deepfake detection becomes increasingly challenging, particularly due to the emergence of fine-grained and localized manipulations that existing models struggle to detect due to their reliance on global features. We apply three network modules for multi-granularity feature extraction. The first module, the Global Feature Branch (GFB), extracts contextual global features to provide broad scene understanding, complementing fine-grained detection. The second module, the Generative Diffusion Feature Branch (GDFB), captures hierarchical multi-grained features, addressing the limitations of conventional backbone models and enhancing the detection of localized deepfake artifacts. The third module, the Sparse Auto-Encoder Branch (SAB), further refines fine-grained artifact detection by emphasizing subtle inconsistencies. Then, we aggregate these multi-grained features using a Feature Pyramid Network (FPN) to ensure a comprehensive representation. Finally, the fused representation is passed to a classifier, enabling robust differentiation between real and deepfake human face. Experimental results on three benchmark datasets prove the superior performance of MG-Det compared to existing state-of-the-art studies, where our model improves the best-performing study in the existing literature by 3.25% and 4.43% in Area Under the Curve (AUC) and accuracy (ACC), respectively. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.","Deepfake Detection; Diffusion Model; Feature Representation"
"Gowsic, K.; Hariprasath, R.; Guruprasad, M.; Kabirajan, M.; Sojan, J.K.","Gowsic, K. (57193127931); Hariprasath, R. (60196369700); Guruprasad, M. (60226938800); Kabirajan, M. (60196460600); Sojan, Joel K. (60195789100)","57193127931; 60196369700; 60226938800; 60196460600; 60195789100","GAN and ResNet based Combination Deep Learning Model for Recognizing Fake Faces","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105021997088&partnerID=40&md5=bf46f330f77b8f7a97832835f4cf48bc","AI-driven deepfake technology has grown and matured to the point of rendering it more difficult to distinguish between real and manipulated photos or videos (e.g., altered faces). Deepfakes are built using a highly advanced neural network and they often share hyper-realistic visual properties that evade human perception. This study presents a hybrid deep learning model for robust, reliable, and efficient fake face detection using GANs and ResNet. The hybrid deep learning model takes advantage of GANs to navigate the generative processes inherent in deepfakes and also utilizes ResNet to extract the fine visual features of faces. In addition, CNNs are used to address spatial inconsistencies such as lighting differences, symmetrical facial differences, and textural manipulations. The system was trained on both real and manipulated photos, and several preprocessing techniques (e.g., normalization, dimension reduction) to provide robustness. The experimental results found that this hybrid model demonstrated measureable improvements over traditional methods (i.e., standalone) in accuracy, precision, and sensitivity. This hybrid model brings forth a cost-effective and scalable method for real-time deepfake detection in digital media security and authentication. © 2025 IEEE.","Convolutional Neural Networks; Deepfake Detection; Generative Adversarial Networks; Hybrid Model; Residual Networks; Visual Manipulation"
"Alkady, Y.; Amer, F.; Abdelhady, M.; Khaled, A.","Alkady, Yasmin (56080786900); Amer, Farah (60194706700); Abdelhady, Mohamed (60194348400); Khaled, Ahmed (60193802400)","56080786900; 60194706700; 60194348400; 60193802400","Smart Access: A Multi-Biometric System with Advanced Spoofing and Deepfake Detection for Secure Access Control","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105021833981&partnerID=40&md5=bab127160d79fb35ffe8272d9c7f46f2","Smart Access is a biometric access control system that leverages artificial intelligence to provide secure, contactless, and cost-effective authentication for physical environments such as offices, hotels, hospitals, and research facilities. Traditional access control systems that rely on keys, PINs, RFID cards, or dedicated biometric hardware often suffer from high costs, vulnerability to spoofing, and usability issues. Smart Access (SA) addresses these challenges by replacing physical tokens and sensors with advanced AI-powered multimodal biometric verification, using the user's smartphone as the interface. The system combines facial recognition, voice authentication, and deepfake detection to verify user identity. Facial authentication is implemented using the Deep Face framework with a VGG-Face model, enhanced by liveness detection to prevent spoofing through images or pre-recorded videos. Voice authentication includes three distinct layers: speaker verification using Speech Brain, transcript verification using Whisper ASR, and deepfake detection via a fine-tuned Wav2Vec2 model. This multi-layered approach effectively counters replay attacks and synthetic voice manipulation. The system architecture includes a mobile/web application, a secure backend for AI processing, and an ESP32 microcontroller that controls physical access points. Once authentication is successful, a secure command is issued to the ESP32 device to unlock the door. The system also includes a comprehensive admin dashboard for managing users, rooms, permissions, and access logs, supporting multi-tenant configurations to isolate organizational data. Evaluation results demonstrate a true acceptance rate of 97.4% for facial recognition and 94.6% detection accuracy for deepfake audio, with an average end-toend authentication time of 2.4 seconds. A user study with 30 participants showed that over 90% found the system intuitive and more secure than traditional methods. © 2025 IEEE.","Authentication; contactless access; deepfake detection; ESP32; facial recognition; liveness detection; multimodal verification; PINs; RFID cards; smartphone interface; speaker verification; spoofing prevention; system architecture; transcript verification; usability; user identity verification; voice authentication; Wav2Vec2; Whisper ASR"
"Rahatwal, K.P.; Pundir, S.; Wazid, M.; Bhat K, K.V.","Rahatwal, Kamendra Prakash (60191103000); Pundir, Sumit (56046765500); Wazid, Mohammad (55480987400); Bhat K, Vivekananda (57298856200)","60191103000; 56046765500; 55480987400; 57298856200","A Novel Approach to Deepfake Detection: Leveraging Fused Facial and Body Dynamics With a CNN–Transformer Hybrid Network","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105021500499&partnerID=40&md5=5e461696cc429a3d967acbb12d07051d","The rapid advancement of generative models like Generative Adversarial Networks (GANs) has contributed significantly to the creation of deep-fake videos. These synthetic videos pose serious threats to personal privacy, public trust, and societal stability, as they manipulate reality and influence perception of other. While Convolutional Neural Networks (CNNs) have shown progress in deepfake detection, many existing approaches struggle to effectively capture temporal inconsistencies across video frames. In this study, a novel hybrid deepfake detection model is proposed that uses both spatial and motion based features. The model utilizes VGG16 to extract high-level facial features and Google MoveNet to capture upper body pose information from data. Each video is divided into sequences of 20 frames, and the combined feature vectors of shape (20, 563) are passed through a deep learning architecture comprising a 1D Convolutional layer followed by a Transformer encoder. This setup enables the model to learn both intra frame and inter-frame dependencies. The model was trained and evaluated using a combined dataset of real and synthetic facial images, supplemented with an additional video dataset consisting of 408 authentic and 795 deepfake samples. Evaluation results demonstrate the effectiveness of the proposed approach, with the model achieving an accuracy of 84.48%. These findings show the potential of the proposed system for practical and reliable automated deepfake detection. © 2013 IEEE.","CNN; Conv1D; deepfake detection; GAN; pose estimation; transformer; VGG16"
"Lukitania, N.F.; Suryani, V.","Lukitania, Nur Fitri (60170494500); Suryani, Vera (56119170400)","60170494500; 56119170400","Swin-BiLSTM with Attention for Face Swap Detection in Deepfake Videos","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105020922999&partnerID=40&md5=2cf7af8a88c5f1216bb368ff3ba03305","Digital manipulation tools like deepfakes have advanced in sophistication because to the quick development of deep learning and artificial intelligence. Face swapping, in which one person's face is swapped out for another, is one of the most alarming types of deepfakes. This technique produces incredibly lifelike movies that may deceive viewers. Detecting these manipulated videos is crucial to mitigating their negative impact on privacy and security. This paper proposes an ensemble approach to detecting face swap deepfakes by combining the Swin Transformer and Bidirectional Long Short-Term Memory (BiLSTM) with an attention mechanism. The Swin Transformer is employed for spatial feature extraction, while the BiLSTM captures temporal patterns between frames, and the attention mechanism focuses on the most relevant timesteps. The model is evaluated on the FaceForensics++ dataset, achieving a validation accuracy of 93.81% with a validation loss of 0.19, outperforming the Long Short-Term Memory (LSTM), Fully Convolutional Network (FCN), and Convolutional Neural Network - Bidi-rectional Long Short-Term Memory (CNN-BiLSTM) models. Experimental results demonstrate the superior ability of the Swin-BiLSTM With Attention model to accurately detect face swap manipulations, even under varying facial poses, lighting conditions, and motion variations. The proposed method shows promise in addressing the challenges of deepfake detection, offering potential applications in privacy protection, misinformation prevention, and security. Future work may explore the integration of additional data modalities or advanced techniques to further enhance detection accuracy and robustness. © 2025 IEEE.","Attention Mechanism; BiLSTM; Deepfake Detection; Face Swap; Swin Transformer"
"Tauseef, M.; Viji, L.S.; Fenwick, J.","Tauseef, Md D. (58244442400); Viji, Lena Sosa (60171650900); Fenwick, Janice (60171875000)","58244442400; 60171650900; 60171875000","Deepfaceguard: A Lightweight CNN Framework for Robust Face Manipulation Detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105020781968&partnerID=40&md5=0d91a8fcf33a21fc845a306405723569","The rapid proliferation of deep-fake technology threatens the credibility of digital media, with face-swap deep fakes posing significant detection challenges due to their high visual fidelity. This paper presents Deep Faceguard, a lightweight CNN-based deepfake detection framework optimized for high accuracy, cross-dataset generalization, and real-time edge deployment. Unlike prior models limited to single-dataset performance, Deep Faceguard integrates transfer learning with Efficient Net and XceptionNet backbones, combined with OpenCV-based facial region alignment to enhance artifact localization. The system effectively detects subtle manipulation artifacts such as illumination inconsistencies, blending anomalies, and edge discontinuities. Trained on FaceForensics ++ and DFDC, it achieves 96.5% accuracy, 95.8% precision, 97.2% recall, and a ROC AUC of 0.982, while cross-dataset testing yields 88.2% accuracy, indicating robustness to domain shift. Optimized via TensorFlow Lite, Deep Faceguard sustains 45 FPS real-time inference and reduces the model size by 40% without accuracy loss, making it suitable for scalable and deployment-ready deepfake detection applications. © 2025 IEEE.","Convolutional Neural Net works (CNNs); cross-dataset generalization; Deepfake detection; digital media forensics; edge deployment; face-swap manipulation; real-time infer ence; TensorFlow Lite"
"Yu, Z.; Dai, Y.; Dai, W.; Lin, Y.","Yu, Zhongyi (60163427600); Dai, Yaping (7401512972); Dai, Wei (59582399500); Lin, Yumin (59706235400)","60163427600; 7401512972; 59582399500; 59706235400","Deepfake Face Detection Algorithm Based on Multi-Scale Attention Reconstruction","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105020291827&partnerID=40&md5=5094d62ea5e742afca96bf608985dee5","Recent advances in deepfake facial technology have enabled its misuse for creating deceptive content and spreading false information, posing serious risks to personal privacy, social order, and national security. However, early deepfake detection methods fell short. For instance, the traditional reconstruction model couldn't adapt to data distribution changes, and the single-scale structure struggled to fully uncover various forgery artifacts. Therefore, we propose a deepfake face detection framework named Multi-scale Attention Reconstruction (MSAR). The framework reconstructs real faces to learn their feature distributions, enhancing detector generalization. Firstly, we introduce the adaptive neighborhood aggregation (ANA) module. It integrates information from adjacent regions at different scales and realizes selective feature fusion at the same scale, improving reconstruction quality. Moreover, we propose the attention collaborative guidance (ACG) module. It takes the mask difference between the reconstructed and source real-face images as input and captures long-range dependencies and local detail information. This guides the model to focus more on key features related to reconstruction errors, thus enhancing the classifier's performance. Experiments on public datasets such as FaceForensics++ and CelebDF show that MSAR outperforms existing methods in key metrics such as ACC and AUC. Ablation experiments also verify the effectiveness of each module. © 2025 Technical Committee on Control Theory, Chinese Association of Automation.","Attention Mechanism; Deepfake Detection; Multi-scale Feature Fusion; Reconstruction Learning"
"Shahzad, S.A.; Hashmi, A.; Peng, Y.-T.; Tsao, Y.; Wang, H.-M.","Shahzad, Sahibzada Adil (57219013187); Hashmi, Ammarah (57989334100); Peng, Yan Tsung (60150033300); Tsao, Yu W. (13608047100); Wang, Hsin-Min (8297293300)","57219013187; 57989334100; 60150033300; 13608047100; 8297293300","AV-Lip-Sync+: Leveraging AV-HuBERT to Exploit Multimodal Inconsistency for Deepfake Detection of Frontal Face Videos","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105019673531&partnerID=40&md5=0e4a98126659713057f30fa44adc2d51","Multimodal manipulations (also known as audio-visual deepfakes) make it difficult for unimodal deepfake detectors to detect forgeries in multimedia content. To avoid the spread of false propaganda and fake news, timely detection is crucial. The damage to either modality (i.e., visual or audio) can only be discovered through multimodal models that can exploit both pieces of information simultaneously. However, previous methods mainly adopt unimodal video forensics and use supervised pretraining for forgery detection. This study proposes a new method based on a multimodal self-supervised-learning (SSL) feature extractor to exploit inconsistency between audio and visual modalities for multimodal video forgery detection. We use the transformer-based SSL pretrained Audio-Visual HuBERT (AV-HuBERT) model as a visual and acoustic feature extractor and a multiscale temporal convolutional neural network to capture the temporal correlation between the audio and visual modalities. Since AV-HuBERT only extracts visual features from the lip region, we also adopt another transformer-based video model to exploit facial features and capture spatial and temporal artifacts caused during the deepfake generation process. Experimental results show that our model outperforms all existing models and achieves new state-of-the-art performance on the FakeAVCeleb and DeepfakeTIMIT datasets. © 2013 IEEE.","Audio-visual; audio-visual deepfake detection; deepfake detection; deepfakes; inconsistency; lip syn; multimedia forensics; multimodality; video forgery"
"Kamil, F.; Maharani, E.M.; Rahmania, R.","Kamil, Faishal (58915710000); Maharani, Eleanor Maritsa (60145438100); Rahmania, Rissa (57209028479)","58915710000; 60145438100; 57209028479","ResNeXt-50 and LSTM for Deepfake Detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105019048551&partnerID=40&md5=35ff1921b8475d2ec61c5510bd6bde73","Deepfake technology presents a significant threat to digital security due to its increasing sophistication and potential for misuse. This research proposes a Deepfake detection model combining ResNeXt-50 32×4d for spatial feature extraction and Long Short-Term Memory (LSTM) networks for temporal analysis. A video processing pipeline was implemented to isolate and retain facial regions from each frame in the dataset. Videos were decomposed into frames, with faces detected using a pre-trained model of face recognition and frames containing faces were cropped, resized to 256×256 pixels, and saved. Only the first 150 frames per video were processed to maintain temporal order for sequential analysis, with the dataset split into training, validation, and test sets (70%, 20%, 10%). The processed frames were then passed through the ResNeXt-50 for spatial feature extraction and LSTM for temporal dependencies. Evaluated on the Celeb-DF and FaceForensics++ datasets, the model achieved peak accuracies of 99.90% and 99.13%, respectively. Future research will focus on integrating multimodal data and leveraging Explainable AI to further improve detection accuracy and interpretability. © 2025 IEEE.","Celeb-DF; Deepfake Detection; FaceForensics++; LSTM; ResNeXt-5032x4d"
"He, Y.; Zhou, W.; Zhao, H.; Fang, Z.; Xing, L.; Huangfu, M.; Zhang, W.; Yu, N.","He, Yiliang (60143840900); Zhou, Wenbo (57192111936); Zhao, Hanqing (57226043096); Fang, Ziyuan (58505872700); Xing, Li (60143708600); Huangfu, Minna (60143708700); Zhang, Weiming (56459354100); Yu, Neng-Hai (7201981769)","60143840900; 57192111936; 57226043096; 58505872700; 60143708600; 60143708700; 56459354100; 7201981769","Enhancing Face Forgery Detection with Augmented Feature Distillation","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105018912522&partnerID=40&md5=0fa3308d4045a5ebd308f7c76db3c63a","Detecting face forgery has emerged as a critical task due to the profound societal implications associated with advanced facial manipulation technologies. Unlike conventional visual classification tasks, the subtle and often imperceptible discrepancies between authentic and forged images present substantial challenges for detection, particularly concerning robustness and generalization. To overcome these limitations, we propose a novel feature-level alignment strategy inspired by knowledge distillation. Our method promotes feature invariance against image perturbations through a quality-diversified selfdistillation framework. Moreover, we introduce a forgery feature augmentation strategy aimed at enhancing generalization by distinctly isolating authentic image representations from those of forged images. Experimental evaluations demonstrate that our method is compatible with various backbone architectures, consistently outperforming state-of-the-art face forgery detection techniques, especially under rigorous assessments of generalization and robustness. © 2025 IEEE.","Deepfake Detection; Feature Augmentation; Generalization; Knowledge Distillation"
"Nalawade, R.; Hegaje, B.; Maiskar, B.; Patil, P.; Gurav, U.","Nalawade, Rajvardhan (57219050501); Hegaje, Bhanudas (60141541100); Maiskar, Bhargav (60141393800); Patil, Prerana (60141444700); Gurav, Uma Prashant (36052794200)","57219050501; 60141541100; 60141393800; 60141444700; 36052794200","Deep Fake Detection: Integration of Inception-Net and Resnet Multitask Cascaded Convolution Networks","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105018801557&partnerID=40&md5=df67d5c03abddaa8718718899f3f5640","Deep learning techniques have found successful applications across various domains, including image detection, big data analytics, voice and image recognition. Deepfakes, a product of combining deep learning with fake creation, involve generating deceptive images or videos using AI, presenting risks such as political manipulation, misinformation, and exploitation. This has raised pressing concerns related to privacy, security, and ethical implications. Notably, face-swapping deepfake methods are prevalent, producing highly realistic videos that pose serious threats to individual and national privacy. Consequently, discerning between authentic and deepfake videos has emerged as a severe challenge.This research focuses on solving this challenge using MTCNN model (Multitask Cascaded Convolution Networks) giving accuracy rate of 93.7%. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.","Contextual analysis; Deepfake; Deepfake detection systems; Facial manipulation; Feature extraction; Machine learning"
"Ramteke, N.; P Ramteke, S.","Ramteke, Nilima Surendra (59958320300); P Ramteke, Surendra (60140571100)","59958320300; 60140571100","Enhanced security through face recognition and deepfake prevention","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105018757473&partnerID=40&md5=b78a5ac8b065e79fcc88386d402dffc1","Face recognition technology has become a potent instrument for security uses, providing a distinct way to identify people by their facial characteristics. However, the security and reliability of face recognition systems are seriously threatened by the quick development of deepfake technology. The goal of this study is to determine whether facial recognition and deepfake avoidance techniques can be combined to create a more secure and dependable authentication system. This paper presents a novel approach, LPbCNN (Local Binary Pattern with Convolution Neural Network), designed to enhance security through accurate face recognition and effective deepfake detection. LPbCNN integrates the texture-based feature extraction capabilities of Local Binary Patterns (LBP) with the deep learning power of CNN. While LBP captures fine-grained local textures that are crucial for distinguishing between authentic and manipulated images, CNNs are used to learn complex facial patterns and anomalies connected to deepfakes. By combining the best features of both approaches, this hybrid model guarantees a thorough examination of facial images. Tested on a variety of real and deepfake photos, the suggested approach shows excellent face recognition accuracy and a strong capacity to identify minute manipulations common in deepfake material. The integration of LBP and CNN enhances the detection capabilities. It improves the overall security of face recognition systems, providing a scalable solution for preventing unauthorized access and misinformation in various digital environments. © 2025 Taylor & Francis Group, LLC.","Convolutional neural networks; deepfake detection; face recognition; local binary pattern"
"Rai, M.; Kour, K.P.; Sharma, A.; Mukhekar, V.S.","Rai, Manish (57213689424); Kour, Kanwalpreet (57221948261); Sharma, Abhay (60136962800); Mukhekar, Vinit Sanjay (60135797800)","57213689424; 57221948261; 60136962800; 60135797800","Deepfake Image Detection using Transfer Learning: A Comparative Analysis","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105018462348&partnerID=40&md5=487eae16b7c23b6f496a6190815ab263","Rapid advancements in the field of generative adversarial network (GAN) technologies have made the detection of AI-generated facial imagery extremely crucial. In this paper, we investigate the efficacy of transfer learning in distinguishing between real and AI-generated fake facial images. We used a comprehensive data set comprising 70,000 real face images from the Flickr data set and 70,000 synthetic faces sampled from a large-scale StyleGAN-generated data set. The combined data set was preprocessed by resizing all images to 256 pixels and partitioning them into training, validation, and testing sets. We evaluated the performance of several pre-trained deep learning architectures, including a Custom Convolutional Neural Network (CNN), MesoNet, ResNet50, EfficientNetB0, and Xception, through fine-tuning on our curated dataset. The results we achieved in this experiment show the importance of the use of, we managed to achieve accuracy of 98. 57% while using the Xception model in successfully distinguishing between real and fake faces. This study highlights the effectiveness of using established convolutional architectures for robust deep-fake detection. © 2025 IEEE.","CNN; Deepfake Detection; EfficientNet; MesoNet; ResNet50; StyleGAN; Transfer Learning; XceptionNet"
"Xu, X.; Chen, J.; Zhang, Y.; Li, C.; Singh, A.K.; Lyu, Z.","Xu, Xu (58389907700); Chen, Junxin (55938853600); Zhang, Yushu (55508709300); Li, Congsheng (56030835200); Singh, Amit Kumar (55726466900); Lyu, Zhihan (55925162500)","58389907700; 55938853600; 55508709300; 56030835200; 55726466900; 55925162500","DeepFake Detection with Multi-View Fusion and Graph Convolutional Network","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105018354654&partnerID=40&md5=d83dd73e0263fadd8e0f4348c8dbb925","Nowadays, massive amounts of facial images have been tampered with and then widely spread through social networks. Many studies have developed algorithms for frame-level DeepFake detection. However, they have low robustness due to their focus on tamper-independent features during training. To this end, we propose a framework, namely MIF-Net, based on multi-information fusion for robust frame-level DeepFake detection. Specifically, key landmarks and the facial area are first detected in the original frame. Then, the graph convolutional network constructs biometric information from these landmarks. Meanwhile, the facial region is processed into multi-view inputs by noise and edge enhancement algorithms. Finally, these products are encoded as high-level features and classified as real or fake. Five benchmark datasets are utilized for testing our model through within-dataset and cross-dataset validations. Extensive experiment results demonstrate that our proposed MIF-Net is robust and has advantages over peer algorithms. © 1999-2012 IEEE.","Attention Mechanism; Deep Learning; DeepFake Detection; Graph Convolutional Network; Multi-View Fusion"
"Ming, L.; He, P.; Li, H.; Wang, S.; Jiang, X.","Ming, Liyue (57209884407); He, Peisong (57075586900); Li, Haoliang (56593801800); Wang, Shiqi (55364979300); Jiang, Xinghao (13607511800)","57209884407; 57075586900; 56593801800; 55364979300; 13607511800","Critical Contour Prior-Guided Graph Learning With Pose Calibration for Identity-Aware Deepfake Detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105017131421&partnerID=40&md5=a2f547ae16b7f52481cbb04ef318f3da","Deepfake has recently raised severe public concerns about security issues, such as creating fake news of celebrities. As countermeasures, identity-aware detection methods leverage identity information to expose forged videos by measuring identity consistency between the suspicious input and its reference samples. However, the performance of existing methods suffers from notable degradation due to undesired variations of head poses and capturing environments. In this work, we first conduct a statistical analysis to illustrate the influence of different facial regions for forensic purposes, which infers more reliable identity information is located in critical face regions. Motivated by this analysis, we propose a graph learning-based identity-aware deepfake detection framework considering critical contour prior as guidance. First, feature sampling based on contour landmarks is applied to construct the graph data as the input of our critical contour prior-guided graph attention network (CP-GAT), where a node position prediction task is constructed as auxiliary supervision to explore rich relationships between nodes. To enhance pose-invariant ability, a rotation compensation block is integrated into CP-GAT and trained using a pose-calibrated contrastive learning to extract identity features, which takes high-quality front faces as the calibration goal with a progressively updating selection. Besides, an adversarial node masking-based training strategy is proposed as feature augmentation to further enhance the reliability. During the inference stage, the similarity between identity features of the input sample and its reference samples extracted by the trained CP-GAT is used to obtain the detection result. Extensive experiments are conducted on various face forgery datasets and state-of-the-art methods are compared to verify the superiority of the proposed method in terms of detection capability and robustness. © 1999-2012 IEEE.","contrastive learning; Deepfake detection; graph learning; video forensics"
"Sheikh, M.S.; Kirtonia, U.; Arthi, N.T.; Al-Imran, M.","Sheikh, Md Sifatullah (60115393900); Kirtonia, Urmi (60115342600); Arthi, Nuzath Tabassum (60115496200); Al-Imran, Md Nazmul (35730828900)","60115393900; 60115342600; 60115496200; 35730828900","AI-Powered Deepfake Detection Using CNN and Vision Transformer Architectures","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105017125372&partnerID=40&md5=ed66015203534b85394629dc5ea608c8","The increasing use of artificial intelligence-generated deepfakes creates major challenges in maintaining digital authenticity. Four AI-based models, consisting of three CNNs and one Vision Transformer, were evaluated using large face image datasets. Data preprocessing and augmentation techniques improved model performance across different scenarios. VFDNET demonstrated superior accuracy with MobileNetV3, showing efficient performance, thereby demonstrating AI's capabilities for dependable deepfake detection. © 2025 IEEE.","Deepfake Detection; DFCNET; MobileNetV3; ResNet50; VFDNET"
"Kabilan, M.; Logeswaran, S.; Kubersrinivash, S.; Alfred Daniel, J.","Kabilan, M. (59999120700); Logeswaran, S. (59999175000); Kubersrinivash, S. (59999120800); Alfred Daniel, J. William (56313790400)","59999120700; 59999175000; 59999120800; 56313790400","Advanced Temporal Analysis for Deepfake Detection using XceptionNet in Media Forensics","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016907924&partnerID=40&md5=6cd9f5dca2e846c2be309f4e731e9cff","Deepfakes videos through advanced AI models, pose a significant threat due to their deceptive realism. This paper presents a deepfake detection framework based on XceptionNet, which provides depthwise separable convolutions for fine-grained image analysis. The proposed system processes both static images and video by detecting and aligning faces, enabling consistent frame-level analysis. Furthermore, for videos, each frame is analyzed using XceptionNet, followed by temporal feature extraction through LSTM and CNN to capture subtle facial expressions and motion variations. The model was evaluated on multiple datasets, achieving strong precision, recall, and F1-scores at both frame and video levels. Results show that the XceptionNet-based approach reliably distinguishes real from manipulated content. However, limitations remain due to dataset diversity and computational complexity, highlighting directions for future research. © 2025 IEEE.","Artificial Intelligence; Deepfake Detection; Face Detection; Generative Models; Media Forensics. XceptionNet; Synthetic Media; Temporal Feature Analysis"
"Patil, S.S.; Archana, M.; Padmashree, M.; Pradeep Paul, C.","Patil, Shravani S. (59407796600); Archana, M. C.P. (59436505600); Padmashree, M. (60104476200); Pradeep Paul, C. (60104342100)","59407796600; 59436505600; 60104476200; 60104342100","AI/ML-Based Solution for Detecting Face-Swap Deepfakes","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016328694&partnerID=40&md5=a6273a8e34da8a6791ab5652dff6d012","The rapid advancement of deepfake technology, particularly in face-swap applications, poses significant challenges to the integrity of digital media and personal security. This research introduces a hybrid system using Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) to detect deepfakes. The model combines spatial and temporal feature analysis to spot inconsistencies in manipulated media. Facial landmarks are detected using the Dlib library, while classifiers like Support Vector Machines (SVM) and Artificial Neural Networks (ANN) enhance detection accuracy. Data augmentation and bidirectional LSTM processing improve the system's robustness in real-world scenarios. By leveraging AI-driven techniques, the model offers a reliable solution to counter the growing misuse of deepfake technology, ensuring high precision and adaptability. © 2025 IEEE.","AI/ML; Artificial Neural Networks (ANN); Convolutional Neural Networks (CNNs); deepfake detection; face-swap; Recurrent Neural Networks (RNNs); Support Vector Machines (SVM)"
"Mangalampalli, S.M.; Mistry, M.J.; Pal, A.M.; Pereira, J.","Mangalampalli, Swapnil Mohan (60102733600); Mistry, Meetkumar Jitendrakumar (60102432500); Pal, Aditya Manoj (60102733700); Pereira, Janisa (60102432600)","60102733600; 60102432500; 60102733700; 60102432600","A CNN Algorithm Based DeepFake Detection System","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016180176&partnerID=40&md5=642d2bf5b7105249716999785e68fbae","DeepFake is a technology that has garnered significant attention in the modern world and is often used for unlawful and immoral practices. The consequences and aftereffects of generation and publication of deepfakes in the public domain can tamper the social image of organizations or individuals. The objective of this study is to find a solution to this upcoming societal horror which can ruin lives and stigmatize the affected individuals. This project mainly concentrated on the development of a DeepFake Detection model that leverages a custom Convolutional Neural Network (CNN) to identify facemanipulated images or video content by extracting frames from images or videos. The model achieved high accuracy in demonstration of effectiveness of custom CNN architecture in identification of subtle facial inconsistencies and performed robustly across the dataset which highlighted the capability for generalization and detection of face-manipulated content in images and videos, alike. In essence, this CNN model stands out as a comprehensive solution not only addressing and amending the challenges faced by current systems but also enables people to be alert. This research serves as a foundational step towards the development of robust and scalable solutions to effectively counter DeepFake technology. © 2025 Bharati Vidyapeeth, New Delhi.","Convolutional Neural Network; DeepFake Detection; face manipulation; frame extraction; video classification; visual features"
"Hirpara, P.; Valangar, H.; Kachhadiya, V.; Chauhan, U.","Hirpara, Priyanshu (60102538500); Valangar, Hardi (60102319300); Kachhadiya, Vishwa (60102394400); Chauhan, Uttam (56045696400)","60102538500; 60102319300; 60102394400; 56045696400","Deepfake Detection: Demodulate Synthetic Videos Using Deep Learning Models","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016137250&partnerID=40&md5=f9c5def6ff4a7b673599b77e87285431","A deepfake detection system that uses machine learning (ML) and deep learning (DL) models to detect manipulated videos and images is presented in the study. Being aware of such synthetic content is crucial considering the emergence of deepfake technology, which might alter photos, videos, and audio for malevolent objectives including fraud, extortion, and disinformation. Deepfake technology has been applied to solve various real-time problems but is also exploited for unethical and illegal purposes. As a result, developing research and detection models is crucial to prevent its misuse. We proposed a CNN-LSTM hybrid model for analysis of cropped images to improve the performance of fake video detection. The suggested method focuses on identifying fake videos using the Celeb-DF dataset, which consists of 1203 videos (795 fake, 408 real). Moreover, the benefits and drawbacks of the various deepfake detection techniques are examined. The paper indicates potential improvements in model accuracy through more datasets and improved architectures, and it emphasizes the significance of sophisticated detection techniques to mitigate the negative consequences of deepfakes. With cropped video frames and deep learning techniques, the model's accuracy increased from 79.06% with the original dataset to 86.82% with cropped videos. © 2025 Bharati Vidyapeeth, New Delhi.","Artificial Intelligence; CNN-LSTM; Deep Learning; Deepfake Detection; Face Manipulation"
"Khaled, R.; Moftah, H.M.; Alsheref, F.K.; Assiri, A.S.; Rahouma, K.H.; Kayed, M.","Khaled, Radwa (60096973400); Moftah, Hossam M. (36960052100); Alsheref, Fahad Kamal (57200692346); Assiri, Adel Saad (57219336907); Rahouma, Kamel Hussein (6506262926); Kayed, Mohammed (14422375000)","60096973400; 36960052100; 57200692346; 57219336907; 6506262926; 14422375000","Boosting Deepfake Detection Accuracy with Unsharp Masking and EfficientNet Models","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015828219&partnerID=40&md5=ea4a893b7dac82259fd737bf0bbd649f","The rapid progress of deepfake technology, fueled by generative adversarial networks (GANs), has increased the challenge of verifying the authenticity of digital media. This study suggests a more powerful deepfake detection framework based on the EfficientNet convolutional neural network family, coupled with an unsharp masking preprocessing method to highlight manipulation artifacts. Based on a big, diverse dataset of over 5000 video samples, the model was trained and tested on several variants of EfficientNets (B0–B4). The results indicate that the integration of unsharp masking significantly improves the model's ability to detect minor irregularities in facial regions, with its best validation accuracy at 97.77% with EfficientNetB4. The method strikes a balance between computational cost and detection accuracy, rendering it applicable to real-world use cases, such as forensic examination and digital content authentication. The stability of the framework across different datasets and manipulation methods highlights its value as a scalable solution for curbing disinformation and protecting media integrity. © 2025 (IJACSA) International Journal of Advanced Computer Science and Applications.","artificial intelligence; computer vision; convolutional neural networks (CNNs); Deepfake detection; efficientnet; facial manipulation detection; unsharp masking"
"Sheelavantmath, K.K.; Isloor, V.; Sheetal, B.; Bhuvisha, N.; Sandesh, B.J.","Sheelavantmath, Khushi Kiran (60098002600); Isloor, Vaibhav (60097910400); Sheetal, B. V. (58069100200); Bhuvisha, N. (60097910500); Sandesh, Balasaraswati J. (57194794854)","60098002600; 60097910400; 58069100200; 60097910500; 57194794854","Localization of Deepfake Facial Images Through U-NET Architecture","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015790368&partnerID=40&md5=b96159862bbae2c9f51061dfa8a23492","Traditional deep fake detection methods predominantly rely on binary classification, categorizing images as either real or fake, which often limits their transparency and interpretability for real-world applications. To address this, we propose a novel approach that integrates Histogram of Oriented Gradients (HOG) features into a U-Net architecture, enabling the capture of both fine-grained texture patterns and high-level contextual information in deep fake regions. For enhanced interpretability, Class Activation Maps (CAM) are transformed into the HSV color space, facilitating intuitive color-based analysis. Contour detection is then employed to localize manipulated regions, and bounding boxes are generated using Dlib to precisely identify these features. By iterating through 68 facial landmarks, textual descriptions are generated to highlight alterations in facial features, providing a detailed understanding of the modifications. To further quantify the extent of manipulation, the resulting feature map undergoes a quantitative assessment by calculating the percentage of contour-detected areas. This method offers a comprehensive framework for identifying and analyzing subtle differences between genuine and modified images, advancing the transparency and accuracy of deep fake detection. ©2025 IEEE.","Class Activation Maps (CAM); Contour Detection; Deepfake Detection; Dlib; Facial Landmark Analysis; Histogram of Oriented Gradients (HOG); HSV Color Space; U-Net Architecture"
"Gottumukkala, K.P.; Manasa, S.; Chakravarthy, K.; Ramakrishna, K.","Gottumukkala, Krishna Prasanna (60092693900); Manasa, Sirikonda (60092679700); Chakravarthy, Komal (60092710400); Ramakrishna, Kolikipogu (60092664000)","60092693900; 60092679700; 60092710400; 60092664000","Deepfake Face Detection Using Deep Convolutional Neural Networks: A Comparative Study","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015669370&partnerID=40&md5=7f0d97156e53b3123b23c724b7c91d51","Concerns over the possible abuse of altered photos have grown significantly as a result of the deepfake technology's quick development. In order to detect deepfake images, this research paper introduces a new and enhanced Deep Convolutional Neural Network (D-CNN) architecture which offers decent accuracy and great generalizability. Observing the issue's seriousness and depth, the study is conducted on different models for deepfake image detection including D-CNN such as DenseNet, Customized CNN, and Mesonet of CNN architectures on a sizable dataset that included both real and deep fake images from seven different sources. This research paper provides a thorough study and examination of various existing CNN-based methods for detecting deepfake images, highlighting their advantages and potential limitations. The solid foundation for detecting deepfake image content is then outlined in the D-CNN-based architecture, which is being exposed. The D-CNN architecture highlights the remarkable accuracy of 92% in recognizing deepfake images, and its potential to mitigate the threat posed by deepfake technologies. While densenet yields an accuracy of 80%, and the mesonet yields 67%. This work not only makes progress in the field of deepfake detection, but also highlights how crucial it is to keep up research to stop deepfake technology from spreading to other sectors of the economy, such as cybersecurity, media, and law enforcement. © 2025 Scrivener Publishing LLC.","Convolutional neural network; Deep CNN; Deepfake detection"
"Palanisamy, D.; Anila, S.","Palanisamy, Devi (59293923000); Anila, S. (35809859000)","59293923000; 35809859000","Multimodal Transformer-Based Framework for Generalized Video Face Anti-Spoofing in Dynamic Environments","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013651123&partnerID=40&md5=e7d09bc175a1bfba26f3ae1304013e5d","Face authentication methods are increasingly prone to sophisticated spoofing techniques, such as deepfakes and multi-modal forgeries, that are dangerous for applications with important security implications. Standard anti-spoofing techniques, though effective under pre-conditioned conditions, are not applicable to various real-world situations as they only take good-quality data and have weak temporal modeling capabilities. This paper presents a new multimodal approach using transformers for high quality temporal feature extraction and deformable convolutions for precise spatial analysis. The platform uses a fully integrated fusion method to incorporate RGB, depth, and binary masking to improve detection performance for different attacks and environments. Many experiments using benchmark datasets such as CelebA-Spoof, Replay-Attack and CASIA-FASD demonstrate the power of the framework, with an average accuracy of 99.1% and remarkably low HTER values. Cross-dataset testing validates its generalisability with very little performance loss on unseen data. The new approach substantially advances current practice by solving fundamental shortcomings of existing solutions including inflexibility in real-time environments and computational overhead. Its scale and real-time features make it ideal for use in IoT, banking and surveillance. This work provides a solid basis for safe and secure face authentication despite changing spoofing methods. © The Author(s) under exclusive licence to The Korean Institute of Electrical Engineers 2025.","Biometric security; Cross-domain generalization; Deepfake detection; Deformable convolutions; Face anti-spoofing; Multimodal integration; Vision transformers"
"Son, S.; Kim, W.","Son, Sangho (58169374800); Kim, Wooju (60005989100)","58169374800; 60005989100","Advancing Generalization in Deepfake Detection: Supervised Contrastive Representation Learning With Dual Stream Spatio-Temporal Features","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013360703&partnerID=40&md5=3192e6380b0b59d7b0828eefc68e7e8b","Deepfake technologies have rapidly evolved, enabling highly realistic facial manipulations that are increasingly difficult to detect. However, existing detection models remain limited in their ability to generalize beyond the manipulation techniques used during training. As deepfake generation methods continue to diversify, enhancing generalization has become critical for deployment in real-world scenarios. To address this challenge, this paper proposes a robust and generalizable deepfake detection framework based on supervised contrastive learning. Rather than overfitting to generation-specific artifacts, the proposed method learns discriminative representations by integrating domain- and similarity-aware contrastive loss with distributional regularization. The framework adopts a dual-stream architecture consisting of a 3D CNN (I3D with Non-Local Blocks) to capture temporal dynamics and a 2D CNN (ResNet) for spatial features. The extracted features are fused and passed to a support vector machine (SVM) classifier to refine decision boundaries. Extensive experiments on FaceForensics++, Celeb-DF, and DFDC datasets demonstrate that the proposed model achieves superior generalization performance across diverse and unseen deepfake generation techniques, outperforming existing methods in cross-dataset settings. Additionally, explainability analyses validate the model's focus on meaningful facial regions. Appendix experiments also highlight its potential for efficient deployment with minimal performance loss. © IEEE. 2013 IEEE.","Attention mechanisms; contrastive learning; cross-dataset evaluation; deepfake; deepfake detection; explainable artificial intelligence; feature extraction; generalization"
"Hriez, S.","Hriez, Safaa (57207038446)","57207038446","Face Swap Detection: A Systematic Literature Review","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013297614&partnerID=40&md5=ddfb27b2bea32c479e464f0cda4112ab","Face swap technology, often associated with deepfakes, has rapidly advanced in recent years, raising serious concerns around misinformation, digital impersonation, and privacy. As a result, the development of reliable face swap detection methods has become a critical area of research. This survey provides a comprehensive review of existing approaches to face swap detection, addressing key research questions such as commonly used datasets, evaluation metrics, comparative model performance, and persistent challenges in the field. It includes a detailed taxonomy of detection methods, categorizing approaches into spatial, temporal, and spatiotemporal techniques. The survey further examines cross-dataset generalization performance to assess how well models adapt to domain shifts between training and testing data. Recent innovative directions are explored, covering adversarial defense strategies, explainability techniques, lightweight models for edge deployment, and privacy-preserving training. Additionally, best practices for building and releasing face swap detection tools are discussed to promote ethical, robust, and practical implementations. Finally, the paper outlines future research directions aimed at advancing model robustness, generalization, and compliance with legal and ethical standards. The discussions provide valuable insights that help researchers and practitioners gain a clear understanding of the face swap detection field, supporting and guiding their future research efforts. © 2025 The Authors.","adversarial attacks; deepfake detection; deepfake evaluation metrics; digital forensics; Face swap detection"
"Sharma, V.K.; Rawat, S.","Sharma, Vishal Kumar (57199918726); Rawat, Seema (56521132600)","57199918726; 56521132600","Enhancing Deepfake Detection Through Dynamics of Facial Expressions","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013073675&partnerID=40&md5=30de418a8e7de90a2320f9a0c5812b6a","The rapid evolution of deepfake technology poses significant threats to digital security, media integrity, and public trust, necessitating the development of robust detection frame-works. Traditional deepfake detection methods primarily rely on pixel inconsistencies, frequency-domain analysis, or handcrafted features, but these approaches are increasingly vulnerable to advanced generative models that produce high-fidelity manipulations. In this study, we introduce MADDM, a Masked Autoencoder-based deepfake detection model that leverages facial expression dynamics to identify inconsistencies in muscle coordination - an aspect that remains challenging for deepfake generators to replicate accurately. Our model is trained in a self-supervised manner, first learning natural facial expressions from real datasets and then detecting anomalies in synthetic videos by reconstructing masked facial regions. Evaluations on Celeb-DF, DFDC, and FaceForensics++ datasets demonstrate that MADDM significantly outperforms existing detection methods, achieving an average accuracy of 81.1%, with state-of-the-art performance on Celeb-DF (86.3%). Further analysis through intra-dataset and cross-dataset testing confirms the model's superior generalization capabilities. The results highlight the potential of expression-based deepfake detection as a powerful and scalable solution for digital forensics and misinformation control. Future research should explore real-time implementation, transformer-based optimizations, and adversarial training strategies to enhance detection efficiency against evolving deepfake techniques. © 2025 IEEE.","convolutional neural network; deepfake detection; facial expressions analysis; masked auto encoders; spatio temporal"
"Fu, X.; Fu, B.; Chen, S.; Yao, T.; Wang, Y.; Ding, S.; Liang, X.; Li, X.","Fu, Xinghe (57549209900); Fu, Benzun (60039282000); Chen, Shen (57216252886); Yao, Taiping (57219787394); Wang, Yiting (58903541400); Ding, Shouhong (55445925600); Liang, Xiubo (29068042800); Li, X. (55718109600)","57549209900; 60039282000; 57216252886; 57219787394; 58903541400; 55445925600; 29068042800; 55718109600","Faces Blind Your Eyes: Unveiling the Content-Irrelevant Synthetic Artifacts for Deepfake Detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013049961&partnerID=40&md5=06541f38146a59a721c2aa22587223f2","Data synthesis methods have shown promising results in general deepfake detection tasks. This is attributed to the inherent blending process in deepfake creation, which leaves behind distinct synthetic artifacts. However, the existence of content-irrelevant artifacts has not been explicitly explored in the deepfake synthesis. Unveiling content-irrelevant synthetic artifacts helps uncover general deepfake features and enhances the generalization capability of detection models. To capture the content-irrelevant synthetic artifacts, we propose a learning framework incorporating a synthesis process for diverse contents and specially designed learning strategies that encourage using content-irrelevant forgery information across deepfake images. From the data perspective, we disentangle the blending operation from face data and propose a universal synthetic module that generates images from various classes with common synthetic artifacts. From the learning perspective, a domain-adaptive learning head is introduced to filter out forgery-irrelevant features and optimize the decision on deepfake face detection. To efficiently learn the content-irrelevant artifacts for detection with a large sampling space, we propose a batch-wise sample selection strategy that actively mines the hard samples based on their effect on the adaptive decision boundary. Extensive cross-dataset experiments show that our method achieves state-of-the-art performance in general deepfake detection. © 1992-2012 IEEE.","adversarial learning; data synthesis; Deepfake detection; self-supervised learning"
"Ambreen, I.; Aatif, M.; Jalil, Z.; Iqbal, F.; Marrington, A.","Ambreen, Iqra (60030551600); Aatif, Muhammad (57226407082); Jalil, Zunera (26321662600); Iqbal, Farkhund (35788088300); Marrington, Andrew (13410675800)","60030551600; 57226407082; 26321662600; 35788088300; 13410675800","PViT: A Hybrid Model for Deepfake Face Detection using Patch Vision Transformers and Deep Learning","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012575167&partnerID=40&md5=c2f4a5cb14272d4c8bdf4b16df1389a3","The proliferation of AI-generated deepfakes, particularly facial image forgeries, poses a significant threat to digital security by facilitating misinformation, identity theft, and privacy breaches. Traditional detection approaches, primarily based on Convolutional Neural Networks (CNNs), often exhibit limited effectiveness when confronted with highly refined or subtle manipulations, leading to compromised detection performance. To address this challenge, this study explores the application of Vision Transformers (ViTs), which leverage self-attention mechanisms to capture fine-grained inconsistencies in visual patterns. This research proposed a hybrid deepfake detection model that integrates patch-oriented ViTs with CNN architectures to improve discriminative feature extraction. Experimental evaluation on benchmark datasets demonstrates that the proposed model achieved a detection accuracy 99%, precision 99%, recall 99%, F1-Score 99% on a validation set comprising 76,161 facial images, outperforming conventional CNN-based methods. These results highlight the potential of transformer-based architectures in advancing the robustness and reliability of deepfake detection systems, thereby contributing to the protection of digital authenticity and information integrity. © 2025 IEEE.","CNN; Deep Learning; Deepfake Detection; Generative Adversarial Networks (GANs); Image Manipulation; Patches; Vision Transformer (ViT)"
"Li, T.; Su, S.","Li, Tianze (60029203400); Su, Sen (7402030114)","60029203400; 7402030114","MICD: Deepfake Detection with Masked Identity Consistency Detector","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012493887&partnerID=40&md5=f450fa6d6c7dc9a256a7d0bac85fb8db","Recent advances in deepfake technology have raised significant concerns regarding identity manipulation, driving rapid progress in detection methods. While traditional low-level feature-based detection methods struggle with robustness in real-world scenarios, high-level feature-based methods offer improved robustness. However, they are prone to overfitting, limiting their performance on unseen datasets. To address these challenges, we propose the Masked Identity Consistency Detector (MICD), a novel framework that detects forgeries by leveraging the consistency between internal and external identity. We introduce an adaptive masking strategy to optimize the model’s receptive field based on the attention map, enhancing generalization while decoupling internal and external identity features. Additionally, we propose two specialized loss functions: Inconsistency loss, which amplifies the difference between internal and external identity features, and Redundancy loss, which minimizes redundant information during feature fusion. Experimental results show that MICD achieves superior performance compared to state-of-the-art methods on commonly used datasets, demonstrating its effectiveness in both in-dataset and cross-dataset scenarios. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.","Deepfake Detection; Face Forgery Detection"
"Farooq, M.U.; Khan, A.; Haq, I.U.; Malik, K.M.","Farooq, Muhammad Umar (59487763400); Khan, Awais (57215962847); Haq, Ijaz Ul (57203240064); Malik, Khalid Mahmood (57200448301)","59487763400; 57215962847; 57203240064; 57200448301","Generalized Deepfake Detection Using Identity, Behavioral, and Geometric Signatures","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012468218&partnerID=40&md5=b1a6507bb44db8e1383be294dc858a60","Trust in online media is increasingly compromised by deepfake multimedia, which undermines the authenticity of shared content. Existing detection techniques often perform well only on specific types of deepfakes, limiting their generalization ability and making them vulnerable in real-world applications. To address this, we propose a novel deepfake detection framework featuring an effective feature descriptor that integrates deep identity, behavioral, and geometric (DBaG) signatures, along with a classifier named DBaGNet. The DBaGNet classifier utilizes the extracted DBaG signatures and applies a triplet loss objective to enhance generalized representation learning for improved classification. These comprehensive DBaG signatures capture both facial geometry inconsistencies and behavioral cues, improving the detection of diverse deepfake types and enhancing generalization. We evaluate our approach using six benchmark deepfake datasets: WLDR, CelebDF, DFDC, FaceForensics++, DFD, and NVFAIR. Cross-dataset evaluations demonstrate significant performance gains over several state-of-the-art methods. © 2014 IEEE.","Behavioral biometrics; DBaG; deepfake detection; face forgery detection; multimedia forensics"
"Gao, J.; Huang, D.; Zhang, J.; Firkat, E.; Liu, C.; Zhu, J.","Gao, Jiazhan (58959641100); Huang, Deqi (51161368800); Zhang, Jinlai (57205630213); Firkat, Eksan (57208129787); Liu, Chao (60029294500); Zhu, Jihong (55608293500)","58959641100; 51161368800; 57205630213; 57208129787; 60029294500; 55608293500","DDformer: Deepfake Detection with Multimodal Fusion Transformer","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012436951&partnerID=40&md5=aa133dd136f0621c18e5e7ebcbc0fcc9","Early deepfakes primarily focused on visual face swapping, but the advancement of multimodal deepfake technology now allows for realistic face and audio replacements. Although some researchers have made advances in using multimodal learning for deepfake detection, they still encounter two major challenges: heterogeneity and complementary data fusion. We propose a novel approach called DDformer, and introduce two fusion methods: Multimodal Fusion Transformer (MFT) and Shared Weight Attention Fusion (SWAF). MFT utilizes the powerful global modeling capability of the transformer, which enhances the fusion of multimodal features. However, SWAF incorporates channel attention with shared weights to further complement and enhance multimodal features. Finally, we design a novel classifier specifically tailored for detecting different types of deepfakes. This classifier effectively utilizes the fused multimodal features to accurately classify and identify various types of deepfake videos. DDformer achieved a multi-class classification accuracy of 97.59% on the challenging FakeAVCeleb dataset and demonstrated its generalization ability through generalization experiments. DDformer provides a promising solution for addressing the challenges of heterogeneity and complementary data fusion in multimodal deepfake detection. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.","Deepfake; Deepfake detection; Face swapping; Multimodal fusion"
"Li, Y.; Li, N.; Liu, A.; Ma, H.; Yang, L.; Chen, X.; Liang, Z.; Liang, Y.; Wan, J.; Lei, Z.","Li, Yongze (59774757700); Li, Ning (58444098300); Liu, Ajian (57214469349); Ma, Hui (59008606900); Yang, Liying (57970797400); Chen, Xihong (59774528500); Liang, Zhiyao (54795489400); Liang, Yanyan (17435256900); Wan, Jun (55555261600); Lei, Zhen (24280193100)","59774757700; 58444098300; 57214469349; 59008606900; 57970797400; 59774528500; 54795489400; 17435256900; 55555261600; 24280193100","FA3-CLIP: Frequency-Aware Cues Fusion and Attack-Agnostic Prompt Learning for Unified Face Attack Detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012254284&partnerID=40&md5=f8acbe4f525ff4a65c21179dc91182a6","Facial recognition systems are vulnerable to physical (e.g., printed photos) and digital (e.g., DeepFake) face attacks. Existing methods struggle to simultaneously detect physical and digital attacks due to: 1) significant intra-class variations between these attack types, and 2) the inadequacy of spatial information alone to comprehensively capture live and fake cues. To address these issues, we propose a unified attack detection model termed Frequency-Aware and Attack-Agnostic CLIP (FA3-CLIP), which introduces attack-agnostic prompt learning to express generic live and fake cues derived from the fusion of spatial and frequency features, enabling unified detection of live faces and all categories of attacks. Specifically, the attack-agnostic prompt module generates generic live and fake prompts within the language branch to extract corresponding generic representations from both live and fake faces, guiding the model to learn a unified feature space for unified attack detection. Meanwhile, the module adaptively generates the live/fake conditional bias from the original spatial and frequency information to optimize the generic prompts accordingly, reducing the impact of intra-class variations. We further propose a dual-stream cues fusion framework in the vision branch, which leverages frequency information to complement subtle cues that are difficult to capture in the spatial domain. In addition, a frequency compression block is utilized in the frequency stream, which reduces redundancy in frequency features while preserving the diversity of crucial cues. We also establish new challenging protocols to facilitate unified face attack detection effectiveness. Experimental results on multiple benchmarks demonstrate that FA3-CLIP significantly improves performance, reducing ACER by over 1.2% on UniAttackData, and increasing AUC by more than 3% as well as reducing EER by over 4% on the JFSFDB dataset. © 2005-2012 IEEE.","cues fusion; deepfake detection; Face anti-spoofing; frequency-aware; unified feature space"
"Wang, Z.; Chen, Y.; Yao, Y.; Han, M.; Xing, W.; Li, M.","Wang, Zhiyuan (59751110000); Chen, Yanxiang (35408499700); Yao, Yuanzhi (55575156200); Han, Meng (55872233600); Xing, Wenpeng (57223308344); Li, Meng (57190021912)","59751110000; 35408499700; 55575156200; 55872233600; 57223308344; 57190021912","IDCNet: Image Decomposition and Cross-View Distillation for Generalizable Deepfake Detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012116902&partnerID=40&md5=7212c0404c9116cdaf3c3eeb7f8f60af","Existing deepfake detectors predominantly process entire facial images as input, which limits their sensitivity to local forgery cues due to representation bias and information loss through CNN feature aggregation. To address these limitations, we propose IDCNet, a novel deepfake detection framework based on image decomposition and cross-view distillation. Our key insight is that decomposing images into complementary views enables specialized processing of global and local forgery cues, while cross-view distillation facilitates their mutual enhancement. Specifically, the framework employs a lightweight U-Net generator with a dual-objective mechanism to decompose input images into global content and local detail views, optimized through reconstruction and classification losses. A cross-view distillation strategy is then applied to enhance complementary feature learning between views. Furthermore, to integrate local artifact information into existing detection models without architectural modifications, we propose a feature alignment method. Extensive experiments across 14 forgery methods demonstrate the effectiveness of our approach, achieving up to 4.4% AUC improvement on the CDFV2 dataset compared to state-of-the-art methods. © 2005-2012 IEEE.","deepfake detection; Face forgery detection; multi-view learning; mutual information; representation disentanglement"
"Li, J.; Zhang, N.; Qu, X.; Wang, J.; Zhong, Y.; Wan, J.","Li, Junjie (58158440100); Zhang, Nan (60009708200); Qu, Xiaoyang (57188590785); Wang, Jiashu (59984382900); Zhong, Yumeng (60009874700); Wan, Jiguang (8342294100)","58158440100; 60009708200; 57188590785; 59984382900; 60009874700; 8342294100","Enhancing Generalization in Video Deepfake Detection via Ambiguous Data Generation","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011360148&partnerID=40&md5=3d31d7d57c76743fda1277f6ff82c0d2","With the rapid advancement of deepfake technology, associated security threats have become increasingly severe, leading to significant interest in deepfake detection techniques. Despite achieving excellent performance on in-dataset evaluations, existing detectors experience substantial performance drops when tested on cross-datasets due to overfitting specific data distributions. To address this issue, we propose a novel Ambiguous Data Generation (ADG) method to generate challenging ambiguous samples that enhance model generalization during training. Specifically, our approach uses maximum mean discrepancy to minimize the distribution gap between natural and synthetic data, ensuring statistical consistency and producing more challenging samples. Additionally, we introduce a Multi-Feature Fusion (MFF) module that combines features before and after perturbation to ensure robust learning and suppress performance degradation in the testing phase. Experimental results across multiple datasets demonstrate that our method significantly improves cross-dataset generalization and overall detection performance. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.","Deepfake Detection; Face Forgery Detection"
"Li, H.; Xu, P.; Zhu, Z.; Zhang, H.","Li, Haoran (60004627100); Xu, Pengyao (57578959600); Zhu, Zhe (58392270200); Zhang, Hongkuan (57872334000)","60004627100; 57578959600; 58392270200; 57872334000","IDD: An Identity Disentanglement Framework for Deepfake Detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011343497&partnerID=40&md5=69565521b760fc8ba61178ed0da3a75f","With the rapid development of deepfake generative techniques, the synthetic hyper-realistic faces have attracted critical public attention. For the purpose of preventing privacy issues, many studies have been proposed to detect fake facial images. However, due to their poor generalization performance, existing deepfake detection approaches have encountered significant challenges posed by suspicious face generated by unknown synthetic algorithms. In this paper, we propose a novel identity disentanglement framework is devised to extract the overt and covert identities from the facial images and perform deepfake detection accordingly based on their consistencies. To formulate and monitor the disentanglement of overt and covert identities, we design reconstruction tasks that incorporate the face swapping tasks. Specifically, an identity encoder is designed to extract and disentangle overt and covert identities from the fake faces. Meanwhile, an attribute encoder is utilized to capture the facial attributes, such as age, gender, and expression. Then, a decoder is constructed to fuse attributes and identities and reconstruct the face-swapped images. The model ability in disentangling overt and covert facial identities is achieved by face swapping with different combinations of attributes, overt identities, and covert identities, restricted by a series of designed loss functions. Extensive experiments across multiple benchmark datasets demonstrate the superior detection performance with promising generalization capability of our approach compared to other state-of-the-art methods. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.","Computer Vision; Deepfake Detection; Multimedia Forensics"
"Om Prakash P, P.G.; Tadi, Y.S.S.; Karumajji, K.","Om Prakash P, G. Gnanaprakasam (57195280929); Tadi, Yoga Sairam Srihari (59987279200); Karumajji, Kyathisree (59988626900)","57195280929; 59987279200; 59988626900","AI-Powered Facial Analysis: Real or Fake Image Detection, Age Group Classification, Grooming Analysis and Emotion Recognition","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010468002&partnerID=40&md5=d4cad9cfac8ea3833d8a2730e6f8f94b","The development of deepfake technology has made it extremely difficult to tell the difference between real and altered facial photos, which presents significant privacy and security risks. This project offers a multifaceted deep learning-driven solution that can classify age, identify emotions, and conduct grooming analysis in addition to detecting deepfake photos. The method achieves 93.91% success rate in deepfake identification using a model built on CNN that was trained on datasets of real and fake faces. Furthermore, an OpenCV-Caffe model categorizes people into various age groups, a Vision Transformer (ViT)-based beard recognition model achieves 99.9% accuracy, and an Xception-based emotion detection method reaches 98.65% accuracy. Users can input photographs, evaluate several faces, and generate a detailed report on age distribution, feelings beard presence and real/fake categorization using the system's real-time Streamlit user interface. This AI-powered solution addresses the growing worries about digital verification of identity and distorted media by offering a safe, effective and automated method of facial analysis. © 2025 IEEE.","Age Classification; Deepfake Detection; Emotion Recognition; Facial Analysis; Grooming Detection and Vision Transformer"
"Liu, C.; Zhang, G.; Guo, S.; Li, Q.; Jeon, G.; Gao, M.","Liu, Changcun (59985636800); Zhang, Guisheng (57865198700); Guo, Siyou (59173914500); Li, Qilei (57202858223); Jeon, Gwanggil (15022497800); Gao, Mingliang (26634962800)","59985636800; 57865198700; 59173914500; 57202858223; 15022497800; 26634962800","Context-Aware Deepfake Detection for Securing AI-Driven Financial Transactions","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010339808&partnerID=40&md5=eb51e693f6e06609779b9c5c6398cf92","The rapid advancement of deepfake technology has threatened the community’s sense of security, particularly in the context of face-based payment systems. Thus, deepfake detection has emerged as a critical issue demanding immediate attention. However, the generalization performance of existing detection models is limited as they are overly reliant on specific forged features while ignoring the common forged features. To address this problem, we introduce the context-aware decoupling network (CADNet) for deepfake detection. Specifically, a context self-calibration (CSC) module is constructed to guide the network to focus on local forged regions. It enlarges possible regions to increase the likelihood of forgery cues. Meanwhile, a frequency domain decoupling (FDD) module is introduced to extract and fuse different frequency components. It realizes the collaborative representation optimization of global semantics and local details. The experimental results prove that the proposed model exhibits strong generalization capability across multiple standard datasets. It achieves average area under the curve (AUC) values of 98.64% for in-domain evaluation and 75.52% for cross-dataset generalization. © 2014 IEEE.","Context self-calibration (CSC); deepfake detection; facial payment; frequency domain decoupling (FDD); generalization"
"Chandrasekaran, N.; Haq, Q.M.U.; Islam, F.U.","Chandrasekaran, Nandhagopal (59514706600); Haq, Qazi Mazhar Ul (57220151657); Islam, Faiz Ul (59629062100)","59514706600; 57220151657; 59629062100","A Robust Framework for Deepfake Detection Using Advanced Neural Architectures and Generalization Techniques","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009408484&partnerID=40&md5=f2b182b63de80e922942e7db13ef8bac","The emergence of deepfake technology has created major obstacles to the quality of digital media and presented major hazards to privacy, security, and public trust. To achieve high speed and scalability, we present a robust deepfake detection system in this paper that blends lightweight Convolutional Neural Network (CNN) architecture with effective preprocessing. Using MTCNN-based face identification, the system accurately isolates and aligns facial regions from video frames, reducing noise while improving feature extraction. To improve model generalization, preprocessing techniques include dynamic frame sampling and data augmentation techniques like color correction and geometric adjustments. The proposed CNN architecture, consisting of three convolutional blocks, dropout regularization, and fully linked layers, enables efficient feature extraction and the identification of genuine or fake facial images. For experimental evaluations, the Deepfake Detection Challenge dataset was utilized. The model achieved 93.5% accuracy and 0.38 validation loss, surpassing state-of-the-art methods like XceptionNet and MesoNet. These results show how the proposed method can detect deepfake changes in various video scenarios while preserving computational efficiency. © 2025 IEEE.","CNN; Deepfake Detection; DFDC dataset; MTCNN"
"Felouat, H.; Nguyen, H.H.; Yamagishi, J.; Echizen, I.","Felouat, Hichem (58907812900); Nguyen, Huy H. (55774055400); Yamagishi, Junichi (7004695833); Echizen, Isao (6602366829)","58907812900; 55774055400; 7004695833; 6602366829","3DDGD: 3D Deepfake Generation and Detection Using 3D Face Meshes","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008805928&partnerID=40&md5=fb0e3cb2db3ed0b112aa5ee40a87534d","3D face technology is revolutionizing various fields by providing superior security and realism compared with 2D methods. In biometric authentication, 3D facial features serve as unique, hard-to-forge identifiers, improving accuracy in facial recognition for border control and criminal identification. Additionally, 3D avatars enhance virtual interactions. In this study, we aimed to strengthen 3D facial biometric systems against deepfakes. Key contributions include proving the superior protection of 3D faces over 2D ones, creating a dataset of real and fake 3D faces, and developing advanced models for accurate 3D deepfake detection. We evaluated our models for generalization to other datasets and stability when changing training data. Our experiments used the mesh multi-layer perceptron model for deepfake detection along with self-attention mechanisms and the newly introduced TabTransformer model. Results indicate that 3D face meshes greatly improve security by distinguishing real faces from deepfakes. Future work will focus on enhancing detection tools and integrating geometric features with facial textures for more accurate 3D deepfake detection. © 2013 IEEE.","3D biometric systems; 3D deepfake detection; 3D deepfake generation; 3D face reconstruction"
"AbdulQudus, A.B.; Amodu, O.A.; Bukar, U.A.; Mahmood, R.A.R.; Zakaria, A.F.; Queen, S.-O.; Hanapi, Z.","AbdulQudus, Akanbi Bolakale (59939201400); Amodu, Oluwatosin Ahmed (57192088051); Bukar, Umar Ali (57211610814); Mahmood, Raja Azlina (59484820400); Zakaria, A. F. (55383618500); Queen, Saki Ogah (59939099200); Hanapi, Z. M. (56703027900)","59939201400; 57192088051; 57211610814; 59484820400; 55383618500; 59939099200; 56703027900","A Contemporary and Comprehensive Bibliometric Exposition on Deepfake Research and Trends","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007823276&partnerID=40&md5=82f6655675c6f038348a394497b5e483","This paper provides a comprehensive bibliometric exposition on deepfake research, exploring the intersection of artificial intelligence and deepfakes as well as international collaborations, prominent researchers, organizations, institutions, publications, and key themes. We performed a search on the Web of Science (WoS) database, focusing on Artificial Intelligence and Deepfakes, and filtered the results across 21 research areas, yielding 1412 articles. Using VOSviewer visualization tool, we analyzed this WoS data through keyword co-occurrence graphs, emphasizing on four prominent research themes. Compared with existing bibliometric papers on deepfakes, this paper proceeds to identify and discuss some of the highly cited papers within these themes: deepfake detection, feature extraction, face recognition, and forensics. The discussion highlights key challenges and advancements in deepfake research. Furthermore, this paper also discusses pressing issues surrounding deepfakes such as security, regulation, and datasets. We also provide an analysis of another exhaustive search on Scopus database focusing solely on Deepfakes (while not excluding AI) revealing deep learning as the predominant keyword, underscoring AI’s central role in deepfake research. This comprehensive analysis, encompassing over 500 keywords from 8790 articles, uncovered a wide range of methods, implications, applications, concerns, requirements, challenges, models, tools, datasets, and modalities related to deepfakes. Finally, a discussion on recommendations for policymakers, researchers, and other stakeholders is also provided. © © 2025 The Authors.","bibliometric; deep learning; Deepfake; deepfake detection; recommendations"
"Li, X.; You, W.; Lin, Q.; Zhou, L.","Li, Xiang (58870976600); You, Weike (57195493773); Lin, Qingran (58991060300); Zhou, Linna (55966192200)","58870976600; 57195493773; 58991060300; 55966192200","Pixel-Level Face Correction Task for More Generalized Deepfake Detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007226481&partnerID=40&md5=1d7eaf618fc22456a11e2bcf5decfefd","Deepfake detectors nowadays have achieved impressive performance on intra-dataset evaluation, where training and testing images are collected from the same dataset. However, their detection results decrease when dealing with deepfake samples from unknown data collection. This paper introduces a novel Pixel-level Face Correction (PFC) task that involves pre-training with authentic facial data. Specifically, PFC generates pixel-level discrepancy by constructing a multi-scale facial pyramid and applying pixel-level resolution blending technique, then leverages masked image modeling framework to correct the subtle difference and learn facial representations that can be transferred to unseen deepfake detections. Extensive experimental results show that the proposed method obtains robust facial reconstruction ability and improves the model generalization to unknown manipulations. © ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2025.","Deepfake detection; Masked image modeling; Multimedia forensics"
"Sagar, N.K.; Arukonda, S.","Sagar, N. (57210633577); Arukonda, Srinivas (57214223923)","57210633577; 57214223923","A Novel CNN-LSTM Approach for Robust Deepfake Detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007157377&partnerID=40&md5=ddd8b78901a5058a5af5fbf4a5b91511","The rapid spread of deepfake videos poses significant challenges to the credibility of digital media, raising concerns over pri- vacy, misinformation, and trustworthiness. This research introduces a hybrid model combining Long Short-Term Memory (LSTM) networks and Convolutional Neural Networks (CNNs) to enhance deepfake detection. By leveraging ResNeXt-50 for extracting relevant features and LSTMs for capturing frame-to-frame dependencies, the proposed architecture effectively detects altered facial features in videos. Key preprocessing techniques, including face detection, extraction, and segmentation, optimize input data by isolating relevant facial regions. Experimental results demonstrate that this approach outperforms current methods in identifying subtle deepfake artifacts, underscoring the need for robust detection mechanisms to protect the credibility of digital media. Future work will explore improved scalability and real-time applications of this technique. © 2025 The Author(s).","Convolutional Neural Networks; Deep Learning; DeepFake Detection; Face Recognition; Image Classification; LSTM; Machine Learning"
"Wang, H.","Wang, Haoxiang (59651091200)","59651091200","Effectiveness and Optimization of Bidirectional Long Short-Term Memory (Bilstm) Based Fast Detection of Deep Fake Face Videos for Real-Time Applications","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007146982&partnerID=40&md5=4fb77970dcd382cf2ed9eb63c654358e","This study proposes a rapid detection method for deepfake face videos designed for real-time applications using bidirectional long short-term memory (BiLSTM) networks. The aim is to overcome the limitations of current technologies in terms of efficiency and accuracy. An optimized BiLSTM architecture and training strategy are employed, enhancing recognition capabilities through data preprocessing and feature enhancement while also minimizing computational complexity and resource consumption during detection. Experiments were conducted on the FaceForensics++ dataset, which includes both authentic and four types of manipulated videos. The results show that the proposed BiLSTM-based approach outperforms existing methods in real-time detection. Specifically, the integration of temporal analysis and conditional random fields (CRF) resulted in significant accuracy improvements: a 1.6% increase in checking accuracy, a 2.0% improvement in checking completeness, and a 2.5% increase in the F1-score. The BiLSTM-based rapid detection approach demonstrated high efficiency and accuracy across multiple standard datasets, achieving notable performance gains over current technologies. These findings highlight the method's potential and value for real-time deepfake detection applications. © (2025), American Psychological Association","Adaptive and Self-Organizing Systems; Artificial Intelligence; BiLSTM; Data Mining and Machine Learning; Deep learning; Deepfake detection; Face video; Neural Networks; Scientific Computing and Simulation"
"Singh, H.; Kumar, R.; Gupta, M.; Joshi, N.Y.","Singh, Harshpal (59742840200); Kumar, Rakesh Teddy (57750087100); Gupta, Meenu (55255409400); Joshi, Nikhil Yogesh (59672792800)","59742840200; 57750087100; 55255409400; 59672792800","Enhanced Deepfake Detection with LSTM and ResNeXt Integration","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006460534&partnerID=40&md5=02fa235c77d21436ebbbfa19fe9ac4a6","Created from advanced artificial intelligence (AI), Deepfakes are privacy, security, and trust shattering to digital media needs. In this work, we propose a novel deepfake detection model based on ResNext followed by Long Short Term Memory (LSTM) networks to achieve extraction of spatial features and temporal sequence analysis, respectively. Our approach combines the strengths of the two architectures and minimizes the investment in model size by retaining only a small portion of that which is accurate. On the Celeb-DF (v2) dataset, our model reached a detection accuracy of 93.59%, beating baseline methods. The demonstrated robustness and reliability of the proposed method make it a promising method to fight deepfakes in real world situations. © 2025 IEEE.","Artificial Intelligence (AI); Convolutional Neural Network (CNN); Deepfake Detection; Digital Deception; Face Recognition; Image Authentication; Image Manipulation; Machine Learning; Multimedia Forensics; Video Analysis"
"Zou, M.; Yu, B.; Zhan, Y.; Lyu, S.; Ma, K.","Zou, Mian (57221976157); Yu, Baosheng (57192112952); Zhan, Yibing (56100491900); Lyu, Siwei (8727557200); Ma, Kede (55624220200)","57221976157; 57192112952; 56100491900; 8727557200; 55624220200","Semantics-Oriented Multitask Learning for DeepFake Detection: A Joint Embedding Approach","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006001564&partnerID=40&md5=a7c4aefc0030138175ee6db8c9851ff2","In recent years, the multimedia forensics and security community has seen remarkable progress in multitask learning for DeepFake (i.e., face forgery) detection. The prevailing approach has been to frame DeepFake detection as a binary classification problem augmented by manipulation-oriented auxiliary tasks. This scheme focuses on learning features specific to face manipulations with limited generalizability. In this paper, we delve deeper into semantics-oriented multitask learning for DeepFake detection, capturing the relationships among face semantics via joint embedding. We first propose an automated dataset expansion technique that broadens current face forgery datasets to support semantics-oriented DeepFake detection tasks at both the global face attribute and local face region levels. Furthermore, we resort to the joint embedding of face images and labels (depicted by text descriptions) for prediction. This approach eliminates the need for manually setting task-agnostic and task-specific parameters, which is typically required when predicting multiple labels directly from images. In addition, we employ bi-level optimization to dynamically balance the fidelity loss weightings of various tasks, making the training process fully automated. Extensive experiments on six DeepFake datasets show that our method improves the generalizability of DeepFake detection and renders some degree of model interpretation by providing human-understandable explanations. © 1991-2012 IEEE.","DeepFake detection; face semantics; joint embedding; multitask learning"
"Liu, B.; Liu, B.; Zhu, T.; Ding, M.","Liu, Baoping (58120121700); Liu, Bo (55574235154); Zhu, Tianqing (9737124100); Ding, Ming (7202280996)","58120121700; 55574235154; 9737124100; 7202280996","A Review of Deepfake and Its Detection: From Generative Adversarial Networks to Diffusion Models","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005401165&partnerID=40&md5=e57c413ae19302000b82335a3df42b7d","Deepfake technology, leveraging advanced artificial intelligence (AI) algorithms, has emerged as a powerful tool for generating hyper-realistic synthetic human faces, presenting both innovative opportunities and significant challenges. Meanwhile, the development of Deepfake detectors represents another branch of models striving to recognize AI-generated fake faces and protect people from the misinformation of Deepfake. This ongoing cat-and-mouse game between generation and detection has spurred a dynamic evolution in the landscape of Deepfake. This survey comprehensively studies recent advancements in Deepfake generation and detection techniques, focusing particularly on the utilization of generative adversarial networks (GANs) and diffusion models (DMs). For both GAN-based and DM-based Deepfake generators, we categorize them based on whether they synthesize new content or manipulate existing content. Correspondingly, we examine various strategies employed to identify synthetic and manipulated Deepfake, respectively. Finally, we summarize our findings by discussing the unique capabilities and limitations of GANs and DM in the context of Deepfake. We also identify promising future directions for research, including the development of hybrid approaches that leverage the strengths of both GANs and DM, the exploration of novel detection strategies utilizing advanced AI techniques, and the ethical considerations surrounding the development of Deepfake. This survey paper serves as a valuable resource for researchers, practitioners, and policymakers seeking to understand the state-of-the-art in Deepfake technology, its implications, and potential avenues for future research and development. © © 2025 Baoping Liu et al. International Journal of Intelligent Systems published by John Wiley & Sons Ltd.","Deepfake; Deepfake detection; diffusion models; generative adversarial networks"
"Wani, P.; Chavan, S.; Paithankar, S.; Ghusse, D.; Barve, S.","Wani, Parth (59563339000); Chavan, Sachin (59899063200); Paithankar, Siddhesh (59897861000); Ghusse, Diptee (59898668000); Barve, Sunita S. (34879375900)","59563339000; 59899063200; 59897861000; 59898668000; 34879375900","Comparative Analyais of CNN Architectures for Deep Fake Detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005204340&partnerID=40&md5=2d75dbd3446c887c07e2eb9de16c38b7","DeepFake technology, driven by advanced generative models, threatens online authenticity and privacy. This paper presents a comparative analysis of three convolutional neural network (CNN) architectures - VGGFace16, DenseNet-121, and a custom CNN model - for DeepFake image detection. The study utilizes the 140k Faces Dataset, comprising 70,000 real and 70,000 synthetic images, and the Real and Fake Face Detection Dataset from Yonsei University, ensuring a diverse and well-balanced training set while accounting for computational constraints. Feature extraction from the final convolutional layers, dimensionality reduction via Principal Component Analysis (PCA), and classification with a Support Vector Machine (SVM) using a polynomial kernel form the core methodology. DenseNet-121 achieved the highest accuracy (97%) on grayscaled images, while the augmented custom CNN balanced accuracy (86%) and interpretability, attaining a Receiver Operating Characteristic Area Under the Curve (ROC-AUC) score of 0.953. PCA visualizations confirmed the models' ability to distinguish real from fake images. The findings underscore dataset selection's role in model performance and the necessity of resource-efficient training. Future work will expand dataset diversity, explore cross-dataset validation, and leverage advanced computational resources to enhance generalization, contributing to more robust DeepFake detection systems. © 2025 IEEE.","140k Faces Dataset; convolutional neural networks (CNN); custom CNN; DeepFake detection; DenseNet-121; feature extraction; polynomial kernel; Principal Component Analysis (PCA); Real and Fake Face Detection Dataset; ROC-AUC; Support Vector Machine (SVM); VGGFace16"
"Zafar, F.; Khan, T.A.; Akbar, S.; Ubaid, M.T.; Javaid, S.; Kadir, K.A.","Zafar, Fazeel (59762743100); Khan, Talha Ahmed (57202944878); Akbar, Salas (58096016200); Ubaid, Muhammad Talha (57477004800); Javaid, Sameena (57212970539); Kadir, Kushsairy Abdul (37079357500)","59762743100; 57202944878; 58096016200; 57477004800; 57212970539; 37079357500","A Hybrid Deep Learning Framework for Deepfake Detection Using Temporal and Spatial Features","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004035953&partnerID=40&md5=8130188762cd064d24603dcc1963e0b7","The rise of deep-fake technology has sparked concerns as it blurs the distinction between fake media by harnessing Generative Adversarial Networks (GANs). This has raised issues surrounding privacy and security in the realm. This has led to a decrease in trust during online interactions; thus, emphasizing the importance of creating reliable methods for detection purposes. Our research introduces a model for detecting deepfakes by utilizing an Enhanced EfficientNet B0 structure in conjunction with Temporal Convolutional Neural Networks (TempCNNs). This approach aims to tackle the challenges presented by the evolving sophistication of deep-fake techniques. The system dissects video inputs into frames to extract features comprehensively by using Multi Test Convolutional Networks (MTCNN). This method ensures face detection and alignment by focusing on facial regions. To enhance the model’s adaptability, to different scenarios and datasets we implement data augmentation techniques such as CutMix, MixUp and Random Erasing. These strategies help the model maintain its strength, against distortions found in deepfake content. The backbone of EfficientNet B0 utilizes Mobile Inverted Bottleneck Convolutions (MBConv) and Squeeze and Excitation (SE) blocks to enhance feature extraction by adjusting channels to highlight details effectively. A Feature Pyramid Network (FPN) facilitates the fusion of scale features capturing intricate details as well, as broader context. When tested on the FFIW 10 K dataset, which comprises 10,000 videos evenly split between manipulated content, the model attained a training accuracy of 91.5 % and a testing accuracy of 92.45 %, after 40 epochs. The findings showcase the model’s proficiency, in identifying videos with precision and tackling the issue of class imbalances found in datasets – a valuable contribution, to advancing dependable deepfake detection solutions. Furthermore, the model achieves an impressive balance between accuracy and computational efficiency, attaining 92.45% testing accuracy with a lightweight computational cost of 0.45 GFLOPs, making it a highly practical choice for real-world deployment. © 2013 IEEE.","Deepfake detection; EfficientNet B0; face detection and alignment; feature pyramid network (FPN); mobile inverted bottleneck convolutions (MBConv); multi-task convolutional neural network (MTCNN); temporal convolutional networks (TCNs)"
"Singh, H.; Kumar, R.; Gupta, M.; Babu Chilluri, V.S.","Singh, Harshpal (59742840200); Kumar, Rakesh Teddy (57750087100); Gupta, Meenu (55255409400); Babu Chilluri, Venkata Suresh (59738648600)","59742840200; 57750087100; 55255409400; 59738648600","Detecting Digital Deception: A CNN-RNN hybrid Approach of Deepfake Detection","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002843610&partnerID=40&md5=f772bd6587607f265ec2e0f3c93371e5","Deepfake technology has forced digital deception to create high demand for detection tools. This paper presents an approach for deepfake video detection using Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) architecture that targets the artifacts present in the output from the generative models including Generative adversarial network (GAN). This approach looks at many strategies in terms of frames, among them for frame comparison, feature extraction based on CNNs, and for the purpose of temporal analysis CNN with long-short-term memory (LSTM) networks. The described model is trained on the set of the genuine vs. forged images and videos and demonstrates quite stable results with respect to digital forging detection. It is discovered that this proposed model achieves higher accuracy than previously used detection approaches in addressing face-swapping and face-reenactment deepfakes. The findings of this research demonstrate that CNN & RNN based deepfake detection is promising for media forensics, as it advances multimedia security and digital media credibility. This proposed method shows an accuracy of 81% in the Deepfake Detection Dataset (DFDS), respectively, with a very reduced number of sample size of ≤ 100 samples(frames). This promises early detection of fake contents compared to existing modalities. © 2025 IEEE.","Artificial Intelligence (AI); Convolutional Neural Network (CNN); Deepfake Detection; Digital Deception; Face Recognition; Image Authentication; Image Manipulation; Machine Learning; Multimedia Forensics; Video Analysis"
"Libourel, A.; Dugelay, J.-L.","Libourel, Alexandre (59249358700); Dugelay, Jean Luc (7004757895)","59249358700; 7004757895","You're not acting like yourself: Deepfake Detection Based on Facial Behavior","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002271732&partnerID=40&md5=f29950bdf06c302d53374c3ab4e43ae7","Politicians and government leaders are critical targets for deepfake attacks. A single deepfake involving these individuals can severely damage their careers or, in extreme cases, pose a national security threat. Attackers can leverage vast amounts of publicly available audio and video recordings to train their models, making this threat even more pressing. In response, specialized deepfake detectors have been developed to focus on detecting deepfakes targeting a specific Person of Interest (POI). By learning facial expressions and movements unique to the POI, these detectors can identify inconsistencies in deepfakes where these authentic attributes are absent. However, previous methods relied on Facial Action Units, which offer an incomplete representation of the POI's behavior. In this paper, we propose a novel approach to learning POI-specific movements without requiring deepfake samples during training, making it independent of any deepfake generation methods. Although our technique is speaker-dependent, it provides a robust solution for protecting high-profile individuals who are particularly exposed to deepfake threats. © 2025 IEEE.","behavioral analysis; biometrics; deepfake detection; media forensics; POI recognition"
"Sun, Z.; Ruan, N.; Li, J.","Sun, Zekun (57223991663); Ruan, Na (54684943100); Li, Jianhua (56103299700)","57223991663; 54684943100; 56103299700","DDL: Effective and Comprehensible Interpretation Framework for Diverse Deepfake Detectors","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002269479&partnerID=40&md5=2c8898a95ef302149cffdb8e5d2441cb","In the context of escalating advancements in AI generative technologies, Deepfakes, the sophisticated face forgeries created using deep learning methods, have emerged as a significant security threat. The predominant countermeasures are Deepfake detectors based on deep learning (DL). However, due to the opaque nature of DL-model, they struggle to offer understandable explanations for their predictive decisions, which undermines their reliability and effectiveness in real-world applications. Existing mainstream DL-oriented interpretation approaches, the feature attribution methods, struggle to work on Deepfake detectors due to issues of low interpretation fidelity, poor intelligibility, and limited applicability across different types of detectors. This paper addresses these critical challenges by proposing the Deepfake Detector Lens (DDL), a novel framework designed to enhance the interpretability of diverse architectural Deepfake detectors, encompassing those based on image, frequency domain, and video. DDL employs a heuristic algorithm to enhance interpretation efficacy and incorporates image segmentation and face parsing techniques to bridge the gap between the machine-generated interpretation saliency map and human understanding. Comprehensive evaluations of DDL demonstrate its superiority over existing feature attribution methods in terms of fidelity, intelligibility, and applicability. The proposed DDL significantly advances the interpretability of Deepfake detection technology, offering a more reliable and understandable tool for combating AI-generated face forgeries. © 2005-2012 IEEE.","feature attribution; Interpretable deepfake detection"
"Sumathi, D.; Singh, A.; Sinha, A.; Aditya, D.; Mohammed Riyaan, K.F.","Sumathi, D. (57224415146); Singh, Ashu (59718257300); Sinha, Arpita (59717985800); Aditya, D. (59717844400); Mohammed Riyaan, K. F. (59718400800)","57224415146; 59718257300; 59717985800; 59717844400; 59718400800","The Deepfake Dilemma: Enhancing Deepfake Detection with Vision Transformers","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001584909&partnerID=40&md5=847eb0c9ed161cc9755a1d369da6958e","The emergence of deepfake videos at an alarming pace has compromised the integrity of digital multimedia and mandates progressive research into detection strategies. A new forensic method for subjecting face tampering detection in videos using the FaceForensics++ dataset is introduced in this work. A Convolutional Neural Network (CNN) based architecture is enhanced with Vision Transformer encoders for identifying facial manipulations introduced at microscopic precision. The hybrid model integrates CNNs and ViTs, allowing for the capturing of both local and global features that help in detecting subtle manipulations. ViTs have a built-in self-attention mechanism, which allows the model to concentrate on essential facial characteristics, thereby enhancing precision even if the manipulations are confirmed in less than optimal situations. Additionally, the pre-trained Gemini 1.5 Pro model is fine-tuned for optimal performance. The classification of faces into authentic or fake is accurately done using the key points by 90%accuracy as shown through experimentation. Moreover, the Haar cascade method is used for human face detection technique as part of integrated design which augments its complete application in real-world functionalities. © 2025 IEEE.","CNN; Data augmentation; Deepfake Detection; Haar cascade Face Forensics++; Vision Transformer"
"Liu, J.; Wang, L.; Wang, R.; Ke, J.; Ye, X.; Wu, Y.","Liu, Jiatong (59163639800); Wang, Li'na (55899978500); Wang, Run (55939516400); Ke, Jianpeng (57220586690); Ye, Xi (57221851791); Wu, Yadi (59657553000)","59163639800; 55899978500; 55939516400; 57220586690; 57221851791; 59657553000","Exposing the Forgery Clues of DeepFakes via Exploring the Inconsistent Expression Cues","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001574418&partnerID=40&md5=41100c97e94296248674259bdb2ab31d","The pervasive prevalence of DeepFakes poses a profound threat to individual privacy and the stability of society. Believing the synthetic videos of a celebrity and trumping up impersonated forgery videos as authentic are just a few consequences generated by DeepFakes. We investigate current detectors that blindly deploy deep learning techniques that are not effective in capturing subtle clues of forgery when generative models produce remarkably realistic faces. Inspired by the fact that synthetic operations inevitably modify the regions of eyes and mouth to match the target face with the identity or expression of the source face, we conjecture that the continuity of facial movement patterns representing expressions that existed in the veritable faces will be disrupted or completely broken in synthetic faces, making it a potentially formidable indicator for DeepFake detection. To prove this conjecture, we utilize a dual-branch network to capture the inconsistent patterns of facial movements within eyes and mouth regions separately. Extensive experiments on popular FaceForensics++, Celeb-DF-v1, Celeb-DF-v2, and DFDC-Preview datasets have demonstrated not only effectiveness but also the robust capability of our method to outperform the state-of-the-art baselines. Moreover, this work represents greater robustness against adversarial attacks, achieving ASR of 54.8% in the I-FGSM attack and 43.1% in the PGD attack on the DeepFakes dataset of FaceForensics++, respectively. © © 2025 Jiatong Liu et al. International Journal of Intelligent Systems published by John Wiley & Sons Ltd.","authenticity classification; DeepFake detection; DeepFakes; expression cues; face manipulation"
"Zhang, B.; Yin, Q.; Lu, W.; Luo, X.","Zhang, Bolin (58088015500); Yin, Qilin (57205390745); Lu, Wei (57715097700); Luo, Xiangyang (8976166200)","58088015500; 57205390745; 57715097700; 8976166200","Deepfake Detection and Localization Using Multi-View Inconsistency Measurement","2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001069804&partnerID=40&md5=09dda07bdd5fa6612c5b7f72ef76224a","As deepfake technology advances, forgery detection techniques have evolved beyond simple classification to include fine-grained localization. However, existing deepfake localization methods struggle with with real-world deepfake videos, which are often multi-face scenarios with only some parts manipulated. To address the above-mentioned problems, we propose a Multi-View Inconsistency Measurement (MVIM) network that simultaneously measures inconsistencies from noise and temporal view to detect and locate tampered regions. Specifically, considering the noise inconsistencies in multi-face scenarios where fake faces have inconsistent noise patterns compared to real faces and backgrounds, we design a Noise Inconsistency Measurement (Noise-IM) module that measures noise similarity among faces and between faces and backgrounds using a masked attention mechanism to identify suspected tampered regions in noise domain. Since facial jitter of tampered regions in deepfake videos is observed to be more intense than that of real regions, we design a Temporal Inconsistency Measurement (Temporal-IM) module which adopts self-attention mechanism and fine-grained bi-direction convolutions to capture tampering traces between frames in temporal domain. Inconsistency features obtained by the two modules are fused for detecting and locating tampered regions. The superiority of our MVIM network is verified by extensive experiments with many state-of-the-art methods in different benchmark datasets. © 2024 IEEE.","Deepfake detection; face forgery localization; inconsistency measurement; multi-face forensics"
"Liu, B.; Liu, B.; Ding, M.; Zhu, T.","Liu, Baoping (58120121700); Liu, Bo (55574235154); Ding, Ming (7202280996); Zhu, Tianqing (9737124100)","58120121700; 55574235154; 7202280996; 9737124100","MeST-Former: Motion-enhanced Spatiotemporal Transformer for generalizable Deepfake detection","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204405647&partnerID=40&md5=a92996b8ed1d0c3703af1db9eb4a7574","The rise of Deepfake technology has sparked significant concerns due to its potential for misuse and malicious manipulation of multimedia content. Various detection approaches aimed at detecting Deepfake videos have been proposed, mostly relying on the identification of spatial and temporal artifacts. However, due to the different contexts of source images and the variety of generation techniques, current Deepfake detection methods usually perform well on training datasets, and yet generalize poorly to those unseen identities in new datasets. This issue is widely known as the generalization challenge of Deepfake detection. To address this challenge, this paper proposes an advanced spatiotemporal Deepfake video detector, named Motion-enhanced Spatiotemporal Transformer (MeST-Former). MeST-Former is based on the spatiotemporal modeling capacity of the video Swin Transformer. The spatial and temporal features are obtained from the RGB and motion images, respectively. To enhance the generalization ability of MeST-Former to unseen identities in unseen datasets, the ID-related components in the spatial and temporal features are detached. Specifically, MeST-Former adopts the newly proposed Identity-Decoupling Attention (IDC-Att) module to disentangle the ID-related and ID-unrelated components. Only the ID-unrelated components are used to construct more generalizable spatiotemporal representations. This process makes the constructed spatiotemporal features identity-agnostic and more generalizable to unseen identities. We conducted extensive experiments to evaluate the performance of the MeST-Former. Our results indicate that MeST-Former achieves accurate and generalizable Deepfake detection performance. Notably, MeST-Former also demonstrates high efficacy in detecting AI-animated talking-head videos. © 2024 The Authors","Deepfake detection; Identity-agnostic; Motion; Spatiotemporal; Transformer"
"Yang, R.; Lan, R.; Deng, Z.; Luo, X.; Sun, X.","Yang, Rui (57215216214); Lan, Rushi (35146229200); Deng, Zhenrong (35106972300); Luo, Xiaonan (57216369979); Sun, Xiyan (23013241000)","57215216214; 35146229200; 35106972300; 57216369979; 23013241000","Deepfake Video Detection Using Facial Feature Points and Ch-Transformer","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217813443&partnerID=40&md5=1ae130e128ed190768349ae3da42bdfe","With the development of Metaverse technology, the avatar in Metaverse has faced serious security and privacy concerns. Analyzing facial features to distinguish between genuine and manipulated facial videos holds significant research importance for ensuring the authenticity of characters in the virtual world and for mitigating discrimination as well as preventing malicious use of facial data. To address this issue, the Facial Feature Points and Class-head-Transformer (FFP-ChT) deepfake video detection model is designed based on the clues of different FFPs distribution in real and fake videos and different displacement distances of real and fake FFPs between frames. The face video input is first detected by the BlazeFace model, and the face detection results are fed into the FaceMesh model to extract 468 FFPs. Then, the Lucas-Kanade (LK) optical flow method is used to track the points of the face, the face calibration algorithm is introduced to re-calibrate the FFPs, and the jitter displacement is calculated by tracking the FFPs between frames. Finally, the Ch is designed in the transformer, and the FFPs and FFP displacement are jointly classified through the ChT model. In this way, the designed ChT classifier is able to accurately and effectively identify deepfake videos. Experiments on open datasets clearly demonstrate the effectiveness and generalization capabilities of our approach. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.","Additional Key Words and PhrasesTransformer; deepfake detection; facial feature; facial feature points; FFP-ChT"
"Zhang, C.; He, X.; Shang, Z.","Zhang, Chunyue (59910215100); He, Xiping (26652968200); Shang, Zihan (59910056100)","59910215100; 26652968200; 59910056100","A method for detecting deepfake faces by integrating multi-scale deep-shallow spatial and frequency features","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005834456&partnerID=40&md5=99c7251961b6740a01e249328effa50c","In recent years, deep learning technology has been excessively used in the creation of fake videos. Deepfake technology alters or replaces the facial information of the original video, synthesizes false voices, and is used to create pornographic films, fake news, political rumors, and so on, posing significant challenges to the authenticity of information and personal privacy. Currently, most face deepfake detection networks are based on single-scale and single-source detection research, and the proposed networks and methods often lack the ability to recognize unknown attack methods and generalization ability. To address these issues, this paper proposes a face deepfake detection method that integrates deep and shallow multi-scale spatial and frequency-domain features to achieve high-accuracy recognition of deepfake faces. The network is based on feature extraction from shallow and deep layers, where the shallow branch captures detailed information from low-level features to detect small-scale targets such as minor noise, while the deep branch focuses on detecting larger and higher-level fake features with a larger receptive field. Each branch adopts a method to fuse multi-scale spatial and frequency-domain features. Multi-scale features can capture information at different levels and granularities, while frequency-domain features can supplement fake traces that are difficult to detect in the spatial domain. Extensive experiments show that tthis framework outperforms most face spoofing detection networks and achieves good performance. © 2024 Copyright held by the owner/author(s).","Face deepfake detection, Multi-scale features Frequency domain features Feature fusion"
"Satone, K.; Amdani, S.Y.","Satone, Kalyani Nakul (58634645500); Amdani, Salim Y. (57191284720)","58634645500; 57191284720","Preserving Video Authenticity in the Age of Synthetic Media using Blockchain","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213551250&partnerID=40&md5=7a708f0272baf859ee4a9e092fb36fbc","Deep fake technology has arisen as a powerful tool for manipulating visual content, presenting significant challenges to the integrity and trustworthiness of videos. The primary objective is to propose and develop a novel approach for deep fake detection using blockchain technology. We develop a comprehensive framework that utilizes machine learning algorithms to analyse objects and classify videos as either genuine or manipulated. To increase the exactness and consistency of our detection system, we integrate blockchain technology as an additional layer of security and verifications & use cases. The blockchain-enabled deep fake detection system operates by storing cryptographic hashes of video frames and metadata on a distributed ledger. This decentralized ledger ensures that once a video is validated and recorded on the blockchain, it becomes incontrovertible and resistant to tampering. By employing consensus mechanisms, the system promises the veracity and transparency of the recorded information sets. We also evaluate the system's performance in footings of computational efficiency and scalability, addressing practical concerns for real-world deployments. The main objectives of this paper is to review and search the blockchain possibilities to secure the digital contents. This paper also studies the different techniques of blockchain which will highlight the general process, detection techniques and existing’s standards. © 2024 AIP Conference Proceedings. All rights reserved.","authentication; Blockchain; CNN; Deep Learning; Deepfake Detection; Face Forensics+; RNN; Video security"
"Lai, Z.; Yao, Z.; Lai, G.; Wang, C.; Feng, R.","Lai, Zhimao (55267884200); Yao, Zhuangxi (59489947400); Lai, Guanyu (56042782300); Wang, Chuntao (54586143100); Feng, Renhai (55706033500)","55267884200; 59489947400; 56042782300; 54586143100; 55706033500","A Novel Face Swapping Detection Scheme Using the Pseudo Zernike Transform Based Robust Watermarking","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213291054&partnerID=40&md5=4773c56e4b9a2d2d39d3815068481652","The rapid advancement of Artificial Intelligence Generated Content (AIGC) has significantly accelerated the evolution of Deepfake technology, thereby introducing escalating social risks due to its potential misuse. In response to these adverse effects, researchers have developed defensive measures, including passive detection and proactive forensics. Although passive detection has achieved some success in identifying Deepfakes, it encounters challenges such as poor generalization and decreased accuracy, particularly when confronted with anti-forensic techniques and adversarial noise. As a result, proactive forensics, which offers a more resilient defense mechanism, has garnered considerable scholarly interest. However, existing proactive forensic methodologies often fall short in terms of visual quality, detection accuracy, and robustness. To address these deficiencies, we propose a novel proactive forensic approach that utilizes pseudo-Zernike moment robust watermarking. This method is specifically designed to enhance the detection and analysis of face swapping by transforming facial data into a binary bit stream and embedding this information within the non-facial regions of video frames. Our approach facilitates the detection of Deepfakes while preserving the visual integrity of the video content. Comprehensive experimental evaluations have demonstrated the robustness of this method against standard signal processing operations and its superior performance in detecting Deepfake manipulations. © 2024 by the authors.","Deepfake detection; face swapping; image hashing; proactive forensics; pseudo-Zernike transform; robust watermarking"
"Peng, C.; Sun, F.; Liu, D.; Wang, N.; Gao, X.","Peng, Chunlei (56313611100); Sun, Feiyang (59314196800); Liu, Decheng (57192557912); Wang, Nannan (55694111900); Gao, Xinbo (7403873424)","56313611100; 59314196800; 57192557912; 55694111900; 7403873424","Local artifacts amplification for deepfakes augmentation","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203185384&partnerID=40&md5=bcf2e5b7165f2305b172ccae51845930","With the rapid and continuous development of AIGC, It is becoming increasingly difficult to distinguish between real and forged facial images, which calls for efficient forgery detection systems. Although many detection methods have noticed the importance of local artifacts, there has been a lack of in-depth discussion regarding the selection of locations and their effective utilization. Besides, the traditional image augmentation methods that are widely used have limited improvements for forgery detection tasks and require more specialized augmentation methods specifically designed for forgery detection tasks. In this paper, this study proposes Local Artifacts Amplification for Deepfakes Augmentation, which amplifies the local artifacts on the forged faces. Furthermore, this study incorporates prior knowledge about similar facial features into the model. This means that within the facial regions defined in this work, forged features exhibit similar patterns. By aggregating the results from all facial regions, the study can enhance the overall performance of the model. The evaluation experiments conducted in this research, achieving an AUC of 93.40% and an Acc of 87.03% in the challenging WildDeepfake dataset, demonstrate a promising improvement in accuracy compared to traditional image augmentation methods and achieve superior performance on intra-dataset evaluation. The cross-dataset evaluation also showed that the method presented in this study has strong generalization abilities. © 2024 Elsevier Ltd","DeepFake detection; Deepfakes augmentation; Local artifacts"
"Yang, R.; You, K.; Pang, C.; Luo, X.; Lan, R.","Yang, Rui (57215216214); You, Kang (58392282100); Pang, Cheng (57210316253); Luo, Xiaonan (57216369979); Lan, Rushi (35146229200)","57215216214; 58392282100; 57210316253; 57216369979; 35146229200","CSTAN: A Deepfake Detection Network with CST Attention for Superior Generalization","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210248360&partnerID=40&md5=e905bb177486e1a692adb3375bc7c930","With the advancement of deepfake forgery technology, highly realistic fake faces have posed serious security risks to sensor-based facial recognition systems. Recent deepfake detection models mainly use binary classification models based on deep learning. Despite achieving high detection accuracy on intra-datasets, these models lack generalization ability when applied to cross-datasets. We propose a deepfake detection model named Channel-Spatial-Triplet Attention Network (CSTAN), which focuses on the difference between real and fake features, thereby enhancing the generality of the detection model. To enhance the feature-learning ability of the model for image forgery regions, we have designed the Channel-Spatial-Triplet (CST) attention mechanism, which extracts subtle local information by capturing feature channels and the spatial correlation of three different scales. Additionally, we propose a novel feature extraction method, OD-ResNet-34, by embedding ODConv into the feature extraction network to enhance its dynamic adaptability to data features. Trained on the FF++ dataset and tested on the Celeb-DF-v1 and Celeb-DF-v2 datasets, the experimental results show that our model has stronger generalization ability in cross-datasets than similar models. © 2024 by the authors.","attention mechanism; deepfake detection; detection model; feature extraction"
"Convertini, V.N.; Impedovo, D.; Lopez, U.; Pirlo, G.; Sterlicchio, G.","Convertini, Vito Nicola (36941197000); Impedovo, Donato (24821831600); Lopez, Ugo (57982469700); Pirlo, Giuseppe (55906867800); Sterlicchio, Gioacchino (57895727600)","36941197000; 24821831600; 57982469700; 55906867800; 57895727600","Discrete Fourier Transform in Unmasking Deepfake Images: A Comparative Study of StyleGAN Creations","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210245310&partnerID=40&md5=36f440e21c85e1f3460c496817f98d67","This study proposes a novel forgery detection method based on the analysis of frequency components of images using the Discrete Fourier Transform (DFT). In recent years, face manipulation technologies, particularly Generative Adversarial Networks (GANs), have advanced to such an extent that their misuse, such as creating deepfakes indistinguishable to human observers, has become a significant societal concern. We reviewed two GAN architectures, StyleGAN and StyleGAN2, generating synthetic faces that were compared with real faces from the FFHQ and CelebA-HQ datasets. The key results demonstrate classification accuracies above 99%, with F1 scores of 99.94% for Support Vector Machines and 97.21% for Random Forest classifiers. These findings underline the fact that performing frequency analysis presents a superior approach to deepfake detection compared to traditional spatial detection methods. It provides insight into subtle manipulation cues in digital images and offers a scalable way to enhance security protocols amid rising digital impersonation threats. © 2024 by the authors.","deepfake detection; discrete Fourier transform (DFT); face forgery; Generative Adversarial Network (GAN); spectrum analysis; StyleGAN"
"Soudy, A.H.; Sayed, O.; Tag-Elser, H.; Ragab, R.; Mohsen, S.; Mostafa, T.; Abohany, A.A.; Slim, S.O.","Soudy, Ahmed Hatem (59254513400); Sayed, Omnia (59254801500); Tag-Elser, Hala (59254360800); Ragab, Rewaa (59253757400); Mohsen, Sohaila (59253757500); Mostafa, Tarek (59254061700); Abohany, Amr A. (56083043100); Slim, Salwa O. (57023780400)","59254513400; 59254801500; 59254360800; 59253757400; 59253757500; 59254061700; 56083043100; 57023780400","Deepfake detection using convolutional vision transformers and convolutional neural networks","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200856501&partnerID=40&md5=279b22437ebe84eb5ffb1a3a641af338","Deepfake technology has rapidly advanced in recent years, creating highly realistic fake videos that can be difficult to distinguish from real ones. The rise of social media platforms and online forums has exacerbated the challenges of detecting misinformation and malicious content. This study leverages many papers on artificial intelligence techniques to address deepfake detection. This research proposes a deep learning (DL)-based method for detecting deepfakes. The system comprises three components: preprocessing, detection, and prediction. Preprocessing includes frame extraction, face detection, alignment, and feature cropping. Convolutional neural networks (CNNs) are employed in the eye and nose feature detection phase. A CNN combined with a vision transformer is also used for face detection. The prediction component employs a majority voting approach, merging results from the three models applied to different features, leading to three individual predictions. The model is trained on various face images using FaceForensics++ and DFDC datasets. Multiple performance metrics, including accuracy, precision, F1, and recall, are used to assess the proposed model’s performance. The experimental results indicate the potential and strengths of the proposed CNN that achieved enhanced performance with an accuracy of 97%, while the CViT-based model achieved 85% using the FaceForences++ dataset and demonstrated significant improvements in deepfake detection compared to recent studies, affirming the potential of the suggested framework for detecting deepfakes on social media. This study contributes to a broader understanding of CNN-based DL methods for deepfake detection. © The Author(s) 2024.","Computer vision; Convolutional neural network; Convolutional vision transformer; Deepfake detection; Face recognition; FaceForensics++; MTCNN"
"Ding, X.; Pang, S.; Guo, W.","Ding, Xinmiao (36730815200); Pang, Shuai (57979141800); Guo, Wen (36610134100)","36730815200; 57979141800; 36610134100","Noise-aware progressive multi-scale deepfake detection","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188178757&partnerID=40&md5=943ad34dd5b6ef9841c186aca229b51f","The proliferation of fake images generated by deepfake techniques has significantly threatened the trustworthiness of digital information, leading to a pressing need for face forgery detection. However, due to the similarity between human face images and the subtlety of artefact information, most deep face forgery detection methods face certain challenges, such as incomplete extraction of artefact information, limited performance in detecting low-quality forgeries, and insufficient generalization across different datasets. To address these issues, this paper proposes a novel noise-aware multi-scale deepfake detection model. Firstly, a progressive spatial attention module is introduced, which learns two types of spatial feature weights: boosting weight and suppression weight. The boosting weight highlights salient regions, while the suppression weight enables the model to capture more subtle artifact information. Through multiple boosting-suppression stages, the proposed model progressively focuses on different facial regions and extracts multi-scale RGB features. Additionally, a noise-aware two-stream network is introduced, which leverages frequency-domain features and fuses image noise with multi-scale RGB features. This integration enhances the model’s ability to handle image post-processing. Furthermore, the model learns global features from multi-modal features through multiple convolutional layers, which are combined with local similarity features for deepfake detection, thereby improving the model’s robustness. Experimental results on several benchmark databases demonstrate the superiority of our proposed method over state-of-the-art techniques. Our contributions lie in the progressive spatial attention module, which effectively addresses overfitting in CNNs, and the integration of noise-aware features and multi-scale RGB features. These innovations lead to enhanced accuracy and generalization performance in face forgery detection. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.","Deepfake detection; Noise-awareness; Spatial attention; Two-stream network"
"Cheng, H.; Guo, Y.; Wang, T.; Nie, L.; Kankanhalli, M.","Cheng, Harry (57226475825); Guo, Yangyang (57204980391); Wang, Tianyi (57211200251); Nie, Liqiang (36439883200); Kankanhalli, Mohan S. (7003629165)","57226475825; 57204980391; 57211200251; 36439883200; 7003629165","Diffusion Facial Forgery Detection","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209821450&partnerID=40&md5=975aedca375eb51b09b0ae709198e3e9","Detecting diffusion-generated images has recently developed as an emerging research area. Existing diffusion-based datasets predominantly focus on general image generation. However, facial forgeries, which pose severe social risks, have remained less explored thus far. To address this gap, this paper introduces DiFF, a comprehensive dataset dedicated to face-focused diffusion-generated images. DiFF comprises over 500,000 images that are synthesized using thirteen distinct generation methods under four conditions. In particular, this dataset utilizes 30,000 carefully collected textual and visual prompts, ensuring the synthesis of images with both high fidelity and semantic consistency. We conduct extensive experiments on the DiFF dataset via human subject tests and several representative forgery detection methods. The results demonstrate that the binary detection accuracies of both human observers and automated detectors often fall below 30%, revealing insights on the challenges in detecting diffusion-generated facial forgeries. Moreover, our experiments demonstrate that DiFF, compared to previous facial forgery datasets, contains a more diverse and realistic range of forgeries, showcasing its potential to aid in the development of more generalized detectors. Finally, we propose an edge graph regularization approach to effectively enhance the generalization capability of existing detectors. © 2024 ACM.","deepfake detection; diffusion-based generation; facial forgery detection"
"Wang, T.; Huang, M.; Cheng, H.; Zhang, X.; Shen, Z.","Wang, Tianyi (57211200251); Huang, Mengxiao (58712721500); Cheng, Harry (57226475825); Zhang, Xiao (59419465000); Shen, Zhiqi (57211681855)","57211200251; 58712721500; 57226475825; 59419465000; 57211681855","LampMark: Proactive Deepfake Detection via Training-Free Landmark Perceptual Watermarks","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209806841&partnerID=40&md5=3cfaf37e9a761ffa5e92f3e117c1f46c","Deepfake facial manipulation has garnered significant public attention due to its impacts on enhancing human experiences and posing privacy threats. Despite numerous passive algorithms that have been attempted to thwart malicious Deepfake attacks, they mostly struggle with the generalizability challenge when confronted with hyper-realistic synthetic facial images. To tackle the problem, this paper proposes a proactive Deepfake detection approach by introducing a novel training-free landmark perceptual watermark, LampMark for short. We first analyze the structure-sensitive characteristics of Deepfake manipulations and devise a secure and confidential transformation pipeline from the structural representations, i.e. facial landmarks, to binary landmark perceptual watermarks. Subsequently, we present an end-to-end watermarking framework that imperceptibly and robustly embeds and extracts watermarks concerning the images to be protected. Relying on promising watermark recovery accuracies, Deepfake detection is accomplished by assessing the consistency between the content-matched landmark perceptual watermark and the robustly recovered watermark of the suspect image. Experimental results demonstrate the superior performance of our approach in watermark recovery and Deepfake detection compared to state-of-the-art methods across in-dataset, cross-dataset, and cross-manipulation scenarios. © 2024 ACM.","deepfake detection; digital forensics; landmark perceptual watermark; robust watermarking"
"Nadimpalli, A.V.; Rattani, A.","Nadimpalli, Aakash Varma (57221785354); Rattani, Ajita (55922829900)","57221785354; 55922829900","ProActive DeepFake Detection using GAN-based Visible Watermarking","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209625816&partnerID=40&md5=34604d060dce85771e835251149c5109","With the advances in generative adversarial networks (GAN), facial manipulations called DeepFakes have caused major security risks and raised severe societal concerns. However, the popular DeepFake passive detection is an ex-post forensics countermeasure and fails in blocking the disinformation spread in advance. Alternatively, precautions such as adding perturbations to the real data for unnatural distorted DeepFake output easily spotted by the human eyes are introduced as proactive defenses. Recent studies suggest that these existing proactive defenses can be easily bypassed by employing simple image transformation and reconstruction techniques when applied to the perturbed real data and the distorted output, respectively. The aim of this article is to propose a novel proactive DeepFake detection technique using GAN-based visible watermarking. To this front, we propose a reconstructive regularization added to the GAN’s loss function that embeds a unique watermark to the assigned location of the generated fake image. Thorough experiments on multiple datasets confirm the viability of the proposed approach as a proactive defense mechanism against DeepFakes from the perspective of detection by human eyes. Thus, our proposed watermark-based GANs prevent the abuse of the pretrained GANs and smartphone apps, available via online repositories, for DeepFake creation for malicious purposes. Further, the watermarked DeepFakes can also be detected by the SOTA DeepFake detectors. This is critical for applications where automatic DeepFake detectors are used for mass audits due to the huge cost associated with human observers examining a large amount of data manually. © 2024 Copyright held by the owner/author(s) Publication rights licensed to ACM.","DeepFakes; facial manipulations; proactive deepfake detection"
"Xiao, S.; Zhang, Z.; Yang, J.; Wen, J.; Li, Y.","Xiao, Shuai (57215612741); Zhang, Zhuo (56704499300); Yang, Jiacheng Chen (25959803600); Wen, Jiabao (57200415294); Li, Yang (57214958963)","57215612741; 56704499300; 25959803600; 57200415294; 57214958963","Forgery Detection by Weighted Complementarity between Significant Invariance and Detail Enhancement","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197346201&partnerID=40&md5=7483e1eac7408f91010e7dd8ea84e04a","Generative adversarial networks have shown impressive results in the modeling of movies and games, but what if such powerful image generation capability is used to harm the Multimedia? The face replacement methods represented by Deepfakes are becoming a threat to everyone, so the development of image authenticity detection methods has become a top priority. For achieving accurate detection resistant to compression effects, we propose a weighted complementary dual-stream detection method. First, to alleviate the influence of image compression on manipulation detection, we propose the concept of pixel-wise saliency invariance. We map fake images onto saliency maps via Quaternary Fourier Transform, which discovers the invariant properties of image phase spectra on different compressions. Meanwhile, to capture boundary traces more easily, we propose the concept of pixel-wise detail enhancement. We apply Bilateral Filtering to preserve the texture edges of fake images and amplify the fake boundaries. Finally, to take full advantage of the two proposed concepts, a weighted complementary dual-stream network is designed as a classifier to fuse features and identify real and fake. On different benchmarks like FaceForensics++ (FF++), Celeb-DF, and DFDC, the experimental results show that the proposed method has the average best detection accuracy compared to existing methods. © 2024 Copyright held by the owner/author(s) Publication rights licensed to ACM.","complementary dual-stream; Deepfakes detection; pixel-wise detailed enhancement; pixel-wise salient invariance"
"Akhtar, Z.; Pendyala, T.L.; Athmakuri, V.S.","Akhtar, Zahid (46661628200); Pendyala, Thanvi Lahari (59345050800); Athmakuri, Virinchi Sai (59344831800)","46661628200; 59345050800; 59344831800","Video and Audio Deepfake Datasets and Open Issues in Deepfake Technology: Being Ahead of the Curve","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204479411&partnerID=40&md5=d9d0a2a75c440171b974c21dfb6248eb","The revolutionary breakthroughs in Machine Learning (ML) and Artificial Intelligence (AI) are extensively being harnessed across a diverse range of domains, e.g., forensic science, healthcare, virtual assistants, cybersecurity, and robotics. On the flip side, they can also be exploited for negative purposes, like producing authentic-looking fake news that propagates misinformation and diminishes public trust. Deepfakes pertain to audio or visual multimedia contents that have been artificially synthesized or digitally modified through the application of deep neural networks. Deepfakes can be employed for benign purposes (e.g., refinement of face pictures for optimal magazine cover quality) or malicious intentions (e.g., superimposing faces onto explicit image/video to harm individuals producing fake audio recordings of public figures making inflammatory statements to damage their reputation). With mobile devices and user-friendly audio and visual editing tools at hand, even non-experts can effortlessly craft intricate deepfakes and digitally altered audio and facial features. This presents challenges to contemporary computer forensic tools and human examiners, including common individuals and digital forensic investigators. There is a perpetual battle between attackers armed with deepfake generators and defenders utilizing deepfake detectors. This paper first comprehensively reviews existing image, video, and audio deepfake databases with the aim of propelling next-generation deepfake detectors for enhanced accuracy, generalization, robustness, and explainability. Then, the paper delves deeply into open challenges and potential avenues for research in the audio and video deepfake generation and mitigation field. The aspiration for this article is to complement prior studies and assist newcomers, researchers, engineers, and practitioners in gaining a deeper understanding and in the development of innovative deepfake technologies. © 2024 by the authors.","computer forensics; deepfake detection; deepfake generation; deepfakes; digital face manipulations; digital forensics; fake news; information authenticity; multimedia manipulations"
"Wang, F.; Zhang, D.; Guo, Z.; Wang, D.; Yang, G.","Wang, Feng (59059273200); Zhang, Dengyong (55318418900); Guo, Zhiqing (57219672095); Wang, Dewang (57210996855); Yang, Gaobo (8647279200)","59059273200; 55318418900; 57219672095; 57210996855; 8647279200","ESRL: efficient similarity representation learning for deepfake detection","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185528988&partnerID=40&md5=7f552ac92d19496a5348e5bbd29b9dd8","For Deepfake detection, many existing works use the cross-entropy loss to enforce the classifier network to learn the mapping relationship from the RGB domain to the class domain, lacking an explicit constraint to guide the feature extraction network to learn discriminative features from an input image. This constrains the feature representation capability to expose deepfake. In this work, we analyze the feature extraction network in terms of both difference and similarity capabilities and propose a new constraint called similarity loss (SL) to improve the detection performance of the convolutional neural network (CNN) based detector. Moreover, according to the experimental results of the SL on data augmentation effectiveness, we propose a simple yet efficient framework, which is called as efficient similarity representation learning (ESRL), for deepfake detection. Extensive experiments on three public datasets (namely FF++, DFDC, and Celeb-DF) show that the feature extraction network trained with the help of SL can map forged faces and real faces to different feature embedding and map the same type of forged faces to similar feature embedding. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.","Deep metric learning; Deepfake detection; Face forgery detection; Similarity representation learning"
"Lian, Z.; Wang, L.","Lian, Zhichao (55822749800); Wang, Ling (57196338149)","55822749800; 57196338149","A novel forgery classification method based on multi-scale feature capsule network in mobile edge computing","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165876075&partnerID=40&md5=c97f2acfc84ba060e5ffea7cc66777e2","Face recognition is one of the most important applications of MEC. However, there have been many fake face data that can deceive MEC devices, causing serious problems such as information leakage. Face forgery detection can effectively solve this problem. Current face forgery detection methods have achieved high accuracy. However, most of the methods are researched on the classification of face authenticity. We find that studying multi-classification of forgery methods can not only improve the accuracy of the model to identify fake faces, but also help improve the generalization ability of fake face classification. We argue that multi-scale features and high-frequency features can expose more detailed forgery artifacts. So, we design four modules, which take advantage of the complementarity of RGB features and frequency features, global features and local features. The first module is a residual-guided multi-scale spatial attention module, which uses residuals to guide the RGB feature extractor to extract fake features from a multi-scale perspective. The second module is a multi-scale retinal feature extraction module. The third module is a multi-scale channel attention-guided local frequency statistics module, which extracts local frequency responses using sliding-window DCT. The last module is a capsule network classification module with overall correlation to classify the fused features. The information transfer between the subject capsule and the classification capsule can increase the integrity of the model, making the model converge faster. We conduct experiments on the databases FaceForensics++, DeepfakeDetection, and FakeAVCeleb. Experimental result shows that our method performs well on forgery classification. © 2023 John Wiley & Sons, Ltd.","capsule network; deepfake detection; forgery classification; mobile edge computing; multi-scale feature"
"Nagarhalli, T.P.; Save, A.; Patil, S.; Aswalekar, U.","Nagarhalli, Tatwadarshi P. (57202110143); Save, Ashwini M. (57191594173); Patil, Sanket D. (57685339800); Aswalekar, Uday V. (57558038800)","57202110143; 57191594173; 57685339800; 57558038800","A Comprehensive Review of Deepfake and its Detection Techniques","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204649542&partnerID=40&md5=6e87732169418d34ce500584b8215ca9","Deepfake technology has emerged as a significant concern in the era of digital media, posing threats to various sectors by enabling the creation of highly realistic synthetic content. This paper presents a comprehensive review of deepfake techniques and detection methods. It analyzes 14 research papers covering a range of approaches, including machine learning algorithms, computer vision techniques, and signal processing methods. Key aspects explored include face and voice manipulation, multimodal fusion, and the use of attention mechanisms. The review highlights the challenges in detecting deepfakes, such as dataset bias and the arms race between creators and detectors. Additionally, it discusses the limitations of current detection techniques and the need for robust, scalable solutions. Through a critical analysis of the literature, this review provides insights into the strengths and weaknesses of existing approaches and identifies areas for future research. The paper contributes to understanding deepfake technology and its implications for society, emphasizing the importance of developing effective detection mechanisms to combat the spread of synthetic media. © 2024 Seventh Sense Research Group.","Audio-video manipulation; Deep Learning; Deepfake; Deepfake detection; Face swap; Synthetic media; Voice spoofing"
"Ghasemzadeh, F.; Moghaddam, T.; Dai, J.; Yun, J.; Kim, D.D.","Ghasemzadeh, Faraz (59212072600); Moghaddam, Tina (57226334738); Dai, Jingming (59213077100); Yun, Joobeom (56911637100); Kim, Dan Dongseong (55667184100)","59212072600; 57226334738; 59213077100; 56911637100; 55667184100","[Short Paper] Towards Generalized Detection of Face-Swap Deepfake Images","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198104673&partnerID=40&md5=2746ad08a9c5c11b9adb4abc08a6fad1","As the prevalence of face-swap deepfakes on the Internet continues to rapidly increase, it is imperative for social media platforms to utilise a robust detection algorithm to identify these fake images in order to minimise the risk of harm from malicious content. However, there is currently no readily available detector to facilitate this process. This is mainly because face-swap detectors often 1) fail to correctly classify fake images generated by architectures that they have not encountered during training and are 2) highly susceptible to image manipulations such as compression techniques. In this paper, we present a novel approach for a deepfake image detector. Our approach adopts the EfficientNet-B4 Convolutional Neural Network architecture with noisy-student pre-training which addresses these issues through maximising the diversity of the training dataset and augmenting the input during training to ensure that the detector performs well on manipulated images. Our detector was tested against two different datasets containing a range of manipulated face-swaps created by DeepFaceLab, FSGAN and Faceswap. Our detector achieves an accuracy of 92.7% whilst maintaining a false positive rate below 1%. The results demonstrate that our proposed approach is effective at addressing the problems of generalisation which hamper efforts of deepfake detection. © 2024 ACM.","Deepfake Detection; Impersonation; Social Media"
"Qi, Y.; Wen, S.; Zhang, H.; Liang, A.; Chen, H.; Cao, P.","Qi, Yongfeng (54893032200); Wen, Shengcong (58718197700); Zhang, Hengrui (58718424800); Liang, Anye (58718888200); Chen, Huili (58718653600); Cao, Panpan (57671802900)","54893032200; 58718197700; 58718424800; 58718888200; 58718653600; 57671802900","Face forgery detection by progressively enhancing spatial and frequency-aware features","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194484700&partnerID=40&md5=7a3d33aae8ee22b806606bd812be8ff7","Due to the security issues caused by face synthesis technology, face forgery detection has received considerable attention. Therefore, there is an increasing necessity to develop effective and generalized face forgery detection models. Some current methods attempt to use frequency features to reveal clues hidden under fake faces. However, the frequency information utilized by these methods is often coarse-grained perceptual features generated by frequency transformation, which makes it difficult for them to extract fine-grained forgery traces in the ordinary learning process. To compensate for these shortcomings, we propose a learning framework that progressively enhances spatial and frequency-aware features, consisting of three carefully designed modules. Specifically, the first is the fine-grained frequency-aware extraction module, which decomposes the RGB image into fine-grained components and extracts content-related frequency information through multiple learnable filters to obtain the frequency-transformed fine-grained perceptual features, which provide fine-grained forgery information for subsequent learning of the network. The second is the noise residual enhancement module, which enhances and guides the network to capture forgery traces from the perspective of image noise. The last is the dual-domain feature attention module, which learns and enhances forgery clues in each other’s features by fusing information from RGB and multi-frequency fine-grained perceptual features. Extensive experimental results and visualizations demonstrate that our proposed model outperforms previous face forgery detection models. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2024.","Deepfake detection; Face forgery detection; Frequency-aware features; Spatial features; SRM"
"Jin, X.; Wu, N.; Jiang, Q.; Kou, Y.; Duan, H.; Wang, P.; Yao, S.","Jin, Xin (56991832300); Wu, Nan (57750887800); Jiang, Qian (57194699462); Kou, Yuru (58988680500); Duan, Hanxian (58988964800); Wang, Puming (57188640245); Yao, Shaowen (24473851600)","56991832300; 57750887800; 57194699462; 58988680500; 58988964800; 57188640245; 24473851600","A dual descriptor combined with frequency domain reconstruction learning for face forgery detection in deepfake videos","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190520119&partnerID=40&md5=15bb77bbd3876d97b34223df6e19fd6d","Conventional face forgery detectors have primarily relied on image artifacts produced by deepfake video generation models. These methods have performed well when the training and test sets were derived from the same deepfake algorithm, but accuracy and generalizability remain a challenge for diverse datasets. In this study, both supervised and unsupervised approaches are proposed for more accurate detection in in-domain and cross-domain experiments. Specifically, two descriptors are introduced to extract rich information in the spatial domain to achieve higher accuracy. A frequency domain reconstruction module is then included to expand the representation space for facial features. A reconstruction method based on an auto-encoder was also applied to obtain a frequency domain coding vector. In this process, reconstruction learning was sufficient for extracting unknown information, while a combination with classification learning provided essential high-frequency pixel differences between real and fake samples, thus facilitating forgery identification. A series of validation experiments with large-scale benchmark datasets demonstrated that the proposed technique was superior to existing methods. © 2024 Elsevier Ltd","Auto encoder; Deep learning; Deepfake detection; Digital forensics; Frequency domain analysis; Video forgery"
"Abdullah, M.T.; Ali, N.H.M.","Abdullah, Mohammed Thajeel (58281636000); Ali, Nada Hussein M. (56316487000)","58281636000; 56316487000","Facial deepfake performance evaluation based on three detection tools: MTCNN, Dlib, and MediaPipe","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193680343&partnerID=40&md5=865ca76ca34a7aaa83a42545fb3ebd2a","DeepFake, DeepFake detection, and face detection technologies have a strong relationship. DeepFake techniques have become a serious threat to celebrities, the general public, and the judiciary, which relies on visual media as evidence in criminal cases. DeepFake detection methods are responsible for detecting DeepFake through a series of procedures, the first and most significant of which is face detection. Note that face detection approaches are used in several methods to detect faces in photos, including those in DeepFake generating and DeepFake detection. Hence, the first part of this paper describes the concept of face detection and three of its tools, two of which are frequently utilized in DeepFake detection (Multi-Task Cascaded Convolutional Networks (MTCNN) and Dlib). MediaPipe has not yet been employed in this field to study and evaluate the performance of these tools through a practical comparison. Consequently, a group of modern DeepFake detection methods proposes a new taxonomy based on extracting the features utilized in each. Lastly, datasets of photos from DeepFake detection experiments were used to determine which one posed a genuine challenge to the three tools. The results presented that the MediaPipe tool is the best in accuracy, 99.3%, and the dataset Open Forensic (OF) is the most challenging due to the many mistakes generated when its works on it. © 2024 AIP Publishing LLC.","DeepFake; DeepFake Detection; Dlib; Face Detection; MediaPipe; MTCNN"
"Wang, S.; Zhang, H.; Yang, G.; Guo, Z.; Chen, J.","Wang, Shuai (57432133200); Zhang, Hanling (13611757700); Yang, Gaobo (8647279200); Guo, Zhiqing (57219672095); Chen, Jiyou (57221655154)","57432133200; 13611757700; 8647279200; 57219672095; 57221655154","A two-stage fake face image detection algorithm with expanded attention","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177873933&partnerID=40&md5=cb01e3ae2d5a1bf2c54662a6ed9a3d00","Convolutional neural networks (CNNs) have achieved impressive successes in fake face image detection. However, CNNs ignore tampering traces outside their attention scope. Moreover, example forgetting events can also pose negative impacts on the face forgery detection accuracy. To address these issues, this paper proposes an attention-expanded two-stage face forgery detector, named Attention-expanded Deepfake Spotter (ADS). In the first stage, the manipulated regions are preliminarily located by utilizing the Region Score Maps (RSMs) generated by the modified CNN. In the second stage, the Expanding and Undetectable Regions (EUR) loss function is designed to encourage another modified CNN to mine manipulation traces outside the manipulated areas exposed in the first stage. To fuse the manipulation traces extracted from different regions in the two stages and mitigate the problems caused by example forgetting events, RSM-weighted accumulation is adopted to integrate the detection information from both stages and obtain the final detection result. The proposed algorithm’s effectiveness for each component is analyzed through ablation experiments, and the method is evaluated on four publicly available datasets: FF++, HFF, DFDC, and Celeb-DF. The experimental results demonstrate that the proposed method has high detection rates and superior transferability, outperforming most existing algorithms. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2023.","Deepfake detection; Ensemble learning; Face forgery detection; Image forensics"
"Hsu, L.-Y.","Hsu, Lingyuan (26654165700)","26654165700","AI-assisted deepfake detection using adaptive blind image watermarking","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186649445&partnerID=40&md5=14e084af89f40e3827d937ce3576eab2","This paper proposes a new adaptive blind watermarking technology for deepfake detection, which can embed deepfake detection information into the image and verify the image's authenticity without requiring additional information. The proposed scheme utilizes mixed modulation combined with partly sign-altered mean value to embed a set of coefficients that enhance robustness against attacks while maintaining high image quality. Additionally, blind adaptive deepfake detection technology with the tamper detection mean value is employed to detect relative positions adaptively, even when face images are slightly modified or deepfaked. To further improve the performance of the proposed scheme, a gray wolf optimizer is introduced to optimize parameters, and a denoising autoencoder is employed to facilitate the identification of extracted watermarks. This technology will adaptively embed watermark information while preserving the original face image, thereby maintaining the authenticity of the face in the image and verifying the owner of the image. The code is available at https://github.com/lyhsu01/AwDD. © 2024 Elsevier Inc.","Blind image watermarking; Deepfake detection; Mixed modulation; Partly sign-altered"
"Ghosh, T.; Naskar, R.","Ghosh, Tanusree (58722055200); Naskar, Ruchira (53866980700)","58722055200; 53866980700","Less is more: A minimalist approach to robust GAN-generated face detection","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185720899&partnerID=40&md5=5880cb9fcc520d3760c71aeb3d413347","Hyper-realistic images that are not differentiable from authentic images to regular viewers have become extremely easy to generate and highly accessible. Furthermore, the increasing pervasiveness of social media networks in our daily lives has facilitated the easy dissemination of fake news accompanied by such synthetic images. Hyper-realistic artificial face images are often illicitly used as profile pictures on social media sites, further using such profiles to spread fabricated information, resulting in social perils. Most available synthetic image detectors are challenging to implement in practical scenarios due to their high complexity and performance degradation for images from Online Social Networks (OSNs). In this work, we develop a deep learning-based lightweight synthetic image detector called Relative Chrominance Distance Network (RCD-Net). In this paper, we introduce the RCD image feature set for the first time, which gives a pair-wise chrominance component-based distance measure. To show its effectiveness, we explore multiple luminance-chrominance spaces. Compared to the state-of-the-art (SOTA), our model hugely reduces the network parameter requirements, making it incredibly lightweight. We also study the robustness of the proposed solution against common post-processing operations in the context of online social media networks. Experimental results prove that the proposed solution achieves SOTA performance at a much lower complexity than available solutions. © 2024 Elsevier B.V.","Deepfake detection; Digital image forensics; Fake image detection; GAN forensics; GAN-face detection; Synthetic image detection"
"Sandotra, N.; Arora, B.","Sandotra, Neha (58767744600); Arora, Bhavna (57225027341)","58767744600; 57225027341","A comprehensive evaluation of feature-based AI techniques for deepfake detection","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179993559&partnerID=40&md5=866b5b9f5c00aeebdc89fcbc58d0a06b","In the contemporary era, where data and information are the key source in every domain, it becomes imperative to identify, detect and distinguish between fake and authentic content available online. Recent technological innovations in the area of artificial intelligence (AI) and computer vision (CV) have been the key players both in generating and detection of these media (both images and videos). The advancement of techniques for generating, fabricating, and manipulating multimedia materials has resulted in a heightened level of realism, thereby giving rise to numerous security concerns. The adoption of these technologies has resulted in the widespread dissemination of fraudulent images and videos, which are being utilised for various criminal purposes and often featuring misleading information and impersonations of public personalities, which have detrimental consequences on the reputations of those individuals involved. The proliferation of counterfeit images poses a significant threat to national security, as these images can be exploited for the purpose of identity forgery. Therefore, it is imperative to design and develop robust algorithms for detecting counterfeit media, capable of effectively distinguishing between authentic and manipulated content. This study aims to present the generative and detection techniques of visual deep fake media using deep learning (CNN, RNN, LSTM, etc.), machine learning (SVM, KNN, Random Forest, and Decision Tree) and statistical learning (3D Morphable Model). This study also conducted an in-depth analysis of the current state of literature concerning the development and application of deepfake technology, as well as the accessibility of open-source tools for generating manipulated media. The present study provides an extensive review of face manipulation methodologies employed in the development of deep fakes, specifically focusing on Identity swap, Image Synthesis, Face Re-enactment, and Attribute Manipulation. A presented review proposed a novel taxonomy based on spatial, temporal and frequency-based features for the detection of visual Deepfake. This study out passes the existing surveys that have been presented by various other researchers in this field in terms of domain, learning methods, features and manipulation techniques used. In this study, the challenges and research gaps along with the analysis of each of these have also been presented with the intent for prioritising the development of deep fake detection tools. © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2023.","Deepfake detection; Deepfake generation; Face manipulation techniques; Fake images; Generative adversarial network"
"Xu, P.; Ma, Z.; Mei, X.; Shen, J.","Xu, Pengxiang (57222580968); Ma, Zhiyuan (58079714800); Mei, Xue (23091706700); Shen, Jie (57196190343)","57222580968; 58079714800; 23091706700; 57196190343","Detecting facial manipulated images via one-class domain generalization","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182641098&partnerID=40&md5=2fa8d6f79f2503bac583ff03ee2cd675","Nowadays, numerous synthesized images and videos generated by facial manipulated techniques have become an emerging problem, which promotes facial manipulation detection to be a significant topic. Much concern about the use of synthesized facial digital contents in society is rising due to their deceptive nature and widespread. To detect such manipulated facial digital contents, many methods have been proposed. Most detection methods focus on specific datasets. It is hard for them to detect facial images or videos manipulated by unknown face synthesis algorithms. In this paper, we propose a method to improve the generalization ability of the facial manipulation detection model using one-class domain generalization. We shape the problem into domain generalization. We divide the dataset into several domains according to different manipulation algorithms. We also try to process the images from the perspective of frequency domain. We utilize two-dimensional wavelet transform to preprocess the images to ensure the effect on compressed images. The results of experiments implemented on FaceForensics++ dataset exceed the baselines and recent works. The feature visualization analyses intuitively show that our method can learn robust feature representation that can be generalized to unseen domains. © 2024, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","Adversarial training; DeepFake detection; Domain generalization; Facial manipulation detection"
"Wu, H.; Leng, L.; Yu, P.","Wu, Haoyu (59682841800); Leng, Lingyun (58046961000); Yu, Peipeng (57211919072)","59682841800; 58046961000; 57211919072","Learning Local Reconstruction Errors for Face Forgery Detection","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000674357&partnerID=40&md5=69649e38958deeca8c70a7847d9b1b3a","Although several deepfake detection technologies have achieved great detection accuracy inside the data domain in recent years, there are still limitations in cross-domain generalization. This is due to the model’s ease of fitting the data sample distribution in the training data domain and its tendency to detect a specific forgery trace in order to reach a judgment rather than catching generalized forgery traces. In this paper, we propose to learn Local Reconstruction Errors for face forgery detection. The local anomaly traces of the fake face are often mapped using the original real face as a reference; however, the original real face of the fake face cannot be acquired in the real scenario. Therefore, this solution designs a local reconstruction autoencoder trained with real samples. By masking key areas of the face, the original real face can be reconstructed. Because the autoencoder only learns how to restore the essential parts of the real face using local patches of real samples, it cannot recover the forging traces or target face information in the fake face. Therefore, the reconstructed image forms a reconstructed difference with the original image. This solution aids the model in detecting local differences in fake faces by producing feature-level local difference attention mappings in the network’s middle layer. A series of experiments demonstrate that this solution has good detection and generalization performance. © (2024), (Science and Information Organization). All rights reserved.","deepfake detection; Face forgery; generalized detection; local anomalies"
"Kim, Y.; Kwon, M.-J.; Lee, W.; Kim, C.","Kim, Younghun (59622688600); Kwon, Myung-joon (57219765100); Lee, Wonjun (59495890100); Kim, Chang Ik (7409875501)","59622688600; 57219765100; 59495890100; 7409875501","FRIDAY: Mitigating Unintentional Facial Identity in Deepfake Detectors Guided by Facial Recognizers","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218193511&partnerID=40&md5=64a2deafb39ba28e53486c923e352fc7","Previous Deepfake detection methods perform well within their training domains, but their effectiveness diminishes significantly with new synthesis techniques. Recent studies have revealed that detection models make decision boundaries based on facial identity instead of synthetic artifacts, leading to poor cross-domain performance. To address this issue, we propose FRIDAY, a novel training method that attenuates facial identity utilizing a face recognizer. To be specific, we first train a face recognizer using the same backbone as the Deepfake detector. We then freeze the recognizer and use it during the detector's training to mitigate facial identity information. This is achieved by feeding input images into both the recognizer and the detector, then minimizing the similarity of their feature embeddings using our Facial Identity Attenuating loss. This process encourages the detector to produce embeddings distinct from the recognizer, effectively attenuating facial identity. Comprehensive experiments demonstrate that our approach significantly improves detection performance on both in-domain and cross-domain datasets. © 2024 IEEE.","Deepfake Detection; Face Recognition; Image Forensics; Unintentional Facial Identity"
"Galdi, C.; Panariello, M.; Todisco, M.; Evans, N.","Galdi, Chiara (55937907100); Panariello, Michele (57223775680); Todisco, Massimiliano (24482053500); Evans, Nicholas W.D. (56207371100)","55937907100; 57223775680; 24482053500; 56207371100","2D-Malafide: Adversarial Attacks Against Face Deepfake Detection Systems","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217283370&partnerID=40&md5=413e82f8c9a93cd078a94757296efa22","We introduce 2D-Malafide, a novel and lightweight adversarial attack designed to deceive face deepfake detection systems. Building upon the concept of 1D convolutional perturbations explored in the speech domain, our method leverages 2D convolutional filters to craft perturbations which significantly degrade the performance of state-of-the-art face deepfake detectors. Unlike traditional additive noise approaches, 2D-Malafide optimises a small number of filter coefficients to generate robust adversarial perturbations which are transferable across different face images. Experiments, conducted using the FaceForensics++ dataset, demonstrate that 2D-Malafide substantially degrades detection performance in both white-box and black-box settings, with larger filter sizes having the greatest impact. Additionally, we report an explainability analysis using GradCAM which illustrates how 2D-Malafide misleads detection systems by altering the image areas used most for classification. Our findings highlight the vulnerability of current deepfake detection systems to convolutional adversarial attacks as well as the need for future work to enhance detection robustness through improved image fidelity constraints. © 2024 IEEE.","adversarial attacks; convolutional filters; deepfake detection; image perturbations; lightweight adversarial attacks"
"Abisha, M.B.; Kathrine, J.W.; Kushmitha, S.","Abisha, M. B. (59511603500); Kathrine, Jaspher W. (57130545500); Kushmitha, S. (59546405800)","59511603500; 57130545500; 59546405800","Capsule Networks and LSTM Models for Robust Deepfake Detection in Audio and Video","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217181497&partnerID=40&md5=4404f08e4804e94140ad60e8bd904f45","Due to the fast advancement of deepfakes, notable difficulties have been presented by deepfake innovation in confirming the believability of computerized content, especially on the audio and video front. This paper introduces a new hierarchical model that articulates Capsule Networks within LSTM for the effective and robust deepfake detection in both audio-video frameworks. It is argued that using Capsule Networks, spatial mindfulness capabilities enable the detection of subtle spatial objects in video outlines, whereas, LSTM models capture transient objects in audio arrangements and video frames over time. Thus, our approach implements two designs at once that reached progressed discovery accuracy, addressing spatial and temporary disorders, inherent in deepfake media. It is discovered from the outcomes that this model is very much effective on several datasets suggesting its better generalizing capability in different types of Deepfake media. In its current form, the design of this approach seems capable of being used for the real-time detection task. In this regard, this research provides practical insights into the development of media forensics offering an approach that can be more effective in the role of dissemination of fake news prevention, and fills the gap in the current literature, thus advancing the overall understanding of media forensics. © 2024 IEEE.","Audio Deepfake; Audio Pre-processing; Capsule Networks; Data Pre-processing; Deepfake Detection; Digital Content Authenticity; Face and Voice Manipulation; Face-Swapping; Feature Extraction; Long-Term Memory; LSTM Networks; Sequence Analysis; Video Deepfake; Video Frame Extraction; Voice Synthesis"
"Krishna, V.; Neha, P.S.; Vyshnavi, P.; Vidyasekaran, H.","Krishna, Vamsi V. (58817451400); Neha, Perla Sree (58929031000); Vyshnavi, P. Sree (57192557525); Vidyasekaran, Harine (58916529900)","58817451400; 58929031000; 57192557525; 58916529900","Evaluating Models for Deepfake Detection: A Comparative Study","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217158198&partnerID=40&md5=605d75da4eeb314d0cf05cb3fb8c9973","Deepfake detection poses a significant challenge in digital forensics due to increasingly advanced AI-generated videos. This study evaluates three models using the FaceForensics++ and DeeperForensics-1.0 datasets. The preprocessing involved video encoding, renaming, trimming, frame extraction, face detection, and data loading. The first model, a Convolutional Neural Network (CNN), achieved 84% accuracy. The second model, Xception, an efficient CNN with depth-wise separable convolutions and residual connections, attained 89% accuracy. The third model, combining CNN with a Recurrent Neural Network (RNN) and LSTM layers, significantly improved detection accuracy to 97%. This hybrid model highlights the importance of capturing spatial and temporal features in deepfake detection, demonstrating the efficacy of advanced deep learning techniques in addressing the deepfake threat. © 2024 IEEE.","classification; CNN; CNN+RNN; Deepfake detection; hybrid model; Xception"
"Alfalasi, H.R.; Hashem, I.A.; Abul, O.","Alfalasi, Hamad Rashed (58763852200); Hashem, Ibrahim Abaker Targio (59129663800); Abul, Osman (6602597612)","58763852200; 59129663800; 6602597612","Generalizable Spatiotemporal Deepfake Detection with Late-Fusion","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216675999&partnerID=40&md5=d293e3be06e4e176c49134d19e09e3b9","Recently, deepfakes have been spreading at an alarming rate, raising concerns about trust and privacy in social media, where misinformation is easily spread. Deepfakes can be used for various malicious reasons, such as for manipulating criminal evidence, blackmailing, or even identity theft. To combat this, many deepfake detection models have been developed. However, these models often struggle with poor generalizability across different datasets and deepfake types. In this paper, a spatiotemporal model is proposed to enhance generalization, using a late-fusion scheme where a spatial and a temporal module separately analyze spatial and temporal features, such as inconsistent lighting or color discrepancy. The spatial module is a Multi-Scale Vision Transformer (MViTv2), which focuses on spatial anomalies within frames. The temporal module is a Temporal Transformer which focuses on inconsistencies between frames in a video. The datasets used are FaceForensics++ (FF++) and CelebDF. The experiments include intra-dataset evaluations, where the model is trained and tested on one dataset, and cross-dataset evaluations, where it is trained on one dataset and tested on another, enabling us to measure the model's generalizability. The model outperforms state-of-the-art models, achieving 91.0% AUC when trained on FF++c23 and tested on CelebDF. © 2024 IEEE.","CelebDF; Deepfake Detection; FaceForensics++; Generalizability; Generalization; Vision Transformers"
"Ciamarra, A.; Caldelli, R.; del Bimbo, A.D.","Ciamarra, Andrea (57721842900); Caldelli, Roberto (6603103996); del Bimbo, Alberto (15018931800)","57721842900; 6603103996; 15018931800","Spotting fully-synthetic facial images via local camera surface frames","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215521459&partnerID=40&md5=cf008e8c11d6a0a0bad0cfaba502387a","The actual capacity to AI-generate realistic fully synthetic images is day-by-day improving and this is particularly true for pictures representing human faces that appear indistinguishable from real people. This poses the crucial need to develop instruments able to discern between true and do not existing people by detecting some eventual inconsistencies embedded within the images during the generation process. The main difference between a pristine picture and a deepfake generated one is that, in the second case, there has not been an effective camera acquisition; so all the various interrelationships among the elements belonging to the scene (lights, reflectance, object respective positions in the 3D space) are not taken by the real world in that precise time instant but just artificially reproduced. According to such consideration, in this work, we introduce local camera surface frames as a possible mean to represent these specific environmental characteristics in order to highlight differences. The experimental analysis carried out has witnessed that this feature can grant a very high level of accuracy and a significant degree of generalization. ©2024 IEEE.","Deepfake; Deepfake detection; facial images; fully synthetic; local surface frames"
"Xie, Z.; Li, B.; Xu, X.; Liang, Z.; Yu, K.; Wu, M.","Xie, Zeyu (57222359565); Li, Baihan (58955129500); Xu, Xuenan (57218699500); Liang, Zheng (58450024600); Yu, Kai (7403385716); Wu, Mengyue (57190753127)","57222359565; 58955129500; 57218699500; 58450024600; 7403385716; 57190753127","FakeSound: Deepfake General Audio Detection","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214827586&partnerID=40&md5=acd567f8a85b76c15abb7b87aa5df142","With the advancement of audio generation, generative models can produce highly realistic audios.However, the proliferation of deepfake general audio can pose negative consequences.Therefore, we propose a new task, deepfake general audio detection, which aims to identify whether audio content is manipulated and to locate deepfake regions.Leveraging an automated manipulation pipeline, a dataset named FakeSound for deepfake general audio detection is proposed, and samples can be viewed on website https://FakeSoundData.github.io.The average binary accuracy of humans on all test sets is consistently below 0.6, which indicates the difficulty humans face in discerning deepfake audio and affirms the efficacy of the FakeSound dataset.A deepfake detection model utilizing a general audio pre-trained model is proposed as a benchmark system.Experimental results demonstrate that the performance of the proposed model surpasses the state-of-the-art in deepfake speech detection and human testers. © 2024 International Speech Communication Association. All rights reserved.","Audio manipulation; Deepfake detection; Deepfake general audio; Deepfake identification; Deepfake location"
"Zhang, D.; Li, D.; Arun Kumar, A.K.; Li, F.; Deng, Z.; Wu, C.","Zhang, Dengyong (55318418900); Li, Daijie (59659913000); Arun Kumar, Sangaiah Kumar (55616335800); Li, Feng (56668990100); Deng, Zelin (7402665633); Wu, Chengcheng (59660103500)","55318418900; 59659913000; 55616335800; 56668990100; 7402665633; 59660103500","Generalizing Face Forgery Detection by Suppressed Texture Network With Two-Branch Convolution","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214290583&partnerID=40&md5=d2f6144d43ca1c006dfc2290322d93ed","With the development of Internet technology, deepfake (DF) videos can spread rapidly through online platforms, providing a new way of cyberbullying by generating nude pictures of female victims and using their faces to generate pornographic movies, which bring potential harm to individuals, society, and the country. Recently, there have been some really impressive results with DF detection models. These models have shown excellent outstanding performance when they are trained and tested using data from the same dataset. However, detecting DF remains difficult when the data comes from challenging datasets. To address this issue, this article aims to enhance the model's generalization by taking full advantage of the learning and representation capabilities of convolutional neural networks (CNNs) to adaptively suppress image texture information and catch deeper and more universal forgery features. Specifically, we introduce the texture suppression module (TSM) as a first step to suppress image content while simultaneously revealing the differences between authentic and tampered regions. Then, we carefully designed the cross stream interaction module (CSIM) and the cross stream mix block (CSMB) module to fully exploit the extracted forgery traces. Our proposed model has demonstrated superior generalization performance in extensive experiments. © 2014 IEEE.","Cyber-bullying detection; deep learning; deepfake (DF) detection; face manipulation; generalization ability"
"Khan, S.A.; Valles, D.","Khan, Shafiqul Alam (59230123600); Valles, Damian (55546860600)","59230123600; 55546860600","Deepfake Detection Using Transfer Learning","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212673974&partnerID=40&md5=6e714c4d031475ec6ff5eead313fbd17","Deepfake technology's rise has led to a surge in false identities, creating a significant and present problem with broad societal ramifications. Concerns over identity theft, harassment, and the dissemination of false information have escalated due to the simplicity with which deepfaked facial images can now be produced and distributed thanks to the broad availability of generative AI tools like Generative Adversarial Networks (GANs). The availability of these tools has political ramifications since it can degrade public opinion and damage institutional trust. As such, the ability to identify deepfake face images has become essential. Ensuring a person's identity is critical in preventing the dissemination of false information on social media. Detection of deepfake facial images is also necessary for identity verification in border control, law enforcement, and security applications. To effectively and precisely recognize deepfake face images, this study effort has focused on modifying transfer learning models, such as ResNet101V2, MobileNetV2, NASNetLarge, NASNetMobile, DenseNet121, DenseNet169, DenseNet201, and Xception. © 2024 IEEE.","deep learning; deepfake detection; GANs; identity verification; transfer learning"
"Choi, J.; Kim, T.; Jeong, Y.; Baek, S.; Choi, J.","Choi, Jongwook (58924492200); Kim, Taehoon (58925517300); Jeong, Yonghyun (57219627723); Baek, Seungryul (57194439397); Choi, Jongwon (57192084517)","58924492200; 58925517300; 57219627723; 57194439397; 57192084517","Exploiting Style Latent Flows for Generalizing Deepfake Video Detection","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212580495&partnerID=40&md5=61a382966f4719bd4dd4ff782b676328","This paper presents a new approach for the detection of fake videos, based on the analysis of style latent vectors and their abnormal behavior in temporal changes in the generated videos. We discovered that the generated facial videos suffer from the temporal distinctiveness in the temporal changes of style latent vectors, which are inevitable during the generation of temporally stable videos with various facial expressions and geometric transformations. Our framework utilizes the StyleGRU module, trained by contrastive learning, to represent the dynamic properties of style latent vectors. Additionally, we introduce a style attention module that integrates StyleGRU-generated features with content-based features, enabling the detection of visual and temporal artifacts. We demonstrate our approach across various benchmark scenarios in deepfake detection, showing its superiority in cross-dataset and cross-manipulation scenarios. Through further analysis, we also validate the importance of using temporal changes of style latent vectors to improve the generality of deepfake video detection. © 2024 IEEE.","Deepfake Detection; Face Forgery Detection"
"Vashistha, M.; Jain, S.; Pandey, S.; Pradhan, A.; Tarwani, S.","Vashistha, Mudit (59470663400); Jain, Sarthak (59470274500); Pandey, Shubham (59470274600); Pradhan, Aryan (59470405000); Tarwani, Sandhya (57190585453)","59470663400; 59470274500; 59470274600; 59470405000; 57190585453","A Comparative Analysis of Machine Learning and Deep Learning Approaches in Deepfake Detection","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211899253&partnerID=40&md5=c68c6fd7993ff8644f7e4bbb4fb32376","Deepfakes refer to the visual media where the faces, bodily movements have been digitally altered using some software or program, this has proven to be more of a double edged sword as it also contributes towards content creation and media creation that may be used for positive purposes. To combat this situation, measures to detect deep fake in the media is a credible approach. This work showcases a comparative analysis among 3 Deep Learning as well as 3 Machine Learning algorithms in order to reach a conclusive state of determining the best algorithms that can be implemented for Deepfake detection. For the machine learning algorithms, KNN, SVM and Logistic Regression have been used whereas CNN, TCN and CNN + LSTM have been used for the Deep Learning Algorithm. Detection of deepfakes through these algorithms works by sequentially processing, analyzing and classifying the features on the basis of the dataset fed for the algorithms. The chosen metrics for performing a comparison between each of the algorithms are Accuracy and F1 Score. The development, implementation and comparison of the algorithms was carried out on Google Collab and Jupyter Notebook. Upon comparative analysis of the algorithms between each other, it was found that CNN had the highest accuracy and Fl-score of 0.9409 and 0.7225 respectively with KNN being the worst-performing algorithm with an accuracy 0.5770 and F1 score of 0.4088 respectively. © 2024 IEEE.","Convolutional Neural Networks; Deep Learning; Deepfake Detection; Face Morphing; Face Recognition; K-Nearest Neighbour; Machine Learning; Support Vector Machine"
"Kou, Y.; Jiang, Q.; Zhang, J.; Jin, X.; Wei, P.; Miao, S.; Chu, X.","Kou, Yuru (58988680500); Jiang, Qian (57194699462); Zhang, Jun (58812724300); Jin, Xin (56991832300); Wei, Ping (57237416800); Miao, Shengfa (54399018500); Chu, Xing (56719085300)","58988680500; 57194699462; 58812724300; 56991832300; 57237416800; 54399018500; 56719085300","Learning dual aggregate features for face forgery detection","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210553320&partnerID=40&md5=a8df613b2d563960d7069c6e154b1466","The rapid development of face forgery technologies brings security issues, and the importance of face forgery detection has increased. While some existing methods deliver satisfactory results when both training and testing occur on the same dataset, these methods struggle to generalize across unseen forgery datasets. Some works consider extracting unseen forgeries in terms of high-frequency information for judgment, but the lack of synergistic global considerations for such forgeries and features of the original RGB image tends to result in overfitting to specific local textures, making it difficult to further improve the generalization. In this work, to address this challenge, we propose a novel two-stream CNN-based face forgery detector. This detector synergistically combines RGB features with global high-frequency constrained forgery features, enhancing the effectiveness of face forgery detection. To this end, we design three components: 1) Multi-scale Aggregated Constrained Convolution (MACC) module. It creates modalities that both preserve comprehensive information and accentuate forgery traces. 2) Dual Spatial Aggregation Enhance (DSAE) module, which globally and synergistically aggregates and enhances features from both streams. 3) Dual Channel Enhance Aggregation (DCEA) module, which harmonizes the information across the two-stream channels based on high correlation between the streams and performs mutual enhancement. Our experimental results demonstrate that our method excels in face forgery detection, thereby achieving an AUC of 99.63% on the FF++ dataset, surpassing the existing state-of-the-art two-stream network-based detection methods. © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2024.","Attention enhancement; Deep learning; Deepfake detection; Face forgery detection"
"An, B.S.; Lim, H.; Seong, H.A.; Lee, E.C.","An, Byeongseon (58292018400); Lim, Hyeji (58571068900); Seong, Hyeonah (58250482500); Lee, Eui Chul (14009024200)","58292018400; 58571068900; 58250482500; 14009024200","Facial and Neck Region Analysis for Deepfake Detection Using Remote Photoplethysmography Signal Similarity","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209990276&partnerID=40&md5=ddbf4fa9435af75b5bcb02d82e44d976","Deepfake (DF) involves utilizing artificial intelligence (AI) technology to synthesize or manipulate images, voices, and other human or object data. However, recent times have seen a surge in instances of DF technology misuse, raising concerns about cybercrime and the credibility of manipulated information. The objective of this study is to devise a method that employs remote photoplethysmography (rPPG) biosignals for DF detection. The face was divided into five regions based on landmarks, with automatic extraction performed on the neck region. We conducted rPPG signal extraction from each facial area and the neck region was defined as the ground truth. The five signals extracted from the face were used as inputs to an support vector machine (SVM) model by calculating the euclidean distance between each signal and the signal extracted from the neck region, measuring rPPG signal similarity with five features. Our approach demonstrated robust performance with an area under the curve (AUC) score of 91.2% on the audio-driven dataset and 99.7% on the face swapping generative adversarial network (FSGAN) dataset, even though we only used datasets excluding DF techniques that can be visually identified in Korean DF Detection Dataset (KoDF). Therefore, our research findings demonstrate that similarity features of rPPG signals can be utilized as key features for detecting DFs. © © 2024 Byeong Seon An et al.","bio signal analysis; cybersecurity; deepfake detection; machine learning; remote photoplethysmography"
"Vaidya, A.O.; Dangore, M.; Borate, V.K.; Raut, N.; Mali, Y.K.; Chaudhari, A.","Vaidya, Anusha Omkar (58909155800); Dangore, Monika Y. (56029154700); Borate, Vishal Kisan (56642826300); Raut, Nutan (59397701500); Mali, Yogesh Kisan (25723576800); Chaudhari, Ashvini R. (57289544700)","58909155800; 56029154700; 56642826300; 59397701500; 25723576800; 57289544700","Deep Fake Detection for Preventing Audio and Video Frauds Using Advanced Deep Learning Techniques","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208283475&partnerID=40&md5=c6b295f59e6d76c28be156c4079d15cb","Deepfakes allow for the automated gen- eration of fake video content, often accomplished through the use of generative adversarial networks. To address the increasing issue of deepfakes, this study focuses on constructing a model that incorporates advanced techniques. The researchers combined the ResNeXt, Long Short-Term Memory (LSTM), and ResNet architectures, selecting them based on their effectiveness in handling complex visual data and capturing temporal dependencies. Prior to detection, the dataset underwent pre-processing using the Multi-Task Cascaded Convolutional Neural Network (MTCNN), which facilitated the accurate extraction of facial regions. Importantly, the study evaluated the model across three diverse and significant datasets: the Face Forensics++ dataset (FF-DF), the Celeb-DF dataset, and the Facebook Deepfake Detection Challenge (DFDC) dataset. This comprehensive evaluation en- sured the model's ability to generalize and its suitability for real-world scenarios, as demonstrated by its exceptional detection accuracy. The combination of models employed in this study yielded highly accurate results and remained robust in the face of evolving deepfake technology. © 2024 IEEE.","CelebDF; Detection Accuracy; DFDC; Face Forensics++; LSTM; Model Architecture; MultiTask Cascaded Convolutional Neural Network (MTCNN); Preprocessing; ResNet; ResNeXt"
"Hydara, E.; Kikuchi, M.; Ozono, T.","Hydara, Ebrima (59252677300); Kikuchi, Masato (57207983450); Ozono, Tadachika (6602251356)","59252677300; 57207983450; 6602251356","Empirical Assessment of Deepfake Detection: Advancing Judicial Evidence Verification Through Artificial Intelligence","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207381324&partnerID=40&md5=04207cb64f7ea5a8a5b5853fe1acf9a5","Deepfake technology poses a profound challenge to the integrity of facial evidence in criminal justice, threatening the authenticity and admissibility of such evidence in the courtroom. In this research, a specialized deepfake detection system tailored for facial evidence verification was developed, aiming to counteract the influence of deepfake technology. The proposed system integrates a unique combination of video-frame selection, confidence thresholds, prediction timestamps, and heat maps for individual frames of suspect videos. This methodological fusion is designed to support forensic analysts by enhancing the reliability and trustworthiness of video evidence used in judicial settings. Our comprehensive evaluation involved diverse user groups participating in experimental scenarios to assess the effectiveness of the system. The results indicated that the combined features of the system significantly enhanced the detection of fabricated evidence, fostering high levels of confidence and trust among users. Moreover, this study delves into the legal and ethical considerations surrounding the deployment of deep fake-detection technologies, underscoring the necessity for legal frameworks to evolve in response to emerging digital threats. By addressing both the technical and jurisprudential challenges, this research contributes to safeguarding the evidential value of facial recognition in the judicial process against the disruptive potential of deepfake technologies. © 2013 IEEE.","Artificial intelligence; criminal justice; deepfake detection; evidence verification; facial evidence"
"Chen, J.; Tian, J.; Yu, C.; Wang, X.; Li, Z.; Chai, Y.; Dai, J.; Han, J.","Chen, Jin (59370135500); Tian, Jiahe (58535569200); Yu, Cai (57223740043); Wang, Xi (57192624112); Li, Zhaoxing (56927768900); Chai, Yesheng (58115601000); Dai, Jiao (37010322300); Han, Jizhong (23008759600)","59370135500; 58535569200; 57223740043; 57192624112; 56927768900; 58115601000; 37010322300; 23008759600","ConfR: Conflict Resolving for Generalizable Deepfake Detection","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206589647&partnerID=40&md5=fc90625550aa8877d5f103203fd557f1","Deepfake detectors often encounter performance degradation when tested on unseen forgery methods. Existing literature tries to capture common features among multiple source forgery domains. However, we show that conflict arises in the shared feature space when each domain expresses domain-specific bias. If left unresolved, this conflict might mislead the model to learn domain-specific features and lead to inferior generalization. In this paper, we propose a new learning approach, Conflict Resolving (ConfR), designed to minimize conflict and learn features that generalize across forgeries. ConfR incorporates two key elements: the Intra-Domain Consistency Preserving (ICP) loss ensures updating consistency within forgery types, and the Inter-Domain Conflict Resolving (ICR) Module resolves updating conflicts between different forgery types. Extensive experiments demonstrate that ConfR significantly improves upon the state-of-the-art method, highlighting its potential for more generalizable deepfake detection. © 2024 IEEE.","Deepfake Detection; Face Forgery Detection"
"Tian, K.; Chen, C.; Zhou, Y.; Hu, X.","Tian, Kaiyue (59369773400); Chen, Chen (57194185980); Zhou, Yichao (56258805600); Hu, Xiyuan (7404710258)","59369773400; 57194185980; 56258805600; 7404710258","Illumination Enlightened Spatial-temporal Inconsistency for Deepfake Video Detection","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206586679&partnerID=40&md5=2b9f22b6e5af1e40a0612ec58bc358fd","The rapid advancement of facial manipulation techniques has greatly simplified the creation of deepfake videos, posing a major threat to social safety, public opinions and even political stability. Existing deepfake detection methods primarily concentrate on capturing spatial artifacts or extracting uniform temporal inconsistency, neglecting the potential of exploiting dynamic spatiotemporal inconsistency. To address these issues, this paper proposes a novel network that effectively leverages dynamic spatiotemporal inconsistency, termed DSTI, by integrating the sequential illumination features and intra/inter-frame clues. The proposed DSTI contains two branches: one branch employs a transformer encoder to perform inconsistency computation from sequential illumination representations derived from 3D facial models, including illumination coefficients, 3D normal vectors, and luminance values. The other branch utilizes a timesformer network to capture intra/inter-frame inconsistency from sampled videos. Extensive experimentation validates that the proposed method outperforms other competitive approaches. © 2024 IEEE.","Deepfake detection; digital feature inconsistency; face forgery detection; illumination inconsistency"
"Qazi, N.; Ahmed, I.","Qazi, Nadeem (57193964080); Ahmed, Iftikhar (58279959300)","57193964080; 58279959300","Enhancing Authenticity Verification with Transfer Learning and Ensemble Techniques in Facial Feature-Based Deepfake Detection","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206455459&partnerID=40&md5=43721caa4e2d090132f6347e61c5ad94","Deepfake technology, facilitated by deep learning algorithms, has emerged as a significant concern due to its potential to deceive humans with fabricated content indistinguishable from reality. The proliferation of deepfake videos presents a formidable challenge, propagating misinformation across various sectors such as social media, politics, and healthcare. Detecting and mitigating these threats is imperative for fortifying defenses and safeguarding information integrity. This paper tackles the complexities associated with deepfake detection, emphasizing the necessity for innovative approaches given the constraints of available data and the evolving nature of forgery techniques. Our proposed solution focuses on leveraging facial features and transfer learning to discern fake videos from genuine ones, aiming to identify subtle manipulations in visual content. We systematically break down videos into frames, employ the Haar cascade algorithm for facial recognition, and utilize transfer learning to extract discriminative features. We evaluate multiple pre-trained models, including VGG16, ConvNeXtTiny, EfficientNetB0, EfficientNetB7, DenseNet201, ResNet152V2, Xception, NASNetMobile, and MobileNetV2, for feature extraction. Subsequently, we feed these features into a Deep Artificial Neural Network (DANN) for deepfake detection and employ ensemble learning to combine the strengths of the best-performing models for enhanced accuracy. We found that the ensemble model comprising ConvNextTiny, EfficientNetB0, and EfficientNetB7 showed enhanced accuracy in detecting deep fakes compared to alternative models achieving up to 98% accuracy through ensemble learning. ©2024 IEEE.","Deepfake detection; DenseNet; EfficentNetB0; Ensemble learning; Transfer learning; video classification"
"Luevano, L.S.; Martínez-Díaz, Y.; Vázquez, H.; Gonzalez-Mendoza, M.; Frey, D.","Luevano, Luis S. (57215962348); Martínez-Díaz, Yoanna (55347885600); Vázquez, Heydi Méndez (36622061300); Gonzalez-Mendoza, Miguel (56000759200); Frey, Davide (7102907698)","57215962348; 55347885600; 36622061300; 56000759200; 7102907698","Assessing the Performance of Efficient Face Anti-Spoofing Detection Against Physical and Digital Presentation Attacks","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206445213&partnerID=40&md5=af8245859def55514c93d0b6ddd00bce","In this paper, we examine how pre-processing and training methods impact on the performance of Lightweight CNNs through evaluations on MobileNetV3 with a spoofing detection head, dubbed ""MobileNetV3-Spoof"". Using the UniAttackData dataset from the 5th Face Anti-Spoofing Challenge@CVPR2024, which covers a broad spectrum of spoofing scenarios including deepfake and adversarial attack samples, we assess how well the model performs over different setups, including pre-trained models and models trained from scratch with or without initial face detection and alignment. Our results show that pre-processing steps significantly boost the model's ability to identify spoof samples, especially against complex attacks. Through detailed comparisons, we offer insights that could guide data curation and the creation of more effective and efficient anti-spoofing techniques suitable for real-world use in the era of digital face attacks. We make our code publicly available at: https://github.com/Inria-CENATAV-Tec/Assessing-Efficient-FAS-CVPR2024 © 2024 IEEE.","Digital Face Anti-Spoofing; Efficient Face Anti-Spoofing; Face Anti-Spoofing; Face Spoofing Deepfake Detection; Lightweight CNNs; Lightweight Face Anti-Spoofing"
"Zhang, L.; Yi, C.; Liu, L.","Zhang, Lei (57204592766); Yi, Ceyuan (59359214800); Liu, Liang (55715426000)","57204592766; 59359214800; 55715426000","BiFAT: Bilateral Filtering and Attention Mechanisms in a Two-Stream Model for Deepfake Detection","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205874498&partnerID=40&md5=10a7a229a939ef25fe3c7e01a076e1b5","Addressing the significant societal concerns triggered by the widespread dissemination of Deepfake facial forgeries on the internet, and the shortcomings of existing Deepfake video detection methods in terms of generalizability and resistance to compression artifacts, we introduce a model named BiFAT. BiFAT synergizes bilateral filtering and attention mechanisms within a two-stream model to transcend the limitations of traditional binary classification approaches in Deepfake detection. Firstly, we employ an attention mechanism combined with the Steganalysis Rich Filters and Attention (SRMA) for spatial feature extraction, capturing intricate local textures and structures. Secondly, discrete Fourier transform and a complex adaptive filter are applied for frequency domain feature extraction, ensuring a comprehensive analysis of the image. This dual-domain approach, augmented by attention layers, refines the feature extraction and amalgamation process, significantly enhancing detection performance on benchmark datasets such as DF-1.0, DFDC, Celeb-DF, and FaceForensics++. Finally, our method demonstrates a notable improvement in model convergence speed, addressing the challenge of managing an excessive number of features, a common issue in contemporary DeepFake detection models, thereby boosting the model’s generalizability and compression artifact resistance. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Deep Learning; DeepFake Detection; Face Forensics"
"Yu, Z.; Li, J.; Wang, G.; Zhu, Y.; Luo, G.","Yu, Zhihan (59227983100); Li, Jiaxin (59652336800); Wang, Guangshuo (59359517000); Zhu, Yuesheng (55453293800); Luo, Guibo (55545955200)","59227983100; 59652336800; 59359517000; 55453293800; 55545955200","Generalizable Deepfake Detection with Unbiased Feature Extraction and Low-Level Forgery Enhancement","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205846698&partnerID=40&md5=4490cfed5527ef6d9c8738b50b361259","Deepfake detection has recently become an urgent issue since the deepfake technology has raised security concerns in society. However, current deepfake detection methods exist susceptibility when encountering unseen data, limiting their generalization ability. In this paper, we propose a straightforward yet effective framework of deepfake detection based on unbiased feature extraction and low-level forgery enhancement (UFELE). Obtaining unbiased features utilizing frozen Visual Foundation Models, we devise a Low-level Forgery Feature Enhancement (LFFE) module to extract and enhance the low-level features from the frozen intermediate block. Also, an Adaptive Feature Fusion (AFF) module is designed to amalgamate the enhanced low-level forgery features with the high-level semantic features flexibly. Extensive experiments on several datasets illustrate that our proposed method has better detection performance than the state-of-the-art methods in terms of generalizability and robustness. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","DeepFake detection; Face forgery detection; Visual foundation models"
"Rasool, A.; Katarya, R.","Rasool, Aale (57219486615); Katarya, Rahul (35810442400)","57219486615; 35810442400","Seeing Through the Lies: A Vision Transformer-Based Solution","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205353291&partnerID=40&md5=ab1e18406a8fe0155de1ea6ce6445583","Deepfake technology has become increasingly sophisticated and poses a growing threat to society, as it can be used to create convincing fake videos for malicious purposes. Therefore, detecting deepfakes has become crucial to ensure the authenticity of visual content. This paper proposes a novel deepfake detection approach that utilizes InceptionResNetV2 for feature extraction and Vision Transformer (ViT) with Nyström Attention mechanism for classification. Our model achieves high accuracy, AUC, precision, and recall on the CelebDFv2 dataset and outperforms state-of-the-art techniques like EfficientNet, XceptionNet, and ResNet. We also perform evaluations on the CelebDFv1 and DFDC datasets. Furthermore, we conduct a comprehensive literature survey to highlight the existing research in deepfake detection. We provide a roadmap for future work in this field, highlighting potential research directions that can further improve the effectiveness and applicability of deepfake detection models. The proposed model shows great potential for real-world applications, and the suggested future work can help to address some of the remaining challenges in this area. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.","Computer vision; Deepfake detection; Face recognition; Image manipulation; Inceptionresnetv2; Nyström Attention mechanism; Video analysis; Vision Transformer"
"Lin, Y.-H.; Xu, Y.-S.","Lin, Yu Hsun (57209831315); Xu, Yushao (59343951000)","57209831315; 59343951000","Training Deepfake Detection Model from Photos with Face Mask","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205020538&partnerID=40&md5=7870ae945b9d0f6a3fe198707f391155","Deepfake is becoming a major security threat nowadays. The development of robust deepfake detection algorithm is booming in recent years. However, the existing works require many face images for model training and the frontal face images collection would have privacy concerns. Therefore, this privacy issue inspires our research work that a deepfake detection model is trained from photos with face mask. We found that training a deepfake detection model from photos with face mask is rarely discussed in the literature. In order to resolve the challenges from face mask, we incorporate sub-regions (e.g., eye, nose, jaw) in a face during the training process. In addition to the extension by including facial sub-regions, we found that the associate training strategy is another important design factor for performance improvement. Our method improved the result significantly and the AUC of FaceForensics++ (FF++) test dataset evaluation is increased from 87.67% to 98.93%. As a result, we can develop a promising deepfake detection model even from the photos with face mask. We expected this work can be a stepping stone to inspire more research works with privacy considerations. © 2024 IEEE.","Deepfake Detection; Face Mask; Partial Blending; Training Strategy"
"Guo, S.; Gao, M.; Li, Q.; Jeon, G.; Camacho, D.","Guo, Siyou (59173914500); Gao, Mingliang (26634962800); Li, Qilei (57202858223); Jeon, Gwanggil (15022497800); Camacho, David (7003774102)","59173914500; 26634962800; 57202858223; 15022497800; 7003774102","Deepfake Detection via a Progressive Attention Network","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204995698&partnerID=40&md5=2edf6bcc9beb2cd7ad717668d40ed081","The rapid advancement of deepfake technology has enabled the creation of highly realistic forged face images or videos. While deepfake technology adds entertainment to people's lives, it also poses a potential threat to social security. Deepfake detection is a crucial technology for identifying forged images. However, existing deep learning-based models for deepfake detection often overlook subtle forged traces. To solve this problem, we propose a Progressive Attention Network (PANet). The PANet incorporates two attention modules, namely the Efficient Multi-Scale Attention Module (EMAM) and the Spatial and Channel Attention Module (SCAM), in a progressive manner. The EMAM focuses on crucial facial regions, such as the eyes, nose, and mouth, rather than the entire face. The SCAM facilitates fine-grained feature extraction. Experimental results demonstrate that the proposed method achieves state-of-the-art results on deepfake detection datasets. © 2024 IEEE.","Deepfake Detection; Efficient Multi-Scale Attention; Feature Extraction; Forged Traces; Information Disorder"
"Lin, C.; Yi, F.; Wang, H.; Deng, J.; Zhao, Z.; Li, Q.; Shen, C.","Lin, Chenhao (57221245073); Yi, Fangbin (58662581500); Wang, Hang (59344036200); Deng, Jingyi (57210359782); Zhao, Zhengyu (57197811483); Li, Qian (57211305736); Shen, Chao (36446592900)","57221245073; 58662581500; 59344036200; 57210359782; 57197811483; 57211305736; 36446592900","Exploiting Facial Relationships and Feature Aggregation for Multi-Face Forgery Detection","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204967137&partnerID=40&md5=a79944b40c63f93dd1ff2945339f5d08","The emergence of advanced Deepfake technologies has gradually raised concerns in society, prompting significant attention to Deepfake detection. However, in real-world scenarios, Deepfakes often involve multiple faces. Despite this, most existing detection methods still detect these faces individually, overlooking the informative correlation between them and the relationship between the global information of the image and the local information of the faces. In this paper, we address this limitation by proposing FILTER, a novel framework for multi-face forgery detection that explicitly captures underlying correlations. FILTER consists of two main modules: Multi-face Relationship Learning (MRL) and Global Feature Aggregation (GFA). Specifically, MRL learns the correlation of local facial features in multi-face images, and GFA constructs the relationship between image-level labels and individual facial features to enhance performance from a global perspective. In particular, a contrastive learning loss function is used to better discriminate between real and fake faces. Extensive experiments on two publicly available multi-face forgery datasets demonstrate the state-of-the-art performance of FILTER in multi-face forgery detection. For example, on Openforensics Test-Challenge dataset, FILTER outperforms the previous state-of-the-art methods with a higher AUC score (0.980) and higher detection accuracy (92.04%). © 2005-2012 IEEE.","Deepfake detection; global feature aggregation; multi-face relationship learning"
"Zhang, Y.; Yu, Z.; Wang, T.; Huang, X.; Shen, L.; Gao, Z.; Ren, J.","Zhang, Yaning (58026359800); Yu, Zitong (57210955519); Wang, Tianyi (57211200251); Huang, Xiaobin (57271351500); Shen, Linlin (7401704647); Gao, Zan (13405375400); Ren, Jianfeng (52763844500)","58026359800; 57210955519; 57211200251; 57271351500; 7401704647; 13405375400; 52763844500","GenFace: A Large-Scale Fine-Grained Face Forgery Benchmark and Cross Appearance-Edge Learning","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204762022&partnerID=40&md5=d9fd076477aacb8394da53524c7a0694","The rapid advancement of photorealistic generators has reached a critical juncture where the discrepancy between authentic and manipulated images is increasingly indistinguishable. Thus, benchmarking and advancing techniques detecting digital manipulation become an urgent issue. Although there have been a number of publicly available face forgery datasets, the forgery faces are mostly generated using GAN-based synthesis technology, which does not involve the most recent technologies like diffusion. The diversity and quality of images generated by diffusion models have been significantly improved and thus a much more challenging face forgery dataset shall be used to evaluate SOTA forgery detection literature. In this paper, we propose a large-scale, diverse, and fine-grained high-fidelity dataset, namely GenFace, to facilitate the advancement of deepfake detection, which contains a large number of forgery faces generated by advanced generators such as the diffusion-based model and more detailed labels about the manipulation approaches and adopted generators. In addition to evaluating SOTA approaches on our benchmark, we design an innovative Cross Appearance-Edge Learning (CAEL) detector to capture multi-grained appearance and edge global representations, and detect discriminative and general forgery traces. Moreover, we devise an Appearance-Edge Cross-Attention (AECA) module to explore the various integrations across two domains. Extensive experiment results and visualizations show that our detection model outperforms the state of the arts on different settings like cross-generator, cross-forgery, and cross-dataset evaluations. Code and datasets will be available at https://github.com/Jenine-321/GenFace. © 2005-2012 IEEE.","appearance-edge fusion; deepfake detection; Face forgery benchmark; transformer"
"Dasgupta, S.; Mason, J.; Yuan, X.; Odeyomi, O.; Roy, K.","Dasgupta, Subhram (59325583300); Mason, Janelle C. (57202453113); Yuan, Xiaohong (56820491900); Odeyomi, Olusola Tolulope (57216412375); Roy, Kaushik (35566325000)","59325583300; 57202453113; 56820491900; 57216412375; 35566325000","Enhancing Deepfake Detection using SE Block Attention with CNN","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203829955&partnerID=40&md5=0fdd97f5b7ac853672118f7b2814dc17","In the digital age, Deepfake present a formidable challenge by using advanced artificial intelligence to create highly convincing manipulated content, undermining information authenticity and security. These sophisticated fabrications surpass traditional detection methods in complexity and realism. To address this issue, we aim to harness cutting-edge deep learning methodologies to engineer an innovative deepfake detection model. However, most of the models designed for deepfake detection are large, causing heavy storage and mem-ory consumption. In this research, we propose a lightweight convolution neural network (CNN) with squeeze and excitation block attention (SE) for Deepfake detection. The SE block module is designed to perform dynamic channel-wise feature recalibration. The SE block allows the network to emphasize informative features and suppress less useful ones, which leads to a more efficient and effective learning module. This module is integrated with a simple sequential model to perform Deepfake detection. The model is smaller in size and it achieves competing accuracy with the existing models for deepfake detection tasks. The model achieved an overall classification accuracy of 94.14% and AVC-ROC score of 0.985 on the Style GAN dataset from the Diverse Fake Face Dataset. Our proposed approach presents a promising avenue for combating the Deepfake challenge with minimal computational resources, developing efficient and scalable solutions for digital content verification. © 2024 IEEE.","CNN; Deepfake Detection; Entire Face Synthesis; SE Block"
"Concas, S.; La Cava, S.M.; Casula, R.; Orru, G.; Puglisi, G.; Marcialis, G.L.","Concas, Sara (56728509000); La Cava, Simone Maurizio (57211713058); Casula, Roberto (57203222831); Orru, Giulia (57192423696); Puglisi, Giovanni (55346939100); Marcialis, Gian Luca (6602798791)","56728509000; 57211713058; 57203222831; 57192423696; 55346939100; 6602798791","Quality-based Artifact Modeling for Facial Deepfake Detection in Videos","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203124276&partnerID=40&md5=8523f1577a071292e2f509ca9bc3b926","Facial deepfakes are becoming more and more realistic, to the point that it is often difficult for humans to distinguish between a fake and a real video. However, it is acknowledged that deepfakes contain artifacts at different levels; we hypothesize a connection between manipulations and visible or non-visible artifacts, especially where the subject's movements are difficult to reproduce in detail. Accordingly, our approach relies on different quality measures, No-Reference (NR) and Full-Reference (FR), over the detected faces in the video. The measurements allow us to adopt a frame-by-frame approach to build an effective matrix-based representation of a video sequence. We show that the results obtained by this basic feature set for a neural network architecture constitute the first step that encourages the empowerment of this representation, aimed to extend our investigation to further deepfake classes. The FaceForensics++ dataset is chosen for experiments, which allows the evaluation of the proposed approach over different deepfake generation algorithms. © 2024 IEEE.","deepfake detection; Deepfakes; face patches; quality; quality measures"
"Talreja, S.; Bindle, A.; Baghel, V.; Budhiraja, I.; Bhattacharya, P.","Talreja, Sumran (57919945500); Bindle, Abhay (57377330500); Baghel, Vimal Kumar (58728480000); Budhiraja, Ishan (57207989270); Bhattacharya, Pronaya (57200306370)","57919945500; 57377330500; 58728480000; 57207989270; 57200306370","Security Strengthen and Detection of Deepfake Videos and Images Using Deep Learning Techniques","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202432497&partnerID=40&md5=764a7b19ab948a5813c81fde0d0878e5","The identification of fraudulent movies or images created using deep learning algorithms is the subject of this research and attempts an in-depth investigation of Deepfake Detection. Deepfakes are created by manipulating or replacing certain parts of an original video or image using machine learning algorithms, usually concentrating on face features. Deepfake detection's main goal is to precisely recognize and distinguish these altered media from real movies and photos. This study looks at a number of deepfake detection techniques, including forensic methods, machine learning algorithms, and picture analysis. These approaches' efficiency and performance are assessed based on their capacity to accurately identify and categories deep-fakes. The paper also examines the difficulties and restrictions of deepfake detection, such as the development of more complex and convincing deepfakes. Further, prospective uses and future possibilities for deepfake detection research are examined, with an emphasis on improving detection skills and creating effective countermeasures. Overall, this research offers insightful information about cutting-edge methods and developments in Deepfake Detection, giving a greater comprehension of its importance in resolving the issues brought on by manipulated media in the current digital era. © 2024 IEEE.","Deep Learning; DeepFake Detection; Machine Learning"
"Liu, B.; Liu, B.; Ding, M.; Zhu, T.","Liu, Baoping (58120121700); Liu, Bo (55574235154); Ding, Ming (7202280996); Zhu, Tianqing (9737124100)","58120121700; 55574235154; 7202280996; 9737124100","Detection of Diffusion Model-Generated Faces by Assessing Smoothness and Noise Tolerance","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201540172&partnerID=40&md5=4bc323216aca642e57755ce6f08f97a8","The fast growth of artificial intelligence (AI) raises much concern about the misinformation brought by AI-generated content (AIGC), especially Deepfake techniques that generate fake human faces. The recent development of Diffusion Models (DMs) moves another critical step forward to generate high-resolution and realistic human faces, which has become a challenge for existing Deepfake detectors. In this paper, we propose a DM-generated image detector by looking into the generation pipeline of DMs and the details of DM-generated images. The detector is based on the observation that DM-generated human faces show over-smooth textures and do not contain details as real human faces. Through a comprehensive analysis of DM-generated faces in spatial and frequency domains, we noticed that the over-smoothness improves the tolerance of Gaussian noise since excessive smoothness mitigates some of the impact of noise. Inspired by the observations, we propose a Deepfake detector capable of recognizing challenging DM-generated faces. We mainly propose the Noise Residual Unit (NRD) in our framework to collect the frequency response of images to Gaussian noise as distinctive features for classification. In detail, for an input face image, we add Gaussian noise to it and get the noise-degraded image. Then, the NRU generates the Noise Residual Image (NRI) by calculating the residual of the high-pass-filtered original image and the high-pass-filtered degraded image. The NRI indicates the high-frequency impact brought by the Gaussian noise and, therefore, suggests the tolerance of the original image to noise degradation. The original image and NRI are encoded and fused to obtain the joint representation, which is then fed to a classifier to predict the binary label. We conducted comprehensive experiments to evaluate the effectiveness of the proposed detector. The results indicate that our proposed detector achieves state-of-the-art detection performance on DM-generated faces and generalizes well to unseen DM-generated and GAN-generated face datasets. © 2024 IEEE.","Deepfake detection; diffusion models; frequency analysis"
"Wang, C.; Shi, C.; Wang, S.; Xia, Z.; Ma, B.","Wang, Chunpeng (55318994100); Shi, Chaoyi (59252980800); Wang, Simiao (57077942700); Xia, Zhiqiu (57188991071); Ma, Bin (57204589541)","55318994100; 59252980800; 57077942700; 57188991071; 57204589541","Dual-Task Mutual Learning with QPHFM Watermarking for Deepfake Detection","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200810812&partnerID=40&md5=f25cf405bfcb065b054b747af70c7e8c","Deepfake technology has rapidly evolved and emerged in recent years, posing significant threats to individuals' reputations and security. Although passive detection methods can achieve reasonable accuracy, they still lack proactive defense mechanisms. To address this issue, this letter proposes a proactive detection framework that combines Quaternion Polar Harmonic Fourier Moments (QPHFMs) with Dual-Task Mutual Learning (DTML) framework. Firstly, watermark information is embedded into QPHFMs, ensuring high imperceptibility while enhancing robustness against common attacks. Secondly, DTML is introduced, where the knowledge distilled from watermark detection can facilitate more accurate deepfake detection. Experimental results on benchmark datasets demonstrate that our method surpasses state-of-the-art techniques, delivering exceptional performance in watermark robustness and imperceptibility while simultaneously accomplishing accurate deepfake detection. © 1994-2012 IEEE.","Dual-task mutual learning; image watermarking; proactive deepfake detection; quaternion polar harmonic Fourier moments"
"Hydara, E.; Kikuchi, M.; Ozono, T.","Hydara, Ebrima (59252677300); Kikuchi, Masato (57207983450); Ozono, Tadachika (6602251356)","59252677300; 57207983450; 6602251356","Deepfake Detection System for Facial Evidence Verification in Criminal Justice and Its Legal and Ethical Implications","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200720039&partnerID=40&md5=6956861524896d0ba8e8169e4b898b51","Deepfake technology poses a significant threat to the integrity of facial evidence in criminal justice. The existence of highly realistic manipulated videos and images raises concerns about the authenticity and admissibility of such evidence in court. This research proposes a deepfake detection system for facial evidence verification to combat the threat of deepfake technology on facial evidence in criminal justice. Our experimental results indicate that the introduction of confidence thresholds, prediction timestamps, and heatmaps of individual frames of the suspected video can be useful and practical in the criminal justice domain preventing wrongful convictions of innocent victims of deepfake technology manipulations. This study contributes to the domain of facial evidence verification in criminal justice with a more robust and explainable approach than the current methods using the combination of the above methods. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","criminal justice; deepfake detection; facial evidence; forensic analysis"
"Qi, Y.","Qi, Yue (57222348865)","57222348865","Research on face replacement detection based on deep learning","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200493625&partnerID=40&md5=f49b77a21f9a892bd09c56f29b5a56fb","With the development of artificial intelligence technology, the thresh- old of information tampering is reduced, and the quality of counterfeiting is increased. More and more fake information is difficult to distinguish. If such false information is widely disseminated, it will have a particular impact on society. It is essential to note that if face information is tampered with and widely distributed, it could lead to social unrest or damage an individual's reputation, resulting in trust crisis.A face tampering detection method combined with a self-attention mechanism is proposed to solve that traditional residual networks cannot capture the long-range dependencies between video frames and ignore local critical information. The face regions in the video are extracted firstly. Then the spatial features are extracted by the residual network, and the local critical information is learned by the self-attention block. Finally, the long-range dependencies of the spatial features are captured using the gated recurrent unit classification module. Experiments are conducted on the Face-Forensics++. The detection accuracy of the method is improved compared with several baseline algorithms, indicating that the methprocess effectively detect whether the face region in the video tampers. © 2024 SPIE.","convolutional neural network; Deep learning; deepfake detection; face forgery detection"
"Zheng, W.; Zhou, F.; Ling, X.","Zheng, Wei (59247394600); Zhou, Fandi (57211124854); Ling, Xia (58663236700)","59247394600; 57211124854; 58663236700","FETNet: frequency-enhanced transformer network for face forgery detection","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200446956&partnerID=40&md5=787f45b16f351231eb25397cee67307f","With the development of deepfake methods, a large number of deepfake images and videos have been widely disseminated on the internet, raising public concerns about the authenticity of information. Therefore, deepfake detection has recently become a hot topic in the field of computer vision, and many methods have been proposed. Currently, frequency-based detection methods have achieved commendable results, but there are still two issues: a) These methods use fixed filters to focus on fixed frequency bands and areas, making them easily distracted by irrelevant information and lacking flexibility for different forgery methods. b) The methods that fuse frequency domain information with RGB information using CNNs do not consider global relationships, so they are insufficient to fully utilize both types of information. To address these issues, we introduce a Frequency-Enhanced Transformer Network (FETNet). Specifically, we propose a Frequency Feature Enhancement Module (FFEM), which is a learnable module capable of flexibly enhancing important frequency bands and regions in the original frequency features. Additionally, we present a Feature Fusion Transformer (FFT) that considers global information to fuse features from the RGB and frequency domains, achieving a more comprehensive feature representation. Through extensive experiments on the FF++ dataset, the effectiveness and superiority of our approach have been demonstrated. © 2024 SPIE.","convolutional neural networks; Deepfake detection; transformer"
"Zhou, X.; Han, H.; Shan, S.; Chen, X.","Zhou, Xinye (59244333100); Han, Hu (57565013600); Shan, Shiguang (57216197144); Chen, Xilin (57215374943)","59244333100; 57565013600; 57216197144; 57215374943","Fine-Grained Open-Set Deepfake Detection via Unsupervised Domain Adaptation","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200271730&partnerID=40&md5=508f903996e992f2e6b423b940414af3","Deepfake represented by face swapping and face reenactment can transfer the appearance and behavioral expressions of a face in one video image to another face in a different video. In recent years, with the advancement of deep learning techniques, deepfake technology has developed rapidly, achieving increasingly realistic effects. Therefore, many researchers have begun to study deepfake detection research. However, most existing studies on deepfake detection are mainly limited to binary classification of real and fake images, rather than identifying different methods in an open-world scenario, leading to failures in dealing with unknown deepfake categories in practice. In this paper, we propose an unsupervised domain adaptation method for fine-grained open-set deepfake detection. Our method first uses labeled data from the source domain for model pre-training to establish the ability of recognizing different deepfake methods in the source domain. Then, the method uses a Network Memorization based Adaptive Clustering (NMAC) approach to cluster unlabeled images in the target domain and designs a Pseudo-Label Generation (PLG) to generate virtual class labels for unknown deepfake categories by matching the adaptive clustering results with the known deepfake categories in the source domain. Finally, we retrain the initial multi-class deepfake detection model using labeled data of the source domain and pseudo-labeled data of the target domain to improve its generalization ability to unknown deepfake classes presented in the target domain. We validate the effectiveness of the proposed method under multiple open-set fine-grained deepfake detection tasks based on three deepfake datasets (ForgerNet, FaceForensics++, and FakeAVCeleb). Experimental results show that our method has better domain generalization ability than the state-of-the-art methods, and achieves promising performance in fine-grained open-set deepfake detection. © 2005-2012 IEEE.","Deepfake detection; domain adaptation; fine-grained classification; unsupervised learning"
"Xu, K.; Hu, X.; Zhou, X.; Xiaolong, X.; Qi, L.; Chen, C.","Xu, Kaiwen (58071667500); Hu, Xiyuan (7404710258); Zhou, Xiaokang (55514932700); Xiaolong, Xu (55706201200); Qi, Lianyong (36519541200); Chen, Chen (57194185980)","58071667500; 7404710258; 55514932700; 55706201200; 36519541200; 57194185980","RLGC: Reconstruction Learning Fusing Gradient and Content Features for Efficient Deepfake Detection","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200220120&partnerID=40&md5=0fdef266311d27d35b71520f2bcfcdd0","Current deepfake detection methods, which utilize noise features, localized textures, or frequency statistics, may perform well in special domains or forgery methods. But the generalization performance of these methods is often unsatisfactory because of the ignorance of mining intrinsic facial features. To address this problem, we re-evaluated the fusion of image gradient features in neural networks and delved deeper into the intrinsic structure of input images. Consequently, we propose a reconstruction-classification network that initially learns face content and gradient separately from a reconstruction perspective and then detects forged faces by fusing them together. This paper introduces three well-designed components: 1) a dual-branch feature extraction module to excite distributional inconsistencies between real and forged faces; 2) a content-gradient feature fusion module to investigate the relationship between face content and image gradient; 3) a reconstruction disparity based Bi-Directional attention module that guides the model in efficiently categorizing the fused features. Extensive experiments on large-scale benchmark datasets demonstrate that our method significantly enhances performance, especially for generalization ability, compared to state-of-the-art methods. © 1975-2011 IEEE.","deep generative model; Deepfake detection; multi-scale feature fusion; reconstruction learning"
"Wang, R.; Ye, D.; Tang, L.; Zhang, Y.; Deng, J.","Wang, Rui (58966052700); Ye, Dengpan (7102368943); Tang, Long (58146809500); Zhang, Yunming (57203832338); Deng, Jiacheng (57712556800)","58966052700; 7102368943; 58146809500; 57203832338; 57712556800","AVT2-DWF: Improving deepfake detection with audio-visual fusion and dynamic weighting strategies","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199534178&partnerID=40&md5=6de42a5e42cc01a65a474dbe48d99f4f","With the continuous improvements of deepfake methods, forgery messages have transitioned from single-modality to multi-modal fusion, posing new challenges for existing forgery detection algorithms. In this letter, we propose AVT2-DWF, the Audio-Visual dual Transformers grounded in Dynamic Weight Fusion, which aims to amplify both intra-and cross-modal forgery cues, thereby enhancing detection capabilities. AVT2-DWF adopts a dual-stage approach to capture both spatial characteristics and temporal dynamics of facial expressions. This is achieved through a face transformer with an n-frame-wise tokenization strategy encoder and an audio transformer encoder. Subsequently, it uses multi-modal conversion with dynamic weight fusion to address the challenge of heterogeneous information fusion between audio and visual modalities. Experiments on DeepfakeTIMIT, FakeAVCeleb, andDFDC datasets indicate thatAVT2-DWFachieves state-of-Theart performance intra-and cross-dataset Deepfake detection. © 1994-2012 IEEE.","Audio-visual; deepfake detection; dynamic weight fusion"
"Kaushik, A.; Doshi, D.N.; Mal, S.; Malviya, L.","Kaushik, Anjali (59231761400); Doshi, Dhyey Nilesh (59232197900); Mal, Sandip (55808341200); Malviya, Lokesh Kumar (57355410200)","59231761400; 59232197900; 55808341200; 57355410200","Advanced Deepfake Detection Using Inception-ResNet-v2","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199449930&partnerID=40&md5=6bd77799774748f7c37004fce7aeb491","In recent years, the prevalence of manipulated videos, commonly referred to as “deepfakes”, has surged, impacting various industries worldwide. These videos are generated by software based on deep learning models. In the near future, making deepfakes is likely to become simpler than it is now, as the current process demands a hefty amount of data and expensive computing power. The repercussions of this technology’s misuse, including the spread of false information and potential threats to national security, pose significant concerns such as libel, sabotage, and blackmail. This study proposes a system employing MTCNN for facial extraction in videos, feeding the data into a sequential model featuring Inception-ResNet-v2 and additional layers. Rigorous testing with diverse video samples demonstrated favorable results, highlighting the model’s effectiveness and accuracy. The proposed model archived better accuracy 91.41% as compared with existing CNN and Xception net accuracy. This abstract encapsulates the key aspects of the research, from the problem statement to the proposed solution and successful outcomes, contributing valuable insights into addressing the challenges posed by deepfake technology. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.","Deepfake detection; Face detection; Inception-ResNet-v2"
"Lv, Q.; Li, Y.; Dong, J.; Chen, S.; Yu, H.; Zhou, H.; Zhang, S.","Lv, Qingxuan (57215968309); Li, Yuezun (57188647738); Dong, Junyu (22634069200); Chen, Sheng (55733364300); Yu, Hui (56115992300); Zhou, Huiyu (23062556900); Zhang, Shu (56366331000)","57215968309; 57188647738; 22634069200; 55733364300; 56115992300; 23062556900; 56366331000","DomainForensics: Exposing Face Forgery Across Domains via Bi-Directional Adaptation","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199043780&partnerID=40&md5=bd34d854f7e5aaabde84e005ec4dd402","Recent DeepFake detection methods have shown excellent performance on public datasets but are significantly degraded on new forgeries. Solving this problem is important, as new forgeries emerge daily with the continuously evolving generative techniques. Many efforts have been made for this issue by seeking the commonly existing traces empirically on data level. In this paper, we rethink this problem and propose a new solution from the unsupervised domain adaptation perspective. Our solution, called DomainForensics, aims to transfer the forgery knowledge from known forgeries (fully labeled source domain) to new forgeries (label-free target domain). Unlike recent efforts, our solution does not focus on data view but on learning strategies of DeepFake detectors to capture the knowledge of new forgeries through the alignment of domain discrepancies. In particular, unlike the general domain adaptation methods which consider the knowledge transfer in the semantic class category, thus having limited application, our approach captures the subtle forgery traces. We describe a new bi-directional adaptation strategy dedicated to capturing the forgery knowledge across domains. Specifically, our strategy considers both forward and backward adaptation, to transfer the forgery knowledge from the source domain to the target domain in forward adaptation and then reverse the adaptation from the target domain to the source domain in backward adaptation. In forward adaptation, we perform supervised training for the DeepFake detector in the source domain and jointly employ adversarial feature adaptation to transfer the ability to detect manipulated faces from known forgeries to new forgeries. In backward adaptation, we further improve the knowledge transfer by coupling adversarial adaptation with self-distillation on new forgeries. This enables the detector to expose new forgery features from unlabeled data and avoid forgetting the known knowledge of known forgery. Extensive experiments demonstrate that our method is surprisingly effective in exposing new forgeries, and can be plug-and-play on other DeepFake detection architectures. © 2005-2012 IEEE.","DeepFake detection; Digital forensics; DomainForensics"
"Wu, H.; Wang, X.; Wang, R.; Xiang, J.; Ren, L.","Wu, Haotian (57938983300); Wang, Xin (56623215300); Wang, Ruobing (58486707100); Xiang, Ji (36678599900); Ren, Liyue (58551918200)","57938983300; 56623215300; 58486707100; 36678599900; 58551918200","Common Forgery Artifact Driven Deepfake Face Detection","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199042460&partnerID=40&md5=64a2ba5b811862295cee00959d2b81e8","Given the substantial security risks associated with Deepfake technology, the identification of manipulated facial images has become a focal point of research. Regrettably, the majority of current Deepfake detection methods struggle to effectively discern forgery artifacts across various resolutions. Variations in image or video resolutions present substantial challenges to maintaining identity security in cooperative work environments. In this study, we introduce a Deepfake face detection model that relies on the identification of common forgery artifacts. Our model utilizes CFNet (Common Forgery Artifact Extraction Network) to automatically filter regions containing forged artifacts. These common forged artifacts are found in images of various resolutions, substantially enhancing the model's accuracy in low-resolution images. Furthermore, our custom-designed multi-modal features ensure the model excels in high-resolution scenarios. Comprehensive experiments validate the efficacy of our model, achieving accuracy rates of 90.464% for Deepfakes, 75.520% for Face2Face, and 83.536% for FaceSwap within the Low Quality (LQ) category of the FF+ dataset. © 2024 IEEE.","Adversarial detection; Deepfake detection; Multi-modal"
"Wu, H.; Chen, Y.; Wang, X.; Wang, L.; Xiang, J.; Ren, L.","Wu, Haotian (57938983300); Chen, Yu (59226563200); Wang, Xin (56623215300); Wang, Lin (59260316200); Xiang, Ji (36678599900); Ren, Liyue (58551918200)","57938983300; 59226563200; 56623215300; 59260316200; 36678599900; 58551918200","DST-FRD: A Distillation Method of Swin Transformer for Facial Reenactment Detection","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199040398&partnerID=40&md5=7aecb6d6292da9b766a0eef8ca42fa86","In recent times, transformer-based deepfake detection networks have exhibited remarkable performance. However, the computational complexity and the number of parameters have constrained the practical application of these networks. To address these issues, we propose a knowledge distillation method for the Swin Transformer network. Specifically, this method utilizes the region prediction results of face images to distill the knowledge of the Swin Transformer in subregions, compensating for the deficiency of the small window size of the Swin Transformer in the early stage. Extensive experiments have demonstrated that our proposed distillation method not only reduces the parameters and computational effort of the model but also surpasses the teacher network in accuracy on low-resolution images. Our student network exhibits significantly lower computational complexity and fewer parameters than the teacher network, with reductions of only 17.96% and 20.44%, respectively. Despite this reduction in complexity and parameters, our student network has achieved state-of-the-art results on the FaceForensics++ dataset, surpassing the teacher network by 0.071%, 0.86%, and 8.339% on Raw/Raw, Raw/C23, and Raw/C40, respectively. © 2024 IEEE.","Adversarial detection; Deepfake detection; Knowledge distillation"
"Sultan, D.A.; Ibrahim, L.M.","Sultan, Duha A. (57218379583); Ibrahim, Laheeb Mohammed (36809457500)","57218379583; 36809457500","Deepfake Detection Model Based on VGGFace with Head Pose Estimation Technique","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197739021&partnerID=40&md5=cdeca50ab91ec6215e140441eabd1593","Rapid developments in deepfake technology have produced hyper-realistic fake media such as images, audio, and video. Especially, the fabricated videos, which have gained a large widespread in social media sites. Because of the great harm inflicted by these videos, many researchers have increased their efforts to find a reliable method to identify and distinguish these fake videos from the actual ones. In this work, we suggested a new model to detect fake videos, based on two major techniques. First, the VGGFace model was used to extract the most important facial features combined with, second: the estimation of the head pose angle that represents the relative orientation of the human face in video frames. All these calculations are done on human faces detected and cropped from video frames, where 10, 20, and 30 frames were extracted from each video. FF++ dataset was used to train and test the model, which produced a max test accuracy of 0.885. The code was written using Python version 3.9. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","CNN; Deepfake Detection; Deeplearning; Head Pose; VGGFace"
"Gu, F.; Dai, Y.; Fei, J.; Chen, X.","Gu, Fei (57217047792); Dai, Yunshu (57908315000); Fei, Jianwei (57213689230); Chen, Xianyi (56071795200)","57217047792; 57908315000; 57213689230; 56071795200","Deepfake detection and localisation based on illumination inconsistency","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197644126&partnerID=40&md5=039cec5e765e336b54b374dcf82e580a","The rapid development of image synthesis technology has encouraged the spread of some fake news, making people gradually lose trust in digital media. The compression in the process of image propagation brings a major challenge to the existing face forgery detection method. In this paper, we propose a multi-task Deepfake detection method according to the motivation of illumination inconsistency between tampered and non-tampered areas. Specifically, we trained a Siamese network as a feature extractor to estimate the illumination, then distinguish the face image and predict the forged region through a U-shaped network. Our method has achieved great accuracy in classification tasks and can still maintain good performance in compressing data. In addition, we can also show the intensity of tampering while locating the forged area. © © 2024 Inderscience Enterprises Ltd.","artificial intelligence security; convolution neural network; deep learning; Deepfake detection; Deepfakes; face forensics; face spoof detection; illumination estimation; image forensics; image manipulation detection; Siamese network; UNet"
"Singh, R.; Ashwini, K.; Priya, B.C.; Kumar, K.P.","Singh, Richa (59188356600); Ashwini, K. (57205097924); Priya, B. Chandu (59187744400); Kumar, K. Pavan (59188150400)","59188356600; 57205097924; 59187744400; 59188150400","Deepfake Face Extraction and Detection Using MTCNN-Vision Transformers","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196805117&partnerID=40&md5=20d04ca746d9ffce730bb178f0e681c5","Deepfake detection is a major problem nowadays. The deepfake detection can be done using face extraction and detection. Strong solutions for face extraction and detection are required in light of the growing prevalence of deepfake technology. This paper combines Vision Transformers with Multi-Task Cascaded Convolutional Networks (MTCNN) to propose a novel method. This approach leverages the real-time face identification skills of MTCNN and the long-range dependency capture ability of Vision Transformers to improve the accuracy of detecting manipulated faces in deepfake footage. We carry out extensive experiments on several deepfake datasets, demonstrating the efficacy of the suggested hybrid strategy. The proposed model findings show that this approach performs better than conventional face identification techniques, particularly when dealing with situations where minor facial alterations are involved. This integration strikes a good compromise between computing efficiency and precision, which makes it a viable option for practical uses. The proposed MT-VIT (Multi-Task Vision Transformer) model provides good accuracy as compared to other state-of-the-art like Residual Networks, Mobile Net, CNN, and Meso-Net. © 2024 IEEE.","deepfake detection; multitask cascaded convolutional neural network (MTCNN); vision transformer (VIT)"
"Jiang, P.; Xie, H.; Yu, L.; Jin, G.; Zhang, Y.","Jiang, Peiqi (59184662300); Xie, Hongtao (35732457100); Yu, Lingyun (56879585300); Jin, Guoqing (57258369600); Zhang, Yongdong (57215882960)","59184662300; 35732457100; 56879585300; 57258369600; 57215882960","Exploring Bi-Level Inconsistency via Blended Images for Generalizable Face Forgery Detection","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196757991&partnerID=40&md5=2715f436455d8bb6a5b1b793c75e7aa5","The challenge of generalization in face forgery detection has become increasingly prominent as manipulation techniques continue to evolve. Although recent image blending-based methods have demonstrated remarkable potential, they often encounter a significant performance drop when applied to datasets exhibiting significant domain gaps. This limitation stems from the exclusive reliance of prior methods on blending unaltered faces with various augmentations to produce common artifacts, which ignores the inherent characteristics of the forged regions. To fully exploit the potential of image blending-based methods for generalizable Deepfake detection, we propose a novel image synthesis framework called Bi-Level Inconsistency Generator (Bi-LIG) to introduce bi-level inconsistency in the synthesized images. Specifically, Bi-LIG generates synthetic images by blending source and target images from both pristine and forged image sets, introducing a) Extrinsic-Inconsistency between real and pseudo-forged regions, and b) Inherent-Inconsistency between real and manipulated areas. In this way, Bi-LIG creates a diverse synthesized image set and establishes a generalizable training domain. Furthermore, we propose a novel face forgery detection network named Token Consistency Constrained Vision Transformer, in which two modules are developed based on patch consistency learning. Firstly, a Patch Token Contrast module is employed to learn the bi-level patch inconsistencies. Secondly, a Progressive Patch Token Assemble module is adopted to aggregate local patch relations and enhance the inconsistency representations. Experimental results demonstrate the effectiveness and superiority of our method on both in-dataset and cross-dataset evaluations. Notably, our approach outperforms state-of-the-art methods by 5.09% and 10.15% on cross-dataset evaluations in DFDCp and DFDC, respectively. © 2005-2012 IEEE.","consistency learning; Deepfake detection; vision transformer"
"Rana, M.S.; Sung, A.H.","Rana, M. S. (57194031026); Sung, Andrew H. (7006265966)","57194031026; 7006265966","Advanced Deepfake Detection using Machine Learning Algorithms: A Statistical Analysis and Performance Comparison","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196075989&partnerID=40&md5=b6c1366a2caa3eda0276b084393eaec0","As techniques and tools for synthetic media and Deepfakes continue to advance, it is increasingly clear that video, audio and images can no longer be relied upon as truthful recordings of reality. Every digital communication channel is now vulnerable to manipulation, and there is widespread use of Deepfakes to propagate misinformation and disinformation, inflame political discord, defame opposition, commit cyber frauds or blackmail individuals. While deep learning (DL) methods have been widely used to identify Deepfakes, this paper demonstrates that classical machine learning (ML) methods can achieve superior performance - comparable with or exceeding state-of-the-art DL methods in detecting Deepfakes. Using the traditional procedures of feature development and selection, training, and testing of ML classifiers for the task actually provides better understandability and interpretability while consuming much less computing resource. In addition, an omnibus test, the Analysis of Variance (ANOVA), is conducted to compare the performance of multiple ML models. We present experiments that achieve 99.84% accuracy on the FaceForecics++ dataset, 99.38% accuracy on the DFDC dataset, 99.66% accuracy on the VDFD dataset, and 99.43% accuracy on the Celeb-DF dataset. Our study thus challenges the notion that DL approaches are the only effective way to detect Deepfakes and demonstrates that judicious use of ML approaches can be highly efficacious and cost-effective. © 2024 IEEE.","Analysis of Variance; Deepfake Detection; Deepfakes; Face Manipulation; Machine Learning; Omnibus Test"
"Vignesh, T.; Tarun, P.H.; Parthav, R.; Bhargavi, V.","Vignesh, Thipparthi (59297471800); Tarun, Potharlanka Harish (58420512500); Parthav, Ryagalla (59172007300); Bhargavi, V. (59397740800)","59297471800; 58420512500; 59172007300; 59397740800","DeepFake Face Detection using Machine Learning with LSTM","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195980968&partnerID=40&md5=0f998366ff82456671b6f5178c4da6c9","Fake face images that are increasingly convincing and realistic can be created because to the development of face image manipulation (FIM) technologies like Face to Face and Deepfake, which can damage the legitimacy and trustworthiness of online content. Malicious uses of these technology include blackmailing people, posing as celebrities, and disseminating false information. As a result, creating trustworthy and strong techniques to identify FIM and safeguard the integrity of digital media is essential. Numerous current techniques utilize on models built on convolutional neural networks (CNNs), which are capable of detecting FIM by examining a face's visual characteristics. But because these models are frequently tested and trained on certain datasets or circumstances. Furthermore, they might not be able to record the temporal information that is included in video data and can be used to identify irregularities or strange anomalies in FIM videos. We provide a novel method that uses both geographical and temporal information to detect FIM in order to get over these difficulties. We present a new type of residual network called CRNet, which is dependent on Convolutional Long Short-Term Memory (LSTM) and is capable of processing a series of consecutive pictures taken from a movie. The model can learn temporal information because to its design, which is essential for spotting oddities that occur in between frames of FIM movies. We performed extensive tests with several kinds of FIM videos from the Kaggle dataset. © 2024 IEEE.","Deepfake detection; Image manipulation; Kaggle; Long-Short Term Memory (LSTM); Residual next convolution neural network (Xception CNN)"
"Coccomini, D.A.; Kordopatis-Zilos, G.K.; Amato, G.; Caldelli, R.; Falchi, F.; Papadopoulos, S.; Gennaro, C.","Coccomini, Davide Alessandro (57217089435); Kordopatis-Zilos, Giorgos (56411991900); Amato, Giuseppe (35963890600); Caldelli, Roberto (6603103996); Falchi, Fabrizio (22940819900); Papadopoulos, Symeon (23095370800); Gennaro, Claudio (22334417200)","57217089435; 56411991900; 35963890600; 6603103996; 22940819900; 23095370800; 22334417200","MINTIME: Multi-Identity Size-Invariant Video Deepfake Detection","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195382276&partnerID=40&md5=67203e1d2192f6fd29eb2e376b15a00a","In this paper, we present MINTIME, a video deepfake detection method that effectively captures spatial and temporal inconsistencies in videos that depict multiple individuals and varying face sizes. Unlike previous approaches that either employ simplistic a-posteriori aggregation schemes, i.e., averaging or max operations, or only focus on the largest face in the video, our proposed method learns to accurately detect spatio-temporal inconsistencies across multiple identities in a video through a Spatio-Temporal Transformer combined with a Convolutional Neural Network backbone. This is achieved through an Identity-aware Attention mechanism that applies a masking operation on the face sequence to process each identity independently, which enables effective video-level aggregation. Furthermore, our system incorporates two novel embedding schemes: (i) the Temporal Coherent Positional Embedding, which encodes the temporal information of the face sequences of each identity, and (ii) the Size Embedding, which captures the relative sizes of the faces to the video frames. MINTIME achieves state-of-the-art performance on the ForgeryNet dataset, with a remarkable improvement of up to 14% AUC in videos containing multiple people. Moreover, it demonstrates very robust generalization capabilities in cross-forgery and cross-dataset settings. The code is publicly available at: https://github.com/davide-coccomini/MINTIME-Multi-Identity-size-iNvariant-TIMEsformer-for-Video-Deepfake-Detection. © 2005-2012 IEEE.","computer vision; convolutional neural networks; deep learning; Deepfake detection; vision transformers"
"Karthikeyan, K.; Swetha, R.; Deepanraj, S.; Dhandapani, S.","Karthikeyan, K. (59155491600); Swetha, Rame (59155866900); Deepanraj, S. (59155296700); Dhandapani, S. (59155959900)","59155491600; 59155866900; 59155296700; 59155959900","Guardian AI: Synthetic Media Forensics through Multimodal Fusion and Advanced Machine Learning","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195120973&partnerID=40&md5=9a061813659231b1fa628849636685dd","The burgeoning spread of synthetic media disrupts content verification and threatens online trust. This research proposes Guardian AI, a robust deepfake detection system achieving 93% accuracy by harnessing the synergistic power of facial recognition, image forensics, and machine learning. Guardian AI extracts diverse features from videos: facial recognition models analyze landmarks, expressions, and lip-syncing for inconsistencies; image forensics algorithms detect manipulated pixels, lighting patterns, and compression artifacts; and temporal analysis captures unnatural head movements and frame-to-frame motion discrepancies. These multifaceted features are then fused and fed into a rigorously trained deep learning model on multi-modal datasets of real and deepfake videos. Guardian AI classifies video inputs as real or fake, providing a confidence score for its prediction. By leveraging facial recognition's subtle inconsistency detection, image forensics' manipulation artifact identification, and machine learning's robust multi-cue integration, Guardian AI achieves exceptional accuracy and generalizability, adapting to evolving deepfake creation techniques with its diverse training data. This study signifies a significant contribution to content verification by delivering a high accuracy deepfake detection system, paving the way for a more reliable and trustworthy online environment. © 2024 IEEE.","Content Verification; Deepfake Detection; Facial Recognition; Image Forensics; Machine Learning; Multimodal Fusion"
"Sudharsana, P.P.; Rajalaxmi, R.R.; Devak, A.; Gokul, R.; Annamalai, R.; Gokila Brindha, P.","Sudharsana, P. P. (58196901000); Rajalaxmi, R. R. (25622829800); Devak, A. (59155582300); Gokul, R. (59520292000); Annamalai, R. (59155394900); Gokila Brindha, P. (57311406900)","58196901000; 25622829800; 59155582300; 59520292000; 59155394900; 57311406900","Enhancing Deepfake Detection: An Ensemble Deep Learning Approach for Efficient Attribute Manipulation Identification","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195115555&partnerID=40&md5=d81716842ce86a9ef8cfcf3f353cbf45","The increasing use of deepfake technology by incorporating Artificial Intelligence (AI) to seamlessly replace faces in videos, poses a significant threat to individuals, societies, and national security. This research study addresses this growing concern by detecting deepfake classification with the integration of two powerful Convolutional Neural Network (CNN) models: InceptionV3 and EfficientNetB0. The existing deepfake detection systems predominantly rely on facial feature analysis, analyzing subtle inconsistencies; however, these methods are susceptible to evolving deepfake techniques. In response, the proposed ensemble model exploits the advantages of InceptionV3 and EfficientNetB0 models to capture intricate features and computational efficiency. The synergy between these models significantly enhances the accuracy upto 93% and adaptability of the proposed deepfake detection system. When compared with conventional facial feature analysis, this approach establishes a resilient defense against emerging deepfake threats. As deepfake technology continues to advance, necessitating continual research in face-based detection systems, this study proposes a cutting-edge ensemble approach that not only mitigates the risks associated with social media manipulation but also serves as a proactive measure against potential challenges in future. © 2024 IEEE.","Attribute Manipulation; Deepfake Detection; Efficient Net; Ensemble Learning; Facial Feature Analysis; Inception Net"
"Johnson, D.; Yuan, X.; Roy, K.","Johnson, David (58460488500); Yuan, Xiaohong (56820491900); Roy, Kaushik (35566325000)","58460488500; 56820491900; 35566325000","Using Ensemble Convolutional Neural Network to Detect Deepfakes Using Periocular Data","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192196049&partnerID=40&md5=61fc7b405049e9af3964cd6e1710ab61","Deepfakes are manipulated or altered images, or video, that are created using deep learning models with high levels of photorealism. A popular method of deepfake creation is using convolutional neural networks (CNN). Deepfakes created using CNN comparatively show high qualities of realism, yet oftentimes leave artifacts and distortions in the generated media that can be detected using machine learning and deep learning algorithms. In recent years, there has been an influx of periocular image and video data because of the increased usage of face masks. By wearing masks, much of what is used for facial recognition is hidden, leaving only the periocular region visible to an observer. This loss of vital information leads to easier misidentification of media, allowing deepfakes to less likely be identified as fake. In this work, feature extraction methods, such as Scale-Invariant Feature Transform (SIFT), Histogram of Oriented Gradients (HOG), and CNN, are used to train an ensemble deep learning model to detect deepfakes in videos on a frame-by-frame level based on the periocular region. Our proposed model is able to distinguish original and manipulated images with averaged accuracy of 98.9 percent, which is an improvement to previous works by combining SIFT and HOG for deepfake detection in convolutional neural networks. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","CNN; Computer vision; Deep neural network; Deepfake detection; Histogram of oriented gradients; Scale invariant feature transform"
"Guan, W.; Wang, W.; Dong, J.; Peng, B.","Guan, Weinan (57223755493); Wang, Wei (56948518500); Dong, Jing (55477985000); Peng, Bo (57201594957)","57223755493; 56948518500; 55477985000; 57201594957","Improving Generalization of Deepfake Detectors by Imposing Gradient Regularization","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192167897&partnerID=40&md5=44296755ea05df782c4c9f5f6ba2fcd9","The rapid development of face forgery technology has posed a significant threat to information security. While deepfake detection has proven to be an effective countermeasure, it often struggles to detect fake images generated by unknown forgery methods. Thus, the generalization ability of deepfake detectors to unseen forgery data is a critical concern. Despite many efforts aimed at discovering new forgery artifacts, they often fail to generalize to new manipulation technologies. In this paper, we tackle this challenge by focusing on the difference in texture patterns between training forgeries and unseen forgeries, which can lead to a degradation of generalization. Based on this principle, we propose a new conjecture that encourages deepfake detectors to reduce their sensitivity to forgery texture patterns, thereby improving the detection performance. To this end, we introduce an additional gradient regularization term to the original empirical loss during training. However, computing the Hessian matrix in the gradient calculation process of the regularization term poses a computational complexity. In order to overcome this issue, we optimize the formulation of the gradient regularization term using a first-order approximation method based on Taylor expansion and design a Perturbation Injection Module (PIM) to simplify the implementation process. Additionally, we provide a theoretical analysis from an optimization perspective and explore an interesting aspect of our method. Extensive experiments demonstrate the effectiveness of our approach in improving the generalization ability of deepfake detectors. Importantly, our method is orthogonal to recent advancements in powerful backbones and training data augmentation techniques. When combined with other effective techniques, our method achieves state-of-the-art experimental results. © 2005-2012 IEEE.","Deepfake detection; forgery texture patterns"
"Zhou, J.; Zhao, X.; Xu, Q.; Zhang, P.; Zhou, Z.","Zhou, Jiting (57195986446); Zhao, Xinrui (58985251300); Xu, Qian (58440887000); Zhang, Pu (58985170000); Zhou, Zhihao (58985328800)","57195986446; 58985251300; 58440887000; 58985170000; 58985328800","MDCF-Net: Multi-Scale Dual-Branch Network for Compressed Face Forgery Detection","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190741441&partnerID=40&md5=a0255f8bc105db4d309efd332569beaf","Face forgery detection aims to identify manipulated or altered facial images or videos created using artificial intelligence. Existing detection methods exhibit favorable performance on high-quality videos, but the videos in daily applications are commonly compressed into low-quality formats via social media. The detection difficulty is increased by the poor quality, indistinct detail features, and noises such as artifacts in these images or videos. To address this challenge, we propose a multi-scale dual-branch network for compressed face forgery, called MDCF-Net, effectively capturing cross-domain forgery features at various scales in compressed facial images. The MDCF-Net comprises two branches: an RGB domain branch utilizing Transformers to extract multi-scale fine-texture features from the original RGB images; a frequency domain branch designed to capture artifacts in low-quality videos by extracting global spectral features as a supplementary measure. Then, we introduce a feature fusion module (FFM) based on multi-head attention to merge diverse feature representations in a spatial-frequency complementary manner. Extensive comparative experiments on public datasets such as FaceForensics++, Celeb-DF, and WildDeepfake demonstrate the significant advantage of MDCF-Net in detecting highly compressed and low-quality forged images or videos, especially in achieving state-of-the-art performance on the FaceForensics++ low-quality dataset. Our approach presents a new perspective and technology for low-quality face forgery detection. © 2013 IEEE.","deepfake detection; Face forgery; feature fusion; frequency domain; transformers; two-branch"
"Uppal, S.; Banga, V.; Neeraj, S.; Singhal, A.","Uppal, Shivansh (58133039000); Banga, Vinayak (58983768700); Neeraj, Sakshi (58132051500); Singhal, Abhishek (56198942000)","58133039000; 58983768700; 58132051500; 56198942000","A Comprehensive Study on Mitigating Synthetic Identity Threats Using Deepfake Detection Mechanisms","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190260473&partnerID=40&md5=f076976fda7301a31acbf81d094ffd27","Synthetic Identity Threats (SIT) present one of the greatest risks that could undermine the integrity and security of digital systems. These threats adapt Deepfake Technology through generation of new faces, modification of facial attributes or reenactment of fake emotions on human faces. This study is a full documentation of how Deepfake Detection mechanisms can be modelled to neutralize these SIT's using various Deep Learning architectures. We also explored applications of Deepfake beyond malicious intent into forms that are less nefarious like entertainment purposes. We utilized Generative Adversarial Networks to create Deepfakes and experimented with conducting face swaps between two distinct photos as well to assess the quality of Deepfake Technology. For detection of Deepfakes, Convolution Neural Network has shown the highest accuracy of 89.36%, Inception ResNet attained an accuracy of 82.978% while Visual Geometry Group and EfficientNet were at a score of 82.8% and 83% respectively. It is evident that although the current detecting methods are competent in their abilities, the SIT environment continues to develop. Through analyzing the nuances of producing Deepfakes and comparing current quality detection methods, we hope to offer useful information on how scholars and administrators can better protect the internet from deceitful attacks of Deepfakes. © 2024 IEEE.","Convolution Neural Network (CNN); Deepfake Detection Challenge Dataset (DFDC); Deepfake Generation; EfficientNet; Face Swapping; Generative Adversarial Networks (GAN); Inception ResNet; Synthetic Identity Threats (SIT); Visual Geometry Group (VGG)"
"Huszar, V.D.; Adhikarla, V.K.","Huszar, Viktor Dénes (57320110300); Adhikarla, Vamsi Kiran (55195687600)","57320110300; 55195687600","Securing Phygital Gameplay: Strategies for Video-Replay Spoofing Detection","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189803750&partnerID=40&md5=f9508af32148e11c5cdd6d2f87e6ea23","Physical Virtual Sports (PVS) utilize digital technologies for the analysis and evaluation of sports performances. This research article addresses the challenge of detecting video-replay spoofing in PVS, with a specific focus on a digital football sport aimed at assessing and improving a player's football juggling skills. In the context of the growing presence of digital coaches as well as PVS, accurate assessment of player performance and identification of deceptive practices in these applications are paramount. The proliferation of sophisticated technologies, such as deepfake algorithms and computer vision techniques, has facilitated the manipulation of video replays, deceiving both viewers and officials. To tackle the challenges associated with video-replay spoofing, this article introduces a meticulously curated dataset comprising 600 players engaged in the digital football sport. Additionally, the dataset includes video-replay spoofing videos captured on a wide range of display devices. A deep learning-based model is developed and trained on this dataset, achieving an accuracy rate of approximately 95%. Generalization studies were also conducted to assess the model's ability to generalize to unseen scenarios and datasets. The ROC-AUC score highlighted the model's discriminative power across different threshold values, validating its effectiveness in distinguishing between genuine and spoofed video replays. The results demonstrate that our trained model exhibited consistent performance across multiple public face biometric spoofing datasets, underscoring its robustness against sophisticated video-replay attacks in various domains. Additionally, ablation studies were carried out by systematically removing or modifying the model's backbone architectures to analyze their effects on detection accuracy and reliability. Furthermore, computational complexity analysis was presented to evaluate the model's efficiency in terms of time and space requirements. The findings underscore the scientific significance and relevance of video replay spoof detection in PVS. By presenting a novel dataset (https://www.fiteq.org/research) and employing an advanced deep learning approach, this article contributes to the scientific community's understanding and progress in combating fraudulent practices, ultimately preserving the integrity and fairness of digital sports applications. © 2013 IEEE.","Active virtual sports; computer vision; dataset; deceptive practices; deep learning; deepfake detection; digital sports applications; fraudulent practices; integrity; video-replay spoofing"
"Qiao, T.; Xie, S.; Chen, Y.; Retraint, F.; Shi, R.; Luo, X.","Qiao, Tong (56177583700); Xie, Shichuang (57741636500); Chen, Yanli (57345637000); Retraint, Florent (6506827303); Shi, Ran (36959827400); Luo, Xiangyang (8976166200)","56177583700; 57741636500; 57345637000; 6506827303; 36959827400; 8976166200","Deepfake Detection Fighting Against Noisy Label Attack","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189642049&partnerID=40&md5=f1810b43d39f21cbcc3f55d4e1228ea0","The face manipulation technique such as Deepfake has been widely used to create realistic faces, which raises growing concerns in the community. Based on the correct labeled data, the current Deepfake detectors are mostly trained on the clean dataset, usually resulting in the reliable high detection accuracy. However, in the real-world scenario, labelers possibly mislabel the data or malicious attackers always intend to poison the training data with incorrect label, namely noisy label attack, leading to poor detection results. To overcome the tough issue, we propose a Deepfake detection framework fighting against noisy label attack. Specifically, a Negative Sample Generator (NSG) utilizes the possibly-poisoned samples to generate label-reliable negative samples through simulating blending artifacts caused by Deepfake. Next, a Noise-immune Contrastive Learner (NiCL) takes both positive and negative samples as training data, exploring blending artifacts and intrinsic forgery clues to filtrate the noisy samples out. Moreover, relying on label purification, the filtrated noisy samples are further purified, which then are fed back to the feature extractor for the following model training. Extensive experiments on the benchmark datasets demonstrate the superiority of our proposed Deepfake detector. In particular, when fighting against noisy label attack, the high performance of the proposed detector is remarkably better than its competitors. © 1999-2012 IEEE.","contrastive learning; Deepfake detection; noisy label attack"
"Yang, R.; Deng, Z.; Zhang, Y.; Luo, X.; Lan, R.","Yang, Rui (57215216214); Deng, Zhenrong (35106972300); Zhang, Yushu (55508709300); Luo, Xiaonan (57216369979); Lan, Rushi (35146229200)","57215216214; 35106972300; 55508709300; 57216369979; 35146229200","4DPM: Deepfake Detection with a Denoising Diffusion Probabilistic Mask","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188539910&partnerID=40&md5=4cf7740735b12aa59c4b15eea39778f4","In the face of increasingly realistic fake human faces, research on enhancing the differences between real and fake images is valuable for improving the generalization capabilities of fake face detection models. In this letter, we propose a method called DPMask (Diffusion Probabilistic Mask) to amplify the distinctions between authentic and counterfeit human facial images. Specifically, we use a dataset consisting of real human facial images and Simplex noise to train a denoising diffusion probabilistic model for the proposed DPMask. Subsequently, we separately apply the DPMask and U-Net to real and fake human facial images to create noticeably distinct genuine and counterfeit human facial images. A lightweight classification network blue is further designed based on RepVGG to classify the newly generated real and fake human faces. Experimental results demonstrate that our model achieves high accuracy on a manually created fake face dataset (RFFD), a GAN-generated fake face dataset (Seq-DeepFake), and a DDPM-generated face dataset (HiFi-IFDL). Furthermore, the addition of DPMask significantly improves the performance of some public fake face detection models. © 1994-2012 IEEE.","DDPM; deepfake detection; DPMask; lightweight model"
"Shao, R.; Wu, T.; Wu, J.; Nie, L.; Liu, Z.","Shao, Rui (57201860007); Wu, Tianxing (57815209400); Wu, Jianlong (57143509300); Nie, Liqiang (36439883200); Liu, Ziwei (56437024900)","57201860007; 57815209400; 57143509300; 36439883200; 56437024900","Detecting and Grounding Multi-Modal Media Manipulation and Beyond","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187974153&partnerID=40&md5=f989032db00fad9d38d219a318012c0a","Misinformation has become a pressing issue. Fake media, in both visual and textual forms, is widespread on the web. While various DeepFake detection and text fake news detection methods have been proposed, they are only designed for single-modality forgery based on binary classification, let alone analyzing and reasoning subtle forgery traces across different modalities. In this paper, we highlight a new research problem for multi-modal fake media, namely Detecting and Grounding Multi-Modal Media Manipulation (DGM4 4). DGM4 4 aims to not only detect the authenticity of multi-modal media, but also ground the manipulated content (i.e., image bounding boxes and text tokens), which requires deeper reasoning of multi-modal media manipulation. To support a large-scale investigation, we construct the first DGM4 4 dataset, where image-text pairs are manipulated by various approaches, with rich annotation of diverse manipulations. Moreover, we propose a novel HierArchical Multi-modal Manipulation rEasoning tRansformer (HAMMER) to fully capture the fine-grained interaction between different modalities. HAMMER performs: 1) manipulation-aware contrastive learning between two uni-modal encoders as shallow manipulation reasoning and 2) modality-aware cross-attention by multi-modal aggregator as deep manipulation reasoning. Dedicated manipulation detection and grounding heads are integrated from shallow to deep levels based on the interacted multi-modal information. To exploit more fine-grained contrastive learning for cross-modal semantic alignment, we further integrate Manipulation-Aware Contrastive Loss with Local View and construct a more advanced model HAMMER++. Finally, we build an extensive benchmark and set up rigorous evaluation metrics for this new research problem. Comprehensive experiments demonstrate the superiority of HAMMER and HAMMER++; several valuable observations are also revealed to facilitate future research in multi-modal media manipulation. © 1979-2012 IEEE.","DeepFake detection; Media manipulation detection; multi-modal learning"
"Le, A.B.N.; Nguyen, H.T.T.; Su, A.K.; Nguyen, H.T.","Le, Anh Bao Nguyen (58938349000); Nguyen, Hien Thanh Thi (58937494100); Su, Anhkim (58937910400); Nguyen, Thanh Hai (56416931800)","58938349000; 58937494100; 58937910400; 56416931800","Fake Face Recognition on Images Generated by Various Deepfakes Tools","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187659219&partnerID=40&md5=a96edc08ddbce369df724d77812b8800","In the era of rapid technological advancement, the emergence of Deepfake technology has transformed our interaction with digital content. Deepfakes are sophisticated synthetic media created using deep learning techniques that alter or replace visual and audio elements in images, videos, and audio recordings. While Deepfakes offer potential benefits in entertainment and training, they also raise ethical, social, and security concerns. Many people have been victims of deepfake tools that are widely available online. Such tools can cheat image recognition algorithms. Therefore, an assessment of the dangers of these tools is necessary so that researchers can focus on novel strategies for anti-deepfake. This study evaluates the ability of four famous deepfake tools, namely Deepfakes, Face2Face, Face Swap, and Neural Textures, to cheat deep learning architectures in fake/real face recognition in images. Experimental results show that the Neural Textures tool is the most sophisticated in creating fake faces, which is the most challenging for the considered fake image detection algorithms. In addition, we propose an architecture that can obtain better performance in fake/real face detection with fewer parameters. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.","Convolutional Neural Network; Deepfake detection; deepfakes tools"
"Deng, J.; Lin, C.; Hu, P.; Shen, C.; Wang, Q.; Li, Q.; Li, Q.","Deng, Jingyi (57210359782); Lin, Chenhao (57221245073); Hu, Pengbin (57547521900); Shen, Chao (36446592900); Wang, Qian (56856235900); Li, Qi (58733251100); Li, Qiming (57838413300)","57210359782; 57221245073; 57547521900; 36446592900; 56856235900; 58733251100; 57838413300","Towards Benchmarking and Evaluating Deepfake Detection","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187009045&partnerID=40&md5=38b9c1f47deb466ee7da5b2f6e8f9862","Deepfake detection automatically recognizes the manipulated media by analyzing whether it contains forgeries generated through deep learning. It is natural to ask which among the existing deepfake detection approaches stand out as top performers. This question is pivotal for identifying promising research directions and offering practical guidance. Unfortunately, conducting a sound benchmark comparison of popular detection approaches based on literature results is challenging due to inconsistent evaluation conditions across studies. In this paper, our objective is to achieve a sound comparison between detection approaches by establishing a comprehensive and consistent benchmark, developing a repeatable evaluation procedure, and performing extensive performance evaluation. Accordingly, a challenging dataset consisting of the manipulated samples generated by more than 12 different methods is collected. Subsequently, we implement and evaluate 13 prominent detection approaches (comprising 11 algorithms) from existing literature, utilizing five fair-minded and practical evaluation metrics. Finally, we provide up to 882 comprehensive evaluations by training 117 detection models. The results, along with the shared data and evaluation methodology, constitute a benchmark for comparing deepfake detection approaches and measuring progress. © 2004-2012 IEEE.","Benchmark; deepfake detection; face swapping; forensic datasets"
"Kim, T.; Choi, J.; Cho, H.; Lim, H.; Choi, J.","Kim, Taehoon (58925517300); Choi, Jongwook (58924492200); Cho, Hyunjin (58924785200); Lim, Hyoungjun (58925225800); Choi, Jongwon (57192084517)","58925517300; 58924492200; 58924785200; 58925225800; 57192084517","Domain Generalization for Face Forgery Detection by Style Transfer","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187006407&partnerID=40&md5=7926d0a7ef7b3a5fe56c7c061442c289","Although deep fake detection models have made significant progress, the challenge of performance degradation remains yet for unseen datasets. To address this, we introduce a novel data generalization approach using style transfer to generate images in various domains. Utilizing style transfer, we create a new domain where domain-specific information is eliminated and subsequently train our model on the new domain. Our approach enhances the generalization performance of the detector by adding the style-transferred images to train the deepfake detector. Through the experiments, we confirm that the performance on the trained dataset remains unchanged while achieving an improvement of 8.8% on an unseen dataset. Therefore, We verify the effectiveness of the style-transferred images for generalizing the performance upon unseen datasets. © 2024 IEEE.","data augmentation; Deepfake detection; forgery detection; style transfer"
"Ezeakunne, U.; Liu, X.","Ezeakunne, Uzoamaka (58918544100); Liu, Xiuwen (57202583383)","58918544100; 57202583383","Facial Deepfake Detection Using Gaussian Processes","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186654343&partnerID=40&md5=4c117bee6733ba09be9e6a6c219ae957","Facial deepfake detection involves detecting images and videos with tampered faces. In this paper, we automatically detect four types of deepfakes: Deepfake, Face2Face, FaceSwap and Neural Textures. From a deepfake video, we extract the faces in its image frames to serve as input. Given a facial image, we preprocessed the image by capturing the different compression levels, extracted features using a feature extraction backbone that focuses on mesoscopic properties, and we make use of Gaussian Processes (GPs) for binary classification because GPs inherently provide more accurate uncertainty estimation which leads to lower prediction error and higher accuracy. To the best of our knowledge, we are the first to apply GPs in deepfake detection. The proposed method was compared with state-of-the-art baseline methods; we performed a cross-dataset evaluation and observed no significant accuracy difference between this approach and the baseline. Also, we experimented on varying dataset sizes and the results show that our method has a competitive accuracy on large datasets and outperforms on small datasets. The implementation is available at: https://github.com/harmz123/FacialDeepfakeDetection © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.","deepfake detection; image forensic; neural networks"
"Felouat, H.; Nguyen, H.H.; Le, T.-N.; Yamagishi, J.; Echizen, I.","Felouat, Hichem (58907812900); Nguyen, Huy H. (55774055400); Le, Trung Nghia (58059122200); Yamagishi, Junichi (7004695833); Echizen, Isao (6602366829)","58907812900; 55774055400; 58059122200; 7004695833; 6602366829","eKYC-DF: A Large-Scale Deepfake Dataset for Developing and Evaluating eKYC Systems","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186081636&partnerID=40&md5=39e236a97b9c4455845edd9dd83b2e20","The reliability of remote identity-proofing systems (i.e., electronic Know Your Customer, or eKYC, systems) is challenged by the development of deepfake generation tools, which can be used to create fake videos that are difficult to detect using existing deepfake detection models and are indistinguishable by facial recognition systems. This poses a serious threat to eKYC systems and a danger to individuals' personal information and property. Existing deepfake datasets are not particularly appropriate for developing and evaluating eKYC systems, which require specific motions, such as head movement, for liveness detection. Furthermore, they do not contain ID information or protocols for facial verification evaluation, which is vital for eKYC. We found that eKYC systems without the ability to detect deepfakes can be easily compromised. We have thus created a large-scale collection of high-quality fake videos (more than 228,000 videos) that are diverse in terms of age, gender, and ethnicity, plus a corresponding facial image subset. The videos include a variety of head movements and facial expressions. This large collection of high-quality diverse videos is well-suited for developing and evaluating various tasks related to eKYC systems. Furthermore, we provide protocols for traditional deepfake detection and facial verification, which are widely used in eKYC systems. It is worth mentioning that systematic evaluation of facial recognition systems on deepfake detection has not been reported. The entire eKYC-DF dataset, evaluation toolkit, and trained models are open access to researchers on GitHub: https://github.com/hichemfelouat/eKYC-DF. © 2013 IEEE.","Deepfake detection; eKYC; electronic Know Your Customer; face recognition; face swapping; facial verification"
"Xia, R.; Liu, D.; Li, J.; Yuan, L.; Wang, N.; Gao, X.","Xia, Ruiyang (57221806404); Liu, Decheng (57192557912); Li, Jie (7410068291); Yuan, Lin (58018329200); Wang, Nannan (55694111900); Gao, Xinbo (7403873424)","57221806404; 57192557912; 7410068291; 58018329200; 55694111900; 7403873424","MMNet: Multi-Collaboration and Multi-Supervision Network for Sequential Deepfake Detection","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184338901&partnerID=40&md5=43b102bfa4964f444903101f0c703f7a","Advanced manipulation techniques have provided criminals with opportunities to make social panic or gain illicit profits through the generation of deceptive media, such as forgery face images. In response, various deepfake detection methods have been proposed to assess image authenticity. Sequential deepfake detection, which is an extension of deepfake detection, aims to identify forged facial regions with the correct sequence for recovery. Nonetheless, due to the different combinations of spatial and sequential manipulations, forgery face images exhibit substantial discrepancies that severely impact detection performance. Additionally, the recovery of forged images requires knowledge of the manipulation model to implement inverse transformations, which is difficult to ascertain as relevant techniques are often concealed by attackers. To address these issues, we propose Multi-Collaboration and Multi-Supervision Network (MMNet) that handles various spatial scales and sequential permutations in forgery face images and achieve recovery without requiring knowledge of the corresponding manipulation method. Furthermore, existing evaluation metrics only consider detection accuracy at a single inferring step, without accounting for the matching degree with ground-truth under continuous multiple steps. To overcome this limitation, we propose a novel evaluation metric called Complete Sequence Matching (CSM), which considers the detection accuracy at multiple inferring steps, reflecting the ability to detect integrally forged sequences. Extensive experiments on several typical datasets demonstrate that MMNet achieves state-of-the-art detection performance and independent recovery performance. Code will be available at https://github.com/xarryon/MMNet © 2005-2012 IEEE.","Deceptive media; face recovery; sequential deepfake detection"
"Jilani, S.K.; Geradts, Z.; Abubakar, A.","Jilani, Shelina Khalid (55509904200); Geradts, Zeno J.M.H. (6603940596); Abubakar, Aliyu (57209984868)","55509904200; 6603940596; 57209984868","Decoding Deception: Understanding Human Discrimination Ability in Differentiating Authentic Faces from Deepfake Deceits","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184095065&partnerID=40&md5=e6cd78177f041266407ad54d441d79a1","Advances in innovative digital technologies present a maturing challenge in differentiating between authentic and manipulated media. The evolution of automated technology has specifically exacerbated this issue, with the emergence of DeepFake content. The degree of sophistication poses potential risks and raise concerns across multiple domains including forensic imagery analysis, especially for Facial Image Comparison (FIC) practitioners. It remains unclear as to whether DeepFake videos can be accurately distinguished from their authentic counterparts, when analysed by domain experts. In response, we present our study where two participant cohorts (FIC practitioners and novice subjects) were shown eleven videos (6 authentic videos and 5 DeepFake videos) and asked to make judgments about the authenticity of the faces. The research findings indicate that when distinguishing between DeepFake and authentic faces, FIC practitioners perform at a similar level to the untrained, novice cohort. Though, statistically, the novice cohort outperformed the practitioners with an overall performance surpassing 70%, relative to the FIC practitioners. This research is still in its infancy stage, yet it is already making significant contributions to the field by facilitating a deeper understanding of how DeepFake content could potentially influence the domain of Forensic Image Identification. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Artificial Intelligence; DeepFake Detection; Face Identification; Forensic Practitioners and Deep Learning"
"Yin, Z.; Wang, J.; Xiao, Y.; Zhao, H.; Li, T.; Zhou, W.; Liu, A.; Liu, X.","Yin, Zixin (57222420604); Wang, Jiakai (57221358581); Xiao, Yisong (57372286800); Zhao, Hanqing (59809221600); Li, Tianlin (57218764226); Zhou, Wenbo (57192111936); Liu, Aishan (57188724406); Liu, Xianglong (36100195100)","57222420604; 57221358581; 57372286800; 59809221600; 57218764226; 57192111936; 57188724406; 36100195100","Improving Deepfake Detection Generalization by Invariant Risk Minimization","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182930873&partnerID=40&md5=3546745e86fd88d492fea73475e2c95c","The abuse of deepfake techniques has raised serious concerns about social security and ethical problems, which motivates the development of deepfake detection. However, without fully addressing the domain gap issue, existing deepfake detection methods still show weak generalization ability among datasets belonging to different domains with domain-specific characteristics like identities and generation methods, limiting their practical applications. In this article, we propose the Invariant Domain-oriented Deepfake Detection method (ID<inf>3</inf>), which improves the generalization of deepfake detection on multiple domains through invariant risk minimization, a novel learning paradigm that addresses the domain gap problem by jointly training a purified invariant predictor and learning an aligned invariant representation. To train a purified invariant predictor, we design the Domain Refinement Data Augmentation strategy with self-face-swapping and region-erasing approaches, which suppresses domain-specific features and encourages the models to focus on critical domain-invariant characteristics. To learn an aligned invariant representation, we propose the Domain Calibration Batch Normalization approach with multiple BN branches, which normalizes input features from different domains into aligned representations during both training and testing. Extensive experiments on multiple datasets demonstrate that our framework can boost the deepfake detection generalization ability and outperform other baselines by large margins. Our codes can be found here. © 2023 IEEE.","Deepfake detection; invariant risk minimization; model generalization"
"Ramadhani, K.N.; Munir, R.; Utama, N.P.","Ramadhani, Kurniawan Nur (56412050200); Munir, Rinaldi (35176324300); Utama, Nugraha Priya (58449636000)","56412050200; 35176324300; 58449636000","Improving Video Vision Transformer for Deepfake Video Detection Using Facial Landmark, Depthwise Separable Convolution and Self Attention","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182930350&partnerID=40&md5=577126d43b07d58f9d9c0277cf7f42a1","In this paper, we present our result of research in video deepfake detection. We built a deepfake detection system to detect whether a video is a deepfake or real. The deepfake detection algorithm still struggle in providing a sufficient accuracy values, especially in challenging deepfake dataset. Our deepfake detection system utilized spatiotemporal feature that extracted using Video Vision Transformer (ViViT). The main contribution of our research is providing a deepfake detection system that based on ViViT architecture and using landmark area images for the input of the system. Our system extracted the feature from a number of spatial features. The spatial feature was extracted using Depthwise Separable Convolution (DSC) block combined with Convolution Block Attention Module (CBAM) from tubelet. The tubelet was a representation of facial landmark area that was extracted from the input video. In our system, we used 25 facial landmark area for an input video. In our experiment we used Celeb-DF version 2 dataset because it is considered to be a challenging deepfake dataset. We conducted augmentation to the dataset, so we obtained 8335 videos for training set, 390 videos for validation set, and 1123 videos for testing set. We trained our deepfake detection system using Adam optimizer, with learning rate of 10-4 and 100 epoch. From the experiment, we obtained the accuracy score of 87.18% and F1 score of 92.52%. We also conducted the ablation study to display the effect of each part of our model to the overall system performance. From this research, we obtained that by using landmark area images, our ViViT based deepfake detection system had a good performance in detecting deepfake videos. © 2013 IEEE.","convolution block attention module; Deepfake detection; depthwise separable convolution; facial landmark; video vision transformer"
"Xu, J.; Wang, G.; Zhou, T.","Xu, Jie (58815504000); Wang, Guoqiang (58815467700); Zhou, Tianxiong (58815394800)","58815504000; 58815467700; 58815394800","Exposing deepfakes in online communication: detection based on ensemble strategy","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182505345&partnerID=40&md5=7c091e1c8d04516cea57a662092cb27b","In recent years, deepfake techniques have appeared in people’s lives. As a product of deep learning, it can generate realistic face-swapping videos. Due to its high fidelity, deepfake is often used to produce porn videos and guide the public opinion, so as to pose a great threat to social stability. Previous studies have been able to improve detection accuracy. This paper aims to improve the detection ability of existing schemes by using the ensemble learning scheme from the perspective of model learning. Specifically, our scheme includes feature extraction, feature selection, feature classification, and a combination strategy. The experimental results on several datasets demonstrate that our scheme can effectively improve the detection ability of the model. © © 2024 Inderscience Enterprises Ltd.","deep learning; deepfake detection; ensemble strategy; online communication; video forensics"
"Alanazi, F.; Ushaw, G.; Morgan, G.","Alanazi, Fatimah (57760921000); Ushaw, Gary (6505827656); Morgan, Graham (9133666100)","57760921000; 6505827656; 9133666100","Improving Detection of DeepFakes through Facial Region Analysis in Images","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181922554&partnerID=40&md5=d91397d61679cc18bb0dacc779965ff1","In the evolving landscape of digital media, the discipline of media forensics, which encompasses the critical examination and authentication of digital images, videos, and audio recordings, has emerged as an area of paramount importance. This heightened significance is predominantly attributed to the burgeoning concerns surrounding the proliferation of DeepFakes, which are highly realistic and manipulated media content, often created using advanced artificial intelligence techniques. Such developments necessitate a profound understanding and advancement in media forensics to ensure the integrity of digital media in various domains. Current research endeavours are primarily directed towards addressing a common challenge observed in DeepFake datasets, which pertains to the issue of overfitting. Many suggested remedies centre around the application of data augmentation methods, with a frequently adopted strategy being the incorporation of random erasure or cutout. This method entails the random removal of sections from an image to introduce diversity and mitigate overfitting. Generating disparities between the altered and unaltered images serves to inhibit the model from excessively adapting itself to individual samples, thus leading to more favourable results. Nonetheless, the stochastic nature of this approach may inadvertently obscure facial regions that harbour vital information necessary for DeepFake detection. Due to the lack of guidelines on specific regions for cutout, most studies use a randomised approach. However, in recent research, face landmarks have been integrated to designate specific facial areas for removal, even though the selection remains somewhat random. Therefore, there is a need to acquire a more comprehensive insight into facial features and identify which regions hold more crucial data for the identification of DeepFakes. In this study, the investigation delves into the data conveyed by various facial components through the excision of distinct facial regions during the training of the model. The goal is to offer valuable insights to enhance forthcoming face removal techniques within DeepFake datasets, fostering a deeper comprehension among researchers and advancing the realm of DeepFake detection. Our study presents a novel method that uses face cutout techniques to improve understanding of key facial features crucial in DeepFake detection. Moreover, the method combats overfitting in DeepFake datasets by generating diverse images with these techniques, thereby enhancing model robustness. The developed methodology is validated against publicly available datasets like FF++ and Celeb-DFv2. Both face cutout groups surpassed the Baseline, indicating cutouts improve DeepFake detection. Face Cutout Group 2 excelled, with 91% accuracy on Celeb-DF and 86% on the compound dataset, suggesting external facial features’ significance in detection. The study found that eyes are most impactful and the nose is least in model performance. Future research could explore the augmentation policy’s effect on video-based DeepFake detection. © 2023 by the authors.","DeepFake detection; face augmentation; face cutout facial recognition; feature fusion; image analysis"
"Guo, Z.; Jia, Z.; Wang, L.; Wang, D.; Yang, G.; Kasabov, N.","Guo, Zhiqing (57219672095); Jia, Zhenhong (57696879200); Wang, Liejun (16833826600); Wang, Dewang (57210996855); Yang, Gaobo (8647279200); Kasabov, Nikola Kirilov (57833590600)","57219672095; 57696879200; 16833826600; 57210996855; 8647279200; 57833590600","Constructing New Backbone Networks via Space-Frequency Interactive Convolution for Deepfake Detection","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174844500&partnerID=40&md5=3ae2ddb50ae8a48e2e793adfa45bc260","The serious concerns over the negative impacts of Deepfakes have attracted wide attentions in the community of multimedia forensics. The existing detection works achieve deepfake detection by improving the traditional backbone networks to capture subtle manipulation traces. However, there is no attempt to construct new backbone networks with different structures for Deepfake detection by improving the internal feature representation of convolution. In this work, we propose a novel Space-Frequency Interactive Convolution (SFIConv) to efficiently model the manipulation clues left by Deepfake. To obtain high-frequency features from tampering traces, a Multichannel Constrained Separable Convolution (MCSConv) is designed as the component of the proposed SFIConv, which learns space-frequency features via three stages, namely generation, interaction and fusion. In addition, SFIConv can replace the vanilla convolution in any backbone networks without changing the network structure. Extensive experimental results show that seamlessly equipping SFIConv into the backbone network greatly improves the accuracy for Deepfake detection. In addition, the space-frequency interaction mechanism does benefit to capturing common artifact features, thus achieving better results in cross-dataset evaluation. Our code will be available at https://github.com/EricGzq/SFIConv. © 2023 IEEE.","backbone network; Deepfake detection; manipulation traces; space-frequency interactive convolution"
"Xie, Y.; Cheng, H.; Wang, Y.; Ye, L.","Xie, Yuankun (57221495955); Cheng, Haonnan (57208690777); Wang, Yutian (55498564100); Ye, Long (14526213800)","57221495955; 57208690777; 55498564100; 14526213800","Domain Generalization via Aggregation and Separation for Audio Deepfake Detection","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174828392&partnerID=40&md5=a9c65c9f628cf583da39ccc4f749dbdf","In this paper, we propose an Aggregation and Separation Domain Generalization (ASDG) method for Audio DeepFake Detection (ADD). Fake speech generated from different methods exhibits varied amplitude and frequency distributions rather than genuine speech. In addition, the spoofing attacks in training sets may not keep pace with the evolving diversity of real-world deepfake distributions. In light of this, we attempt to learn an ideal feature space that can aggregate real speech and separate fake speech to achieve better generalizability in the detection of unseen target domains. Specifically, we first propose a feature generator based on Lightweight Convolutional Neural Networks (LCNN), which is employed for generating a feature space and categorizing the feature into real and fake. Meanwhile, single-side domain adversarial learning is leveraged to make only the real speech from different domains indistinguishable, which enables the distribution of real speech to be aggregated in the feature space. Furthermore, a triplet loss is adopted to separate the distribution of fake speech while aggregating the distribution of real speech. Finally, in order to test the generalizability of the model, we train it with three different English datasets and evaluate in harsh conditions: cross-language and noisy datasets. The extensive experiments show that ASDG outperforms the baseline models in cross-domain tasks and decreases Equal Error Rate (EER) by up to 39.24% when compared to that of RawNet2. It is proved that the proposed Aggregation and Separation Domain Generalization method can be an effective strategy to improve the model generalizability. © 2023 IEEE.","Audio deepfake detection; domain generalization; feature generator; triplet loss"
"Yu, Y.; Liu, X.; Ni, R.; Yang, S.; Zhao, Y.; Kot, A.C.","Yu, Yang (57210753156); Liu, Xiaolong (57225057703); Ni, Rongrong (55632437300); Yang, Siyuan (57221158200); Zhao, Yao (35304414700); Kot, Alex Chichung (35588578100)","57210753156; 57225057703; 55632437300; 57221158200; 35304414700; 35588578100","PVASS-MDD: Predictive Visual-Audio Alignment Self-Supervision for Multimodal Deepfake Detection","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170554970&partnerID=40&md5=beff7c258fe37d12e2bd53f1a637ecd3","Deepfake techniques can forge the visual or audio signals in the video, which leads to inconsistencies between visual and audio (VA) signals. Therefore, multimodal detection methods expose deepfake videos by extracting VA inconsistencies. Recently, deepfake technology has started VA collaborative forgery to obtain more realistic deepfake videos, which poses new challenges for extracting VA inconsistencies. Recent multimodal detection methods propose to first extract natural VA correspondences in real videos in a self-supervised manner, and then use the learned real correspondences as targets to guide the extraction of VA inconsistencies in the subsequent deepfake detection stage. However, the inherent VA relations are difficult to extract due to the modality gap, which leads to the limited auxiliary performance of the aforementioned self-supervised methods. In this paper, we propose Predictive Visual-audio Alignment Self-supervision for Multimodal Deepfake Detection (PVASS-MDD), which consists of PVASS auxiliary and MDD stages. In the PVASS auxiliary stage in real videos, we first devise a three-stream network to associate two augmented visual views with corresponding audio clues, leading to explore common VA correspondences based on cross-view learning. Secondly, we introduce a novel cross-modal predictive align module for eliminating VA gaps to provide inherent VA correspondences. In the MDD stage, we propose to the auxiliary loss to utilize the frozen PVASS network to align VA features of real videos, to better assist multimodal deepfake detector for capturing subtle VA inconsistencies. We conduct extensive experiments on existing widely used and latest multimodal deepfake datasets. Our method obtains a significant performance improvement compared to state-of-the-art methods. © 1991-2012 IEEE.","Multimodal deepfake detection; self-supervised auxiliary; visual-audio alignment"
"Li, C.; Zheng, Z.; Bin, Y.; Wang, G.; Yang, Y.; Li, X.; Shen, H.T.","Li, Congrui (58523252800); Zheng, Ziqiang (57202612793); Bin, Yi (56490132600); Wang, Guoqing (56467514700); Yang, Yang (57222954946); Li, Xuesheng (35744943600); Shen, Hengtao (7404523209)","58523252800; 57202612793; 56490132600; 56467514700; 57222954946; 35744943600; 7404523209","Pixel Bleach Network for Detecting Face Forgery Under Compression","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166782027&partnerID=40&md5=33c5801d176f1d17d8fee8a5f72ffa3e","The existing face forgery algorithms have achieved remarkable progress in how to generate reasonable facial images and can even successfully deceive human beings. Considering public security, face forgery detection is of vital importance, making it essential to design face forgery detection algorithms to detect forgery images over the Internet. Despite the great success achieved by the existing Deepfake detection algorithms, they usually failed to achieve satisfactory Deepfake detection performance when deployed to handle the forgery videos in practice. One significant reason is compression. The videos over the Internet are inevitably compressed considering the transmission efficiency. The video compression results in significant Deepfake detection performance degradation for the existing Deepfake detection algorithms. To address this issue, in this article, we propose a generic, simple yet effective 'bleaching' pre-processing module based on the generative model and the high-level feature representations to produce a bleached image, which shares a similar appearance with the compressed images. The bleached images with recovered information can be identified accurately by the optimized Deepfake detection models without retraining. The proposed method has utilized a redesigned feature representation, which serves as a navigator to effectively and sufficiently alter the feature distribution in the high-dimensional space to remedy the difference between real facial images and forgery counterparts. Thus, the proposed method can successfully avoid misclassification. Comprehensive and extensive experiments are carried out on four low-quality Faceforensics++ datasets, demonstrating the effectiveness of our method in recovering the information loss caused by the compression artifacts across various backbones and compression. © 1999-2012 IEEE.","adversarial learning; Deepfake detection; robust deepfake detection under compression"
"Lu, W.; Liu, L.; Zhang, B.; Luo, J.; Zhao, X.; Zhou, Y.; Huang, J.","Lu, Wei (57715097700); Liu, Lingyi (57225946988); Zhang, Bolin (58088015500); Luo, Junwei (57220005361); Zhao, Xianfeng (55623697900); Zhou, Yicong (24175343600); Huang, Jiwu (56057258200)","57715097700; 57225946988; 58088015500; 57220005361; 55623697900; 24175343600; 56057258200","Detection of Deepfake Videos Using Long-Distance Attention","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147274802&partnerID=40&md5=125a32284add9bba30a850c8ef4f0e85","With the rapid progress of deepfake techniques in recent years, facial video forgery can generate highly deceptive video content and bring severe security threats. And detection of such forgery videos is much more urgent and challenging. Most existing detection methods treat the problem as a vanilla binary classification problem. In this article, the problem is treated as a special fine-grained classification problem since the differences between fake and real faces are very subtle. It is observed that most existing face forgery methods left some common artifacts in the spatial domain and time domain, including generative defects in the spatial domain and interframe inconsistencies in the time domain. And a spatial-temporal model is proposed which has two components for capturing spatial and temporal forgery traces from a global perspective, respectively. The two components are designed using a novel long-distance attention mechanism. One component of the spatial domain is used to capture artifacts in a single frame, and the other component of the time domain is used to capture artifacts in consecutive frames. They generate attention maps in the form of patches. The attention method has a broader vision which contributes to better assembling global information and extracting local statistic information. Finally, the attention maps are used to guide the network to focus on pivotal parts of the face, just like other fine-grained classification methods. The experimental results on different public datasets demonstrate that the proposed method achieves state-of-the-art performance, and the proposed long-distance attention method can effectively capture pivotal parts for face forgery. © 2023 IEEE.","Attention mechanism; deepfake detection; face manipulation; spatial; temporal artifacts"
"Wang, F.; Chen, Q.; Jing, B.; Tang, Y.; Song, Z.; Wang, B.","Wang, Fei (58366999700); Chen, Qile (59750265200); Jing, Botao (59336619000); Tang, Yeling (58120138500); Song, Zengren (57367945900); Wang, Bo (57216234699)","58366999700; 59750265200; 59336619000; 58120138500; 57367945900; 57216234699","Deepfake Detection Based on the Adaptive Fusion of Spatial-Frequency Features","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003150882&partnerID=40&md5=451678173b529f075493173354472720","Detecting deepfake media remains an ongoing challenge, particularly as forgery techniques rapidly evolve and become increasingly diverse. Existing face forgery detection models typically attempt to discriminate fake images by identifying either spatial artifacts (e.g., generative distortions and blending inconsistencies) or predominantly frequency-based artifacts (e.g., GAN fingerprints). However, a singular focus on a single type of forgery cue can lead to limited model performance. In this work, we propose a novel cross-domain approach that leverages a combination of both spatial and frequency-aware cues to enhance deepfake detection. First, we extract wavelet features using wavelet transformation and residual features using a specialized frequency domain filter. These complementary feature representations are then concatenated to obtain a composite frequency domain feature set. Furthermore, we introduce an adaptive feature fusion module that integrates the RGB color features of the image with the composite frequency domain features, resulting in a rich, multifaceted set of classification features. Extensive experiments conducted on benchmark deepfake detection datasets demonstrate the effectiveness of our method. Notably, the accuracy of our method on the challenging FF++ dataset is mostly above 98%, showcasing its strong performance in reliably identifying deepfake images across diverse forgery techniques. © © 2024 Fei Wang et al.","adaptive fusion; deepfake detection; spatial and frequency domain; wavelet transform"
"Zheng, Z.; Qi, G.; Cao, Y.; Wei, M.; Li, Y.","Zheng, Zhuqing (59721217700); Qi, Guanglei (56704389900); Cao, Yuqing (59721401300); Wei, Mingqi (59721760500); Li, Yimeng (59721942400)","59721217700; 56704389900; 59721401300; 59721760500; 59721942400","DeepFake Detection with 3D Face Perception","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001674694&partnerID=40&md5=42df8d068029186b9ab84c4033cb23f5","With the development of deep learning technology, the emergence of DeepFake technology makes fake video and image become more real, it brought many safe hidden trouble to the society. In this paper, we propose a DeepFake detection method based on 3D face perception, which aims to effectively identify fake face images. By generating and detecting facial features, we use a binary classifier to discriminate the generated weights. In addition, combining Generative adversarial Network (GAN) and Convolutional Neural Network (CNN) technology, we designed a feature detection and extraction mechanism to improve the accuracy and robustness of detection. The experimental results show that the proposed method has significant performance advantages in DeepFake detection task. © 2024 IEEE.","3D face perception; DeepFake detection task; facial features"
"Bharti, A.; Sinha, V.K.; Peter, J.S.P.; Esther, B.","Bharti, Ayush (59540669400); Sinha, Vishal Kumar (59540687100); Peter, J. Selvin Paul (60023910100); Esther, B. Priya (57076747600)","59540669400; 59540687100; 60023910100; 57076747600","ForgeryDetect: AI-driven Deep Fake Identification","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001659409&partnerID=40&md5=e3e21ffa340b5130bddf53a016999693","The rise of deepfake videos presents substantial obstacles in guaranteeing the genuineness and reliability of visual media material. This study focuses on the crucial problem of identifying deepfake content by introducing a sophisticated method that combines ResNext CNNs along with LSTM models, utilizing transfer learning approaches. Employed a comprehensive approach by using a wide array of datasets such as FaceForensics++, Celeb-DF, and the Deepfake Detection Challenge. Utilizing transfer learning, a ResNext CNN that has been pre-trained is employed to extract complex features from video frames. This enables the subsequent training of an LSTM layer to identify temporal patterns and distinctive cues that are exclusive to modified videos. The effectiveness of fusion model has been demonstrated through extensive experimentation and validation on these rich datasets. It demonstrates a strong ability to reliably distinguish between authentic and manipulated movies, regardless of the different facial alteration techniques, environmental variables, and complex situations seen in real-life situations. The integration of ResNext-based feature extraction with LSTM-based temporal modeling shows substantial progress in the detection of deepfake videos. The efficacy of approach is highly promising, since it provides both dependability and scalability. This study makes a significant contribution to the field of deepfake identification by offering a powerful collection of techniques to tackle the growing concerns surrounding disinformation and manipulation in visual media. © 2024 IEEE.","Celeb-DF; Convolutional neural networks (CNNs); Deepfake detection; Deepfake Detection Challenge; FaceForensics++; long short-term memory (LSTM); LSTM; ResNext; Transfer learning; Video manipulation"
"Chouhan, Y.A.; Chudasama, C.; Verma, D.K.; Lunagaria, M.","Chouhan, Yashoda Alpesh (59699988700); Chudasama, Chetankumar (59700764100); Verma, Deepak Kumar (57486550400); Lunagaria, Munindra (57194506650)","59699988700; 59700764100; 57486550400; 57194506650","Comparative Analysis of Machine Learning and Deep Learning Models for Deepfake Detection: Insights from the Celeb-DF Dataset","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000269892&partnerID=40&md5=956361bc3735c1f9dde592385a90aae0","We live in a digital age where reality is a maze of mirrors, where manipulation of data is at the tip of our fingers. The spread of misinformation and the unwanted spread of deepfakes have become prevalent. In times like these, there is a dire need to create a foundation of security that can be generated by accurate deepfake detection models. In order to conduct this research, we train 12 deepfake detection models using the Celeb-DF dataset, which consists of real and artificial celebrity videos. We then evaluate the results using five metrics: Accuracy, Precision, Recall, F1 Score, and ROC AUC Score. Among all the models the highest accuracy score of 94% was achieved by ResNet50. The AUC score of the models were impressive ranging from 89% -98%. The main objective of this paper is to use a thorough comparative study of a blend of deep learning and machine learning models in order to address privacy and confidentiality issues in the era of digital deception and build confidence in visual media. © 2024 IEEE.","Celeb-DF; Deep learning; Deepfake Detection; Face forging; Machine learning"
"Kundu, S.; Ghosh, T.; Naskar, R.","Kundu, Srijit (59407898000); Ghosh, Tanusree (58722055200); Naskar, Ruchira (53866980700)","59407898000; 58722055200; 53866980700","Using Local Phase Quantization to Identify Fake Faces in Online Social Networks","2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000249821&partnerID=40&md5=38bfb39f7772609b705616c9fec9c309","The rapid advancement of Generative AI, especially Generative Adversarial Networks (GANs), has increased the issue of fake news on Online Social Networks (OSNs) by generating deceptive face images for social media profiles. Although existing detection methods are accurate, their effectiveness decreases when images are post-processed, which is common on OSNs. In this paper, we present LPQ-Net, a model combining Local Phase Quantization (LPQ) for feature extraction with a CNN-based classifier. We explore two variants: one sets a new benchmark in detecting StyleGAN2-generated images, and the other excels in identifying images shared on Facebook, WhatsApp, and Instagram. LPQ-Net also operates with minimal parameters, outperforming state-of-the-art methods and making it ideal for resource-constraint applications. Furthermore, our solution demonstrates its effectiveness by performing exceptionally well in detecting images generated by various Diffusion models. We further show that incorporating LPQ features into fine-tuned classifiers like ResNet50, ResNet101, InceptionV3, and DenseNet121 significantly improves performance. © 2024 IEEE.","Deepfake Detection; Diffusion Models; Digital Image Forensics; GAN"
"Jiang, W.; Guo, Z.; Liang, R.","Jiang, Weiqiang (57217307920); Guo, Zhongyuan (58416367300); Liang, Ruigang (57205634095)","57217307920; 58416367300; 57205634095","Using ensemble models to detect deepfake images of human faces","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185536692&partnerID=40&md5=794e128b8044d09b4cf626e7543bb157","Deepfakes, synthetic media generated through advanced artificial intelligence techniques, are a rising threat to content authenticity. This paper explores deepfake detection methods to discern manipulated media from genuine content. We evaluate two convolutional neural network (CNN) architectures - EfficientNetB4 and EfficientNetB4 with attention mechanisms - on the Forensics++ and DeepFake Detection Challenge datasets. Our key contributions are: 1) Demonstrating that integrating attention enhances model performance, with EfficientNetB4 attention achieving superior accuracy over baseline EfficientNetB4 in both intra-dataset and cross-dataset scenarios; 2) Elucidating attention’s efficacy in improving deepfake detection by concentrating on manipulated regions. Our experiments highlight attention’s potential in advancing state-of-the-art deepfake detection. As deepfakes grow increasingly realistic, robust techniques like attention become imperative for multimedia forensics. This paper provides valuable insights toward developing adaptable deepfake detection systems to preserve content integrity. © 2023 Copyright held by the owner/author(s).","CNN; Deepfake Detection; Multiple-Head Attention"
"Huang, P.-H.; Han, Y.-H.; Chu, E.; Chen, J.-C.; Hua, K.-L.","Huang, Pohan (58087552100); Han, Yuehua (58087467500); Chu, Ernie (58345064000); Chen, Juncheng (56684395200); Hua, Kailung (55223901500)","58087552100; 58087467500; 58345064000; 56684395200; 55223901500","Multi-Task Self-Blended Images for Face Forgery Detection","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182947502&partnerID=40&md5=2e6d0d50a0a16a4dd4183b231ac9978d","Deepfake detection has attracted extensive attention due to widespread forged images on social media. Recently, self-supervised learning (SSL) based Deepfake detection approaches have outperformed supervised methods in terms of model generalization. However, we notice that most SSL-based methods do not take the manipulation strength levels of synthesized forgery samples into consideration according to different synthesis parameters and result in suboptimal detection performances. To address this issue, we introduce several auxiliary losses to the state-of-the-art SSL-based method based on different synthesis sub-tasks during data generation by inferring their synthesis parameters where the ground-truth labels are obtained from the synthesis pipeline for free. With comprehensive evaluations on various benchmarks, our approach has achieved noticeable performance improvement. Specifically, for the cross-dataset evaluation, the proposed approach outperforms the state-of-the-art method in terms of AUC on various datasets with improvements of 3.4%, 1.47%, 1.56%, and 1.3% on the CDF, DFDC, DFDCP, and FFIW datasets and achieves competitive performance on the DFD dataset. This further demonstrates the effectiveness of the proposed approach in its generalization ability. © 2023 Copyright held by the owner/author(s).","Deepfake Detection; Face Forgery Detection; Multi-Task; Self-Supervised Learning"
"Yang, J.; Sun, Y.; Mao, M.; Bai, L.; Zhang, S.; Wang, F.","Yang, Jun (57337213700); Sun, Yaoru (36562722100); Mao, Maoyu (57336378200); Bai, Lizhi (57939051800); Zhang, Siyu (57202335087); Wang, Fang (56892440700)","57337213700; 36562722100; 57336378200; 57939051800; 57202335087; 56892440700","Model-Agnostic Method: Exposing Deepfake Using Pixel-Wise Spatial and Temporal Fingerprints","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162725777&partnerID=40&md5=18b6a3829eea05b0482a7d2546707713","Deepfake poses a serious threat to the reliability of judicial evidence and intellectual property protection. Existing detection methods either blindly utilize deep learning or use biosignal features, but neither considers spatial and temporal relevance of face features. These methods are increasingly unable to resist the growing realism of fake videos and lack generalization. In this paper, we identify a reliable fingerprint through the consistency of AR coefficients and extend the original PPG signal to 3-dimensional fingerprints to effectively detect fake content. Using these reliable fingerprints, we propose a novel model-agnostic method to expose Deepfake by analyzing temporal and spatial faint synthetic signals hidden in portrait videos. Specifically, our method extracts two types of faint information, i.e., PPG features and AR features, which are used as the basis for forensics in temporal and spatial domains, respectively. PPG allows remote estimation of the heart rate in face videos, and irregular heart rate fluctuations expose traces of tampering. AR coefficients reflect pixel-wise correlation and spatial traces of smoothing caused by up-sampling in the process of generating fake faces. Furthermore, we employ two ACBlock-based DenseNets as classifiers. Our method provides state-of-the-art performance on multiple deep forgery datasets and demonstrates better generalization. © 2023 IEEE.","Auto-regressive (AR); deep learning; deepfake detection; fingerprint; photoplethysmography (PPG); temporal and spatial"
"Cheng, H.; Guo, Y.; Wang, T.; Li, Q.; Chang, X.; Nie, L.","Cheng, Harry (57226475825); Guo, Yangyang (57204980391); Wang, Tianyi (57211200251); Li, Qi (57832229800); Chang, Xiaojun (56177050500); Nie, Liqiang (36439883200)","57226475825; 57204980391; 57211200251; 57832229800; 56177050500; 36439883200","Voice-Face Homogeneity Tells Deepfake","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181501368&partnerID=40&md5=508000663f215df2cd6ffe89bd100931","Detecting forgery videos is highly desirable due to the abuse of deepfake. Existing detection approaches contribute to exploring the specific artifacts in deepfake videos and fit well on certain data. However, the growing technique on these artifacts keeps challenging the robustness of traditional deepfake detectors. As a result, the development of these approaches has reached a blockage. In this article, we propose to perform deepfake detection from an unexplored voice-face matching view. Our approach is founded on two supporting points: first, there is a high degree of homogeneity between the voice and face of an individual (i.e., they are highly correlated), and second, deepfake videos often involve mismatched identities between the voice and face due to face-swapping techniques. To this end, we develop a voice-face matching method that measures the matching degree between these two modalities to identify deepfake videos. Nevertheless, training on specific deepfake datasets makes the model overfit certain traits of deepfake algorithms. We instead advocate a method that quickly adapts to untapped forgery, with a pre-training then fine-tuning paradigm. Specifically, we first pre-train the model on a generic audio-visual dataset, followed by the fine-tuning on downstream deepfake data. We conduct extensive experiments over three widely exploited deepfake datasets: DFDC, FakeAVCeleb, and DeepfakeTIMIT. Our method obtains significant performance gains as compared to other state-of-the-art competitors. For instance, our method outperforms the baselines by nearly 2%, achieving an AUC of 86.11% on FakeAVCeleb. It is also worth noting that our method already achieves competitive results when fine-tuned on limited deepfake data. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.","cross-modal matching; Deepfake detection; face; voice"
"Wu, J.; Zhou, J.; Wang, D.; Wang, L.","Wu, Jiujiu (59426904000); Zhou, Jiyu (59426878400); Wang, Danyu (58154359400); Wang, Lin (59426892000)","59426904000; 59426878400; 58154359400; 59426892000","Exploring spatial–temporal features fusion model for Deepfake video detection","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210321530&partnerID=40&md5=032f9b324e9ec71b66efc106dee085d4","The rapid development of Deepfake technology has posed significant challenges in detecting fake videos. In response to the existing problems in reference frame selection, spatial–temporal feature mining, and fusion in face-swapping video detection techniques, we propose a face-swapping video detection model based on spatial–temporal feature fusion. First, key frame sequences are selected using interframe facial edge region differences. Then, the key frame sequences are separately input into the spatial branch to extract hidden artifacts and the temporal branch to extract inconsistent information. Finally, the spatial–temporal features are fused using a self-attention mechanism and input into a classifier to achieve detection results. To validate the effectiveness of the proposed model, we conducted experiments on the Faceforensics++ and Celeb-DF open-source Deepfake datasets. The experimental results demonstrate that the proposed model achieves better detection accuracy and higher-ranking generalization performance than state-of-the-art competitors. © 2023 SPIE and IS&T.","attention block; Deepfake detection; key frame; temporal–spatial fusion"
"Chen, B.; Liu, X.; Xia, Z.; Zhao, G.","Chen, Beijing (36805188500); Liu, Xin (58744297900); Xia, Zhihua (35075519800); Zhao, Guoying (47661917700)","36805188500; 58744297900; 35075519800; 47661917700","Privacy-preserving DeepFake face image detection","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173809074&partnerID=40&md5=cbb4e285c9ea7c343e504443cdbb1f15","All the existing models for DeepFake detection focus on plaintext faces. However, outsourced computing is usually considered in practical applications for DeepFake detection and the input data may contain private and sensitive information. Thus, a privacy-preserving model named Secure DeepFake Detection Network (SecDFDNet) is proposed for the first time in this paper. The SecDFDNet uses the additive secret sharing method for secure DeepFake face detection. Specifically, firstly, some multi-party secure interaction protocols are designed for non-linear activation functions, i.e., SecReLU for ReLU function, SecSigm for sigmoid function, SecSpatial for spatial attention, and SecChannel for channel attention. Their security is proved in theory. Our protocols have low communication and space complexity. Then, the SecDFDNet model is proposed by using the designed secure protocols and trained plaintext DeepFake detection network (DFDNet). The experimental results show that the proposed SecDFDNet can detect DeepFake faces without revealing anything of private input, achieve the same accuracies as the plaintext DFDNet and outperform some existing models. The source code is available at https://github.com/imagecbj/Privacy-Preserving-DeepFake-Face-Image-Detection. © 2023 Elsevier Inc.","Additive secret sharing; DeepFake; DeepFake detection; Privacy protection; Secure interaction protocol"
"Tian, L.; Yao, H.; Li, M.","Tian, Lulu (58261894100); Yao, Hongxun (57204325155); Li, Ming (57250212100)","58261894100; 57204325155; 57250212100","FakePoI: A Large-Scale Fake Person of Interest Video Detection Benchmark and a Strong Baseline","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159711770&partnerID=40&md5=2c0eef42cc996894f2481daaea4ac039","Deepfake technique can synthesize realistic images, audios, and videos, facilitating the thriving of entertainment, education, healthcare, and other industries. However, its abuse may pose potential threats to personal privacy, social stability, and even national security. Therefore, the development of deepfake detection methods is attracting more and more attention. Existing works mainly focus on the detection of common videos for entertainment purposes. In contrast, fake videos maliciously synthesized for Person of Interest (PoI, i.e., who is in an authoritative position and has broadly public influences) are much more harmful to society because of celebrity endorsement. However, there is no particular benchmark for driving related research in the community. Motivated by this observation, we present the first large-scale benchmark dataset, named FakePoI, to enable the research on fake PoI detection. It contains numerous fake videos of important people from all walks of life, e.g., police chiefs, city mayors, famous artists, and well-known Internet bloggers. In summary, our FakePoI includes 11092 synthesized videos where only a few clips rather than the entire are fake. Previous fake detection algorithms deteriorate heavily or even fail on our FakePoI due to two main challenges. On the one hand, the rich diversity of our fake videos makes it pretty difficult to find universally applicable patterns for detection. On the other hand, the high credibility contributed by the presence of real frames easily confuses a common detector. To tackle these challenges, we present an amplifier framework, highlighting the feature gap between real and generated video frames. Specifically, we present a quadruplet loss to narrow the distance of all real PoIs and meanwhile push away each real and fake PoI in embedding space. We implement our framework and conduct extensive experiments on the proposed benchmark. The quantitative results demonstrate that our approach outperforms existing methods significantly, setting a strong baseline on FakePoI. The qualitative analysis also shows its superiority. We will release our dataset and code at https://github.com/cslltian/deepfake-detection to encourage future research on this valuable area. © 2023 IEEE.","deepfake detection; face reconstruction; face swap; Person of interest; video clustering"
"Wu, J.; Zhang, B.; Li, Z.; Pang, G.; Teng, Z.; Fan, J.","Wu, Jianghao (58260652500); Zhang, Baopeng (57211546343); Li, Zhaoyang (58084749500); Pang, Guilin (57202025774); Teng, Zhu (36553668200); Fan, Jianping (57220794072)","58260652500; 57211546343; 58084749500; 57202025774; 36553668200; 57220794072","Interactive Two-Stream Network Across Modalities for Deepfake Detection","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159670945&partnerID=40&md5=7c9a44d4eb64d4a023c5088f157740ac","As face forgery techniques have become more mature, the proliferation of deepfakes may threaten the security of human society. Although existing deepfake detection methods achieve good performance for in-dataset evaluation, it remains to be improved in the generalization ability, where the representation of the imperceptible artifacts plays a significant role. In this paper, we propose an Interactive Two-Stream Network (ITSNet) to explore the discriminant inconsistency representation from the perspective of cross-modality. In particular, the patch-wise Decomposable Discrete Cosine Transform (DDCT) is adopted to extract fine-grained high-frequency clues, and information from different modalities communicates with each other via a designed interaction module. To perceive the temporal inconsistency, we first develop a Short-term Embedding Module (SEM) to refine subtle local inconsistency representation between adjacent frames, and then a Long-term Embedding Module (LEM) is designed to further refine the erratic temporal inconsistency representation from the long-range perspective. Extensive experimental results conducted on three public datasets show that ITSNet outperforms the state-of-the-art methods both in terms of in-dataset and cross-dataset evaluations. © 2023 IEEE.","cross-modality learning; Deepfake detection; inconsistency representation"
"Liu, C.; Chen, H.; Zhu, T.; Zhang, J.; Zhou, W.","Liu, Chi (57206078266); Chen, Huajie (57566120100); Zhu, Tianqing (9737124100); Zhang, Jun (57198771239); Zhou, Wanlei (7404511655)","57206078266; 57566120100; 9737124100; 57198771239; 7404511655","Making DeepFakes More Spurious: Evading Deep Face Forgery Detection via Trace Removal Attack","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148464129&partnerID=40&md5=86ba1a0d9f39b31b23d23b89bd24d085","DeepFakes are raising significant social concerns. Although various Despite various DeepFake detectors having been developed as countermeasures, their vulnerability under attacks remains further explorations. Recently, several attacks, such as adversarial attacks, have successfully fooled DeepFake detectors. However, existing attacks suffer from detector-specific designs, requiring detector-side knowledge, leading to poor transferability. Moreover, they only consider simplified security scenarios; but less is known about the attacking performance in complex scenarios where the capability of detectors or attackers varies. To fill the gap, we propose a novel, detector-agnostic trace removal attack. The attack removes all possible counterfeiting traces arising from the original DeepFake manufacture procedure to make DeepFakes essentially more ""realistic""and thus able to defeat arbitrary or unknown detectors. Concretely, we first perform an in-depth DeepFake trace discovery, identifying three intrinsic traces: spatial anomalies, spectral disparities, and noise fingerprints. Then an adversarial learning-based trace removal network (TR-Net) involving one generator and multiple discriminators is proposed. Each discriminator is responsible for one individual trace representation to avoid inner-trace interference. All discriminators are optimized in parallel to enforce the generator to remove various traces simultaneously. We additionally craft heterogeneous security scenarios where the detectors are embedded with different levels of defense and the attackers own varying background data knowledge. The experimental results show that the proposed trace removal attack can significantly compromise the detection accuracy of six state-of-the-art DeepFake detectors while causing only a negligible degradation in visual quality. © 2004-2012 IEEE.","Adversarial attack; anti-forensics; deepfake detection; image forgery"
"Yang, G.; Xu, K.; Fang, X.; Zhang, J.","Yang, Gaoming (36976637300); Xu, Kun (57920584000); Fang, Xianjin (26423619800); Zhang, Ji (57225122203)","36976637300; 57920584000; 26423619800; 57225122203","Video face forgery detection via facial motion-assisted capturing dense optical flow truncation","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139500002&partnerID=40&md5=4e68234623468347addaa31a2254a450","Deep learning advancements have resulted in breakthroughs in facial forgery techniques. Facial forgery videos are growing increasingly lifelike, making it impossible for people to tell the difference between the real and the fake. The proliferation of facial forgery techniques, as well as the slowness with which they may be detected, could jeopardize personal data security. As a result, it’s critical to look at approaches that can be trained on both real and fake videos and then utilized to identify facial forgeries or not in videos. This study found that forged face videos undergo truncation between consecutive frames of optical flow imaging after dense optical flow processing. We present an approach for detecting video face forgery that extracts and analyzes characteristics from real and fake material, then use those features to train classification models on Celeb-DF and FaceForensics++. In addition, we employ a unique facial double-triangle region to assist in the extraction of video inter-frame feature data. Experiments results show that the facial motion features extracted from the double triangle region successfully assist in capturing the dense optical flow truncation. Extensive evaluation suggests that our proposed approach is effective for video face forgery detection. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","Deep learning; Deepfakes detection; Dense optical flow; Face forgery detection"
"Naitali, A.; Ridouani, M.; Salahdine, F.; Kaabouch, N.","Naitali, Amal (58667629500); Ridouani, Mohammed (56038636000); Salahdine, Fatima (57189066697); Kaabouch, Naima (22634156500)","58667629500; 56038636000; 57189066697; 22634156500","Deepfake Attacks: Generation, Detection, Datasets, Challenges, and Research Directions","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175002929&partnerID=40&md5=925b3ace65405dd62265eb2dfe622245","Recent years have seen a substantial increase in interest in deepfakes, a fast-developing field at the nexus of artificial intelligence and multimedia. These artificial media creations, made possible by deep learning algorithms, allow for the manipulation and creation of digital content that is extremely realistic and challenging to identify from authentic content. Deepfakes can be used for entertainment, education, and research; however, they pose a range of significant problems across various domains, such as misinformation, political manipulation, propaganda, reputational damage, and fraud. This survey paper provides a general understanding of deepfakes and their creation; it also presents an overview of state-of-the-art detection techniques, existing datasets curated for deepfake research, as well as associated challenges and future research trends. By synthesizing existing knowledge and research, this survey aims to facilitate further advancements in deepfake detection and mitigation strategies, ultimately fostering a safer and more trustworthy digital environment. © 2023 by the authors.","deep learning; deepfake detection; face forgery; generative artificial intelligence; vision transformers"
"Kingra, S.; Aggarwal, N.; Kaur, N.","Kingra, Staffy (57192255022); Aggarwal, Naveen (36875216400); Kaur, Nirmal (57189220908)","57192255022; 36875216400; 57189220908","SiamNet: Exploiting source camera noise discrepancies using Siamese Network for Deepfake Detection","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163196991&partnerID=40&md5=0a1d12c675526a544737a4808469475a","Recent advancements in deep neural networks especially GAN (Generative Adversarial Network) have resulted in the creation of more realistic deepfake media. This technology can swap the source person's face or alter facial expressions in an image or video; Media manipulated in such a way is termed deepfake. This type of manipulated media poses potential risks to journalism, politics, court proceedings and various social aspects. While existing approaches concentrate on the use of deep neural networks to directly extract facial artefacts for deepfake detection, they do not examine subtle inconsistencies in/across frame/frames. Moreover, state-of-the-art deepfake detection networks appear more complex and tend to overfit on specific artefacts which limits their generalizability on unseen data. This paper proposed a novel technique that tackles the problem of manipulated face detection in videos and images by exploiting the noise pattern inconsistency amongst face region and rest of the frame. To enable a comparison between the noise patterns of these two regions, we propose a two-stream Siamese-like network called SiamNet. This network can extract the noise patterns of the face region and patch through separate streams without increasing the number of parameters, thereby enhancing its efficiency and effectiveness. Each branch consists of pretrained Inception-v3 architecture for camera noise extraction. Siamese training is utilized to compare both noise patterns computed through different base models. The proposed two-branch network, SiamNet is found efficient for several large-scale deepfake datasets such as FF++, Celeb-DF, DFD and DFDC achieving accuracy rates of 99.7%, 98.3%, 96.08% and 89.2% respectively. Furthermore, the proposed technique exhibits greater generalizability and outperforms state-of-the-art of deepfake detection methods. Performance of the proposed model is also evaluated on FaceForensics benchmark dataset against different approaches. © 2023 Elsevier Inc.","Camera noise; Deepfake detection; Face-patch; Facial manipulation detection; Video forensics"
"Liu, S.; Chen, J.; Chen, W.; Li, J.","Liu, Shuo (57191659103); Chen, Jie (58852386500); Chen, Wentao (58837725300); Li, Jichao (58788668700)","57191659103; 58852386500; 58837725300; 58788668700","Research on robustness evaluation and verification for facial deepfake detection","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181148207&partnerID=40&md5=30e95aa826a318e325c8d9888d895d4a","Recently, due to the increasing harm caused by facial deepfake videos, the detection technology of facial deepfakes has attracted wide interest, and designing a scientific evaluation mechanism is conducive to the application of the technology. However, the complex perturbations in the actual scene reduce the detection performance of facial deepfake detection, and the existing evaluation indicators can not fully measure the robustness of the detection technology. To this end, this paper proposes a new robustness evaluation index system, the AUC decrease rate, and AUC stability range under multiple perturbations. Through the verification of multiple detection models with multiple datasets, the experimental results show that the proposed index can simply and intuitively evaluate the robustness of the detection technology, which is valuable for the construction of future evaluation standards. © 2023 ACM.","Facial deepfake detection; indicator validation; perturbations analysis; robustness evaluation"
"Yu, Y.; Ni, R.; Zhao, Y.; Yang, S.; Xia, F.; Jiang, N.; Zhao, G.","Yu, Yang (57210753156); Ni, Rongrong (55632437300); Zhao, Yao (35304414700); Yang, Siyuan (57221158200); Xia, Fen (58303787300); Jiang, Ning (57264662700); Zhao, Guoqing (57928752500)","57210753156; 55632437300; 35304414700; 57221158200; 58303787300; 57264662700; 57928752500","MSVT: Multiple Spatiotemporal Views Transformer for DeepFake Video Detection","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161067862&partnerID=40&md5=3d59a7978322be77eada5868903a0a5b","Recently, DeepFake videos have developed rapidly, causing new security issues in society. Due to the rough spatiotemporal view, existing video-based detection methods struggle to capture fine-grained spatiotemporal information, resulting in limited generalization ability. In addition, although the transformer has achieved great success in the past few years, the application of transformer on deepfake video detection still needs to be studied. To solve this problem, in this paper, we propose a novel Multiple Spatiotemporal Views Transformer (MSVT) with Local Spatiotemporal View (LSV) and Global Spatiotemporal View (GSV), to mine more detailed spatiotemporal information. Firstly, for establishing the LSV, different from existing works that sparsely sample a single frame to build the input sequence, we employ the local-consecutive temporal view to capture vital dynamic inconsistency. Furthermore, the extracted frame features within each group are fed to the temporal transformer followed by the feature fusion module, to generate group-level spatiotemporal features. Then, we further establish Global Spatiotemporal View (GSV) by feeding all the frame features within the whole video to the temporal transformer followed by the feature fusion module. Finally, we propose a novel global-local transformer (GLT) to effectively integrate these multi-level features for mining more subtle and comprehensive features. Extensive experiments on six large datasets demonstrate that our MSVT outperforms state-of-the-art detection methods. © 1991-2012 IEEE.","Generalized DeepFake detection; global-local transformer; multiple spatiotemporal views"
"Liang, Y.; Wang, M.; Jin, Y.; Pan, S.; Yong, Y.","Liang, Yufei (57547903500); Wang, Mengmeng (57193745284); Jin, Yining (57224528340); Pan, Shuwen (7402713446); Yong, Liu (56011543900)","57547903500; 57193745284; 57224528340; 7402713446; 56011543900","Hierarchical supervisions with two-stream network for Deepfake detection","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162908018&partnerID=40&md5=6403886f30c80d8770c356a2f008d15c","Recently, the quality of face generation and manipulation has reached impressive levels, making it difficult even for humans to distinguish real and fake faces. At the same time, methods to distinguish fake faces from reals came out, such as Deepfake detection. However, the task of Deepfake detection remains challenging, especially the low-quality fake images circulating on the Internet and the diversity of face generation methods. In this work, we propose a new Deepfake detection network that could effectively distinguish both high-quality and low-quality faces generated by various generation methods. First, we design a two-stream framework that incorporates a regular spatial stream and a frequency stream to handle the low-quality problem since we find that the frequency domain artifacts of low-quality images will be preserved. Second, we introduce hierarchical supervisions in a coarse-to-fine manner, which consists of a coarse binary classification branch to classify reals and fakes and a five-category classification branch to classify reals and four different types of fakes. Extensive experiments have proved the effectiveness of our framework on several widely used datasets. © 2023","Coarse to fine; Deepfake detection; Frequency domain; Two stream"
"Xu, K.; Yang, G.; Fang, X.; Zhang, J.","Xu, Kun (57920584000); Yang, Gaoming (36976637300); Fang, Xianjin (26423619800); Zhang, Ji (57225122203)","57920584000; 36976637300; 26423619800; 57225122203","Facial depth forgery detection based on image gradient","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149045180&partnerID=40&md5=72192db88633da154cd3298c1b52c0d0","With the widespread application of deep learning, many artificially generated fake images and videos appear on the Internet. However, it is difficult for people to distinguish the real from the fake ones, making the research on detecting and recognizing fake images or videos receive significant attention. Since new forgery techniques can reduce the effectiveness of specific detection methods or even make them ineffective, research on detecting facial depth forgery needs to be continuously developed. To defend against the onslaught of new facial depth forgery methods, we proposed an image gradient-based approach to transform the facial depth forgery detection problem into the recognition and analysis of video frames. Specifically, there are two key components in this approach: (1) we capture images from videos and crop the face section, which dramatically reduces the amount of data; (2) we use the image gradient operator to process the face image that extracts image features for detection and recognition. After these, we have conducted extensive experiments on different facial depth forgery datasets. Experimental results demonstrated that using our image gradient approach could effectively detect facial depth forgery and achieve excellent detection and identification performance. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Deep learning; DeepFakes detection; Facial depth forgery detection; Image gradient"
"Zhao, Y.; Jin, X.; Gao, S.; Wu, L.; Yao, S.; Jiang, Q.","Zhao, Yi (58605259600); Jin, Xin (56991832300); Gao, Song (57202999590); Wu, Liwen (57200984308); Yao, Shaowen (24473851600); Jiang, Qian (57194699462)","58605259600; 56991832300; 57202999590; 57200984308; 24473851600; 57194699462","TAN-GFD: generalizing face forgery detection based on texture information and adaptive noise mining","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148240697&partnerID=40&md5=d1bb4d0b25d4f5176801cfeb6448744a","Face forgery detection has become a research hotspot due to security concerns about spreading ultrarealisitc fake faces over social platforms. However, most existing deep learning-based approaches fail to generalize in cross-dataset scenarios since the learning-based methods tend to overfit manipulation-specific artifacts and advanced manipulations tamper with the target face locally or globally. In this work, we find that multiscale texture differences and regional noise inconsistencies are two intrinsic but complementary forged clues in the face manipulation pipeline. To comprehensively dig into generalized forgery clues, we propose a novel framework named TAN-GFD, based on texture information and adaptive noise mining. Specifically, we design a texture difference representation block that combines pixel intensity and gradient information of feature maps to extract multiscale texture difference features from different shallow feature maps. Moreover, since face tampering in real scenes swaps the whole face or partial facial expressions, we thus design the multilevel adaptive noise mining module, which consists of data preprocessing with learnable SRM filters and a cross-modality feature pyramid block, to capture the abundant features of regional noise inconsistencies. In addition, we introduce the cross-entropy loss with supervised contrastive loss collaboration strategy to guide the framework in learning more generalized representations. Extensive experiments on several benchmark datasets demonstrate the effectiveness and superior generalization performance of our framework. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","DeepFake detection; Face forgery detection; Multimedia forensics; SRM; Texture difference"
"Pang, G.; Zhang, B.; Teng, Z.; Qi, Z.; Fan, J.","Pang, Guilin (57202025774); Zhang, Baopeng (57211546343); Teng, Zhu (36553668200); Qi, Zige (58087970800); Fan, Jianping (57220794072)","57202025774; 57211546343; 36553668200; 58087970800; 57220794072","MRE-Net: Multi-Rate Excitation Network for Deepfake Video Detection","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147287860&partnerID=40&md5=320fa9985e9013574dca4cc987676a59","The current social media is flooded with hyper realistic face-synthetic videos due to the explosion of DeepFake technology that has brought a serious impact on human society security, which calls for further exploring on deepfake video detection methods. Existing methods attempt to isolated capture spatial artifacts or extract the homogeneous temporal inconsistency to detect deepfake video, but little attention has been paid to the exploitation of dynamic spatial-temporal inconsistency. To mitigate this issue, in this paper, we propose a novel Multi-Rate Excitation Network (MRE-Net) to effectively excite dynamic spatial-temporal inconsistency from the perspective of multiple rates for deepfake video detection. The proposed MRE-Net is composed of two components: Bipartite Group Sampling (BGS) and multiple rate branches. The BGS draws the entire video into multiple bipartite groups with different rates to cover various face motion dynamic evolution. We further design multiple rate branches to capture both short-term and long-term spatial-temporal inconsistency from corresponding bipartite groups of BGS. Concretely, for the early stages of the multi-rate branches, Momentary Inconsistency Excitation (MIE) module is developed to encode the spatial artifacts and intra-group short-term temporal inconsistency. Meanwhile, for the last stages of the multi-rate branches, Longstanding Inconsistency Excitation (LIE) module is constructed to perceive inter-group long-term temporal dynamics. Extensive experiments and visualizations conducted on four popular datasets demonstrate the effectiveness of the proposed method against state-of-the-art deepfake detection methods. © 2023 IEEE.","Deepfake detection; longstanding inconsistency; momentary inconsistency"
"Liang, P.; Liu, G.; Xiong, Z.; Fan, H.; Zhu, H.; Zhang, X.","Liang, Peifeng (59775033100); Liu, Gang (56403521800); Xiong, Zenggang (22636267500); Fan, Honghui (34871760900); Zhu, Hongjin (55637664700); Zhang, Xuemin (55715193100)","59775033100; 56403521800; 22636267500; 34871760900; 55637664700; 55715193100","A facial geometry based detection model for face manipulation using CNN-LSTM architecture","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150044861&partnerID=40&md5=1ebee9494551bb9b3c516cfb837567f9","This issue of DeepFake technique that may cause great threat to privacy, democracy, and national security has attracted the attention of deep learning researchers. DeepFake detection, therefore, has been a very hot issue in deep learning research. The face landmark feature maps are often used by many DeepFake approaches in generating fake faces. It also provides key information to help to detect manipulated face images. In this paper, we propose a detection approach for manipulated face images. To make full use of face landmark information, we propose a facial geometry prior module (FGPM) to extract facial geometry feature maps. Then the facial geometry feature maps are embedded into upsampling feature maps generated by the CNN-LSTM network. The proposed FGPM exploits facial maps and frequency domain correlation to analyze the discriminative characteristics between manipulated and non-manipulated regions by incorporating the CNN-LSTM network. Finally, a decoder is used to learn the mapping from low-resolution feature maps to pixel-wise to predict manipulation localization. Or a softmax classifier is used to predict real or fake face images. By experimenting on several popular datasets, the proposed detection model has demonstrated the capability of localizing manipulation at the pixel level and with a high prediction on real or fake face images. © 2023","CNN-LSTM; DeepFake detection; Facial analysis; Facial geometry prior module; Resampling"
"Beckmann, A.; Hilsmann, A.; Eisert, P.","Beckmann, Arian (58310040500); Hilsmann, Anna (24830180600); Eisert, Peter (55892485300)","58310040500; 24830180600; 55892485300","Fooling State-of-the-art Deepfake Detection with High-quality Deepfakes","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165736654&partnerID=40&md5=26035f8a6eec61cc72381ed794c0dd29","Due to the rising threat of deepfakes to security and privacy, it is most important to develop robust and reliable detectors. In this paper, we examine the need for high-quality samples in the training datasets of such detectors. Accordingly, we show that deepfake detectors proven to generalize well on multiple research datasets still struggle in real-world scenarios with well-crafted fakes. First, we propose a novel autoencoder for face swapping alongside an advanced face blending technique, which we utilize to generate 90 high-quality deepfakes. Second, we feed those fakes to a state-of-the-art detector, causing its performance to decrease drastically. Moreover, we fine-tune the detector on our fakes and demonstrate that they contain useful clues for the detection of manipulations. Overall, our results provide insights into the generalization of deepfake detectors and suggest that their training datasets should be complemented by high-quality fakes since training on mere research data is insufficient. © 2023 Owner/Author.","dataset; deepfake detection; face swapping; forgery"
"Dogoulis, P.; Kordopatis-Zilos, G.K.; Kompatsiaris, I.; Papadopoulos, S.","Dogoulis, Pantelis (55541551800); Kordopatis-Zilos, Giorgos (56411991900); Kompatsiaris, Ioannis (Yiannis) (7004756014); Papadopoulos, Symeon (23095370800)","55541551800; 56411991900; 7004756014; 23095370800","Improving Synthetically Generated Image Detection in Cross-Concept Settings","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163632342&partnerID=40&md5=1c9093b8db44308c1a83400370d74e12","New advancements for the detection of synthetic images are critical for fighting disinformation, as the capabilities of generative AI models continuously evolve and can lead to hyper-realistic synthetic imagery at unprecedented scale and speed. In this paper, we focus on the challenge of generalizing across different concept classes, e.g., when training a detector on human faces and testing on synthetic animal images - highlighting the ineffectiveness of existing approaches that randomly sample generated images to train their models. By contrast, we propose an approach based on the premise that the robustness of the detector can be enhanced by training it on realistic synthetic images that are selected based on their quality scores according to a probabilistic quality estimation model. We demonstrate the effectiveness of the proposed approach by conducting experiments with generated images from two seminal architectures, StyleGAN2 and Latent Diffusion, and using three different concepts for each, so as to measure the cross-concept generalization ability. Our results show that our quality-based sampling method leads to higher detection performance for nearly all concepts, improving the overall effectiveness of the synthetic image detectors. © 2023 ACM.","deepfake detection; generalization; synthetically generated images"
"Zhu, C.; Yin, C.; Zhang, B.; Yin, Q.; Lu, W.","Zhu, Chuntao (57393753500); Yin, Chengxi (58529050800); Zhang, Bolin (58088015500); Yin, Qilin (57205390745); Lu, Wei (57715097700)","57393753500; 58529050800; 58088015500; 57205390745; 57715097700","Forgery face detection method based on multi-domain temporal features mining; 基于多域时序特征挖掘的伪造人脸检测方法","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167455377&partnerID=40&md5=7671a61d69d3ef7e9267418e1ec478d6","Financial technology has greatly facilitated people’s daily life with the continuous development of computer technology in the financial services industry. However, digital finance is accompanied by security problems that can be extremely harmful. Face biometrics, as an important part of identity information, is widely used in payment systems, account registration, and many other aspects of the financial industry. The emergence of face forgery technology constantly impacts the digital financial security system, posing a threat to national asset security and social stability. To address the security problems caused by fake faces, a forgery face detection method based on multi-domain temporal features mining was proposed. The tampering features were distinguished and enhanced based on the consistency of statistical feature data distribution and temporal action trend in the temporal features of videos existing in the spatial domain and frequency domain. Temporal information was mined in the spatial domain using an improved LSTM, while in the frequency domain, temporal information existing in different frequency bands of the spectrum was mined using 3D convolution layers. The information was then fused with the tampering features extracted from the backbone network, thus effectively distinguishing forged faces from real ones. The effectiveness of the proposed method was demonstrated on mainstream datasets. © © Editorial Office of Journal of Fisheries of China.","Deepfake detection; face authentication; multi-domain features; temporal features"
"Dong, F.; Zou, X.; Wang, J.; Liu, X.","Dong, Fengkai (58174333800); Zou, Xiaoqiang (58172828500); Wang, Jiahui (57211449510); Liu, Xiyao (57095810500)","58174333800; 58172828500; 57211449510; 57095810500","Contrastive learning-based general Deepfake detection with multi-scale RGB frequency clues","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151906434&partnerID=40&md5=603f5eb21a4f36f4ae0d7733d4d87637","Deepfake is a type of image and video face manipulation methods which could cause security and society threats. Although some related databases and detection models have been proposed for detecting face forgery media, achieving a generalizable detector for both known and unknown manipulations remains challenging. In this study, a novel deepfake detection model with high generalizability is proposed to tackle this issue. We employ supervised contrastive learning to enhance the generalizability to unknown manipulations and datasets. In addition, we design a cross-modality data augmentation method by combining SRM and RGB features to extract detection clues comprehensively. Furthermore, we propose a multi-scale feature enhancement module to enhance textural and semantic information. Extensive experiments have demonstrated that our method improves model generalization in both intra- and cross- dataset scenarios. © 2023 The Author(s)","Contrastive learning; Data augmentation; Deepfake detection; Face forgery detection; Multi-modality feature learning"
"Firc, A.; Malinka, K.; Hanáček, P.","Firc, Anton (57699371300); Malinka, Kamil (24824985000); Hanáček, Petr (6508388287)","57699371300; 24824985000; 6508388287","Deepfakes as a threat to a speaker and facial recognition: An overview of tools and attack vectors","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151552922&partnerID=40&md5=ea70f98bad877b1f1bc8875fb2c58cf2","Deepfakes present an emerging threat in cyberspace. Recent developments in machine learning make deepfakes highly believable, and very difficult to differentiate between what is real and what is fake. Not only humans but also machines struggle to identify deepfakes. Current speaker and facial recognition systems might be easily fooled by carefully prepared synthetic media – deepfakes. We provide a detailed overview of the state-of-the-art deepfake creation and detection methods for selected visual and audio domains. In contrast to other deepfake surveys, we focus on the threats that deepfakes represent to biometrics systems (e.g., spoofing). We discuss both facial and speech deepfakes, and for each domain, we define deepfake categories and their differences. For each deepfake category, we provide an overview of available tools for creation, datasets, and detection methods. Our main contribution is a definition of attack vectors concerning the differences between categories and reported real-world attacks to evaluate each category's threats to selected categories of biometrics systems. © 2023","Biometrics systems; Cybersecurity; Deepfake detection; Face deepfakes; Facial recognition; Speaker recognition; Speech deepfakes"
"Guo, Z.; Yang, G.; Zhang, D.; Xia, M.","Guo, Zhiqing (57219672095); Yang, Gaobo (8647279200); Zhang, Dengyong (55318418900); Xia, Ming (55994627200)","57219672095; 8647279200; 55318418900; 55994627200","Rethinking gradient operator for exposing AI-enabled face forgeries","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143813019&partnerID=40&md5=085c851c1d67beb9c5b2b2500f4d9be0","For image forensics, convolutional neural networks (CNNs) tend to learn image content features rather than subtle manipulation traces, which constrains detection performance. Existing works usually address this issue by following a common pipeline, namely subtracting the original pixel value from the predicted pixel value to enforce CNNs to learn more features from the manipulation traces. However, due to the complicated learning mechanism, they might still have some unnecessary performance losses. In this work, we rethink the advantages of image gradient operator in exposing AI-enabled face forgeries, and design two plug-and-play modules, namely tensor pre-processing (TP) and manipulation trace attention (MTA), by combining the gradient operator with CNNs. Specifically, the TP module refines the feature tensor of each channel in the network by the gradient operator to highlight manipulation traces and improve feature representation. Moreover, the MTA module considers two dimensions, namely channel and manipulation traces, to enforce the network to learn the distribution of the manipulation traces. Both modules can be seamlessly integrated into existing CNNs for end-to-end training. Experiments show that the proposed expert system achieves better results than prior works on five public image datasets. The code is available at: https://github.com/EricGzq/GocNet-pytorch. © 2022 Elsevier Ltd","Attention mechanism; Deepfake detection; Face forgery detection; Gradient operator; Tensor pre-processing"
"Li, X.; Ni, R.; Yang, P.; Fu, Z.; Zhao, Y.","Li, Xin (57775419200); Ni, Rongrong (55632437300); Yang, Pengpeng (57193388775); Fu, Zhiqiang (57219867572); Zhao, Yao (35304414700)","57775419200; 55632437300; 57193388775; 57219867572; 35304414700","Artifacts-Disentangled Adversarial Learning for Deepfake Detection","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141481872&partnerID=40&md5=ec01619ddefc052e701d3d389bb93d8b","Due to the development of facial manipulation technologies, the generated deepfake videos cause a severe trust crisis in society. Existing methods prove that effective extraction of the artifacts introduced during the forgery process is essential for deepfake detection. However, since the features extracted by supervised binary classification contain a lot of artifact-irrelevant information, existing algorithms suffer severe performance degradation in the case of the mismatch between training and testing datasets. To overcome this issue, we propose an Artifacts-Disentangled Adversarial Learning (ADAL) framework to achieve accurate deepfake detection by disentangling the artifacts from irrelevant information. Furthermore, the proposed algorithm provides visual evidence by effectively estimating artifacts. Specifically, Multi-scale Feature Separator (MFS) in the disentanglement generator is designed to precisely transmit the artifact features and optimize the connection between the encoder and decoder. In addition, we design an Artifacts Cycle Consistency Loss (ACCL) which uses the disentangled artifacts to construct new samples and enables pixel-level supervised training for the generator to estimate more accurate artifacts. The symmetric discriminators are paralleled to differentiate the constructed samples from the original images in both fake and real domains, making the adversarial training process more stable. Extensive experiments on existing benchmarks demonstrate that the proposed method outperforms the state-of-the-art approaches. © 1991-2012 IEEE.","artifacts; Deepfake detection; disentanglement learning; video forensics"
"Ma, Z.; Mei, X.; Chen, H.; Shen, J.","Ma, Zhiyuan (58079714800); Mei, Xue (23091706700); Chen, Haoyang (58079458100); Shen, Jie (57196190343)","58079714800; 23091706700; 58079458100; 57196190343","Multi-Scale Feature Enhancement Network for Face Forgery Detection","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163285997&partnerID=40&md5=246d67660759851445d66992492d5d77","Nowadays, synthesizing realistic fake face images and videos becomes easy benefiting from the advance in generation technology. With the popularity of face forgery, abuse of the technology occurs from time to time, which promotes the research on face forgery detection to be an emergency. To deal with the potential risks, we propose a face forgery detection method based on multi-scale feature enhancement. Specifically, we analyze the forgery traces from the perspective of texture and frequency domain, respectively. We find that forgery traces are hard to be perceived by human eyes but noticeable in shallow layers of CNNs and middle-frequency domain and high-frequency domain. Hence, to reserve more forgery information, we design a texture feature enhancement module and a frequency domain feature enhancement module, respectively. The experiments on FaceForensics++ dataset and Celeb-DF dataset show that our method exceeds most existing networks and methods, which proves that our method has strong classification ability. © 2023 ACM.","DeepFake detection; Digital video forensics; Face forgery detection; Multi-scale feature fusion"
"Ke, J.; Wang, L.","Ke, Jianpeng (57220586690); Wang, Li'na (55899978500)","57220586690; 55899978500","DF-UDetector: An effective method towards robust deepfake detection via feature restoration","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146677449&partnerID=40&md5=c1da0485c8574da5227d9eef1366bb85","The abuse of deepfakes, a rising face swap technique, causes severe concerns about the authenticity of visual content and the dissemination of misinformation. To alleviate the threats imposed by deepfakes, a vast body of data-centric detectors has been deployed. However, the performance of these methods can be easily defected by degradations on deepfakes. To improve the performance of degradation deepfake detection, we creatively explore the recovery method in the feature space to preserve the artifacts for detection instead of directly in the image domain. In this paper, we propose a method, namely DF-UDetector, against degradation deepfakes by modeling the degraded images and transforming the extracted features to a high-quality level. To be specific, the whole model consists of three key components: an image feature extractor to capture image features, a feature transforming module to map the degradation features into a higher quality, and a discriminator to determine whether the feature map is of high quality enough. Extensive experiments on multiple video datasets show that our proposed model performs comparably or even better than state-of-the-art counterparts. Moreover, DF-UDetector outperforms by a small margin when detecting deepfakes in the wild. © 2023 Elsevier Ltd","Deep learning; Deep neural networks; Deepfakes; Degradation deepfake detection; Face manipulation; Feature space manipulation"
"Chen, H.; Lin, Y.; Li, B.; Tan, S.","Chen, Han (57192537490); Lin, Yuzhen (57210221355); Li, Bin (57102112000); Tan, Shunquan (25960429800)","57192537490; 57210221355; 57102112000; 25960429800","Learning Features of Intra-Consistency and Inter-Diversity: Keys Toward Generalizable Deepfake Detection","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139497781&partnerID=40&md5=45c6008470bfe3aec2cb6c429b6d05a9","Public concerns about deepfake face forgery are continually rising in recent years. Most deepfake detection approaches attempt to learn discriminative features between real and fake faces through end-to-end trained deep neural networks. However, the majorities of them suffer from the problem of poor generalization across different data sources, forgery methods, and/or post-processing operations. In this paper, following the simple but effective principle in discriminative representation learning, i.e., towards learning features of intra-consistency within classes and inter-diversity between classes, we leverage a novel transformer-based self-supervised learning method and an effective data augmentation strategy towards generalizable deepfake detection. Considering the differences between the real and fake images are often subtle and local, the proposed method firstly utilizes Self Prediction Learning (SPL) to learn rich hidden representations by predicting masked patches at a pre-training stage. Intra-class consistency clues in images can be mined without deepfake labels. After pre-training, the discrimination model is then fine-tuned via multi-task learning, including a deepfake classification task and a forgery mask estimation task. It is facilitated by our new data augmentation method called Adjustable Forgery Synthesizer (AFS), which can conveniently simulate the process of synthesizing deepfake images with various levels of visual reality in an explicit manner. AFS greatly prevents overfitting due to insufficient diversity in training data. Comprehensive experiments demonstrate that our method outperforms the state-of-the-art competitors on several popular benchmark datasets in terms of generalization to unseen forgery methods and untrained datasets. © 1991-2012 IEEE.","Deepfake detection; generalization; masked image modeling; self-supervised learning; transformer"
"Kingra, S.; Aggarwal, N.; Kaur, N.","Kingra, Staffy (57192255022); Aggarwal, Naveen (36875216400); Kaur, Nirmal (57189220908)","57192255022; 36875216400; 57189220908","Emergence of deepfakes and video tampering detection approaches: A survey","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136822967&partnerID=40&md5=0ba52f712aa105f5f8837bf00d9bc210","Digital content, particularly the digital videos recorded at specific angle, though, provides a truthful picture of reality but the widespread proliferation of easy-to-use content editing softwares doubt about its authenticity. Recently, Artificial Intelligence (AI) based content altering mechanism, known as deepfake, became popular on social media platforms, wherein any person can be able to purport the behaviour of another person in a video who is actually not there. Depending on the type of manipulation performed, different types of deepfakes are described in this paper. Moreover, rely on digital content for trustworthy evidence as well as to avoid spread of misinformation, integrity and authenticity of digital content has-been of utmost concerns. This paper aims to present a survey of the state-of-art video integrity verification techniques with special emphasis on emerging deepfake video detection approaches. Seeing the advancement in creation of more realistic deepfake videos, this review facilitates the development of more generalized methods with a thorough discussion on different research trends in the wake of deepfake detection. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Audio deepfake detection; Deepfake detection; Facial manipulation detection; Video forensics; Video forgery detection"
"Liang, B.; Wang, Z.; Huang, B.; Zou, Q.; Wang, Q.; Liang, J.","Liang, Buyun (57226460106); Wang, Zhongyuan (57325546400); Huang, Baojin (57219588586); Zou, Qin (55628590470); Wang, Qian (56856235900); Liang, Jingjing (58018670600)","57226460106; 57325546400; 57219588586; 55628590470; 56856235900; 58018670600","Depth map guided triplet network for deepfake face detection","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144083980&partnerID=40&md5=ea129f3206f148ce17241dc8d974c6e9","The widespread dissemination of facial forgery technology has brought many ethical issues and aroused widespread concern in society. Most research today treats deepfake detection as a fine grained classification task, which however makes it difficult to enable the feature extractor to express the features related to the real and fake attributes. This paper proposes a depth map guided triplet network, which mainly consists of a depth prediction network and a triplet feature extraction network. The depth map predicted by the depth prediction network can effectively reflect the differences between real and fake faces in discontinuity, inconsistent illumination, and blurring, thus in favor of deepfake detection. Regardless of the facial appearance changes induced by deepfake, we argue that real and fake faces should correspond to their respective latent feature spaces. Particularly, the pair of real faces (original–target) remain close in the latent feature space, while the two pairs of real–fake faces (original–fake, target–fake) instead keep faraway. Following this paradigm, we suggest a triplet loss supervision network to extract the sufficiently discriminative deep features, which minimizes the distance of the original–target pair and maximize the distance of the original–fake (also target–fake) pair. The extensive results on public FaceForensics++ and Celeb-DF datasets validate the superiority of our method over competitors. © 2022 Elsevier Ltd","Deepfake detection; Depth map; Triplet network"
"Sunil, R.; Mer, P.; Diwan, A.","Sunil, Reshma (58883764800); Mer, Parita (58883877800); Diwan, Anjali (57216898522)","58883764800; 58883877800; 57216898522","Autonomous Detection and Evaluation of Deepfakes: A Comprehensive Study","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195240724&partnerID=40&md5=e00398b09a17ad6ce77268e935305830","In recent times, there has been a notable advancement in deepfake techniques and the accessibility of extensive, cost-free databases. Consequently, even folks lacking technological expertise can now edit or produce visually authentic samples for various goals, both benign and harmful in nature. This paper provides a comprehensive analysis of the classification of methods used for deepfake generation and detection. The paper considers numerous factors, including the identified forgery, methodology or techniques used, evaluation metrics used for performance analysis, and the utilized dataset. By studying the development of deepfakes and the most up-to-date deepfake detecting methods, this study gives a full picture of deepfake techniques and makes it easier to come up with new, more reliable methods to fight the growing difficulty of deepfakes. © 2023 IEEE.","Artifacts; CNN; Deepfake Detection; Deepfakes; Face Swap; Facial Reenactment; GANs; Synthetic Media"
"Neha; Arora, B.","Neha (58422138500); Arora, Bhavna (57225027341)","58422138500; 57225027341","Deep Learning based Model for Deepfake Image Detection: An Analytical Approach","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191814583&partnerID=40&md5=d3de2d17ea187f4abf1ec101533fa262","Recent years have witnessed great improvement in deepfake technology, spurred by advancements in deep learning models and improved processing capacity. Generative models at the cutting edge of technology have made it possible to produce convincingly realistic synthetic videos, images, and even audio recordings. Deeply fabricated media has the power to harm not just individuals but also our society, institutions, countries, religions, and others. These fake images may circulate online in low quality and contain many forms of distortion that could impair the effectiveness of detection methods. Our study employed a dataset of 140K Real and Fake images to analyse how image distortions affect the detection model using one of the deep learning models, DenseNet. This is accomplished by adding blur and noise to the original dataset and feeding it to the trained neural network to discriminate real and deepfake images. The results demonstrate that the model's accuracy decreased with the low-quality dataset. © 2023 IEEE.","Deep Learning; Deepfake Detection; Deepfake Generation; Face Manipulation; Generative Adversarial Networks; Image Distortions"
"Yu, Q.; Wang, X.; Jia, M.; Bai, N.; Hou, J.; Liu, D.","Yu, Qinhua (58660625000); Wang, Xiaofeng (56028744400); Jia, Mao (58862963600); Bai, Ningning (58102462000); Hou, Jianpeng (58861477200); Liu, Dong (58421064500)","58660625000; 56028744400; 58862963600; 58102462000; 58861477200; 58421064500","GTA-Net: A Robust Method for Deepfake Face Image Detection","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189371187&partnerID=40&md5=9cc03f234257a36d4955be5eb973938e","The rapid advancement of artificial intelligence technology has resulted in the emergence of deepfake, which has had a significant impact on various fields due to its realistic effects. Addressing the challenges posed by deepfake has become a crucial area of research. In this study, we propose a two-stream network framework, GTA-Net, for the detection of deepfake face images. The framework comprises a Global Residual Attention module (GRA), a Texture Feature Saliency module (TFS), and an Attention Feature Fusion module (AFF). We incorporate Local Binary Patterns (LBP) features into the network input to guide the decision-making process of the model towards prominent texture features, thereby enhancing detection accuracy. Additionally, we employ a residual attention mechanism to focus on specific deepfake-generated features and improve robustness by avoiding interference from content-preserving manipulations. Experimen-tal results show that the proposed method has high detection accuracy and strong robustness against degraded datasets, and generalization for cross-dataset detection. © 2023 IEEE.","deepfake detection; generalization; robustness; texture feature saliency"
"Yasser, B.; Hani, J.; El-Gayar, S.; Amgad, O.; Ahmed, N.; Ebied, H.M.; Amr, H.; Salah, M.","Yasser, Basma (58876477800); Hani, Jumana (58876691000); El-Gayar, Salma (58876585100); Amgad, Omar (58876426000); Ahmed, Nourhan (58277395200); Ebied, Hala Mousher (25640793000); Amr, Habiba (58876691100); Salah, Mohamed (57208404295)","58876477800; 58876691000; 58876585100; 58876426000; 58277395200; 25640793000; 58876691100; 57208404295","Deepfake Detection Using EfficientNet and XceptionNet","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184655300&partnerID=40&md5=2ed92b728b77a5aa439f2c9649d9aec4","The increasing prevalence of manipulated media, particularly deepfake videos, poses significant challenges in distinguishing real from fake content. This paper addresses the issue of detecting deepfake videos using advanced CNN architectures such as EfficientNet-B4 and XceptionNet. The FF++ and Celeb-DF (v2) datasets are used to compare real and fake videos. The methodology involves preprocessing the Celeb- DF dataset by extracting frames and isolating faces, training the models, and evaluating their performance using log loss and Area Under the Curve (AUC) metrics. The study shows that both models are effective in accurately classifying real and fake videos and highlights the importance of continuously updating deepfake detection algorithms in response to evolving deepfake generation techniques. © 2023 IEEE.","accuracy; cropping faces; Deepfake Detection; EfficientNet; Extracting Frames; XceptionNet"
"Yang, R.; Xu, D.; Cheng, Y.","Yang, Ruijun (55976231000); Xu, Donggai (58810368900); Cheng, Yan (57199040774)","55976231000; 58810368900; 57199040774","Lightweight detection method for deepfake face video","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182271608&partnerID=40&md5=8e8700aab4100eaaf0dcc11580fc46dd","This paper proposes a lightweight fake facial video classification detection model to address the issues of insufficient accuracy, poor robustness, and excessive parameters in existing forgery face video detection models. The model utilizes an improved version of EfficientNetV2-S as the backbone network for feature extraction. The MTCNN algorithm is employed to extract the facial region and perform alignment, while data augmentation techniques are applied to enhance the model's robustness. The pre-processed data is then fed into the backbone network for classification detection. Furthermore, in order to improve the performance of the network model, reduce the influence of network parameters, and decrease model complexity, the structure of the backbone network is streamlined and the composition of the network is adjusted. Additionally, the CBAM attention module is introduced to enable the shallow model to capture more facial details. Experimental results demonstrate that compared to the original EfficientNetV2-S model, the proposed model achieves a 50% reduction in parameter count. Moreover, it achieves accuracy improvements of 1.1%, 2.8%, and 3.1% on the FaceForensice++, Celeb-DF-v1, and DFDC datasets, respectively. When compared with the Xception, CapsuleNet, and DefakeHop models in the field, varying degrees of improvement are also observed. © 2023 IEEE.","CBAM; Deepfake Detection; EfficientnetV2-S; Lion Optimization; MTCNN"
"Patel, Y.; Tanwar, S.; Gupta, R.; Bhattacharya, P.; Davidson, I.E.; Nyameko, R.; Aluvala, S.; Vimal, V.","Patel, Yogesh M. (57214439687); Tanwar, Sudeep (56576145100); Gupta, Rajesh (57201584761); Bhattacharya, Pronaya (57200306370); Davidson, Innocent Ewean (7103403083); Nyameko, Royi (58764621200); Aluvala, Srinivas (46160933400); Vimal, Vrince (56595022000)","57214439687; 56576145100; 57201584761; 57200306370; 7103403083; 58764621200; 46160933400; 56595022000","Deepfake Generation and Detection: Case Study and Challenges","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179831457&partnerID=40&md5=6eb5fb6bba6cc677b26acf000abbe68d","In smart communities, social media allowed users easy access to multimedia content. With recent advancements in computer vision and natural language processing, machine learning (ML), and deep learning (DL) models have evolved. With advancements in generative adversarial networks (GAN), it has become possible to create fake images/audio/and video streams of a person or use some person's audio and visual details to fit other environments. Thus, deepfakes are specifically used to disseminate fake information and propaganda on social circles that tarnish the reputation of an individual or an organization. Recently, many surveys have focused on generating and detecting deepfake images, audio, and video streams. Existing surveys are mostly aligned toward detecting deepfake contents, but the generation process is not suitably discussed. To address the survey gap, the paper proposes a comprehensive review of deepfake generation and detection and the different ML/DL approaches to synthesize deepfake contents. We discuss a comparative analysis of deepfake models and public datasets present for deepfake detection purposes. We discuss the implementation challenges and future research directions regarding optimized approaches and models. A unique case study, IBMM is discussed, which presents a multi-modal overview of deepfake detection. The proposed survey would benefit researchers, industry, and academia to study deepfake generation and subsequent detection schemes. © 2023 The Authors.","Artificial intelligence; Deepfake detection; Deepfake generation; fake content; generative adversarial networks"
"Shakya, A.; Jenni, K.; Perumal, M.; Srinivas, M.","Shakya, Ankit (58759265600); Jenni, Kommineni (56592775600); Perumal, Murukessan (57217871215); Srinivas, Mettu (56289483700)","58759265600; 56592775600; 57217871215; 56289483700","HF-Detect A Hybrid Detector for Manipulated Face Detection","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179504048&partnerID=40&md5=487d15cf58cf43489170519f9d85c2d3","The recent advancement of fake face creation and fake face generation motivates the development of an excellent fake face detection method that can effectively detect the difference between fake and real. Various fake detection methods are available with adequate performance, but the limitation of those available methods is they are not performing well with highly compressed images with degraded quality. Manipulation of face images is getting advanced, and becoming difficult to trust the content over the media, and generating and detection should go parallelly to balance society. Therefore we are proposing a novel approach to solve this problem which uses the hybrid model HF-Detect, which combines the advantage of the Xception network along with the F3Net. © 2023 IEEE.","Artificial Intelligence; Computer Vision; Deep Learning; DeepFake Detection"
"She, H.; Hu, Y.; Liu, B.; Li, J.; Li, C.-T.","She, Huimin (58504567900); Hu, Yongjian (35766130600); Liu, Beibei (55544736500); Li, Jicheng (57201859261); Li, Chang Tsun (26648782200)","58504567900; 35766130600; 55544736500; 57201859261; 26648782200","Learnable Information-Preserving Image Resizer for Face Forgery Detection","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177071505&partnerID=40&md5=2d557a13625e0e87dc6f937c6655aacb","Resizing input face images of arbitrary sizes to a uniform size is an essential preprocessing to satisfy the architectural requirements of face forgery detectors. In this letter, we reveal an important observation that traditional resizing methods degrade the performance of face forgery detectors due to the loss of high-frequency information. To address this issue, we propose a simple yet effective learnable information-preserving resizer to replace its lossy traditional counterparts. Specifically, we use Haar transform to separate low- and high-frequency components, and then perform learnable resizing on the high-frequency sub-bands. We conduct experiments to compare our learnable resizer with other methods and evaluate three existing detectors with and without incorporating our resizer. Experimental results show that our resizer outperforms other resizers and consistently enhances the detection performance of tested detectors, confirming the effectiveness of our proposed resizer. © 1994-2012 IEEE.","deepfake detection; Face forgery detection; information-preserving resizer; learnable resizer"
"Lu, Y.; Luo, R.; Ebrahimi, T.","Lu, Yuhang (57352219800); Luo, Ruizhi (57565509600); Ebrahimi, Tourad (35560920500)","57352219800; 57565509600; 35560920500","Improving Deepfake Detectors against Real-world Perturbations with Amplitude-Phase Switch Augmentation","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176248132&partnerID=40&md5=60d8559c11ee3219a6f75c2bffaa4a92","In recent years, the remarkable progress in facial manipulation techniques has raised social concerns due to their potential malicious usage and has received considerable attention from both industry and academia. While current deep learning-based face forgery detection methods have achieved promising results, their performance often degrades drastically when they are tested in non-trivial situations under realistic perturbations. This paper proposes to leverage the information in the frequency domain, particularly the phase spectrum, to better differentiate between deepfakes and authentic images. Specifically, a new augmentation method called degradation-based amplitude-phase switch (DAPS) is proposed, which disregards the sensitive amplitude spectrum of a forged facial image and enforces the detection network to focus on phase components during the training process. Extensive evaluation results from a realistic assessment framework show that the proposed augmentation method significantly improves the robustness of two deepfake detectors analyzed and consistently outperform other augmentation approaches under various perturbations. © 2023 SPIE.","Data Augmentation; Deepfake Detection; Face Manipulation; Robustness"
"Wang, X.; Ma, D.; Wang, L.; Lu, Z.; Zhang, Z.; Jiang, J.","Wang, Xinzhe (57796712500); Ma, Duohe (56975751300); Wang, Liming (57196337846); Lu, Zhitong (57223248801); Zhang, Zhenchao (58684375400); Jiang, Junye (58613908000)","57796712500; 56975751300; 57196337846; 57223248801; 58684375400; 58613908000","Deepfake Detection Using Multiple Facial Features","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175956055&partnerID=40&md5=12bdbebc1ba23f2b4d0423398464f7d4","Deepfake digital forgery techniques leverage deep learning to replace faces and modify facial expressions in images and videos. The techniques have been used to produce fake pornography, spread fake news and rumors, influence public opinion and even elections. However, deepfake detection techniques are well behind deepfake generation technology. This chapter describes a deepfake video detection method that leverages aspect ratios to express multiple facial features. The aspect ratios of facial features are computed for every frame in a video and a time window is used to segment processed frame sequences into multiple short segments, following which pattern matching is employed to identify abnormal expressions that are indicative of deepfakes. Experiments with the FaceForensics++ and Celeb-DF datasets reveal that the proposed method detects deepfake videos effectively. Moreover, the aspect ratio computations improve the ability to detect compressed deepfake videos. © 2023, IFIP International Federation for Information Processing.","Aspect Ratios; Deepfake Detection; Facial Feature Extraction"
"Atamna, M.; Tkachenko, I.; Miguet, S.","Atamna, Mehdi (58784339900); Tkachenko, Iuliia (56038201900); Miguet, Serge (55932981600)","58784339900; 56038201900; 55932981600","Improving Generalization in Facial Manipulation Detection Using Image Noise Residuals and Temporal Features","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175075957&partnerID=40&md5=24887b0af3a77ac7934564ca81fea5d0","The high visual quality of modern deepfakes raises significant concerns about the trustworthiness of digital media and makes facial tampering detection more challenging. Although current deep learning-based deepfake detectors achieve excellent results when tested on deepfake images or image sequences generated using known methods, generalization - where a trained model is tasked with detecting deepfakes created with previously unseen manipulation techniques - is still a major challenge. In this paper, we investigate the impact of training spatial and spatio-temporal deep learning network architectures in the image noise residual domain using spatial rich model (SRM) filters on generalization performance. To this end, we conduct a series of tests on the manipulation methods of the FaceForensics++, DeeperForensics-1.0 and Celeb-DF datasets, demonstrating the value of image noise residuals and temporal feature exploitation in tackling the generalization task. © 2023 IEEE.","Deepfake detection; image forensics; steganalysis features; video manipulation detection"
"Wang, T.; Lü, X.","Wang, Tiantian (58655705100); Lü, Xiaoqi (14039286600)","58655705100; 14039286600","Face Forgery Detection Algorithm Based on Improved MobileViT Network","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174527071&partnerID=40&md5=ebea18beb5b9e4bc4564019fbbb45bab","DeepFakes blur the boundaries between reality and forgery, resulting in the collapse of exiting credit system, causing immeasurable consequences for national security and social order. Through analysis of existing face forgery techniques, it is found that most generation techniques rely on random noise distribution, and global information will be lost after up sampling. Therefore, we propose a deepfake detection algorithm based on improved MobileViT, which uses CNN local space biasing and the global space representation of the Transformer network to learn the local features and global representation of forged faces, respectively. Coordinate attention is introduced to obtain directional perception and position sensitive information, making the model locate synthetic traces of fake faces better and fusion local and global representation more effectively. For the improved generalization of the model, with the GELU activation function to solve the problem of neuron death. Our model achieved 96.2% on FF++(C23) datasets, and 93.7%,94.1%,96.3%,87.9% on DF, F2F, FS, and NT datasets, respectively. Comparing with previous methods, our model has shown detection robustness and better generalization. © 2023 IEEE.","Coordinate Attention; Deepfake Detection; GELU; MobileViT"
"Mao, Y.; You, W.; Zhou, L.; Lu, Z.","Mao, Yuzhe (58210037100); You, Weike (57195493773); Zhou, Linna (55966192200); Lu, Zhigao (58553429700)","58210037100; 57195493773; 55966192200; 58553429700","Fixing Domain Bias for Generalized Deepfake Detection","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171157496&partnerID=40&md5=2817c50faa4cefd148f40282e2bcfc43","Generalizing deepfake detection has posed a great challenge to digital media forensics, as inferior performance is obtained when training sets and testing sets are domain-mismatched. In this paper, we show that a CNN-based detection model can significantly improve performance by fixing domain bias. Specifically, we propose a novel Fixing Domain Bias network (FDBN). FDBN does not rely on manual features, but is based on three core designs. Firstly, a domain-invariant network based on randomly stylized normalization is devised to constrain the domain discrepancy in the feature space. Then, through adversarial learning, a generalizing representation in the stylized distribution is learned to enhance the shared feature bias among manipulation methods in the domain-specific network. Finally, to encourage equality of biases among different domains, we utilize the bias extrapolation penalty strategy by suppressing the expected bias on the extremely-performing domains. Extensive experiments demonstrate that our framework achieves effectiveness and generalization towards unseen face forgeries. © 2023 IEEE.","deepfake detection; domain bias; domain generalization; face forgery detection"
"Zhang, J.; Ni, J.","Zhang, Jian (58612848800); Ni, Jiangqun (13106118300)","58612848800; 13106118300","Domain-Invariant Feature Learning for General Face Forgery Detection","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171130441&partnerID=40&md5=06a7ae863134d027a52c908e88ad011b","Though existing methods for face forgery detection achieve fairly good performance under the intra-dataset scenario, few of them gain satisfying results in the case of cross-dataset testing with more practical value. To tackle this issue, in this paper, we propose a novel domain-invariant feature learning framework - DIFL for face forgery detection. In the framework, an adversarial domain generalization is introduced to learn the domain-invariant features from the forged samples synthesized by various algorithms. Then a center loss in fractional form (CL) is utilized to learn more discriminative features by aggregating the real faces while separating the fake faces from the real ones in the embedding space. In addition, a global and local random crop augmentation strategy is utilized to generate more data views of forged facial images at various scales. Extensive experimental results demonstrate the effectiveness and generalization of the proposed method compared with other state-of-the-art methods. © 2023 IEEE.","adversarial domain generalization; center loss; DeepFake detection"
"Xu, Y.; Zhang, D.D.; Sun, C.","Xu, Yijia (58567636900); Zhang, Dongdong (36633595100); Sun, Chengyu (35079450000)","58567636900; 36633595100; 35079450000","Frequency domain deepfake detection based on two-stream neural network","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170205700&partnerID=40&md5=8bce608ce5b4b8084e7ee2035d338659","Benefiting from the progress of deep learning driven generative models, face forgery technologies have rapidly become mature, thus raising public concerns about the illegal usage of these technologies. Despite the fact that fake images and videos are often unrecognizable to human eyes, recent work has found that hidden artifacts can be exposed in frequency domain. Our meth-od introduces the idea of separating human face area using landmarks before mining the forgery patterns in frequency domain. This we believe can help the network learn more discriminative features, also, a two-stream learning framework combining single-frame pathway and multi-frame pathway is developed to mine frequency clues. Compared with previous methods, our approach showed good results while using a few training data and little time. The effectiveness of our method is shown on different versions of the FF++ and Celeb-DF dataset. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","Deepfake Detection; Frequency Clues; Region Segmentation"
"Guo, W.; Du, S.; Deng, H.; Yu, Z.; Feng, L.","Guo, Wenxuan (58559615500); Du, Shuo (58560725100); Deng, Huiyuan (57222188054); Yu, Zikang (58560095400); Feng, Lin (36561284000)","58559615500; 58560725100; 57222188054; 58560095400; 36561284000","Towards Spatio-temporal Collaborative Learning: An End-to-End Deepfake Video Detection Framework","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169560939&partnerID=40&md5=9c515954992d10a601cac61d46f110fd","With the rapid development of facial tampering techniques, the deepfake detection task has attracted widespread social concerns. Most existing video-based methods adopt temporal convolution to learn temporal discontinuities directly, where they might neglect to explore both local detail mutation and inconsistent global expression semantics in the temporal dimension. This makes it difficult to learn more discriminative forgery cues. To mitigate this issue, we introduce a novel deepfake video detection framework specifically designed to capture fine-grained traces of tampering. Concretely, we first present a Multi-layered Feature Extraction module (MFE) that constructs comprehensive spatio-temporal representations by stitching different levels of features together. Afterward, we propose a Bidirectional temporal Artifact Enhancement module (BAE), which exploits local differences between adjacent frames to enhance frame-level features. Moreover, we present a Cross temporal Stride Aggregation strategy (CSA) to mine inconsistent global semantics and adaptively obtain multi-timescale representations. Extensive experiments on several benchmarks demonstrate that the proposed method outperforms state-of-the-art performance compared to other competitive approaches. © 2023 IEEE.","Deep Learning; Deepfake Detection; Face Forensics; Spatio-temporal Modeling"
"Li, Z.; Zhang, X.; Pu, Y.; Wu, Y.; Ji, S.","Li, Zeyu (58847214400); Zhang, Xuhong (57219174118); Pu, Yuwen (57892668600); Wu, Yiming (57201324849); Ji, Shouling (36918358000)","58847214400; 57219174118; 57892668600; 57201324849; 36918358000","A Survey on Multimodal Deepfake and Detection Techniques; 多模态深度伪造及检测技术综述","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169555553&partnerID=40&md5=603775446a6efac9a7935a90a9893baf","With the application of all kinds of deep learning generation models in various fields, the authenticity of their generated multimedia files has become increasingly difficult to distinguish, therefore, deepfake technology has been born and developed. Utilizing deep learning related techniques, the deepfake technology can tamper with the facial identity information, expressions, and body movements in videos or pictures, and generate fake voice of a specific person. Since 2018, when Deepfakes sparked a wave of face swapping on social networks, a large number of deepfake methods have been proposed, which had demonstrated their potential applications in education, entertainment, and some other fields. But at the same time, the negative impact of deepfake on public opinion, judicial and criminal investigations, etc. can not be ignored. As a consequence, more and more countermeasures have been proposed to prevent deepfake from being utilized by the criminals, such as the detection of deepfake and watermark. Firstly, a review and summary of deepfake technologies of different modal types and corresponding detection technologies are carried out, and the existing researches are analyzed and classified according to the research purpose and research method. Secondly, the video and audio datasets widely used in the recent studies are summarized. Finally, the opportunities and challenges for future development in this field are discussed. © 2023 Science Press. All rights reserved.","deep learning; deepfake; deepfake detection; face replacement; generative adversarial network"
"Rebello, L.; Tuscano, L.; Shah, Y.; Solomon, A.; Shrivastava, V.","Rebello, Lian (58538600600); Tuscano, Linnet (58538600700); Shah, Yash N. (57221354088); Solomon, Alvin (58538600800); Shrivastava, Varsha (57205388860)","58538600600; 58538600700; 57221354088; 58538600800; 57205388860","Detection of Deepfake Video using Deep Learning and MesoNet","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168143231&partnerID=40&md5=8c7b066c566d2071923906568231d393","Fraudsters are increasingly using evidence tampering to evade criminal charges and the acquisition of personal data for identity-related offenses. Deepfake is one of the most common strategies used today for identity theft and reputation defamation. To prevent the spread of these crimes, we need a system that can tell the difference between real and deep fake videos. Deep Neural Networks will be used in our system to identify and mark films as legitimate or manipulated, as well as the altered sections, by running the video through our trained Sequence Model, which can detect any discrepancies or alterations as a sequence of frames. LSTM will be used for temporal sequence analysis, and CNN will be employed for frame feature extraction. MesoNet is a neural network built primarily to identify deep fakes, but it would also be used for other purposes. MesoNet manages the noise produced by low-quality video processing, which impedes analysis. DeepFakes jeopardizes facial recognition and internet content. This deception is risky and can be exploited to impersonate a legitimate user. Our approach will propose a temporal-aware method for automatically detecting deepfake videos. © 2023 IEEE.","Convolution Neural Network; Deep Learning; DeepFake Detection; Long Short-Term Memory; MesoNet; Neural Networks; Recurrent Neural Network"
"Papa, L.; Faiella, L.; Corvitto, L.; Maiano, L.; Amerini, I.","Papa, Lorenzo (57670269300); Faiella, Lorenzo (58504544800); Corvitto, Luca (58503743800); Maiano, Luca (57212243213); Amerini, Irene (27567536300)","57670269300; 58504544800; 58503743800; 57212243213; 27567536300","On the use of Stable Diffusion for creating realistic faces: From generation to detection","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165617768&partnerID=40&md5=f483af0dab24b7d35c239068b4858030","The mass adoption of diffusion models has shown that artificial intelligence (AI) systems can be used to easily generate realistic images. The spread of these technologies paves the way to previously unimaginable creative uses while also raising the possibility of malicious applications. In this work, we propose a critical analysis of the overall pipeline, i.e., from creating realistic human faces with Stable Diffusion v1.5 [1] to recognizing fake ones. We first propose an analysis of the prompts that allow the generation of extremely realistic faces with a human-in-the-loop approach. Our objective is to identify the text prompts that drive the image generation process to obtain realistic photos that resemble everyday portraits captured with any camera. Next, we study how complex it is to recognize these fake contents for both AI-based models and non-expert humans. We conclude that similar to other deepzfake creation techniques, despite some limitations in generalization across different datasets, it is possible to use AI to recognize these contents more accurately than non-expert humans would. © 2023 IEEE.","Computer vision; Deepfake detection; Diffusion models; Prompt engineering; Security"
"Jaleel, Q.; Ali, I.H.","Jaleel, Qasim (57200678270); Ali, Israa H. (56526190500)","57200678270; 56526190500","MesoNet3: A Deepfakes Facial Video Detection Network Based on Object Behavior Analysis","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164273071&partnerID=40&md5=f8824233b86d33b21ba6c113cb4aa8a8","Deepfake is the process of manipulating objects with images and video. As a result of the development of deep learning techniques such as GAN, Deepfake has become closer to the truth. Many researchers are based on discovering deep fakes that were created by traditional methods. These methods produce often generate artifacts that may be subtle to humans. This paper can detect deepfakes that are perfectly created. Through the use of the new MesoNet3 algorithm to analyze behavior, facial expressions, and the appearance of an object based on a dataset. This paper consists of two stages. The first stage is to build a new MesoNet3 network that is trained on a set of data using a deepfake dataset. The second stage is to test the videos through the extraction of the face. After that, enter it into MesoNet3 and discover whether it is fake or not. The new MesoNet3 algorithm has proven its ability and accuracy in detecting fake video, compared to the old Meso-4. The accuracy of the MesoNet3 in detecting and distinguishing fake and real videos is %99.54. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","DeepFake Detection; Face Detection; Media Forensics; Meso-4; MesoNet3"
"Ma, Z.; Mei, X.; Shen, J.","Ma, Zhiyuan (58079714800); Mei, Xue (23091706700); Shen, Jie (57196190343)","58079714800; 23091706700; 57196190343","3D Attention Network for Face Forgery Detection","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164271522&partnerID=40&md5=5b5ecb2db12cb63b71ee190d116f5f75","With the rapid development of face forgery techniques, a large number of face synthesis videos are widely spread on the Internet, which threatens the security and trustworthiness of digital content online. It is necessary to develop face forgery detection methods. Many existing methods use only 2D CNNs to detect video frames. There are few 3D networks designed for face forgery detection. In this work, we propose to use 3D CNN for video-level face forgery detection and add a lightweight attention module to construct a 3D attention network. The network extracts both spatial and temporal features. The attention maps generated by the attention module focus on several forged regions of the fake face. To avoid the discrepancy of different regions affecting the detection results, a global attention pool is designed to replace the global average pool. The experiments implemented on FaceForensics++ show that our model achieves great accuracy and exceeds most existing methods. Cross-dataset evaluation implemented on Celeb-DF verifies that our model has strong transferability and generalization ability. © 2023 IEEE.","3D convolutional neural network; DeepFake detection; Digital video forensics; Face forgery; Face forgery detection"
"Budhiraja, R.; Kumar, M.; Das, M.K.; Bafila, A.S.; Singh, S.","Budhiraja, Rajat (57190491952); Kumar, Manish (57207935496); Das, Mrinal K. (57210523532); Bafila, Anil Singh (57222111714); Singh, Sanjeev (57216140046)","57190491952; 57207935496; 57210523532; 57222111714; 57216140046","LIED: A Lightweight and Ensemble learning approach for fake face Detection","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164269739&partnerID=40&md5=f0e5185b61b3971d2a9a2edd5c2d2376","For many years, machine learning problems have primarily been driven by the availability and quality of data. Being the key, data has been equally vulnerable and got a savior in the form of generative adversarial networks (GANs) which opened the floodgates for generating almost any type of real, yet synthetic data. Human face became one of the initial victims to this superior technology, where in highly realistic and convincing fake content is generated using deep learning technologies or ''DeepFakes''. Taking a giant leap forward from manipulating facial attributes, to be now able to swap expressions seamlessly and even generate new (non-existent) synthetic faces poses a grave threat not only to chosen few, but for the entire society. This upshoot has been reciprocated with significant efforts and investments for its detection, but the techniques are often marred with either lower accuracies, or, higher computation costs. This is where convolutional reservoir networks (CoRN) come to rescue owing to their lightweight nature, able to do ensemble feature extraction and its generalization ability. This paper investigates, implements and demonstrates the application of CoRN based architectures to the task of human fake face detection. The steep performance improvements as evident from our results further ratify the effectiveness of this approach, which is also shown to perform exceedingly well against smaller datasets. © 2023 IEEE.","Convolution Neural Networks; Convolutional Reservoir Networks; DeepFake Detection; Ensemble Feature Extraction; Fake Face Detection; Reservoir Computing"
"Jellali, A.; Ben Fredj, I.B.; Kais, K.","Jellali, Ameni (57705205100); Ben Fredj, Ines (56600892900); Kais, Ouni Is (6505828746)","57705205100; 56600892900; 6505828746","Data Augmentation for Convolutional Neural Network DeepFake Image Detection","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164260762&partnerID=40&md5=76e7e51c51700e6682fa41ad246d15e5","We need to develop a technique for better identifying deepfakes because they can distort our perception of reality. This study offers a brand-new forensic technique for spotting falsified facial photos. We made advantage of the Kaggle- provided 'real-and - fake- facial-detection' dataset. We are able to distinguish between probable facial alterations based on CNN's design. Thanks to data augmentation approaches, the results exhibit performances that are equivalent to those of previous works. The proposed approach fared better for this binary categorization into fake or real faces than the other cutting-edge studies. Our accuracy is close to 99 percent. © 2023 IEEE.","CNN; Data Augmentation; Deep Learning; Deepfakes Detection; Faces Manipulations"
"Jellali, A.; Ben Fredj, I.B.; Kais, K.","Jellali, Ameni (57705205100); Ben Fredj, Ines (56600892900); Kais, Ouni Is (6505828746)","57705205100; 56600892900; 6505828746","An Approach of Fake Videos Detection Based on Haar Cascades and Convolutional Neural Network","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164254032&partnerID=40&md5=03e2e4081340937422814485e6a4c6b3","Because deep fakes might skew our impression of the truth, we need to come up with a method for better spotting them. This paper proposes a new forensic technique to detect manipulated facial images from videos. It is based on CNNs architecture that can distinguish possible face manipulations in the 'real-and-fake-face-detection' dataset offered by Kaggle. The results obtained highlight comparable performances with the state-of-the-art methods. It showed an accuracy of approximately 99 % for this binary classification into fake or real faces. Then to validate this model we added a human face detection technique using the Haar Cascade method to this model in order to detect the manipulated videos from Deep Fake Detection Challenge (DFDC) dataset and we achieve an accuracy of 91 correct predictions out of 100 total videos. © 2023 IEEE.","CNN; Data Augmentation; Deep Learning; Deepfakes Detection; Faces Manipulations; Fake and real videos; Haar-Cascade"
"Kingra, S.; Aggarwal, N.; Kaur, N.","Kingra, Staffy (57192255022); Aggarwal, Naveen (36875216400); Kaur, Nirmal (57189220908)","57192255022; 36875216400; 57189220908","SiamLBP: Exploiting Texture Discrepancies for Deepfake Detection","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163406126&partnerID=40&md5=4719b89e1aa6592a1516ddb8a140fe96","Advancement in technology to generate and synthesize digital media imposed both positive and negative impacts on the society from entertainment to malevolent faking of content. Progression in artificial intelligence (AI)-based synthesizing techniques, like deepfakes, provided more realism to the manipulated content. Though digital media has the ability to be utilized as proof of evidence, trust on these has diminished greatly. Considering the impact of deepfakes on the society, researchers have worked in the detection of synthesized media. This paper introduces a novel model, SiamLBP based on Siamese network that captures the texture dissimilarities between original and deepfaked faces. The proposed model is evaluated on FF++ and Celeb-DF datasets and provided a detection accuracy of 99% and 91%, respectively. In addition, deepfake dataset, focused on Indian celebrities, is generated using popular mobile applications such as FaceApp and FOM. The proposed model provided an average accuracy of 98% on generated dataset. Owing to its simplicity and efficient performance, the proposed SiamLBP outperforms other state-of-the-art detection models such as fCNN and iCaps-Dfake. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","Deepfake detection; Face manipulation; LBP; Siamese; Texture"
"Zhuo, W.; Li, D.; Wang, W.; Dong, J.","Zhuo, Wenqi (57998347200); Li, Dongze (57226877028); Wang, Wei (56948518500); Dong, Jing (55477985000)","57998347200; 57226877028; 56948518500; 55477985000","Data-free model compression for light-weight DeepFake detection; 面向轻量级深度伪造检测的无数据模型压缩","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162868504&partnerID=40&md5=84ddc39d1927d4fca8653fce5a90eb9f","Objective Deep generative models-based human facial images and videos analyses have been developing in recent years. To cope with the faked issues effectively, a novel DeepFake detection (DFD) technique has emerged. Multiple DFD methods are yielded the detector to discriminate between the real and fake faces analysis with over 95% precision. However, it is still a great challenge to deploy them online because of the memory and computational cost. So, we develop a quantified model to DFD domain. Quantization-related model compression can be used to optimize model size through converting a model’s key parameters from high precision floating points into low precision integers. However, the degradation issue is still being challenged. To resolve degradation problem, it can be segmented into 2 categories: 1) quantification-oriented fine-tuning and 2) post-training quantification. To optimize cost effective, the latter one is optioned to develop a light-weight DFD detector. In addition, to clarify the privacy concerns and information security, data-free scenario-oriented models-quantified are constructed and optimized with no prior training set. Method The proposed framework consists of 2 steps: 1) key parameters-related quantification and 2) activation-ranged calibration. First, the weights and activations of a well-trained high accuracy DFD model are optioned as the target parameters to be quantified. A linear transformation-asymmetric is used to convert them from 32-bit floating points into lower bit-width representation like INT8 and INT6. Next, the activation-ranged errors are validated based on calibration set. For data-free scenario, it is challenged to collect data from prior training set. Therefore, to produce more effective calibration data, a batch of normalization layers of a pre-trained DFD model is tailored to guide the generator. Such statistics knowledge is often used to reflect the distribution of training data like running-relevant means and variances. We can optimize the input data of those are sampled in random from a standard Gaussian distribution in terms of our L2-norm constraint. Furthermore, to reduce the accuracy loss, the ReLU6 are employed to optimize its activation function for all DFD models. The interval [0, 6] is introduced to ReLU6 as a natural range for activations, which is beneficial to the quantification. The data-coordinated is fed into the quantified model and the activation-ranged is calibrated during the inference-forward process. Result our proposed scheme is tested with popular multi-DFD models of those are ResNet50, Xception, EfficientNet-b3 and MobileNetV2 in relevant to the deepfake datasets-popular like FaceForensics + + and Celeb-DF v2. For FaceForensics + +, the Xception and MobileNetV2 achieve Acc scores of 93. 98% and 92. 25% in W8A8 quantitatively and optimized by 0. 01% and 0. 92% to benchmark. The detection accuracy of ResNet50 is reached to 92. 56% in W6A8. The performance of EfficientNet-b3 is required to be resolved and calibrated further. For Celeb-DF v2, each MobileNetV2 precision gains in W8A8, W8A6 and W6A6 are improved by 0. 07%, 0. 77% and 0. 09% of each compared to its benched model. For 3 sorts of DFD models-relevant, the detection accuracy of their quantified versions is higher than 92%, even in W6A6 quantization. In comparison with a similar work “DefakeHop”, it can construct a DFD-featured light-weight network as well. For the quantified DFD models, they can get higher scores of AUC (area under the ROC curve) on public datasets although the parameter amount is unchanged and larger than DefakeHop. Actually, to make DFD models more light-weight, we can use the proposed scheme to compress DefakeHop. To evaluate our approach better, a series of ablation experiments are carried out to analyze the bit-width setting of weights and activation-derived quantification impact, the type of calibration data, and activation function as well. Conclusion The model-compressed methods are melted into DFD tasks and a data-free post-quantization scheme is also developed. It can convert a pre-trained DFD model into light-weight. Experiments are implemented on FaceForensics + + and Celeb-DF v2 with a range of typical DFD models, including ResNet50, Xception, EfficientNet-b3 and MobileNetV2. The quantified DFD models can be customized to recognize fake faces accurately and efficiently. Future research direction is potential to assign the DFD models online or on some resource-constrained platforms like mobile and edge devices. © 2023 Editorial and Publishing Board of JIG","data-free distillation; DeepFake detection; fake face; lightweight model; low bit-width representation; model compression"
"Jeon, S.M.; Seong, H.A.; Lee, E.C.","Jeon, Su-min (57580359800); Seong, Hyeonah (58250482500); Lee, Eui Chul (14009024200)","57580359800; 58250482500; 14009024200","Deepfake Video Detection Using the Frequency Characteristic of Remote Photoplethysmography","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159407357&partnerID=40&md5=e58671c5f09ecb995774c54455cf1dd8","Photoplethysmography is a technique for measuring the blood flow per unit time of an artery. Remote photoplethysmography is a method for obtaining photoplethysmography signals in a non-contact manner through a sensor such as a camera and has been recently applied to various fields. In this study, we propose a method for detecting Deepfake modulated color video based on remote photoplethysmography concept. As experimental data, 50 real videos and their 50 Deepfake videos using Face Swapping Generative Adversarial Networks were used. The photoplethysmography signals of face and neck regions were extracted, respectively, and the signals were preprocessed by detrending and performing Butterworth bandpass filtering. The 80 power values ​​in the frequency domain were defined as feature vectors. As a result of analyzing the L2 Norm between the two vectors extracted from the face region and the neck region, the L2 Norms of the real video and the fake video were 0.0000307 and 0.0001332, respectively, confirming that the distributions were clearly separated. It was confirmed that there is a significant difference between the real and the fake videos. Also, as a result of calculating the degree of separation of distributions with d-prime, 2.32 was derived. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Bio-signals; Deepfake detection; Face recognition; Face substitution; Remote photoplethysmography"
"Han, R.; Wang, X.; Bai, N.; Wang, Q.; Liu, Z.; Xue, J.","Han, Ruidong (58199903300); Wang, Xiaofeng (56028744400); Bai, Ningning (58102462000); Wang, Qin (57876406800); Liu, Zinian (58199955400); Xue, Jianru Ru (8899818900)","58199903300; 56028744400; 58102462000; 57876406800; 58199955400; 8899818900","FCD-Net: Learning to Detect Multiple Types of Homologous Deepfake Face Images","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153802595&partnerID=40&md5=ae28cb679eed9a9f6e3a4f0d47d35531","With the rapid development of artificial intelligence technology, a variety of GAN generated deepfake face images/videos have emerged endlessly. The abuse of deepfake has brought serious negative effects to many industries. Therefore, there is an urgent need to develop advanced methods to combat the abuse of deepfake. As far as we know, there are almost no techniques that can distinguish multiple types of homologous deepfake face images. In this study, we propose a method based on the multi-classification task to address this issue. The proposed method relies on a novel network framework named FCD-Net that consists of the facial synaptic saliency module (FSS), the contour detail feature extraction module (CDFE), and the distinguishing feature fusion module (DFF). Utilizing this method, the imperceptible features introduced by deepfake can be exposed, and the differences caused by different types of deepfake can be distinguished, even if deepfake images are homologous. To test the proposed method and compare it with other SOTA methods, we establish a new homologous dataset named HDFD that contains real face images, entire face synthesis images, face swap images, and facial attribute manipulation images. Among them, the three types of deepfake images are all generated from the same real face images through different deepfake techniques. Abundant experiment results demonstrate that the proposed method has a high-level detection accuracy and relatively strong robustness against content-preserving manipulations. Moreover, the generalization of our method is superior to other SOTA methods. © 2005-2012 IEEE.","contour detail feature extraction; Deepfake detection; distinguishable feature fusion (DFF); facial synaptic saliency (FSS); homologous face images"
"Mohzary, M.; Almalki, K.; Choi, B.-Y.; Song, S.","Mohzary, Muhammad (57216589335); Almalki, Khalid Jaber (57207316955); Choi, Baek Young (15768734900); Song, Sejun (7403350196)","57216589335; 57207316955; 15768734900; 7403350196","CHIEFS: Corneal-Specular Highlights Imaging for Enhancing Fake-Face Spotter","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152585193&partnerID=40&md5=4e2c5380ad16df14207145877adc087e","This paper presents a novel Machine Learning (ML)-based DeepFake detection technology named CHIEFS (Corneal-Specular Highlights Imaging for Enhancing Fake-Face Spotter). We focus on the most reflective area of a human face, the eyes, upon the hypothesis that the existing DeepFake creation methods fail to coordinate their counterfeits with the reflective components. In addition to the traditional checking of the reflection shape similarity (RSS), we detect various corneal-specular highlights features, such as color components and textures, to find corneal-specular highlights consistency (CHC). Furthermore, we inspect the ensemble of the highlights with the surrounding environmental factors (SEF), including the light settings, directions, and strength. We designed and built them as modular features and have conducted extensive experiments with different combinations of the components using various input parameters and Deep Neural Network (DNN) architectures on Generative Adversarial Network (GAN)-based DeepFake datasets. The empirical results show that CHIEFS with three modules improves the accuracy from 86.05% (with the RSS alone) to 99.00% with the ResNet-50-V2 architecture. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Corneal-Specular Highlights; DeepFake; DeepFake Detection; Digital Media Forensics; Media Manipulation"
"Yang, W.; Zhou, X.; Chen, Z.; Guo, B.; Ba, Z.; Xia, Z.; Cao, X.; Ren, K.","Yang, Wenyuan (57214131847); Zhou, Xiaoyu (58162231900); Chen, Zhikai (57212484869); Guo, Bofei (58169488900); Ba, Zhongjie (56028729300); Xia, Zhihua (35075519800); Cao, Xiaochun (8920951000); Ren, Kui (8396435500)","57214131847; 58162231900; 57212484869; 58169488900; 56028729300; 35075519800; 8920951000; 8396435500","AVoiD-DF: Audio-Visual Joint Learning for Detecting Deepfake","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151494518&partnerID=40&md5=2eb1084e0b15cb3d205d8d8bca7e496e","Recently, deepfakes have raised severe concerns about the authenticity of online media. Prior works for deepfake detection have made many efforts to capture the intra-modal artifacts. However, deepfake videos in real-world scenarios often consist of a combination of audio and visual. In this paper, we propose an Audio-Visual Joint Learning for Detecting Deepfake (AVoiD-DF), which exploits audio-visual inconsistency for multi-modal forgery detection. Specifically, AVoiD-DF begins by embedding temporal-spatial information in Temporal-Spatial Encoder. A Multi-Modal Joint-Decoder is then designed to fuse multi-modal features and jointly learn inherent relationships. Afterward, a Cross-Modal Classifier is devised to detect manipulation with inter-modal and intra-modal disharmony. Since existing datasets for deepfake detection mainly focus on one modality and only cover a few forgery methods, we build a novel benchmark DefakeAVMiT for multi-modal deepfake detection. DefakeAVMiT contains sufficient visuals with corresponding audios, where any one of the modalities may be maliciously modified by multiple deepfake methods. The experimental results on DefakeAVMiT, FakeAVCeleb, and DFDC demonstrate that the AVoiD-DF outperforms many state-of-the-arts in deepfake detection. Our proposed method also yields superior generalization on various forgery techniques. © 2005-2012 IEEE.","audio-visual; Deepfake detection; joint learning; multi-modal"
"Yang, P.; Huang, H.; Wang, Z.; Yu, A.; He, R.","Yang, Puning (58161052400); Huang, Huaibo (57200614611); Wang, Zhiyong (36976302000); Yu, Aijing (57219527558); He, Ran (35764463900)","58161052400; 57200614611; 36976302000; 57219527558; 35764463900","Confidence-Calibrated Face Image Forgery Detection with Contrastive Representation Distillation","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151062248&partnerID=40&md5=fa98b57dd39bb6a8d861082f3bbfb3b4","Face forgery detection has been increasingly investigated due to the great success of various deepfake techniques. While most existing face forgery detection methods have achieved excellent results on the test split of the same dataset or the same type of manipulations, they often do not work well on unseen datasets or unseen manipulations due to the issue of model generalization. Therefore, in this paper, we propose a novel contrastive distillation calibration (CDC) framework, which distills the contrastive representations with confidence calibration to address this generalization issue. Different from previous methods that equally treat the two forgery types, Face Swapping and Face Reenactment, we devise a dual-teacher module where the knowledge is separately learned for each forgery type. A contrastive representation learning strategy is further presented to enhance the representations of diverse forgery artifacts. To prevent the proposed model from being overconfident, we propose a novel Kullback-Leibler divergence loss with dynamic weights to moderate the dual-teacher’s outputs. In addition, we introduce label smoothing to calibrate the model confidence with the target outputs. Extensive experiments on three popular datasets show that our proposed method achieves the state-of-the-art performance for cross-dataset face forgery detection. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Confidence calibration; Deepfake detection; Knowledge distillation"
"Patel, Y.; Tanwar, S.; Bhattacharya, P.; Gupta, R.; Alsuwian, T.; Davidson, I.E.; Mazibuko, T.F.","Patel, Yogesh M. (57214439687); Tanwar, Sudeep (56576145100); Bhattacharya, Pronaya (57200306370); Gupta, Rajesh (57201584761); Alsuwian, Turki M. (57193701610); Davidson, Innocent Ewean (7103403083); Mazibuko, Thokozile F. (58127772800)","57214439687; 56576145100; 57200306370; 57201584761; 57193701610; 7103403083; 58127772800","An Improved Dense CNN Architecture for Deepfake Image Detection","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149390557&partnerID=40&md5=f2ee72d1af6a7a2476208122fd5ffc28","Recent advancements in computer vision processing need potent tools to create realistic deepfakes. A generative adversarial network (GAN) can fake the captured media streams, such as images, audio, and video, and make them visually fit other environments. So, the dissemination of fake media streams creates havoc in social communities and can destroy the reputation of a person or a community. Moreover, it manipulates public sentiments and opinions toward the person or community. Recent studies have suggested using the convolutional neural network (CNN) as an effective tool to detect deepfakes in the network. But, most techniques cannot capture the inter-frame dissimilarities of the collected media streams. Motivated by this, this paper presents a novel and improved deep-CNN (D-CNN) architecture for deepfake detection with reasonable accuracy and high generalizability. Images from multiple sources are captured to train the model, improving overall generalizability capabilities. The images are re-scaled and fed to the D-CNN model. A binary-cross entropy and Adam optimizer are utilized to improve the learning rate of the D-CNN model. We have considered seven different datasets from the reconstruction challenge with 5000 deepfake images and 10000 real images. The proposed model yields an accuracy of 98.33% in AttGAN, [Facial Attribute Editing by Only Changing What You Want (AttGAN)] 99.33% in GDWCT,[Group-wise deep whitening-and-coloring transformation (GDWCT)] 95.33% in StyleGAN, 94.67% in StyleGAN2, and 99.17% in StarGAN [A GAN capable of learning mappings among multiple domains (StarGAN)] real and deepfake images, that indicates its viability in experimental setups. © 2013 IEEE.","CNN; convolutional neural network; Deepfake detection; GAN"
"Yang, Z.; Liang, J.; Xu, Y.; Zhang, X.-Y.; He, R.","Yang, Ziming (57538382600); Liang, Jian (56999503100); Xu, Yuting (57227677100); Zhang, Xiaoyu (54895721300); He, Ran (35764463900)","57538382600; 56999503100; 57227677100; 54895721300; 35764463900","Masked Relation Learning for DeepFake Detection","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149365578&partnerID=40&md5=392d54a1996ae46575ac3f972121f6f2","DeepFake detection aims to differentiate falsified faces from real ones. Most approaches formulate it as a binary classification problem by solely mining the local artifacts and inconsistencies of face forgery, which neglect the relation across local regions. Although several recent works explore local relation learning for DeepFake detection, they overlook the propagation of relational information and lead to limited performance gains. To address these issues, this paper provides a new perspective by formulating DeepFake detection as a graph classification problem, in which each facial region corresponds to a vertex. But relational information with large redundancy hinders the expressiveness of graphs. Inspired by the success of masked modeling, we propose Masked Relation Learning which decreases the redundancy to learn informative relational features. Specifically, a spatiotemporal attention module is exploited to learn the attention features of multiple facial regions. A relation learning module masks partial correlations between regions to reduce redundancy and then propagates the relational information across regions to capture the irregularity from a global view of the graph. We empirically discover that a moderate masking rate (e.g., 50%) brings the best performance gain. Experiments verify the effectiveness of Masked Relation Learning and demonstrate that our approach outperforms the state of the art by 2% AUC on the cross-dataset DeepFake video detection. Code will be available at https://github.com/zimyang/MaskRelation. © 2005-2012 IEEE.","DeepFake detection; masked learning; Multimedia forensics; relation feature"
"Tran, V.-N.; Lee, S.-H.; Le, H.-S.; Kim, B.-S.; Kwon, K.-R.","Tran, Van Nhan (57230314500); Lee, Sukhwan (24721765800); Le, Hoanh Su (57200087070); Kim, Bo-sung (58121517300); Kwon, Ki-ryong (13606061300)","57230314500; 24721765800; 57200087070; 58121517300; 13606061300","Learning Face Forgery Detection in Unseen Domain with Generalization Deepfake Detector","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149135195&partnerID=40&md5=f592e2344e007c57a1d89df72e592f65","Face forgery generation algorithms have advanced rapidly, resulting in a diverse range of manipulated videos and images which are difficult to identify. As a result, face manipulation using deepfake technique has a significantly increased societal anxiety and posed serious security problems. Recently, a variety of deep fake detection techniques have been presented. Convolutional neural networks (CNN) architecture are used for most of the deepfake detection models as binary classification problems. These methods usually achieve very good accuracy for specific dataset. However, when evaluated across datasets, the performance of these approaches drastically declines. In this paper, we propose a face forgery detection method to increase the generalization of the model, named Generalization Deepfake Detector (GDD). The Generalization Deepfake Detector model has ability to instantly solve new unseen domains without the requirement for model updates. © 2023 IEEE.","deepfake dataset; Deepfake detection; machine learning; meta learning"
"Guo, Z.; Yang, G.; Chen, J.; Sun, X.","Guo, Zhiqing (57219672095); Yang, Gaobo (8647279200); Chen, Jiyou (57221655154); Sun, Xingming (8439524300)","57219672095; 8647279200; 57221655154; 8439524300","Exposing Deepfake Face Forgeries With Guided Residuals","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147275282&partnerID=40&md5=ba343c97f6bf4233b79d6466fde60ef8","For Deepfake detection, residual-based features can preserve tampering traces and suppress irrelevant image content. However, inappropriate residual prediction brings side effects on detection accuracy. Meanwhile, residual-domain features are easily affected by some image operations such as lossy compression. Most existing works exploit either spatial-domain or residual-domain features, which are fed into the backbone network for feature learning. Actually, both types of features are mutually correlated. In this work, we propose an adaptive fusion based guided residuals network (AdapGRnet), which fuses spatial-domain and residual-domain features in a mutually reinforcing way, for Deepfake detection. Specifically, we present a fine-grained manipulation trace extractor (MTE), which is a key module of AdapGRnet. Compared with the prediction-based residuals, MTE can avoid the potential bias caused by inappropriate prediction. Moreover, an attention fusion mechanism (AFM) is designed to selectively emphasize feature channel maps and adaptively allocate the weights for two streams. Experimental results show that AdapGRnet achieves better detection accuracies than the state-of-the-art works on four public fake face datasets including HFF, FaceForensics++, DFDC and CelebDF. Especially, AdapGRnet achieves an accuracy up to 96.52% on the HFF-JP60 dataset, which improves about 5.50%. That is, AdapGRnet achieves better robustness than the existing works. © 1999-2012 IEEE.","attention fusion mechanism; Deepfake detection; guided residuals; image forensics"
"Yu, Y.; Zhao, X.; Ni, R.; Yang, S.; Zhao, Y.; Kot, A.C.","Yu, Yang (57210753156); Zhao, Xiaohui (57725332200); Ni, Rongrong (55632437300); Yang, Siyuan (57221158200); Zhao, Yao (35304414700); Kot, Alex Chichung (35588578100)","57210753156; 57725332200; 55632437300; 57221158200; 35304414700; 35588578100","Augmented Multi-Scale Spatiotemporal Inconsistency Magnifier for Generalized DeepFake Detection","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147259717&partnerID=40&md5=42da42f643e676562c96bf8728a64fbd","Recently, realistic DeepFake videos have raised severe security concerns in society. Existing video-based detection methods observe local spatial regions with the coarse temporal view, thus it is difficult to obtain subtle spatiotemporal information, resulting in limited generalization ability. In this paper, we propose a novel Augmented Multi-scale Spatiotemporal Inconsistency Magnifier (AMSIM) with a Global Inconsistency View (GIV) and a more meticulous Multi-timescale Local Inconsistency View (MLIV), focusing on mining comprehensive and more subtle spatiotemporal cues. Firstly, the GIV that includs the global spatial and long-term temporal views is established to ensure comprehensive spatiotemporal clues are captured. Then, the MLIV with the critical local spatial and multi-timescale local temporal views is designed for magnifying the indetectable spatiotemporal abnormality. Subsequently, GIV is utilized to guide MLIV to dynamically find local spatiotemporal anomalies that are highly relevant to the overall video. Finally, to further obtain a generalized framework, the adversarial data augmentation is specially designed to expand source domains and simulate unseen forgery domains. Extensive experiments on six large-scale datasets show that our AMSIM outperforms state-of-the-art detection methods and remains effective when applied to unseen forgery techniques and datasets. © 1999-2012 IEEE.","Adversarial data augmentation; generalized DeepFake detection; global guidance; multi-scale spatiotemporal inconsistency"
"Akhtar, Z.","Akhtar, Zahid (46661628200)","46661628200","Deepfakes Generation and Detection: A Short Survey","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146785445&partnerID=40&md5=1f3c496c80b61609aaaf4b1bfa45703a","Advancements in deep learning techniques and the availability of free, large databases have made it possible, even for non-technical people, to either manipulate or generate realistic facial samples for both benign and malicious purposes. DeepFakes refer to face multimedia content, which has been digitally altered or synthetically created using deep neural networks. The paper first outlines the readily available face editing apps and the vulnerability (or performance degradation) of face recognition systems under various face manipulations. Next, this survey presents an overview of the techniques and works that have been carried out in recent years for deepfake and face manipulations. Especially, four kinds of deepfake or face manipulations are reviewed, i.e., identity swap, face reenactment, attribute manipulation, and entire face synthesis. For each category, deepfake or face manipulation generation methods as well as those manipulation detection methods are detailed. Despite significant progress based on traditional and advanced computer vision, artificial intelligence, and physics, there is still a huge arms race surging up between attackers/offenders/adversaries (i.e., DeepFake generation methods) and defenders (i.e., DeepFake detection methods). Thus, open challenges and potential research directions are also discussed. This paper is expected to aid the readers in comprehending deepfake generation and detection mechanisms, together with open issues and future directions. © 2023 by the author.","biometrics; deep learning; deepfake detection; deepfake generation; DeepFakes; digital face manipulations; digital forensics; disinformation face morphing attack; face recognition; fake news; fake news; generative AI; information authenticity; misinformation; multimedia manipulations"
"Tran, V.-N.; Kwon, S.-G.; Lee, S.-H.; Le, H.-S.; Kwon, K.-R.","Tran, Van Nhan (57230314500); Kwon, Seong-geun (7402624380); Lee, Sukhwan (24721765800); Le, Hoanh Su (57200087070); Kwon, Ki-ryong (13606061300)","57230314500; 7402624380; 24721765800; 57200087070; 13606061300","Generalization of Forgery Detection With Meta Deepfake Detection Model","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146229547&partnerID=40&md5=a2ac5c13e636491aa6c1a960c1890a4f","Face forgery generating algorithms that produce a range of manipulated videos/images have developed quickly. Consequently, this causes an increase in the production of fake information, making it difficult to identify. Because facial manipulation technologies raise severe concerns, face forgery detection is gaining increasing attention in the area of computer vision. In real-world applications, face forgery detection systems frequently encounter and perform poorly in unseen domains, due to poor generalization. In this paper, we propose a deepfake detection method based on meta-learning called Meta Deepfake Detection (MDD). The goal of the model is to develop a generalized model capable of directly solving new unseen domains without the need for model updates. The MDD algorithm establishes various weights for facial images from various domains. Specifically, MDD uses meta-weight learning to shift information from the source domains to the target domains with meta-optimization steps, which aims for the model to generate effective representations of the source and target domains. We build multi-domain sets using meta splitting strategy to create a meta-train set and meta-test set. Based on these sets, the model determines the gradient descent and obtains backpropagation. The inner and outer loop gradients were aggregated to update the model to enhance generalization. By introducing pair-attention loss and average-center alignment loss, the detection capabilities of the system were substantially enhanced. In addition, we used some evaluation benchmarks established from several popular deepfake datasets to compare the generalization of our proposal in several baselines and assess its effectiveness. © 2013 IEEE.","artificial intelligence; computer vision; Deepfake detection; meta-learning"
"Guo, Z.; Yang, G.; Wang, D.; Zhang, D.","Guo, Zhiqing (57219672095); Yang, Gaobo (8647279200); Wang, Dewang (57210996855); Zhang, Dengyong (55318418900)","57219672095; 8647279200; 57210996855; 55318418900","A data augmentation framework by mining structured features for fake face image detection","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142155380&partnerID=40&md5=fdbc28a1fa25381f703bc3b321d8405d","For fake face image detection, most existing detectors exploit local artifacts, ignoring the mining of structured forgery clues existed in global images, which greatly constrains detection performance. In this work, we verify the importance of structured forgery clues for fake face image detection, and present a new data augmentation framework called Mining Structured Features (MSF) to promote the convolutional neural network (CNN) based detector. Specifically, MSF generates a position-sensitive artifact map, which is exploited to divide a candidate face image into strong correlation (SC) and weak correlation (WC) regions. By dynamically erasing some positions in SC and WC regions during the training process, MSF can promote the robustness of the detector to the above regions. In essence, MSF expands the attention range of the detector and fully mines the structured features from global images. MSF plays an auxiliary role, which can be seamlessly integrated into existing CNN-based detectors for end-to-end training. Extensive experimental results on four public datasets including HFFD, FF++, DFDC and Celeb-DF show that the detectors trained with the guidance of MSF can mine more useful clues distributed in fake face images to improve detection accuracies, achieving better results than state-of-the-art works. Our code will be available at https://github.com/EricGzq/MSF. © 2022 Elsevier Inc.","Data augmentation; Deepfake detection; Face forgery detection; Structured forgery clues"
"Zhang, L.; Qiao, T.; Xu, M.; Zheng, N.; Xie, S.","Zhang, Li (57221584414); Qiao, Tong (56177583700); Xu, Ming (56443054200); Zheng, Ning (35274126400); Xie, Shichuang (57741636500)","57221584414; 56177583700; 56443054200; 35274126400; 57741636500","Unsupervised Learning-Based Framework for Deepfake Video Detection","2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132719492&partnerID=40&md5=a8cfa6900913d7b94cea9c1f2e901620","With the continuous development of computer hardware equipment and deep learning technology, it is easier for people to swap faces in videos by currently-emerging multimedia tampering tools, such as the most popular deepfake. It would bring a series of new threats of security. Although many forensic researches have focused on this new type of manipulation and achieved high detection accuracy, most of which are based on supervised learning mechanism with requiring a large number of labeled samples for training. In this paper, we first develop a novel unsupervised detection manner for identifying deepfake videos. The main fundamental behind our proposed method is that the face region in the real video is taken by the camera while its counterpart in the deepfake video is usually generated by the computer; the provenance of two videos is totally different. Specifically, our method includes two clustering stages based on Photo-Response Non-Uniformity (PRNU) and noiseprint feature. Firstly, the PRNU fingerprint of each video frame is extracted, which is used to cluster the full-size identical source video (regardless of its real or fake). Secondly, we extract the noiseprint from the face region of the video, which is used to identify (re-cluster for the task of binary classification) the deepfake sample in each cluster. Numerical experiments verify our proposed unsupervised method performs very well on our own dataset and the benchmark FF++ dataset. More importantly, its performance rivals that of the supervised-based state-of-the-art detectors. © 2022 IEEE.","Deepfake detection; noiseprint; PRNU; unsupervised learning; video clustering"
"Ma, Z.; Liu, B.","Ma, Zekun (58042380800); Liu, Bin (56431524800)","58042380800; 56431524800","Accurate and Time-saving Deepfake Detection in Multi-face Scenarios Using Combined Features","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145556168&partnerID=40&md5=da88e5b3a667efc2725aca93a2021c29","There has been an increasing interest in Deepfake detection because of the hidden risks that Deepfake technology poses for social privacy and security. Nowadays, many models achieve impressive performance on existing public benchmarks. However, the majority of existing methods are restricted to single-face scenarios. In this paper, we propose a model that can perform accurate and time-saving Deepfake detection in multi-face scenarios. We fuse different levels of features to improve the performance of the model and use single-face data to aid the training of the multi-face data. Our apporach achieves the state-of-the-art performance in multi-face scenarios and comprehensible experiments have been conducted to demonstrate the soundness and validity of our model. © 2022 ACM.","computer vision; Deepfake detection; features fusion; multi-face scenarios"
"Gong, D.; Kumar, Y.J.; Goh, O.S.; Choo, C.Y.; Ye, Z.; Chi, W.","Gong, Dafeng (57649756600); Kumar, Y. J. (54405994500); Goh, Ong Sing (8922471400); Choo, Yun Huoy (24823962800); Ye, Zi (57825564800); Chi, Wanle (7006817241)","57649756600; 54405994500; 8922471400; 24823962800; 57825564800; 7006817241","AN IMPROVED DEEPFAKE DETECTION METHOD BASED ON CNNS","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138980431&partnerID=40&md5=f5759e6efc6cbf073a4f330e041cce79","Today's image generation technology can generate high-quality face images, and it isn't easy to recognize the authenticity of the generated images through human eyes. This study aims to improve deepfake detection, a face swapping forgery, by absorbing the advantages of deep learning technologies. This study generates a unified and enhanced data set from multiple sources using spatial enhancement technology to solve the problem of poor detection performance on cross-data sets. Taking the advantages of Inception and ResNet networks, new deepfake detection architecture composed of 20 network layers is proposed as the deepfake detection model. To further improve the proposed model, hyperparameter values are optimized. The experiment result shows that the proposed network significantly enhanced over the mainstream methods, such as ResNeXt50, ResNet101, XceptionNet, and VGG19, in terms of accuracy, loss value, AUC, numbers of parameters, and FLOPs. Overall, the methods introduced in this study can help to expand the data set, better detect deepfake contents, and effectively optimize network models. © 2022 Little Lion Scientific.","Cross Data set; Data Enhancement; Deepfake Detection; Face Swapping; Optimized Hyperparameters"
"Khan, S.A.; Dang-Nguyen, D.-T.","Khan, Sohail Ahmed (57222183917); Dang-Nguyen, Duc Tien (54792686300)","57222183917; 54792686300","Hybrid Transformer Network for Deepfake Detection","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139942557&partnerID=40&md5=787e90c687eac237a2ae497e04a2bbe4","Deepfake media is becoming widespread nowadays because of the easily available tools and mobile apps which can generate realistic looking deepfake videos/images without requiring any technical knowledge. With further advances in this field of technology in the near future, the quantity and quality of deepfake media is also expected to flourish, while making deepfake media a likely new practical tool to spread mis/disinformation. Because of these concerns, the deepfake media detection tools are becoming a necessity. In this study, we propose a novel hybrid transformer network utilizing early feature fusion strategy for deepfake video detection. Our model employs two different CNN networks, i.e., (1) XceptionNet and (2) EfficientNet-B4 as feature extractors. We train both feature extractors along with the transformer in an end-to-end manner on FaceForensics++, DFDC benchmarks. Our model, while having relatively straightforward architecture, achieves comparable results to other more advanced state-of-the-art approaches when evaluated on FaceForensics++ and DFDC benchmarks. Besides this, we also propose novel face cut-out augmentations, as well as random cut-out augmentations. We show that the proposed augmentations improve the detection performance of our model and reduce overfitting. In addition to that, we show that our model is capable of learning from considerably small amount of data. © 2022 Owner/Author.","attention mechanisms; deepfake detection; face forensics; feature fusion; image analysis; misinformation detection; transformers"
"Wang, G.; Jiang, Q.; Jin, X.; Li, W.; Cui, X.","Wang, Gaojian (57226340383); Jiang, Qian (57194699462); Jin, Xin (56991832300); Li, Wei (57196308169); Cui, Xiaohui (57195974967)","57226340383; 57194699462; 56991832300; 57196308169; 57195974967","MC-LCR: Multimodal contrastive classification by locally correlated representations for effective face forgery detection","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131412788&partnerID=40&md5=e25a98d20823670e8a9432aa96f2e401","As the remarkable development of facial manipulation technologies is accompanied by severe security concerns, face forgery detection has spurred recent research. Most detection methods train a binary classifier under global supervision to judge whether a face is real or fake. However, advanced manipulations only perform small-scale tampering, posing challenges to comprehensively capturing subtle and local forgery artifacts, especially in high-compression settings and cross-dataset scenarios. To address such limitations, we propose a framework, multimodal contrastive classification by locally correlated representations (MC-LCR), for effective face forgery detection. Instead of specific appearance features, MC-LCR amplifies implicit local discrepancies between authentic and forged faces from both the spatial and frequency domains. A shallow style representation block measures the pairwise correlation of shallow feature maps, encoding local style information to extract more discriminative features in the spatial domain. We observe that subtle forgery artifacts can be further exposed in the patch-wise phase and amplitude spectrum, and that they exhibit different clues. According to the complementarity of amplitude and phase information, we develop a patch-wise amplitude and phase dual attention module to capture locally correlated inconsistencies in the frequency domain. The collaboration of supervised contrastive loss with cross-entropy loss helps the network learn more discriminative and generalized representations. Through extensive experiments and comprehensive studies, we achieve state-of-the-art performance and demonstrate the robustness and generalization of our method. © 2022 Elsevier B.V.","Deepfake detection; Face forgery detection; Local feature correlation; Multimedia forensics"
"Xia, Z.; Qiao, T.; Xu, M.; Zheng, N.; Xie, S.","Xia, Zhiming (57695631300); Qiao, Tong (56177583700); Xu, Ming (56443054200); Zheng, Ning (35274126400); Xie, Shichuang (57741636500)","57695631300; 56177583700; 56443054200; 35274126400; 57741636500","Towards DeepFake video forensics based on facial textural disparities in multi-color channels","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131960722&partnerID=40&md5=155c151e3f537663a260a634cb1d6405","With the development of deep learning, AI-synthesized techniques, such as DeepFake, are widely spread on the Internet. Although many state-of-the-art detection methods have been able to obtain a good detection performance, most neural network models based on data-driven training lack interpretability during feature extraction and analysis. In this study, we propose an interpretable DeepFake video detection method based on facial textural disparities in multi-color channels. We observe that the face region from the DeepFake video appears to be smoother than that of the real one. First, we analyze the statistical disparities between the real and fake frame in each color channel. Next, it is proposed to use the co-occurrence matrix to construct a low-dimensional set of features to distinguish the real video from the DeepFake video. Meanwhile, we evaluate the video-level and frame-level detection performance on the benchmark, where the method can achieve AUC value of 0.996 on FaceForensics++, and 0.718 on Celeb-DF. Our proposed method performs remarkably better than the traditional machine learning based detectors, and comparably to some current deep learning based detectors. More importantly, our proposed method is robust in the face of compression attacks, and more time-efficient compared to existing methods based on deep learning. © 2022 Elsevier Inc.","Color channels; DeepFake detection; Facial texture; Multimedia forensics"
"Juefei-Xu, F.; Wang, R.; Huang, Y.; Guo, Q.; Ma, L.; Liu, Y.","Juefei-Xu, Felix (54911989900); Wang, Run (55939516400); Huang, Yihao (57214756217); Guo, Qing (57191163500); Ma, Lei (55479591700); Liu, Yang (56911879800)","54911989900; 55939516400; 57214756217; 57191163500; 55479591700; 56911879800","Countering Malicious DeepFakes: Survey, Battleground, and Horizon","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131013969&partnerID=40&md5=8768ad6984c5f9719ecee91ae652163c","The creation or manipulation of facial appearance through deep generative approaches, known as DeepFake, have achieved significant progress and promoted a wide range of benign and malicious applications, e.g., visual effect assistance in movie and misinformation generation by faking famous persons. The evil side of this new technique poses another popular study, i.e., DeepFake detection aiming to identify the fake faces from the real ones. With the rapid development of the DeepFake-related studies in the community, both sides (i.e., DeepFake generation and detection) have formed the relationship of battleground, pushing the improvements of each other and inspiring new directions, e.g., the evasion of DeepFake detection. Nevertheless, the overview of such battleground and the new direction is unclear and neglected by recent surveys due to the rapid increase of related publications, limiting the in-depth understanding of the tendency and future works. To fill this gap, in this paper, we provide a comprehensive overview and detailed analysis of the research work on the topic of DeepFake generation, DeepFake detection as well as evasion of DeepFake detection, with more than 318 research papers carefully surveyed. We present the taxonomy of various DeepFake generation methods and the categorization of various DeepFake detection methods, and more importantly, we showcase the battleground between the two parties with detailed interactions between the adversaries (DeepFake generation) and the defenders (DeepFake detection). The battleground allows fresh perspective into the latest landscape of the DeepFake research and can provide valuable analysis towards the research challenges and opportunities as well as research trends and future directions. We also elaborately design interactive diagrams (http://www.xujuefei.com/dfsurvey) to allow researchers to explore their own interests on popular DeepFake generators or detectors. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","DeepFake Detection; DeepFake Generation; DeepFakes; Disinformation; Face; Misinformation"
"Chen, B.; Li, T.; Ding, W.","Chen, Beijing (36805188500); Li, Tianmu (57574695400); Ding, Weiping (57193448087)","36805188500; 57574695400; 57193448087","Detecting deepfake videos based on spatiotemporal attention and convolutional LSTM","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128119994&partnerID=40&md5=581010604140a13109c1122b7435cd0a","Fake face detection is in dilemma with the rapid development of face manipulation technology. One way to improve the effectiveness of detector is to make full use of intra and inter frame information. In this paper, a novel Xception-LSTM algorithm is proposed by using our new spatiotemporal attention mechanism and convolutional long short-term memory (ConvLSTM). In the algorithm, the spatiotemporal attention mechanism, including spatial and temporal attention mechanism, is proposed to capture and enhance spatiotemporal correlations before dimension reduction of Xception. Thereafter, the ConvLSTM is introduced to consider frame structure information while modeling temporal information. The experimental results on three widely used datasets demonstrate that the proposed algorithms perform better than the state-of-the-art algorithms. In addition, the effectiveness of the spatiotemporal attention mechanism and ConvLSTM are illustrated in ablation experiments. © 2022 Elsevier Inc.","Attention mechanism; Convolutional LSTM; Deepfake detection; Face identification"
"Korshunov, P.; Marcel, S.","Korshunov, Pavel (20433948000); Marcel, Sébastien (57207602545)","20433948000; 57207602545","Improving Generalization of Deepfake Detection With Data Farming and Few-Shot Learning","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123384440&partnerID=40&md5=9cb0523c2ec7223f4f52568724e3f5b4","Recent advances in automated video and audio editing tools, generative adversarial networks (GANs), and social media allow creation and fast dissemination of high quality tampered videos, which are generally called deepfakes. Typically, in these videos, a face is swapped with someone else's using GANs. Accessible open source software and apps for the face swapping led to a wide and rapid dissemination of the generated deepfakes, posing a significant technical challenge for their detection and filtering. In response to the threat, which deepfake videos can pose to our trust in video evidence, several large datasets of deepfake videos and several methods to detect them were proposed recently. However, the proposed methods suffer from a problem of overfitting on the training data and the lack of the generalization across different databases and the generative models. Therefore, in this paper, we investigate the techniques for improving the generalization of deepfake detection methods that can be employed in practical settings. We have selected two popular state of the art deepfake detectors: based on Xception and EfficientNet models, and we use five databases: from Google and Jigsaw, FaceForensics++, DeeperForensics, Celeb-DF, and our own publicly available large dataset DF-Mobio. To improve generalization, we apply different augmentation strategies used during training, including a proposed aggressive 'data farming' technique based on random patches. We also tested two few-shot tuning methods, when either a first convolutional layer or a last layer of a pre-trained model is tuned on 100 seconds from a training set of the test database. The experimental results clearly expose the generalization problem of deepfake detection methods, since the accuracy drops significantly when a model is trained on one dataset and evaluated on another. However, the silver lining is that an aggressive augmentation during training and a few-shot tuning on the test database can improve the accuracy of the detection methods in a cross-database scenario. As a side observation, we show the importance of database selection for training and evaluation, as FaceForensics++ is found to be better to use for training, while DeeperForensics is found to be significantly more challenging as a test database. © 2019 IEEE.","deepfake dataset; Deepfakes detection; evaluation; generalization"
"Wang, G.; Jiang, Q.; Jin, X.; Cui, X.","Wang, Gaojian (57226340383); Jiang, Qian (57194699462); Jin, Xin (56991832300); Cui, Xiaohui (57195974967)","57226340383; 57194699462; 56991832300; 57195974967","FFR_FD: Effective and fast detection of DeepFakes via feature point defects","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126380050&partnerID=40&md5=df9a5a075ba7360296d2de990c9c155c","DeepFakes are widespread on social networks, and they result in severe information concerns. Although various detection methods have been proposed, there are still practical limitations. Previous specific artifact-based methods were insufficient to capture fine-grained features, which limited their effectiveness against advanced DeepFakes. Current DNN-based detectors tend to trade high costs for performance improvement, and are not efficient enough, given that DeepFakes can be created easily by mobile apps, and DNN-based models require expensive computational resources. Furthermore, most methods lack generalizability under the cross-dataset scenario. In this work, we instead mine the more subtle and generalized defects of DeepFakes and propose the fused facial region_feature descriptor (FFR_FD), which is only a vector of the discriminative feature description, for effective and fast DeepFake detection. We show that DeepFake faces have fewer feature points than real ones, especially in facial regions. FFR_FD capitalizes on such key observations, and thus has strong generalizability. We train a random forest classifier with FFR_FD to achieve efficient detection. Extensive experiments on six large-scale DeepFake datasets demonstrate the effectiveness of our lightweight method. Our model generalizes well on the challenging Celeb-DF (v2) dataset, with 0.706 AUC, which is superior to most state-of-the-art methods. © 2022 Elsevier Inc.","Deep generative models; DeepFake detection; Face forensics; Feature detection-description"
"Zhang, D.; Wu, P.; Li, F.; Zhu, W.; Sheng, V.S.","Zhang, Dengyong (55318418900); Wu, Pengjie (57755770500); Li, Feng (56668990100); Zhu, Wenjie (57754115700); Sheng, Victor S. (14049181900)","55318418900; 57755770500; 56668990100; 57754115700; 14049181900","Cascaded-Hop For DeepFake Videos Detection","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132435287&partnerID=40&md5=cdfa048c63e652884c480852a0f1c614","Face manipulation tools represented by Deepfake have threatened the security of people's biological identity information. Particularly, manipulation tools with deep learning technology have brought great challenges to Deepfake detection. There are many solutions for Deepfake detection based on traditional machine learning and advanced deep learning. However, those solutions of detectors almost have problems of poor performance when evaluated on different quality datasets. In this paper, for the sake of making high-quality Deepfake datasets, we provide a preprocessing method based on the image pixel matrix feature to eliminate similar images and the residual channel attention network (RCAN) to resize the scale of images. Significantly, we also describe a Deepfake detector named Cascaded-Hop which is based on the PixelHop++ system and the successive subspace learning (SSL) model. By feeding the preprocessed datasets, Cascaded-Hop achieves a good classification result on different manipulation types and multiple quality datasets. According to the experiment on FaceForensics++ and Celeb-DF, the AUC (area under curve) results of our proposed methods are comparable to the state-of-the-art models. © © 2022 KSII.","Deepfake detection; Face manipulation; Machine learning; PixelHop++; SSL"
"Park, G.-W.; Park, E.-J.; Woo, S.S.","Park, Geonwoo (57808320600); Park, Eun-ju (57808861200); Woo, Simon S. (57202046772)","57808320600; 57808861200; 57202046772","Zoom-DF: A Dataset for Video Conferencing Deepfake","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134411567&partnerID=40&md5=b78bc3b58552c121d1b76a0e120198ff","With the rapid growth of deep learning methods, AI technologies for generating deepfake videos also have been significantly advanced. Nowadays, the manipulated videos such as deepfakes are so sophisticated that one cannot easily differentiate between real and fake, and one can create such videos with little effort. However, such technologies can be likely to be abused by people with malicious intents. To address this issue, approaches and efforts to detect deepfakes have been researched significantly. However, the performances of the detectors in general depends on the quantity and quality of the training data. In this paper, we introduce a new deepfake dataset, Zoom-DF, which can be injected during the remote meeting and video conferencing, to create a sequence of fake participant images. While most deepfake datasets focus on the face area, our dataset primarily targets for the remote meeting, and manipulates movements of the participants. We evaluate existing deepfake detectors on our new Zoom-DF dataset and present the performance results. © 2022 ACM.","deepfake dataset; deepfake detection; video conferencing"
"Lee, S.; Ko, D.; Park, J.; Shin, S.; Hong, D.; Woo, S.S.","Lee, Sangjun (57484104500); Ko, Donggeun (57483420300); Park, Jinyong (57484442300); Shin, Saebyeol (57484274700); Hong, Donghee (57483420400); Woo, Simon S. (57202046772)","57484104500; 57483420300; 57484442300; 57484274700; 57483420400; 57202046772","Deepfake Detection for Fake Images with Facemasks","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134393705&partnerID=40&md5=ef2efba1298f62f2b7b98b185a69332b","Hyper-realistic face image generation and manipulation have given rise to numerous unethical social issues, e.g., invasion of privacy, threat of security, and malicious political maneuvering, which resulted in the development of recent deepfake detection methods with the rising demands of deepfake forensics. Proposed deepfake detection methods to date have shown remarkable detection performance and robustness. However, none of the suggested deepfake detection methods assessed the performance of deepfakes with the facemask during the pandemic crisis after the outbreak of the COVID-19. In this paper, we thoroughly evaluate the performance of state-of-The-Art deepfake detection models on the deepfakes with the facemask. Our result shows that fake facial images with facemask can deceive well-known deepfake detection models, thereby evading the real-world security systems. © 2022 ACM.","deepfake detection; deepfake with facemask; deepfakes"
"Kim, T.; Kim, J.; Kim, J.; Woo, S.S.","Kim, Taejune (57809143900); Kim, Jeongho (57865611000); Kim, Jeonghyeon (59642589800); Woo, Simon S. (57202046772)","57809143900; 57865611000; 59642589800; 57202046772","A Face Pre-Processing Approach to Evade Deepfake Detector","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134369176&partnerID=40&md5=6717456c1a312445e2dcc424202cc1ba","Recently, various image synthesis technologies have increased the prevalence of impersonation attacks. With the development of such technologies, damages to people such as defamation or fake news have also increased. Deepfakes have already evolved to the point, where people cannot easily distinguish fake from real. This leads to an urgent need for developing detection methods. Currently, in order to detect deepfakes, many deepfake datasets are widely used in deep neural networks. And several methods have been proposed and demonstrated to be effective in detecting deepfakes. In this work, we present pre-processing techniques such as face restoration, edge smoothing, face beautification to mitigate the artifacts of deepfakes and makes them appear more natural to humans, while lowering the deepfake detection performance. Through extensive experiments, our method can significantly lower the performance of the state-of-The-Art deepfake detectors and expose the vulnerability of deployed detectors. © 2022 ACM.","deepfake detection; face beautification; image forensics"
"Woo, S.S.; Tariq, S.; Kim, H.","Woo, Simon S. (57202046772); Tariq, Shahroz (57196864129); Kim, Hyoungshick (35310921400)","57202046772; 57196864129; 35310921400","WDC'22: 1st Workshop on the Security Implications of Deepfakes and Cheapfakes","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133194730&partnerID=40&md5=36ed5a948906c46997f112507b1d5ac6","The development of techniques for creating completely synthetic photographic images and videos, as well as the increasing prevalence of disinformation associated with such synthetic media, have sparked interest in the computer community. One such issue is the proliferation of deepfakes. However, much of the research is devoted to outwitting the SOTA in order to generate and detect fabricated images and video. Considering them from the perspective of computer security and human ethics is largely ignored. As such, this workshop aims to provide a forum for researchers to exchange ideas and methodologies, as well as to provide academia and industry with insights into the development and identification of fake media from a computer security perspective. © 2022 Owner/Author.","deep learning; deepfake detection; deepfake generation; deepfakes; face manipulation; gan; synthetic images"
"Taeb, M.; Chi, H.","Taeb, Maryam (57441688300); Chi, Hongmei (8888500200)","57441688300; 8888500200","Comparison of Deepfake Detection Techniques through Deep Learning","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149326951&partnerID=40&md5=87c2ce2820e8b4b0b236caf92aaa46c3","Deepfakes are realistic-looking fake media generated by deep-learning algorithms that iterate through large datasets until they have learned how to solve the given problem (i.e., swap faces or objects in video and digital content). The massive generation of such content and modification technologies is rapidly affecting the quality of public discourse and the safeguarding of human rights. Deepfakes are being widely used as a malicious source of misinformation in court that seek to sway a court’s decision. Because digital evidence is critical to the outcome of many legal cases, detecting deepfake media is extremely important and in high demand in digital forensics. As such, it is important to identify and build a classifier that can accurately distinguish between authentic and disguised media, especially in facial-recognition systems as it can be used in identity protection too. In this work, we compare the most common, state-of-the-art face-detection classifiers such as Custom CNN, VGG19, and DenseNet-121 using an augmented real and fake face-detection dataset. Data augmentation is used to boost performance and reduce computational resources. Our preliminary results indicate that VGG19 has the best performance and highest accuracy of 95% when compared with other analyzed models. © 2022 by the authors.","deep learning; deepfake detection; digital forensics; face-image manipulation; media forensics; VGG19"
"Zhu, K.; Xu, W.; Lu, W.; Zhao, X.","Zhu, Kaiman (57224126434); Xu, Wenbo (57222359967); Lu, Wei (57715097700); Zhao, Xianfeng (55623697900)","57224126434; 57222359967; 57715097700; 55623697900","Deepfake video detection with feature interaction amongst key frames; 多关键帧特征交互的人脸篡改视频检测","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123258080&partnerID=40&md5=3bbcef2cfce39ad6ef684eaa702a643d","Objective: Images and videos manipulation is becoming more easy-use and indistinguishable with development of deep learning. Deepfake is a sort of face manipulation technique which poses a great threat to social security and individual rights. Researchers have been working to propose various detection models or frameworks, which can be divided into three categories combined with their inputs factors like frame level, clip level and video level, respectively. Detection models of frame level have focused on single frame and ignore temporal information only, potentially leading to low confidence in videos detection. Although detection models of clip level make use of a sequence of frames simultaneously, the length of sequence is relatively shorter than the real length of a video. Thus, a clip cannot well represent a video. Moreover, video clips are fragmented and may have adverse effect on video level detection. The consecutive frames in a short clip have little difference and cause redundant information, which may cut the detection performance. The video level detection methods use frames of large interval as input and capture more key features to represent qualified video. The existing methods ignore the impact of sample extraction procedure and its expensive computation of decoding video stream. To solve this problem and provide more efficient detection method on face-swap manipulation videos, a detection framework based on the interaction of key frames' features is illustrated. Method: The proposed detection framework has consisted of two parts: key frames extraction in context of face region images extraction and the detection model. First, an amount of key frames from the video stream have been extracted and checked. Inter-frame decoding is avoided and computation time is deducted via key frames extraction. Next, multitask cascaded convolutional neural networks(MTCNN) is applied to locate the position of face region on the extracted frames. Face images are cropped with 80 margins from them. MTCNN is re-applied to the images extracted before. Compact face images are extracted from them. The face images input are mapped into high dimensional embedding space by Inception-ResNet-V1. This convolution neural network is initialized by pre-trained parameters in face recognition task and updated end-to-end implementation. At last, these features of key frames are melted into an interaction learning module, which contains various self-attention-based encoders. In this module, each key frame feature can learn from every other key frame and update itself. Distinctive abnormal features of manipulated images are extracted via part of linear and non-linear transformations. A global classification vector is concatenated at the first of key frame features, updating along with them, and makes the final decision. Result: The detection framework has been evaluated on five mainstream datasets listed below: Deepfakes, FaceSwap, FaceShifter, DeepFakeDetection and Celeb-DF, respectively. The three datasets of Deepfakes, FaceSwap, FaceShifter are from FaceForensics++. It achieves accuracies of 97.50%, 97.14%, 96.79%, 97.09% and 98.64%, respectively, with a small quantity of key frames. Original 3D convolution models and LSTM-based models are compared with the illustrated detection model on Celeb-DF in terms of 16 key frames as input. A demonstrated lightweight 3D model(L3D) for deepfake detection has been tested as well. As the samples size is smaller than that of exisited work, R3D, C3D, I3D and L3D have demonstrated poor detection performance while LSTM-based one achieves an accuracy of 98.06%. The demonstrated model is much better than before (99.61%). In the condition that the input is changed to consecutive frames, the proposed model has shown qualified performance 98.64% as well. The time cost of detection is evaluated and illustrated that our framework can detect a video in an average time of 3.17 s, less than major models or with consecutive frames as input. The research strategy of key frame extraction and the framework proposed are shown to be efficient based on the experiments results. A realistic scene has been considered, in which key frames quantity of the video has been checked. A little more frames than training can achieve higher accuracy as the detection model has learned the relation well amongst frames and can be generalized well, but fewer frames can also lead to insufficient information and worse performance. In general, the proposed model can achieve good and stable detection performance, training with 16 key frames. Conclusion: An efficient detection framework for face-swap manipulation videos has been demonstrated. It takes the advantage of key frame extraction that it skips the procedure of inter-frame decoding and get time cutting in the preprocessing step. Based on face region images being cropped from valid key frames' pictures, Inception-ResNet-V1 maps them to a standardized embedding space followed by several layers of self-attention based encoders and linear or non-linear transformations. More meaningful and distinguishing information is captured when every frame feature can learn from each other. The experiments on Celeb-DF dataset demonstrate that the illustrated model outperforms other sequential model and 3D convolution neural networks. The time cost is relatively deducted and the effiency of the proposed framework is improved. © 2022, Editorial Office of Journal of Image and Graphics. All right reserved.","Deepfake detection; Face-swap manipulation videos; Hierarchical structure; Key frames; Multi-frame interaction; Self-attention mechanism"
"Jaleel, Q.; Hadi, I.","Jaleel, Qasim (57200678270); Hadi, Israa Hussein Abdel (56715877400)","57200678270; 56715877400","Facial Action Unit-Based Deepfake Video Detection Using Deep Learning","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182591440&partnerID=40&md5=9bb6f94100207c06f0dfe2662f1f4118","Deepfake videos are becoming more realistic, making them a menace. As a result of the development of deep learning techniques such as Generative adversarial networks (GAN), Deepfake has become closer to the truth. Widespread use of falsified videos and images on social media requires accurate detection. An identity switch (DeepFake) and an expression swap create facial modifications. This paper can detect deepfakes that are perfectly created. Traditional detection approaches that observe artifacts and pixel irregularities cannot keep up with modern technology. The paper is divided into two stages. In the first stage, the paper extracts facial action units from a person and creates a profile for him. This profile represents the behavior of his facial expressions, which differ from one person to another. This was done by building a deep learning network and training it based on a dataset. The second stage is testing, which involves taking videos, extracting facial action units, and testing them on the network to classify them as fake or real. The network has proven its ability to classify with high accuracy of %95.75 compared to traditional methods. © 2022 IEEE.","DeepFake Detection; face detection; facial action unit; Facial expression recognition; GAN; Media Forensics"
"Jaleel, Q.; Ali, I.H.","Jaleel, Qasim (57200678270); Ali, Israa H. (56526190500)","57200678270; 56526190500","Facial Behavior Analysis-Based Deepfake Video Detection using GAN Discriminator","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152190107&partnerID=40&md5=2fe32553f32518d10e323e97d8bc6512","Deepfake is an artificial intelligence-based method for making fake images of people. It works by putting the existing (source) images or videos on the final (destination) images or videos. But recent improvements in deep learning have made it much easier to make fake videos that look real and are convincing with a relatively small amount of data and computing power. As a result of the development of deep learning techniques such as Generative adversarial networks (GAN), Deepfake has become closer to the truth. Many researchers are based on discovering deep fakes that were created by traditional methods. Traditional methods of detection that look for artifacts and pixels that don't match up can't keep up. This paper can detect deepfakes that are perfectly created. It is detected by modifying the GAN algorithm and inverting its function. The discriminator model of a GAN network is used to analyze behavior, facial gestures, and the appearance of an object. The paper is divided into two stages. The first stage is to use a GAN discriminator that has been modified. It is then trained using a deepfake dataset. The second stage is to test the videos by extracting the faces. Next, run it through the GAN discriminator to see if it's a forgery. In comparison to other networks, the GAN discriminator has demonstrated its ability and accuracy in detecting fake videos. The network's accuracy in detecting and distinguishing between real and fake videos is %94.65. © 2022 IEEE.","DeepFake Detection; Face Detection; GAN; GAN discriminator; Media Forensics"
"Liu, D.; Yang, Z.; Zhang, R.; Liu, J.","Liu, Dazhuang (58175923000); Yang, Zhen (57198698830); Zhang, Ru (56890004200); Liu, Jianyi (55705849900)","58175923000; 57198698830; 56890004200; 55705849900","A Robust Deepfake Video Detection Method based on Continuous Frame Face-swapping","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152142619&partnerID=40&md5=9795e8daa7d5899d8009518b540c6894","Detection of deepfake videos faces serious generalization problem in real world application scenarios. Existing robust deepfake detection methods can only works on single frame image but not continuous frame videos. In this paper, we propose a robust deepfake video detection method based on continuous frame face-swapping. We design our face-swapping dataset with Delaunay triangulation and piecewise affine transform to achieve continuous frame face-swapping. We design a feature enhancement module with facial and background information covered to make the method focus on the mask fusion zone. We build our detection model with Efficient Net to extract intra-frame fusion feature and LSTM to extract inter-frame time feature. Cross-domain experiments show that our method achieves better detection AUC than existing methods, which proves our method is robust because of generalization. © 2022 IEEE.","continuous frame face-swapping; deepfake detection; Efficient Net; generalization; LSTM"
"Liu, D.; Yang, Z.; Zhang, R.; Liu, J.","Liu, Dazhuang (58175923000); Yang, Zhen (57198698830); Zhang, Ru (56890004200); Liu, Jianyi (55705849900)","58175923000; 57198698830; 56890004200; 55705849900","MaskGAN: A Facial Fusion Algorithm for Deepfake Image Detection","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151993348&partnerID=40&md5=1b2597235dba8fcdb6988d180438131d","The rapid development of deepfakes has caused serious harm to social cognition. However, the current deepfake detection algorithms generally have the problem of poor generalization, and the accuracy rate drops sharply on datasets with unknown deepfake methods. In this paper, we propose a facial fusion algorithm called MaskGAN to enable more generalized deepfake detection. The generator of MaskGAN uses U-Net and SSE to extract the features of face images, and realizes mask generation and face fusion, The discriminator of MaskGAN uses the convolution layer to discriminate the face-swaping images generated by MaskGAN. Then, the obtained face-swaping images are used as training sets and input into an improved Deeplab V3+for training, so that the network can extract the fusion feature circle generated during the face-swaping process from the face-swaping images, so as to identify the authenticity of the face-swaping images. We achieve accurate face swapping with only fused features introduced, generating a face swapping dataset with fused labels. It solves the common problems of over-fitting and poor generalization of existing algorithms. Through a large number of experiments, it is proved that MaskGAN enabled Deeplab V3+detection model can perform well in the case of unknown tampering methods, which achieved 23.02% and 6.9% cross-domain AUC performance improvement. © 2022 IEEE.","deepfake detection; faceswap detection; fusion feature; generative adversarial network"
"Ilyas, H.; Irtaza, A.; Javed, A.; Malik, K.M.","Ilyas, Hafsa (57894630000); Irtaza, Aun (54882450900); Javed, Ali (57190125008); Malik, Khalid Mahmood (57200448301)","57894630000; 54882450900; 57190125008; 57200448301","Deepfakes Examiner: An End-to-End Deep Learning Model for Deepfakes Videos Detection","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147686689&partnerID=40&md5=c891a3a8ef70adf828fb4425e29e9ed2","Deepfakes generation approaches have made it possible even for less technical users to generate fake videos using only the source and target images. Thus, the threats associated with deepfake video generation such as impersonating public figures, defamation, and spreading disinformation on media platforms have increased exponentially. The significant improvement in the deepfakes generation techniques necessitates the development of effective deepfakes detection methods to counter disinformation threats. Existing techniques do not provide reliable deepfakes detection particularly when the videos are generated using different deepfakes generation techniques and contain variations in illumination conditions and diverse ethnicities. Therefore, this paper proposes a novel hybrid deep learning framework, InceptionResNet-BiLSTM, that is robust to different ethnicities and varied illumination conditions, and able to detect deepfake videos generated using different techniques. The proposed InceptionResNet-BiLSTM consists of two components: customized InceptionResNetV2 and Bidirectional Long-Short Term Memory (BiLSTM). In our proposed framework, faces extracted from the videos are fed to our customized InceptionResNetV2 for extracting frame-level learnable features. The sequences of features are then used to train a temporally aware BiLSTM to classify between the real and fake video. We evaluated our proposed approach on the diverse, standard, and largescale FaceForensics++ (FF++) dataset containing videos manipulated using different techniques (i.e., DeepFakes, FaceSwap, Face2Face, FaceShifter, and NeuralTextures) and the FakeA VCeleb dataset. Our method achieved an accuracy greater than 90% on DeepFakes, FaceSwap, and Face2Face subsets. Performance and generalizability evaluation highlights the effectiveness of our method for detecting deepfake videos generated through different techniques on diverse FF++ and FakeA VCeleb datasets. © 2022 IEEE.","Bidirectional LSTM; Deepfakes Detection; Face-swap; FaceForensics++; FakeAVCeleb; InceptionResNetV2; Puppet-master"
"Nguyen, H.T.; Dao, T.C.; Phan, T.M.N.; Phan, T.T.","Nguyen, Thanh Hai (57209166507); Dao, Congtinh (57220594100); Phan, Thao Minh Nguyen (57221946242); Phan, Tai Tan (57188881882)","57209166507; 57220594100; 57221946242; 57188881882","Fake face detection in video using shallow deep learning architectures","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147539891&partnerID=40&md5=5c086fb8ad5e36b81cd3217cc01c1713","Deep learning techniques have been used in various disciplines, ranging from simple data processing to complicated image classification tasks. Deepfakes is a deep learning approach with benefits and drawbacks impacting the world. However, deepfakes are now cutting-edge technology being exploited for nefarious purposes such as the breach of human privacy and identity. Because deep learning is advancing rapidly daily, people use AI to produce deepfakes videos and images. Hence newer AI technology to detect deepfakes is critical. Therefore, the study has proposed detecting video and image deepfakes based on convolutional neural network (CNN) combined with the long short-term memory (LSTM) model, which constructs a deep learning model classifying images and video deepfakes. The proposed model investigated a novel approach to research more powerful models which can be applied to any large dataset. The experimental results demonstrated that the proposed method had achieved promising performance on modified datasets from Celeb-DF with high AUC performance up to 0.7584 and MCC reaching 0.558. Besides, this paper presents brief research on creating and detecting the image and video deepfakes technologies and points out the challenges of using deepfakes in many different contexts. © © 2022 Inderscience Enterprises Ltd.","CNN; convolutional neural network; deep learning; deepfake detection; deepfakes; long short-term memory; LSTM"
"To, T.-A.; Luong, H.-C.; Nguyen, N.-T.; Nguyen, T.-T.; Tran, M.-T.; Do, T.-L.","To, Tuan (57782602800); Luong, Hoangchau (58089295000); Nguyen, Nham Tan (57782769000); Nguyen, Trong Tin (58089233200); Tran, Minh Triet (35176729700); Do, Trongle (57212828893)","57782602800; 58089295000; 57782769000; 58089233200; 35176729700; 57212828893","Deepfake Detection using EfficientNet: Working Towards Dense Sampling and Frames Selection","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147331265&partnerID=40&md5=18fb2916cde070e43b15d73afa2fbc2e","Deepfake is a controversial technology that allows the automatic generation of video content through generative adversarial networks. The emergence of Deepfake technology is problematic and sophisticated, making it more difficult to detect. In our paper, we contribute a deep-learning method to resolve that problem. We use the MTCNN face detector to extract facial images and apply data augmentation and EfficientNet for real-fake classification. We apply frame selection with the raw label prediction to tackle the fault cases and receive the final label. With the approach above applied, we utilize training and evaluation datasets from FaceForensics++ and achieve an accuracy of 62.5%. © 2022 IEEE.","Deepfake Detection; Dense Sampling; Efficient Net; Frame Selection"
"Lin, Y.; Chen, H.; Li, B.; Wu, J.","Lin, Yuzhen (57210221355); Chen, Han (57192537490); Li, Bin (57102112000); Wu, Junqiang (57969946100)","57210221355; 57192537490; 57102112000; 57969946100","TOWARDS GENERALIZABLE DEEPFAKE FACE FORGERY DETECTION WITH SEMI-SUPERVISED LEARNING AND KNOWLEDGE DISTILLATION","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146666540&partnerID=40&md5=6ed4cf53452e170499379cbac992d0dc","Existing methods for deepfake face forgery detection have already achieved tremendous progress in well-controlled laboratory conditions. However, under wild scenarios where the training and testing forgeries are synthesized by different algorithms and when labeled data are insufficient, the performance always drops greatly. In this work, we present a Semi-supervised Contrastive Learning and Knowledge Distillationbased framework (SCL-KD) for deepfake detection to reduce the aforementioned performance gap. Our proposed framework contains three stages: self-supervised pre-training, supervised training, and knowledge distillation. Specifically, a feature encoder is firstly trained in a self-supervised manner with a large number of unlabeled samples through a momentum contrastive mechanism. Secondly, a fully-connected classifier on top of the feature encoder is trained in a supervised manner with a small amount of labeled samples to build a teacher model. Finally, a compact student model is trained with the help of the teacher model using knowledge distillation, in order to avoid overfitting to labeled data and have better generalizability on mismatched datasets. Evaluations on several benchmark datasets corroborate the good performance of our approach in cross-dataset situations and few labeled data scenarios. It reveals the potential of our proposed method for real-world deepfake detection. © 2022 IEEE.","Deepfake detection; knowledge distillation; self-supervised contrastive learning"
"John, J.; Sherif, B.V.","John, Jerry (57271904100); Sherif, Bismin V. (57216592661)","57271904100; 57216592661","Comparative Analysis on Different DeepFake Detection Methods and Semi Supervised GAN Architecture for DeepFake Detection","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146439192&partnerID=40&md5=86ea1893b03623b1b751f7cb8de36472","The use of deep learning results in solving a wide range of real-world problems and applications, but there are some drawbacks along with this positive side. One of the most recent and advanced problems among them is the wide use of deepfakes. Deepfakes are digital tampered images or videos created using different deep learning methods. In a deepfake, the face of a targeted person is superimposed on a source image so that this digital tampered data can be used for digital frauds, blackmailing, pornography etc. With the developments in the deep learning field, it is becoming challenging to distinguish between real and fake manually. So it is essential to do research and development in the area of deepfake detection. In this paper, an extensive discussion and timely overview on different deepfake detection methods are done under the classification of feature-based, temporal-based, and deep feature-based deepfake detection. The comparison study is mainly done based on the key features used, face detection architecture, deep learning architecture, video-based or image-based, the dataset used, frames size, and dataset size used. Along with the comparison, a semisupervised GAN architecture is also proposed and developed to detect the deepfake images. © 2022 IEEE.","DeepFake; DeepFake Detection; SGAN"
"Wu, M.; Wang, F.; Wu, X.; Yu, F.; Wang, B.; Song, Z.","Wu, Mingkan (57459748600); Wang, Fei (58366999700); Wu, Xiaohan (57460009800); Yu, Fei (57204396101); Wang, Bo (57216234699); Song, Zengren (57367945900)","57459748600; 58366999700; 57460009800; 57204396101; 57216234699; 57367945900","Deepfake Detection with Data Privacy Protection","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143588145&partnerID=40&md5=9092ea2edcac5ac686777b565b8e2d58","As image and video forgery can be easily used for malicious purposes, the detection of such forgeries has social and technical significance. In this work, we are particularly interested in the detection of Deepfake. For privacy and sensitive data preserving reasons, we engage a flank attack using Federated Learning, a distributed framework-based model which keeps data locally during training while uploading model parameters for aggregate instead. We propose a shallow network for tampering face detection. Also, we made some progress in promoting cross-dataset detection performance which is crucial in Deepfake detection. Our experiments show a well-balanced trade-off result between detection performance and privacy preservation. © 2022 IEEE.","Deepfake Detection; Federated Learning"
"Budhiraja, R.; Kumar, M.; Das, M.K.; Bafila, A.S.; Singh, S.","Budhiraja, Rajat (57190491952); Kumar, Manish (57207935496); Das, Mrinal K. (57210523532); Bafila, Anil Singh (57222111714); Singh, Sanjeev (57216140046)","57190491952; 57207935496; 57210523532; 57222111714; 57216140046","MeDiFakeD: Medical Deepfake Detection using Convolutional Reservoir Networks","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142869741&partnerID=40&md5=ee2fdf2d8ec19bdc211a5dde1787f166","Generation of photo-realistic fake content using Artificial Intelligence (AI)-based Generative Adversarial Networks has not only engulfed media, facial recognition or social networks, but is now rapidly surging ahead in the realm of medical imaging and is further facilitated by worldwide Covid-19 outbreak. Medical Deepfake pertains to application of AI-triggered deepfake technology on to medical modalities like Computed Tomography (CT) scan, X-Ray, Ultrasound etc. Owing to its high degree of privacy and sensitivity, any threats originating from exposed vulnerabilities, or, attacks on patients medical imagery takes an extremely threatening stance, either devastating the patients remaining lifespan, or resulting in grave financial frauds while satiating corrupt business motives. These tampering attacks, involve either insertion or removal of certain disease conditions, tumors in/from the modality under analysis. This paper implements and demonstrates a practical, lightweight technique which aims to accelerate deepfake detection for biomedical imagery by detecting malignant tumors injected in modalities of healthy patients. The developed technique makes use of convolutional reservoir networks (CoRN), which enable ensemble feature extraction and results in improved classification metrics. We further corroborate its effectiveness while working with a miniscule (< 100) set of images and illustrate the extent of generalization attained with different forms of the same medical imagery. © 2022 IEEE.","Computed Tomography; Convolution Neural Networks; Convolutional Reservoir Network; Medical Deepfake Detection; Medical Image Tampering; Reservoir Computing"
"Fathan, A.; Alam, J.; Kang, W.","Fathan, Abderrahim (57224498886); Alam, Jahangir (56973051800); Kang, Woohyun (57189587935)","57224498886; 56973051800; 57189587935","Multiresolution Decomposition Analysis via Wavelet Transforms for Audio Deepfake Detection","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142724295&partnerID=40&md5=85b474a47fa2b871e274a4e9cedc1720","Voice and face recognition are becoming omnipresent, and the need for secure biometric technologies increases as technologies like deepfake are making it increasingly harder to spot fake generated content. To improve current audio spoofing detection, we propose a curated selection of wavelet transforms based-models where, instead of the widely employed acoustic features, the Mel-spectrogram image features are decomposed through multiresolution decomposition analysis to better handle spectral information. For that, we adopt the use of median-filtering harmonic percussive source separation (HPSS), and perform a large-scale study on the application of several recent state-of-the-art computer vision models on audio anti-spoofing detection. These wavelet transforms are experimentally found to be very useful and lead to a notable performance of 4.8% EER on the ASVspoof2019 challenge logical access (LA) evaluation set. Finally, a more adversarialy robust WaveletCNN-based model is proposed. © 2022, Springer Nature Switzerland AG.","Audio anti-spoofing; Deepfake detection; Wavelet CNNs; Wavelet transform"
"Shao, R.; Wu, T.; Liu, Z.","Shao, Rui (57201860007); Wu, Tianxing (57815209400); Liu, Ziwei (56437024900)","57201860007; 57815209400; 56437024900","Detecting and Recovering Sequential DeepFake Manipulation","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142719199&partnerID=40&md5=2f8e2a488158ca20f4110c660e41e46c","Since photorealistic faces can be readily generated by facial manipulation technologies nowadays, potential malicious abuse of these technologies has drawn great concerns. Numerous deepfake detection methods are thus proposed. However, existing methods only focus on detecting one-step facial manipulation. As the emergence of easy-accessible facial editing applications, people can easily manipulate facial components using multi-step operations in a sequential manner. This new threat requires us to detect a sequence of facial manipulations, which is vital for both detecting deepfake media and recovering original faces afterwards. Motivated by this observation, we emphasize the need and propose a novel research problem called Detecting Sequential DeepFake Manipulation (Seq-DeepFake). Unlike the existing deepfake detection task only demanding a binary label prediction, detecting Seq-DeepFake manipulation requires correctly predicting a sequential vector of facial manipulation operations. To support a large-scale investigation, we construct the first Seq-DeepFake dataset, where face images are manipulated sequentially with corresponding annotations of sequential facial manipulation vectors. Based on this new dataset, we cast detecting Seq-DeepFake manipulation as a specific image-to-sequence (e.g. image captioning) task and propose a concise yet effective Seq-DeepFake Transformer (SeqFakeFormer). Moreover, we build a comprehensive benchmark and set up rigorous evaluation protocols and metrics for this new research problem. Extensive experiments demonstrate the effectiveness of SeqFakeFormer. Several valuable observations are also revealed to facilitate future research in broader deepfake detection problems. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","DeepFake detection; Sequential facial manipulation"
"Testa, R.L.; Machado-Lima, A.; Nunes, F.L.S.","Testa, Rafael Luiz (56902306100); Machado-Lima, Ariane L. (57195959173); Nunes, Fátima de Lourdes dos Santos (7102392843)","56902306100; 57195959173; 7102392843","Deepfake Detection on Videos Based on Ratio Images","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139556657&partnerID=40&md5=e9dbeeb290a00d34b5fbafcc932cb686","Deepfake detection comes as a countermeasure to identify fake media content to reduce its harmful implications. Most detection approaches rely on identifying specific artifacts that can quickly become obsolete due to the fast advance in facial forgery methods. Some facial manipulation detection methods use temporal information to classify the video as real or fake. These methods mainly rely on 3D CNN architectures or two-stream networks using frame and video features. Our method not only considers temporal aspects, but it comes from a different perspective: extracting features that can account for inter-frame changes on a video. Inspired by the concept of ratio images, we extract features based on the ratio between adjacent frames for the face and its background. The experimental evaluation showed better results in intra- and cross-dataset tests on FaceForensics++ (FF++) and CelebDF datasets compared to the state-of-the-art deepfake detection approaches in the assessment with seen and unseen facial manipulation methods, as well as in seen and unseen video settings. In the intra-dataset experiment, the model resulted in an AUC of 100% for both CelebDF and FF++ datasets. In the cross dataset experiment, the model resulted in an AUC of 98% when trained with CelebDF and tested with FF++ and 86% when trained with FF++ and tested with CelebDF. © 2022 IEEE.","Deepfake detection; Expression Ratio Image; facial forgery; facial manipulation; spatial-temporal; video"
"Johnson, D.; Gwyn, T.; Qingge, L.; Roy, K.","Johnson, David (58460488500); Gwyn, Tony (57222376122); Qingge, Letu (56183038700); Roy, Kaushik (35566325000)","58460488500; 57222376122; 56183038700; 35566325000","Deepfake Detection Using CNN Trained on Eye Region","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137981885&partnerID=40&md5=af28c78ce4b63c2b59b343deb5191c6a","In this work, we will develop a simple convolutional neural network to detect deepfakes in videos on a frame-by-frame level, focusing on the region around the eyes. Since deepfakes are increasingly being created using forms of CNN, it should be possible to also detect deepfakes using CNN. OpenCV allows for frame extraction from videos, while also allowing image cropping. The well-developed Multitask Cascade Neural Network (MTCNN) is a stacked neural network for face detection and alignment. MTCNN is used for high accuracy face detection to greatly reduce false positive images in the dataset. Finally, a region around both eyes are cropped, with extra padding, to be used as input to train a CNN, using returned coordinates from MTCNN for the eyes. This research will focus on measuring if the eye region can be a useful area of interest for comparing original videos to deepfake videos. © 2022, Springer Nature Switzerland AG.","CNN; Computer vision; Deep learning; Deepfake; Deepfake detection; Eye region"
"Yu, C.; Chen, P.; Dai, J.; Wang, X.; Zhang, W.; Liu, J.; Han, J.","Yu, Cai (57223740043); Chen, Peng (57216430660); Dai, Jiao (37010322300); Wang, Xi (57192624112); Zhang, Weibo (57210575012); Liu, Jin (58850741400); Han, Jizhong (23008759600)","57223740043; 57216430660; 37010322300; 57192624112; 57210575012; 58850741400; 23008759600","Focus by Prior: Deepfake Detection Based on Prior-Attention","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137659706&partnerID=40&md5=8a8d0ef1d0391415df15d8a107173364","Nowadays advanced facial manipulation techniques produce deepfake videos more realistically, which makes deepfake detection more difficult. To capture subtle and intricate artifacts, recent works attempt to enhance low-level textural information by attention-based framework. However, these methods require complex simulated data or extra supervision. Highly dependent on training settings, these methods not only have high training costs but also are prone to overfitting. To address this issue, we propose a novel perspective of deepfake detection via so-called prior-attention. Specifically, we introduce prior textural information, such as edge and noise, to model the attention maps explicitly. Benefiting from these natural 'attention maps', our model significantly enhances discriminative information without additional supervision. Furthermore, we design a Feature Abstraction Block (FAB) to facilitate cross-layer features interaction and insert it into distinct layers of CNN to detect the inconsistencies at multiple spatial levels. Extensive experiments demonstrate that our method achieves performance comparable to state-of-the-art methods. © 2022 IEEE.","Attention Mechanism; Deepfake Detection; Face Forensics"
"Yuan, Y.; Fu, X.; Wang, G.; Li, Q.; Li, X.","Yuan, Yike (57219736335); Fu, Xinghe (57549209900); Wang, Gaoang (57193333173); Li, Qiming (57838413300); Li, X. (55718109600)","57219736335; 57549209900; 57193333173; 57838413300; 55718109600","Forgery-Domain-Supervised Deepfake Detection With Non-Negative Constraint","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135739583&partnerID=40&md5=f8e70036694c12246d1d03d95f909172","Fake faces produced by deepfake techniques have attracted public concerns in recent years. Deepfake detection is a binary classification task that distinguishes fake faces from real ones. As the training data for deepfake detection is usually generated from real faces via various face forgery methods, it is difficult for a single binary decision boundary to distinguish fake faces. Besides that, the learned features often involve irrelevant information for identifying fake faces that are generated from diverse forgery methods. To deal with such challenges, unlike existing approaches that regard fake detection as a binary classification, we re-model the task as a multiclass forgery-domain classification task, where each forgery method is treated as a distinct class. This simplifies the complex decision boundary brought by the diversity of forgery patterns and provides more forgery-relevant information for the learning process. In addition, we introduce a non-negative constrained learning framework composed of non-negative features and a non-negative constrained classifier (NCC) to block irrelevant features with zero weights and enhance forgery-relevant features with positive weights, leading to a sparse structure of the classifier. Furthermore, to capture subtle and discriminative forgery-relevant features, we propose an integration module over augmented faces based on cross-attention. We demonstrate that our approach achieves competitive performance and generalization ability on widely-used benchmarks through extensive experiments. © 1994-2012 IEEE.","Classifier regularization; deepfake detection; face classification; face forensics; feature integration"
"Wang, J.; Qi, Y.; Hu, J.; Hu, J.","Wang, Jiaying (59860866600); Qi, Yongfeng (54893032200); Hu, Jinlin (57667017800); Hu, Jihong (57829952900)","59860866600; 54893032200; 57667017800; 57829952900","Face forgery detection with a fused attention mechanism","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135414981&partnerID=40&md5=d3d69dd7de23fb9c8c30bdce1675806f","In recent years, the technology of forged faces has become more and more sophisticated, and the human eye cannot even distinguish these forged products. The fake face images or videos generated by this series of technologies are widely disseminated on the Internet, causing a serious impact on society, thus drawing attention to DeepFake detection, and more research is also inclined to this, but The current research has the problem that the extracted artifact features are relatively single, which leads to the relatively low performance of the artifact detection algorithm. To solve the limitations of the existing methods, the DeepFake detection method fused with attention mechanism is proposed, which extracts the global and local features of the face respectively. Artifact features are found in multiple regions of the face. The method is trained on the FaceForensics++ dataset, and the detection accuracy is improved in different network structures. © 2022 IEEE.","attention mechanism; DeepFake Detection; feature fusion"
"Wu, W.; Zhou, W.; Zhang, W.; Fang, H.; Yu, N.","Wu, Wenxuan (57821071700); Zhou, Wenbo (57192111936); Zhang, Weiming (34769199700); Fang, Han (57203894357); Yu, Nenghaif Hai (57201634030)","57821071700; 57192111936; 34769199700; 57203894357; 57201634030","Capturing the Lighting Inconsistency for Deepfake Detection","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135031817&partnerID=40&md5=eadb0797a6dd16b8b3fe3c32de3d3c6c","The rapid development and widely spread of deepfake techniques have raised severe societal concerns. Thus detecting such forgery contents has become a hot research topic. Many deepfake detection methods have been proposed in an artifacts-driven manner. They are well-designed to capture subtle artifacts of the face region in different domains. But since the lighting information is usually ignored during the forgery process, which may cause inconsistent lighting between the original face and forged one, we believe that this kind of semantic information can be useful to promote detection accuracy. In this paper, we propose a lighting inconsistency based deepfake detection method. We apply the color constancy technique to each sample and obtain a pre-processed image. Then the unique lighting information of each sample can be obtained by calculating the difference between the processed image and the original one. The lighting information will be used as an assistant channel for better detection accuracy. Extensive experiments show that our method can achieve obvious enhancements compared to the baseline method. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Color constancy; Deepfake detection; Light inconsistency"
"Guefrachi, S.; Jabra, M.B.; Hamam, H.","Guefrachi, Sarra (58202437700); Jabra, Marwa Ben (57216435445); Hamam, Habib (7004762599)","58202437700; 57216435445; 7004762599","Deepfake video detection using InceptionResnetV2","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134197904&partnerID=40&md5=87a544e7026731ea303f2ba3dfe20647","Recently, deepfake face-swapping technology has become popular, making it easy to create ultra-realistic fake videos. Detecting the authenticity of videos is becoming increasingly important due to the potential negative impact videos can have on the world. This research is a method for developing a deep learning model, which can make a distinction between real and fake videos. Research papers on the subject of transfer learning in the domain of computer vision to take advantage of the earlier created neural network functions for image classification and to create new models based on them. Deep learning continues to evolve in both generating and detecting deepfakes. Models developed to detect deepfakes are designed using older datasets, may become outdated over time, and require new detection techniques all the time. Research results are promising with over 90% accuracy and areas for development and further development © 2022 IEEE.","Deepfake; Deepfake detection; Fine-tuning; InceptionResnet-V2; Video authenticity"
"Wang, J.; Sun, Y.; Tang, J.","Wang, Jian (57221358673); Sun, Yunlian (55866644500); Tang, Jinhui (56364850900)","57221358673; 55866644500; 56364850900","LiSiam: Localization Invariance Siamese Network for Deepfake Detection","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133737405&partnerID=40&md5=19092f3c703bec5717e04bcec65f1672","Advances in facial manipulation technology have led to increasing indistinguishable and realistic face swap videos, which raises growing concerns about the security risk of deepfakes in the community. Although current deepfake detectors can gain promising performance when handling high-quality faces under within-database settings, most detectors suffer from performance degradation in cross-database evaluation. Moreover, when test faces' quality is different from training faces, the performance degrades even under within-database settings. To this end, we propose a novel Localization invariance Siamese Network (LiSiam) to enforce localization invariance against different image degradation for deepfake detection. Specifically, our Siamese network-based feature extractor takes the original image and the corresponding quality-degraded image as pairwise inputs and outputs two segmentation maps. A localization invariance loss is further proposed to impose localization consistency between the two segmentation maps. In addition, we design a Mask-guided Transformer to capture the co-occurrence between the forgery region and its surroundings. Finally, a multi-task learning strategy is utilized to obtain a robust and discriminative feature representation and jointly optimize multiple objective functions (i.e., segmentation, classification, and localization invariance losses) in an end-to-end manner. Experimental results on two public datasets, i.e., FaceForensics++ and Celeb-DF, demonstrate the superior performance of our proposed method to state-of-the-art methods. © 2005-2012 IEEE.","attention mechanism; Beepfake detection; localization invariance; multi-task learning; Siamese network"
"Cao, X.; Gong, N.Z.","Cao, Xiaoyu (57195334596); Gong, Neil Zhengqiang (37101758300)","57195334596; 37101758300","Understanding the Security of Deepfake Detection","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132785449&partnerID=40&md5=50dd499017845e843bfe9415b6c553c3","Deepfakes pose growing challenges to the trust of information on the Internet. Thus, detecting deepfakes has attracted increasing attentions from both academia and industry. State-of-the-art deepfake detection methods consist of two key components, i.e., face extractor and face classifier, which extract the face region in an image and classify it to be real/fake, respectively. Existing studies mainly focused on improving the detection performance in non-adversarial settings, leaving security of deepfake detection in adversarial settings largely unexplored. In this work, we aim to bridge the gap. In particular, we perform a systematic measurement study to understand the security of the state-of-the-art deepfake detection methods in adversarial settings. We use two large-scale public deepfakes data sources including FaceForensics++ and Facebook Deepfake Detection Challenge, where the deepfakes are fake face images; and we train state-of-the-art deepfake detection methods. These detection methods can achieve 0.94–0.99 accuracies in non-adversarial settings on these datasets. However, our measurement results uncover multiple security limitations of the deepfake detection methods in adversarial settings. First, we find that an attacker can evade a face extractor, i.e., the face extractor fails to extract the correct face regions, via adding small Gaussian noise to its deepfake images. Second, we find that a face classifier trained using deepfakes generated by one method cannot detect deepfakes generated by another method, i.e., an attacker can evade detection via generating deepfakes using a new method. Third, we find that an attacker can leverage backdoor attacks developed by the adversarial machine learning community to evade a face classifier. Our results highlight that deepfake detection should consider the adversarial nature of the problem. © 2022, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","Deepfake detection; Security"
"Wang, P.; Liu, K.; Zhou, W.; Zhou, H.; Liu, H.; Zhang, W.; Yu, N.","Wang, Ping (57211999886); Liu, Kunlin (57219670381); Zhou, Wenbo (57192111936); Zhou, Hang (57192375762); Liu, Honggu (57222171343); Zhang, Weiming (34769199700); Yu, Nenghaif Hai (57201634030)","57211999886; 57219670381; 57192111936; 57192375762; 57222171343; 34769199700; 57201634030","ADT: ANTI-DEEPFAKE TRANSFORMER","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131241338&partnerID=40&md5=3c4ca8fbe64d2538cb28e3f2fa68aa5e","Recently almost all the mainstream deepfake detection methods use Convolutional Neural Networks (CNN) as their backbone. However, due to the overreliance on local texture information which is usually determined by forgery methods of training data, these CNN-based methods cannot generalize well to unseen data. To get out of the predicament of prior methods, in this paper, we propose a novel transformer-based framework to model both global and local information and analyze anomalies of face images. In particular, we design attention leading module, multi-forensics module and variant residual connections for deepfake detection, and leverage token-level contrast loss for more detailed supervision. Experiments on almost all popular public deepfake datasets demonstrate that our method achieves state-of-the-art performance in cross-dataset evaluation and comparable performance in intra-dataset evaluation. © 2022 IEEE","Deepfake Detection; Face Forensics; Transferability; Vision Transformer"
"Rana, M.S.; Nobi, M.N.; Murali, B.; Sung, A.H.","Rana, M. S. (57194031026); Nobi, Mohammad Nur (58112800800); Murali, Beddhu (24399389300); Sung, Andrew H. (7006265966)","57194031026; 58112800800; 24399389300; 7006265966","Deepfake Detection: A Systematic Literature Review","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125748386&partnerID=40&md5=a72540ae9e163f44bf1f301defc8d131","Over the last few decades, rapid progress in AI, machine learning, and deep learning has resulted in new techniques and various tools for manipulating multimedia. Though the technology has been mostly used in legitimate applications such as for entertainment and education, etc., malicious users have also exploited them for unlawful or nefarious purposes. For example, high-quality and realistic fake videos, images, or audios have been created to spread misinformation and propaganda, foment political discord and hate, or even harass and blackmail people. The manipulated, high-quality and realistic videos have become known recently as Deepfake. Various approaches have since been described in the literature to deal with the problems raised by Deepfake. To provide an updated overview of the research works in Deepfake detection, we conduct a systematic literature review (SLR) in this paper, summarizing 112 relevant articles from 2018 to 2020 that presented a variety of methodologies. We analyze them by grouping them into four different categories: deep learning-based techniques, classical machine learning-based methods, statistical techniques, and blockchain-based techniques. We also evaluate the performance of the detection capability of the various methods with respect to different datasets and conclude that the deep learning-based methods outperform other methods in Deepfake detection. © 2013 IEEE.","Deepfake detection; digital media forensics; systematic literature review; video or image manipulation"
"Huang, Y.; Juefei-Xu, F.; Guo, Q.; Liu, Y.; Pu, G.","Huang, Yihao (57214756217); Juefei-Xu, Felix (54911989900); Guo, Qing (57191163500); Liu, Yang (56911879800); Pu, Geguang (9534351100)","57214756217; 54911989900; 57191163500; 56911879800; 9534351100","FakeLocator: Robust Localization of GAN-Based Face Manipulations","2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122580859&partnerID=40&md5=fbf6a86e9937bd300566a329ef65b721","Full face synthesis and partial face manipulation by virtue of the generative adversarial networks (GANs) and its variants have raised wide public concerns. In the multi-media forensics area, detecting and ultimately locating the image forgery has become an imperative task. In this work, we investigate the architecture of existing GAN-based face manipulation methods and observe that the imperfection of upsampling methods therewithin could be served as an important asset for GAN-synthesized fake image detection and forgery localization. Based on this basic observation, we have proposed a novel approach, termed FakeLocator, to obtain high localization accuracy, at full resolution, on manipulated facial images. To the best of our knowledge, this is the very first attempt to solve the GAN-based fake localization problem with a gray-scale fakeness map that preserves more information of fake regions. To improve the universality of FakeLocator across multifarious facial attributes, we introduce an attention mechanism to guide the training of the model. To improve the universality of FakeLocator across different DeepFake methods, we propose partial data augmentation and single sample clustering on the training images. Experimental results on popular FaceForensics++, DFFD datasets and seven different state-of-the-art GAN-based face generation methods have shown the effectiveness of our method. Compared with the baselines, our method performs better on various metrics. Moreover, the proposed method is robust against various real-world facial image degradations such as JPEG compression, low-resolution, noise, and blur. © 2005-2012 IEEE.","DeepFake; DeepFake detection and localization; face manipulation"
"Agarwal, A.; Singh, R.; Vatsa, M.; Noore, A.","Agarwal, Akshay (57188752637); Singh, Richa K. (15061841400); Vatsa, Mayank (55908650100); Noore, Afzel (6701728917)","57188752637; 15061841400; 55908650100; 6701728917","MagNet: Detecting Digital Presentation Attacks on Face Recognition","2021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121603131&partnerID=40&md5=f9492e6a953880cca4ec5de5807a537a","Presentation attacks on face recognition systems are classified into two categories: physical and digital. While much research has focused on physical attacks such as photo, replay, and mask attacks, digital attacks such as morphing have received limited attention. With the advancements in deep learning and computer vision algorithms, several easy-to-use applications are available where with few taps/clicks, an image can be easily and seamlessly altered. Moreover, generation of synthetic images or modifying images/videos (e.g. creating deepfakes) is relatively easy and highly effective due to the tremendous improvement in generative machine learning models. Many of these techniques can be used to attack the face recognition systems. To address this potential security risk, in this research, we present a novel algorithm for digital presentation attack detection, termed as MagNet, using a “Weighted Local Magnitude Pattern” (WLMP) feature descriptor. We also present a database, termed as IDAgender, which consists of three different subsets of swapping/morphing and neural face transformation. In contrast to existing research, which utilizes sophisticated machine learning networks for attack generation, the databases in this research are prepared using social media platforms that are readily available to everyone with and without any malicious intent. Experiments on the proposed database, FaceForensic database, GAN generated images, and real-world images/videos show the stimulating performance of the proposed algorithm. Through the extensive experiments, it is observed that the proposed algorithm not only yields lower error rates, but also provides computational efficiency. © © 2021 Agarwal, Singh, Vatsa and Noore.","DeepFake detection; digital threats; face morphing attack; face recognition (FR); face swapping"
"Khan, S.A.; Dai, H.","Khan, Sohail Ahmed (59882368100); Dai, Hang (56086273700)","59882368100; 56086273700","Video Transformer for Deepfake Detection with Incremental Learning","2021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119328332&partnerID=40&md5=5b930744dbcb62cdd7df3ace457953c3","Face forgery by deepfake is widely spread over the internet and this raises severe societal concerns. In this paper, we propose a novel video transformer with incremental learning for detecting deepfake videos. To better align the input face images, we use a 3D face reconstruction method to generate UV texture from a single input face image. The aligned face image can also provide pose, eyes blink and mouth movement information that cannot be perceived in the UV texture image, so we use both face images and their UV texture maps to extract the image features. We present an incremental learning strategy to fine-tune the proposed model on a smaller amount of data and achieve better deepfake detection performance. The comprehensive experiments on various public deepfake datasets demonstrate that the proposed video transformer model with incremental learning achieves state-of-the-art performance in the deepfake video detection task with enhanced feature learning from the sequenced data. © 2021 ACM.","deepfakes detection; face forensics; transformer; video analysis"
"Liu, J.; Zhu, K.; Lu, W.; Luo, X.; Zhao, X.","Liu, Jiarui (57209139159); Zhu, Kaiman (57224126434); Lu, Wei (57715097700); Luo, Xiangyang (8976166200); Zhao, Xianfeng (55623697900)","57209139159; 57224126434; 57715097700; 8976166200; 55623697900","A lightweight 3D convolutional neural network for deepfake detection","2021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107075937&partnerID=40&md5=487dcf125cbf7cbb2ecf8d04132f0b4d","The rapid development of DeepFake technologies has brought great challenges to the authenticity of video contents. It is of vital importance to develop DeepFake detection methods, among which three-dimensional (3D) convolution neural networks (CNN) have attracted wide interest and achieved satisfying performances. However, there are few 3D CNNs designed for DeepFake detection and the parameters of them are large, which cause heavy memory and storage consumption. In this paper, a lightweight 3D CNN is proposed for DeepFake detection. Channel transformation module is designed to extract features with much fewer parameters in higher level. Serving as spatial-temporal module, 3D CNNs are adopted to fuse the spatial features in time dimension. To suppress frame content and highlight frame texture, spatial rich model features are extracted from the input frames, which helps the spatial-temporal module achieve better performance. Experimental results show that the number of parameters of the proposed network is much less than those of other networks and the proposed network outperforms other state-of-the-art DeepFake detection methods on mainstream DeepFake data sets. © 2021 Wiley Periodicals LLC","3D CNN; deepfake; deepfake detection; face manipulation; face swapping"
"Lee, S.; Tariq, S.; Shin, Y.; Woo, S.S.","Lee, Sangyup (57204707958); Tariq, Shahroz (57196864129); Shin, Youjin (57204708168); Woo, Simon S. (57202046772)","57204707958; 57196864129; 57204708168; 57202046772","Detecting handcrafted facial image manipulations and GAN-generated facial images using Shallow-FakeFaceNet","2021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102968256&partnerID=40&md5=ab5fc2d912de054f267d49cfd8c83494","The rapid progress of sophisticated image editing tools has made it easier to manipulate original face images and create fake media content by putting one's face to another. In addition to image editing tools, creating natural-looking fake human faces can be easily achieved by Generative Adversarial Networks (GANs). However, malicious use of these new media generation technologies can lead to severe problems, such as the development of fake pornography, defamation, or fraud. In this paper, we introduce a novel Handcrafted Facial Manipulation (HFM) image dataset and soft computing neural network models (Shallow-FakeFaceNets) with an efficient facial manipulation detection pipeline. Our neural network classifier model, Shallow-FakeFaceNet (SFFN), shows the ability to focus on the manipulated facial landmarks to detect fake images. The detection pipeline only relies on detecting fake facial images based on RGB information, not leveraging any metadata, which can be easily manipulated. Our results show that our method achieves the best performance of 72.52% in Area Under the Receiver Operating Characteristic (AUROC), gaining 3.99% F1-score and 2.91% AUROC on detecting handcrafted fake facial images, and 93.99% on detecting small GAN-generated fake images, gaining 1.98% F1-score and 10.44% AUROC compared to the best performing state-of-the-art classifier. This study is targeted for developing an automated defense mechanism to combat fake images used in different online services and applications, leveraging our state-of-the-art hand-crafted fake facial dataset (HFM) and the neural network classifier Shallow-FakeFaceNet (SFFN). In addition, our work presents various experimental results that can help guide better applied soft computing research in the future to effectively combat and detect human and GAN-generated fake face images. © 2021 Elsevier B.V.","Deepfake detection; Fake image dataset; Fake media content detection; GAN-generated image detection; Multimedia forensics; Soft computing"
"Lugstein, F.; Baier, S.; Bachinger, G.; Uhl, A.","Lugstein, Florian (57225882287); Baier, Simon (57225888490); Bachinger, Gregor (57225897449); Uhl, Andreas (7005841206)","57225882287; 57225888490; 57225897449; 7005841206","PRNU-based Deepfake Detection","2021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109677300&partnerID=40&md5=42428f53f66b446cfeb818fc696a8b9e","As deepfakes become harder to detect by humans, more reliable detection methods are required to fight the spread of fake images and videos. In our work, we focus on PRNU-based detection methods, which, while popular in the image forensics scene, have not been given much attention in the context of deepfake detection. We adopt a PRNU-based approach originally developed for the detection of face morphs and facial retouching, and performed the first large scale test of PRNU-based deepfake detection methods on a variety of standard datasets. We show the impact of often neglected parameters of the face extraction stage on detection accuracy. We also document that existing PRNU-based methods cannot compete with state of the art methods based on deep learning but may be used to complement those in hybrid detection schemes. © 2021 ACM.","deepfake detection; deepfakes; PRNU; video forensics"
"Joseph, Z.; Nyirenda, C.","Joseph, Zane (57331372700); Nyirenda, Clement N. (16643199800)","57331372700; 16643199800","Deepfake detection using a two-stream capsule network","2021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118937405&partnerID=40&md5=0c7096c3bed0f069a41d8bc00361cde3","This paper aims to address the problem of Deepfake Detection using a Two-Stream Capsule Network. First we review methods used to create Deepfake content, as well as methods proposed in the literature to detect such Deepfake content. We then propose a novel architecture to detect Deepfakes, which consists of a two-stream Capsule network running in parallel that takes in both RGB images/frames as well as Error Level Analysis images. Results show that the proposed approach exhibits the detection accuracy of 73.39 % and 57.45 % for the Deepfake Detection Challenge (DFDC) and the Celeb-DF datasets respectively. These results are, however, from a preliminary implementation of the proposed approach. As part of future work, population-based optimization techniques such as Particle Swarm Optimization (PSO) will be used to tune the hyper parameters for better performance. © 2021 IST-Africa Institute and Authors.","Capsule networks; Convolutional neural networks; Deep learning; Deepfake; Deepfake detection; Error Level Analysis; Face tampering"
"Li, Y.; Zhang, C.; Sun, P.; Ke, L.; Ju, Y.; Qi, H.; Lyu, S.","Li, Yuezun (57188647738); Zhang, Cong (57225061190); Sun, Pu (57220983672); Ke, Lipeng (57188640127); Ju, Yan (57226836411); Qi, Honggang (12242502500); Lyu, Siwei (8727557200)","57188647738; 57225061190; 57220983672; 57188640127; 57226836411; 12242502500; 8727557200","DeepFake-o-meter: An Open Platform for DeepFake Detection","2021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112819420&partnerID=40&md5=98db8c76487736c04e96b7def02a830b","In recent years, the advent of deep learning-based techniques and the significant reduction in the cost of computation resulted in the feasibility of creating realistic videos of human faces, commonly known as DeepFakes. The availability of open-source tools to create DeepFakes poses as a threat to the trustworthiness of the online media. In this work, we develop an open-source online platform, known as DeepFake-o-meter, that integrates state-of-The-Art DeepFake detection methods and provide a convenient interface for the users. We describe the design and function of DeepFake-o-meter in this work. © 2021 IEEE.","DeepFake Detection; Multimedia Forensics; Software Engineering"
"Huang, Y.; Luo, Z.; Zhang, M.; Liu, W.; Li, S.","Huang, Yun (57862817600); Luo, Zhiming (57192367715); Zhang, Miaohui (57230006600); Liu, Wei (56987996800); Li, Shaozi (57204367236)","57862817600; 57192367715; 57230006600; 56987996800; 57204367236","DF-VLAD: Deepfake Video Detection based on Feature Aggregation","2021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128808956&partnerID=40&md5=1c3b054adfb75ad44821f752679802ad","With the rapid development of Deepfake technology, face video forgery can produce highly deceptive video content and bring serious security threats. The detection of this kind of fake video is more urgent and challenging. Most of the existing detection methods regard this problem as a common binary classification problem, and using a simple average or maximum as the prediction of video results can easily lead to missed detection or false detection. While the video-based detection work such as LSTM, in Deepfake detection, too much focus on timing modeling will affect the performance of Deepfake video detection to a certain extent. Based on this, this paper proposes a VLAD-based aggregation module DF-VLAD, which advances the aggregation of multiple frames from the output layer to the feature layer, which on the one hand makes the aggregation more flexible, on the other hand, it also uses the objective function of forgery detection to directly guide the learning of frame-level depth representation; On the other hand, this paper deals with this problem as a special fine-grained classification problem, because the difference between fake face and real face is very subtle. It is found that the existing face forgery methods such as Face2Face and NeuralTextures leave some common artifacts in the spatial domain. Different forgery methods produce different artifacts, while natural faces have more similar features. To make the model pay more attention to artifacts, a forgery trace capture model based on the fusion of self-attention mechanism and channel attention mechanism is proposed in this paper. Like other fine-grained classification methods, note intentions are used to guide the network to pay attention to key parts of the face. Experimental results on different public data sets show that the proposed method achieves the latest performance. © 2021 IEEE.","attention; Deepfake detection; face manipulation; VLAD"
"Lin, J.; Zhou, W.; Liu, H.; Zhou, H.; Zhang, W.; Yu, N.","Lin, Jiaying (57552360200); Zhou, Wenbo (57192111936); Liu, Honggu (57222171343); Zhou, Hang (57192375762); Zhang, Weiming (34769199700); Yu, Nenghaif Hai (57201634030)","57552360200; 57192111936; 57222171343; 57192375762; 34769199700; 57201634030","Lip Forgery Video Detection via Multi-Phoneme Selection","2021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127127873&partnerID=40&md5=e769e35700df557978ace4d20e61386b","Deepfake technique can produce realistic manipulation videos including full-face synthesis and local region forgery. General methods work well in detecting the former but are usually intractable in capturing local artifacts especially for lip forgery detection. In this paper, we focus on the lip forgery detection task. We first establish a robust mapping from audio to lip shapes. Then we classify the lip shapes of each video frame according to different spoken phonemes, enable the network in capturing the dissonances between lip shapes and phonemes in fake videos, increasing the interpretability. Each lip shape-phoneme set is used to train a sub-model, those with better discrimination will be selected to obtain an ensemble classification model. Extensive experimental results demonstrate that our method outperforms the most state-of-the-art methods on both the public DFDC dataset and a self-organized lip forgery dataset. © 2021 CEUR-WS. All rights reserved.","Deepfake Detection; Lip Forgery; Phoneme; Viseme"
"Khichi, M.; Yadav, R.K.","Khichi, Manish (57486018700); Yadav, Rajesh Kumar (58964706200)","57486018700; 58964706200","A Threat of Deepfakes as a Weapon on Digital Platform and their Detection Methods","2021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126219354&partnerID=40&md5=5f94b051427b1e6d13d8b2a302eba4d0","Advances in machine learning, deep learning, and Artificial Intelligence(AI) allows people to exchange other people's faces and voices in videos to make it look like what they did or say whatever you want to say. These videos and photos are called”deepfake” and are getting more complicated every day and this has lawmakers worried.This technology uses machine learning technology to provide computers with real data about images, so that we can make forgeries. The creators of Deepfake use artificial intelligence and machine learning algorithms to mimic the work and characteristics of real humans. It differs from counterfeit traditional media because it is difficult to identify. As In the 2020 elections loomed, AI-generated deepfakes were hit the news cycle.DeepFakes threatens facial recognition and online content. This deception can be dangerous, because if used incorrectly, this technique can be abused. Fake video, voice, and audio clips can do enormous damage. This paper examines the algorithms used to generate deepfakes as well as the methods proposed to detect them. We go through the threats, research patterns, and future directions for deepfake technologies in detail. This research provides a detailed description of deep imitation technology and encourages the creation of new and more powerful methods to deal with increasingly severe deep imitation by studying the history of deep imitation. © 2021 IEEE.","Convolutional Neural Networks(CNNs); Deep Neural Networks(DNNs); Deepfake; Deepfake Detection Challenge(DFDC); Generative Adversarial Networks(GANs); Recurrent Neural Networks(RNNs)"
"Luo, Z.; Kamata, S.-I.; Sun, Z.","Luo, Zhengbo (57221943680); Kamata, Seiichirou Ichiro (35615032600); Sun, Zitang (57221923880)","57221943680; 35615032600; 57221923880","TRANSFORMER AND NODE-COMPRESSED DNN BASED DUAL-PATH SYSTEM FOR MANIPULATED FACE DETECTION","2021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125596078&partnerID=40&md5=7fc8b1ac4dfffdb8005285006e52fd72","Deep neural networks (DNNs) have extensively promoted data generation development; the quality of these generated content has achieved an impressive new level. Therefore, manipulated content, especially facial manipulation, is a growing concern for online information legitimacy. Most current deep learning-based methods depend on local features sampled by convolutional kernels and lack knowledge globally. To address the problem, we propose a dual-path pipeline using Neural Ordinary Differential Equations (NODE) based neural network and facial-feature biased transformer to deal with the visual content from a different view. The transformer path could link these landmarks in a long-range, moreover, we adopt an attention guided augmentation based self-ensemble for more robust performance. Extensive experiments show that our system could surpass several commonly used approaches in terms of video-level accuracy and AUC with better interpretability. © 2021 IEEE.","DeepFake detection; Face manipulation; Image forensics; Neural network"
"Hu, J.; Wang, S.; Li, X.","Hu, Jiashang (57473971100); Wang, Shilin (16204388400); Li, Xiaoyong (57094287000)","57473971100; 16204388400; 57094287000","IMPROVING THE GENERALIZATION ABILITY OF DEEPFAKE DETECTION VIA DISENTANGLED REPRESENTATION LEARNING","2021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125581032&partnerID=40&md5=019f8b30b750cc34a3dd69bb426470fe","Deepfake refers to a deep learning based technology which can synthesize visually realistic face images/videos. The misuse of this technology poses a great threat to the society. Although numerous approaches have been proposed to detect Deepfake forgeries, their generalization ability on unseen datasets is limited. In this paper, we propose a new approach that detects human face forgeries by automatically locating the forgery-related region to make the final decision. The proposed network contains two modules, including: the disentanglement module to extract forgery relevant information and the classification module to detect the manipulation artifacts from various regions at different scales. The experiment results on three widely used Deepfake datasets show that the proposed approach can achieve high detection accuracies and outperforms several state-of-the-arts methods especially when evaluated on the unseen datasets. © 2021 IEEE.","Deep neural network; Deepfake detection; Disentangle representation learning"
"Rafique, R.; Nawaz, M.; Kibriya, H.; Masood, M.","Rafique, Rimsha (57223049281); Nawaz, Marriam (57220484885); Kibriya, Hareem (57223038383); Masood, Momina (57210789934)","57223049281; 57220484885; 57223038383; 57210789934","DeepFake Detection Using Error Level Analysis and Deep Learning","2021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125345386&partnerID=40&md5=769a9bbeba550937d97dc602410bd9bc","The image recognition software is used in numerous distinctive industries that include entertainment and media. The deep learning (DL) algorithms have been of great help in the development of several techniques used for creating, altering, and locating any data. The deepfake method is a photo-faking technique that includes replacing two people's faces to an extent that it becomes very difficult to identify it with a naked eye. The convolution neural network (CNN) models including Alex Net and Shuffle Net are used to recognize genuine and counterfeit face images in this article. The technique analyzes the performance and working of all distinctive algorithms using the real/fake face recognition collection from Yonsei University's Computational Intelligence Photography Lab. The first step in the process starts by the normalizing of pictures then the Error Level Analysis is carried out before it is put into several difference CNN models. Then the in-depth features are extracted from the CNN models utilizing the Support Vector Machine and the K-nearest neighbor methods. The most perfect accuracy of 88.2% of Shuffle Net via KNN was analyzed while Alex Net's vector had the accuracy of 86.8%. © 2021 IEEE.","CNN; Deep Learning; Deepfake Detection; KNN; Machine Learning; SVM"
"Li, Z.; Yang, W.; Liu, R.; Zhu, Y.","Li, Zuoyan (57388572000); Yang, Wenyuan (57214131847); Liu, Ruixin (57220546242); Zhu, Yuesheng (55453293800)","57388572000; 57214131847; 57220546242; 55453293800","Manipulation-Invariant Fingerprints for Cross-Dataset Deepfake Detection","2021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121927880&partnerID=40&md5=418d2de0ffb0a04baa59ef37730513c5","Most of the current deepfake detection methods make efforts to learn the classifiers on the manipulated face dataset forged by a single manipulation method. However, these classifiers lack the generalization capacity to other kinds of manipulated face images, limiting their applications in real-world scenarios. In this paper, we find common detectable fingerprints for face images manipulated by different forgery methods through mapping images into a fingerprint space. Such fingerprints are called manipulation-invariant fingerprints, which would allow a classifier to generalize to face datasets forged by other methods. Therefore, a mask drop regularized unsupervised domain adaptation (MDRUDA) method is proposed for cross-dataset deepfake detection through building up the manipulation-invariant fingerprints. Specifically, a feature generator and a discriminator are trained adversarially to align the fingerprint distributions from face images forged by different methods, building up the manipulation-fingerprints that could train a more generalized classifier. We impose a mask drop regularization on the discriminator and the classifier to enrich the fingerprint space and further boost generalization ability. Experiments on public deepfake datasets show that our approach can gain significantly better generalization capability in cross-datasets scenarios, compared with prior works. © 2021, Springer Nature Switzerland AG.","Deepfake detection; Digital forensics; Face manipulation"
"Do, T.-L.; Tran, M.-K.; Nguyen, H.H.; Tran, M.-T.","Do, Trongle (57212828893); Tran, Mai Khiem (57208841121); Nguyen, Huy H. (55774055400); Tran, Minh Triet (35176729700)","57212828893; 57208841121; 55774055400; 35176729700","Potential Threat of Face Swapping to eKYC with Face Registration and Augmented Solution with Deepfake Detection","2021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121147278&partnerID=40&md5=4df9ed4c601bd30450d40458232351e4","It is necessary to develop an efficient and secure mechanism to verify customers digitally for various online transactions. Integrating biometric solutions into the online user registration and verification processes is a promising trend for electronic Know Your Customer (eKYC) systems. However, Deepfake or face manipulation techniques may become a threat for eKYC with face authentication. In this paper, we introduce this potential attack of Deepfake on eKYC by swapping and manipulating faces between source and target faces. We then propose to augment the security for current eKYC systems with Deepfake detection. We conduct the experiments on the 10K video clips in the private test of Deepfake Detection Challenge 2020, and our method, following the Capsule-forensics approach, achieves the Logloss score of 0.5189, among the top 6% best results among the 2114 teams worldwide. This result demonstrates that our deepfake detection algorithm can be a promising method to provide extra protection for eKYC solutions with face registration and authentication. © 2021, Springer Nature Switzerland AG.","Deepfake detection; eKYC; Faceswap"
"Zobaed, S.; Rabby, F.; Hossain, I.; Hossain, E.; Hasan, S.; Karim, A.; Hasib, K.","Zobaed, Sakib M. (57204513948); Rabby, Fazle (59940484100); Hossain, Md Istiaq (57271605200); Hossain, Ekram (6701362398); Hasan, Sazib (57272027000); Karim, Asif (57206327767); Hasib, Khan Md (57207760588)","57204513948; 59940484100; 57271605200; 6701362398; 57272027000; 57206327767; 57207760588","DeepFakes: Detecting Forged and Synthetic Media Content Using Machine Learning","2021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120576306&partnerID=40&md5=43c8b42ebceacc32c95633582b223be6","The rapid advancement in deep learning makes the differentiation of authentic and manipulated facial images and video clips unprecedentedly harder. The underlying technology of manipulating facial appearances through deep generative approaches, enunciated as DeepFake that have emerged recently by promoting a vast number of malicious face manipulation applications. Subsequently, the need of other sort of techniques that can assess the integrity of digital visual content is indisputable to reduce the impact of the creations of DeepFake. A large body of research that are performed on DeepFake creation and detection create a scope of pushing each other beyond the current status. This study presents challenges, research trends, and directions related to DeepFake creation and detection techniques by reviewing the notable research in the DeepFake domain to facilitate the development of more robust approaches that could deal with the more advance DeepFake in future. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Adversarial attack; DeepFake detection; DeepFake generation; Face swap"
"Hubens, N.; Mancaş, M.; Gosselin, B.; Preda, M.; Zaharia, T.","Hubens, Nathan (57215532738); Mancaş, Matei (8569088000); Gosselin, Bernard (57162610800); Preda, Marius (7005864787); Zaharia, Titus (6601999900)","57215532738; 8569088000; 57162610800; 7005864787; 6601999900","Fake-buster: A lightweight solution for deepfake detection","2021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118619647&partnerID=40&md5=e40e30ea253e15da195b4d9756424bfa","Recent advances in video manipulation techniques have made synthetic media creation more accessible than ever before. Nowadays, video edition is so realistic that we cannot rely exclusively on our senses to assess the veracity of media content. With the amount of manipulated videos doubling every six months, we need sophisticated tools to process the huge amount of media shared all over the internet, to remove the related videos as fast as possible, thus reducing potential harm such as fueling disinformation or reducing trust in mainstream media. In this paper, we tackle the problem of face manipulation detection in video sequences targeting modern facial manipulation techniques. Our method involves two networks: (1) a face identification network, extracting the faces contained in a video, and (2) a manipulation recognition network, considering the face as well as its neighbouring context to find potential artifacts, indicating that the face was manipulated. More particularly, we propose to make use of neural network compression techniques such as pruning and knowledge distillation to create a lightweight solution, able to rapidly process streams of videos. Our approach is validated on the DeepFake Detection Dataset, consisting of videos coming from 5 different manipulation techniques, reflecting the organic content found on the internet, and compared to state-of-the-art deepfake detection approaches. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","DeepFake Detection; Image Manipulation; Neural Network Compression"
"Ismail, A.; Elpeltagy, M.; Zaki, M.; El-Dahshan, K.A.","Ismail, Aya (55377386200); Elpeltagy, Marwa S. (57188851602); Zaki, Mervat S. (57226593608); El-Dahshan, Kamal A. (36967841100)","55377386200; 57188851602; 57226593608; 36967841100","Deepfake video detection: YOLO-Face convolution recurrent approach","2021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117199235&partnerID=40&md5=cce76ab5d593d2dfb6e2cc1982512477","Recently, the deepfake techniques for swapping faces have been spreading, allowing easy creation of hyper-realistic fake videos. Detecting the authenticity of a video has become increasingly critical because of the potential negative impact on the world. Here, a new project is introduced; You Only Look Once Convolution Recurrent Neural Networks (YOLO-CRNNs), to detect deepfake videos. The YOLO-Face detector detects face regions from each frame in the video, whereas a fine-tuned EfficientNet-B5 is used to extract the spatial features of these faces. These features are fed as a batch of input sequences into a Bidirectional Long Short-Term Memory (Bi-LSTM), to extract the temporal features. The new scheme is then evaluated on a new large-scale dataset; CelebDF-FaceForencics++ (c23), based on a combination of two popular datasets; FaceForencies++ (c23) and Celeb-DF. It achieves an Area Under the Receiver Operating Characteristic Curve (AUROC) 89.35% score, 89.38% accuracy, 83.15% recall, 85.55% precision, and 84.33% F1-measure for pasting data approach. The experimental analysis approves the superiority of the proposed method compared to the state-of-the-art methods. © 2021. Ismail et al. All Rights Reserved.","Convolution recurrent neural networks; Deepfake; Deepfake detection; Video authenticity; YOLO-Face"
"Chen, H.-S.; Rouhsedaghat, M.; Ghani, H.; Hu, S.; You, S.; Kuo, C.-C.J.","Chen, Hongshuo (57209878017); Rouhsedaghat, Mozhdeh (57219508544); Ghani, Hamza (57219412576); Hu, Shuowen (34881794700); You, Suya (7201517015); Kuo, C. C.Jay (55533887300)","57209878017; 57219508544; 57219412576; 34881794700; 7201517015; 55533887300","DEFAKEHOP: A LIGHT-WEIGHT HIGH-PERFORMANCE DEEPFAKE DETECTOR","2021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111179528&partnerID=40&md5=9e0be1b8d25b142ba2f7b693286decde","A light-weight high-performance Deepfake detection method, called DefakeHop, is proposed in this work. State-of-the-art Deepfake detection methods are built upon deep neural networks. DefakeHop uses the successive subspace learning (SSL) principle to extracts features automatically from various parts of face images. The features are extracted by channel-wise (c/w) Saab transform and further processed by our feature distillation module using spatial dimension reduction and soft classification for each channel to get a more concise description of the face. Extensive experiments are conducted to demonstrate the effectiveness of the proposed DefakeHop method. With a small model size of 42,845 parameters, DefakeHop achieves state-of-the-art performance with the area under the ROC curve (AUC) of 100%, 94.95%, and 90.56% on UADFV, Celeb-DF v1, and Celeb-DF v2 datasets, respectively. Our codes are available on GitHub. © 2021 IEEE","Deepfake detection; Light-weight; Successive subspace learning (SSL)"
"Jiang, J.; Li, B.; Wei, B.; Li, G.; Liu, C.; Huang, W.; Li, M.; Yu, M.","Jiang, Jianguo (55731810500); Li, Boquan (56129960300); Wei, Baole (57215125489); Li, Gang (56336374700); Liu, Chao (56938528500); Huang, Weiqing (56419055500); Li, Meimei (55834699000); Yu, Min (56438359400)","55731810500; 56129960300; 57215125489; 56336374700; 56938528500; 56419055500; 55834699000; 56438359400","FakeFilter: A cross-distribution Deepfake detection system with domain adaptation","2021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111151138&partnerID=40&md5=40acf13605319bfba8e6a62ac08866d7","Abuse of face swap techniques poses serious threats to the integrity and authenticity of digital visual media. More alarmingly, fake images or videos created by deep learning technologies, also known as Deepfakes, are more realistic, high-quality, and reveal few tampering traces, which attracts great attention in digital multimedia forensics research. To address those threats imposed by Deepfakes, previous work attempted to classify real and fake faces by discriminative visual features, which is subjected to various objective conditions such as the angle or posture of a face. Differently, some research devises deep neural networks to discriminate Deepfakes at the microscopic-level semantics of images, which achieves promising results. Nevertheless, such methods show limited success as encountering unseen Deepfakes created with different methods from the training sets. Therefore, we propose a novel Deepfake detection system, named FakeFilter, in which we formulate the challenge of unseen Deepfake detection into a problem of cross-distribution data classification, and address the issue with a strategy of domain adaptation. By mapping different distributions of Deepfakes into similar features in a certain space, the detection system achieves comparable performance on both seen and unseen Deepfakes. Further evaluation and comparison results indicate that the challenge has been successfully addressed by FakeFilter. © 2021 - IOS Press. All rights reserved.","Deepfake detection; Digital multimedia forensics; domain adaptation; face swap"
"Mehra, A.; Spreeuwers, L.; Strisciuglio, N.","Mehra, Akul (57222527253); Spreeuwers, Luuk J. (6601970410); Strisciuglio, Nicola (55973353300)","57222527253; 6601970410; 55973353300","Deepfake detection using capsule networks and long short-term memory networks","2021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103011515&partnerID=40&md5=ce0e2aa2c8271326363ea5949167d8fd","With the recent advancements of technology, and in particular with graphics processing and artificial intelligence algorithms, fake media generation has become easier. Using deep learning techniques like Deepfakes and FaceSwap, anyone can generate fake videos by manipulating the face/voice of target subjects in videos. These AI synthesized videos are a big threat to the authenticity and trustworthiness of online information and can be used for malicious purposes. Detecting face tampering in videos is of utmost importance. We propose a spatio-temporal hybrid model of Capsule Networks integrated with Long Short-Term Memory (LSTM) networks. This model exploits the inconsistencies in videos to distinguish real and fake videos. We use three different frame selection techniques and show that frame selection has a significant impact on the performance of models. The combined Capsule and LSTM network have comparable performance to state-of-the-art models and about 1/5th the number of parameters, resulting in reduced computational cost. © © 2021 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.","Capsule Networks; Deepfake Detection; Face Video Manipulation; Long Short-Term Memory Networks"
"Lin, Y.; Qu, Y.; Li, Y.; Nie, Z.","Lin, Ying (55714566600); Qu, Yanzhen (50561793000); Li, Yuanpei (57230477500); Nie, Zhishen (57229895800)","55714566600; 50561793000; 57230477500; 57229895800","Exploring Generalization Capability for Video Forgery and Detection based on Generative Adversarial Network","2020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113405054&partnerID=40&md5=e0779b92695763752a2566137940e85d","With the development of digital image processing technology based on deep learning, the potential risk of using related technologies to threaten the security of multimedia information is increasing. Because the generated human face effect largely depends on the completeness of the input sample set, most of the current deep forgery models have the problem of human side-face collapse. This paper has studied the deep forgery technology of Deepfacelab and Faceswap, and adjusts the original auto-encoder-based model architecture to a generative adversarial network. By using the harmonic mean of cross entropy and mean square error as the loss function, the improved model can reduce the probability of some frames being discarded during training. Meanwhile, by adjusting key characteristics and the weights of features in different frames, it further optimizes the cross-dataset detection performance. Experimental results have shown that the improved model can keep more facial details while still maintain high human face clarity. The detection performance is improved and the cross-dataset average error rate of the deep detection model is about 35%. © 2020 IEEE.","Deepfake; Deepfake Detection; Detection Generalization; Face Swap; Generative Adversarial Network"
"Qi, H.; Guo, Q.; Juefei-Xu, F.; Xie, X.; Ma, L.; Feng, W.; Liu, Y.; Zhao, J.","Qi, Hua (57211029245); Guo, Qing (57191163500); Juefei-Xu, Felix (54911989900); Xie, Xiaofei (55268560900); Ma, Lei (55479591700); Feng, Wei (56471162500); Liu, Yang (56911879800); Zhao, Jianjun (35786932000)","57211029245; 57191163500; 54911989900; 55268560900; 55479591700; 56471162500; 56911879800; 35786932000","DeepRhythm: Exposing DeepFakes with Attentional Visual Heartbeat Rhythms","2020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106960135&partnerID=40&md5=b2962e098f5b42f77617f2402747c7a9","As the GAN-based face image and video generation techniques, widely known as DeepFakes, have become more and more matured and realistic, there comes a pressing and urgent demand for effective DeepFakes detectors. Motivated by the fact that remote visual photoplethysmography (PPG) is made possible by monitoring the minuscule periodic changes of skin color due to blood pumping through the face, we conjecture that normal heartbeat rhythms found in the real face videos will be disrupted or even entirely broken in a DeepFake video, making it a potentially powerful indicator for DeepFake detection. In this work, we propose DeepRhythm, a DeepFake detection technique that exposes DeepFakes by monitoring the heartbeat rhythms. DeepRhythm utilizes dual-spatial-temporal attention to adapt to dynamically changing face and fake types. Extensive experiments on FaceForensics++ and DFDC-preview datasets have confirmed our conjecture and demonstrated not only the effectiveness, but also the generalization capability of DeepRhythm over different datasets by various DeepFakes generation techniques and multifarious challenging degradations. © 2020 ACM.","deepfake detection; dual-spatial-temporal attention; face forensics; heartbeat rhythm; remote photoplethysmography(ppg)"
"Zi, B.; Chang, M.; Chen, J.; Ma, X.; Jiang, Y.-G.","Zi, Bojia (57222068798); Chang, Minghao (57222069380); Chen, Jingjing (55613576900); Ma, Xingjun (57195682647); Jiang, Yugang (14054081900)","57222068798; 57222069380; 55613576900; 57195682647; 14054081900","WildDeepfake: A Challenging Real-World Dataset for Deepfake Detection","2020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099811365&partnerID=40&md5=ff689bd6e6c5672a102998123db490db","In recent years, the abuse of a face swap technique called deepfake has raised enormous public concerns. So far, a large number of deepfake videos (known as ""deepfakes"") have been crafted and uploaded to the internet, calling for effective countermeasures. One promising countermeasure against deepfakes is deepfake detection. Several deepfake datasets have been released to support the training and testing of deepfake detectors, such as DeepfakeDetection [1] and FaceForensics++ [23]. While this has greatly advanced deepfake detection, most of the real videos in these datasets are filmed with a few volunteer actors in limited scenes, and the fake videos are crafted by researchers using a few popular deepfake softwares. Detectors developed on these datasets may become less effective against real-world deepfakes on the internet. To better support detection against real-world deepfakes, in this paper, we introduce a new dataset WildDeepfake, which consists of 7,314 face sequences extracted from 707 deepfake videos collected completely from the internet. WildDeepfake is a small dataset that can be used, in addition to existing datasets, to develop and test the effectiveness of deepfake detectors against real-world deepfakes. We conduct a systematic evaluation of a set of baseline detection networks on both existing and our WildDeepfake datasets, and show that WildDeepfake is indeed a more challenging dataset, where the detection performance can decrease drastically. We also propose two (eg. 2D and 3D) Attention-based Deepfake Detection Networks (ADDNets) to leverage the attention masks on real/fake faces for improved detection. We empirically verify the effectiveness of ADDNets on both existing datasets and WildDeepfake. The dataset is available at: https://github.com/deepfakeinthewild/deepfake-in-the-wild. © 2020 ACM.","datasets; deep learning; deepfake detection"
"Zhu, K.; Wu, B.; Wang, B.","Zhu, Kui (57218558683); Wu, Bin (56449782000); Wang, Bai (7405918429)","57218558683; 56449782000; 7405918429","Deepfake detection with clustering-based embedding regularization","2020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092053151&partnerID=40&md5=1afbd7f1a240653f20e96a7bb323cb65","In recent months, AI-synthesized face swapping videos referred to as deepfake have become an emerging problem. False video is becoming more and more difficult to distinguish, which brings a series of challenges to social security. Some scholars are devoted to studying how to improve the detection accuracy of deepfake video. At the same time, in order to conduct better research, some datasets for deepfake detection are made. Companies such as Google and Facebook have also spent huge sums of money to produce datasets for deepfake video detection, as well as holding deepfake detection competitions. The continuous advancement of video tampering technology and the improvement of video quality have also brought great challenges to deepfake detection. Some scholars have achieved certain results on existing datasets, while the results on some high-quality datasets are not as good as expected. In this paper, we propose new method with clustering-based embedding regularization for deepfake detection. We use open source algorithms to generate videos which can simulate distinctive artifacts in the deepfake videos. To improve the local smoothness of the representation space, we integrate a clustering-based embedding regularization term into the classification objective, so that the obtained model learns to resist adversarial examples. We evaluate our method on three latest deepfake datasets. Experimental results demonstrate the effectiveness of our method. © 2020 IEEE.","Clustering-based; Deepfake detection; Face swapping; Regularization"
"Feng, D.; Lu, X.; Lin, X.","Feng, Disheng (57220153522); Lu, Xuequan (55794820600); Lin, Xufeng (55204959700)","57220153522; 55794820600; 55204959700","Deep Detection for Face Manipulation","2020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097049147&partnerID=40&md5=c7d70bf54dabac61910a7a92ddad1113","It has become increasingly challenging to distinguish real faces from their visually realistic fake counterparts, due to the great advances of deep learning based face manipulation techniques in recent years. In this paper, we introduce a deep learning method to detect face manipulation. It consists of two stages: feature extraction and binary classification. To better distinguish fake faces from real faces, we resort to the triplet loss function in the first stage. We then design a simple linear classification network to bridge the learned contrastive features with the real/fake faces. Experimental results on public benchmark datasets demonstrate the effectiveness of this method, and show that it generates better performance than state-of-the-art techniques in most cases. © 2020, Springer Nature Switzerland AG.","Deepfake detection; Digital forensics; Face manipulation"
"Maksutov, A.A.; Morozov, V.O.; Lavrenov, A.A.; Smirnov, A.S.","Maksutov, A. A. (56703290900); Morozov, Viacheslav O. (57216271114); Lavrenov, Aleksander A. (57216270317); Smirnov, Alexander S. (56412376800)","56703290900; 57216271114; 57216270317; 56412376800","Methods of Deepfake Detection Based on Machine Learning","2020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082991408&partnerID=40&md5=83aba434eeae6a804c0056f354c7e7f4","Nowadays, people faced an emerging problem of AI-synthesized face swapping videos, widely known as the DeepFakes. This kind of videos can be created to cause threats to privacy, fraudulence and so on. Sometimes good quality DeepFake videos recognition could be hard to distinguish with people eyes. That's why researchers need to develop algorithms to detect them. In this work, we present overview of indicators that can tell us about the fact that face swapping algorithms were used on photos. Main purpose of this paper is to find algorithm or technology that can decide whether photo was changed with DeepFake technology or not with good accuracy. © 2020 IEEE.","deep learning; DeepFake detection; face swapping indicators; neural networks"
"Yang, X.; Li, Y.; Lyu, S.","Yang, Xin (57212206392); Li, Yuezun (57188647738); Lyu, Siwei (8727557200)","57212206392; 57188647738; 8727557200","Exposing Deep Fakes Using Inconsistent Head Poses","2019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069004552&partnerID=40&md5=dbaf7b398e245b4185fc2c6de97b11a6","In this paper, we propose a new method to expose AI-generated fake face images or videos (commonly known as the Deep Fakes). Our method is based on the observations that Deep Fakes are created by splicing synthesized face region into the original image, and in doing so, introducing errors that can be revealed when 3D head poses are estimated from the face images. We perform experiments to demonstrate this phenomenon and further develop a classification method based on this cue. Using features based on this cue, an SVM classifier is evaluated using a set of real face images and Deep Fakes. © 2019 IEEE.","DeepFake Detection; Head Pose Estimation; Media Forensics"
