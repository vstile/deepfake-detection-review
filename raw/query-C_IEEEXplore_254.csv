Document Title;Authors;Author Affiliations;Publication Title;Date Added To Xplore;Publication Year;Volume;Issue;Start Page;End Page;Abstract;ISSN;ISBNs;DOI;Funding Information;PDF Link;Author Keywords;IEEE Terms;Mesh_Terms;Article Citation Count;Patent Citation Count;Reference Count;License;Online Date;Issue Date;Meeting Date;Publisher;Document Identifier
Detecting Deepfakes using Temporal Consistency of Facial Expression Transitions;"R. E. Chacko; G. Bajwa";"Department of Computer Science, Lakehead University, Thunder Bay, Ontario, Canada; Department of Computer Science, Lakehead University, Thunder Bay, Ontario, Canada";2025 22nd Annual International Conference on Privacy, Security, and Trust (PST);3 Dec 2025;2025;;;1;7;Deepfake generation techniques have developed at a rapid rate, making it possible to generate highly realistic yet misleading videos with potentially far-reaching implications for privacy, security, and public confidence. This paper presents a study on the detection of deepfakes using the temporal consistency of facial expression transitions. Our method captures and integrates significant spatial and temporal information, facial edges, and dense optical flow with an Xception-based CNN and a bidirectional LSTM (BiLSTM) with an attention mechanism. We evaluated the approach on a multi-expression dataset obtained from DeeperForensics-1.0, comparing performance systematically across a range of expressions from Angry to Neutral. The experiments demonstrate a detection rate of up to $98.38 \%$ on the combined multi-expressions and point to the unique challenge of less expressive emotions. The findings affirm that face expression continuity examination plays an important part in enhancing the robustness of deepfake detection, achieving a scalable and adaptive approach to verifying the integrity of real-world media.;2643-4202;979-8-3315-0343-7;10.1109/PST65910.2025.11268852;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11268852;"Deepfake detection;temporal consistency;facial expression analysis;optical flow;edges;Xception;bidirectional LSTM;attention mechanism;video forensics;spatio-temporal modeling";"Deepfakes;Privacy;Attention mechanisms;Image edge detection;Bidirectional long short term memory;Media;Robustness;Security;Optical flow;Faces";;;;34;IEEE;3 Dec 2025;26-28 Aug. 2025;26-28 Aug. 2025;IEEE;IEEE Conferences
GASGM-GFT: Gaussian Attenuation Singing Graph Model and Graph Fourier Transform for Singing Voice Deepfake Detection;"B. Wu; Q. Qian; L. Ran; H. Wang";"School of Information, Guizhou University of Finance and Economics, Guiyang, China; School of Information, Guizhou University of Finance and Economics, Guiyang, China; School of Information, Guizhou University of Finance and Economics, Guiyang, China; School of Information, Guizhou University of Finance and Economics, Guiyang, China";2025 International Joint Conference on Neural Networks (IJCNN);14 Nov 2025;2025;;;1;8;Singing voice synthesis and singing voice conversion technologies have raised significant concerns regarding music copyright and authenticity. While extant research has predominantly focused on detecting spoofing speech, much less attention has been given to deepfake singing voice. Moreover, conventional techniques frequently prove incapable of capturing the intricate temporal relationships inherent in vocalisation, thus impeding their capacity to effectively extract both local and global characteristics. To address these challenges, this paper introduces a novel deepfake detection method of singing voice called GASGM-GFT (Gaussian Attenuation Singing Graph Model and Graph Fourier Transform). In this approach, a singing graph model between sampling points of the original singing is creatively constructed using a Gaussian attenuation function. This model captures the complex temporal relationships of the singing signal. Next, the Graph Fourier Transform (GFT) is applied to map the singing signal into the graph frequency domain. This helps capture both local and global frequency features within the singing graph model, revealing hidden deepfake properties of the signal. The one-dimensional graph frequency domain signals are then expanded into two dimensions and processed through residual blocks for feature enhancement. Finally, the graph attention module is utilized to model node relationships, compute attention weights, and aggregate features through graph pooling layers to produce the final discrimination result. The experimental results demonstrate that GASGM-GFT outperforms existing advanced methods for spoofing speech detection and singing voice deepfake detection on the CtrSVDD dataset. It achieves an equal error rate (EER) of only 2.53% on the Vocals test set and surpasses other systems on the Mixture test set.;2161-4407;979-8-3315-1042-8;10.1109/IJCNN64981.2025.11228680;"National Natural Science Foundation of China; Department of Education of Guizhou Province; Guizhou Normal University; ";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11228680;"Graph Signal Processing;Singing Voice Deepfake Detection;Graph Neural Network";"Voice activity detection;Deepfakes;Fourier transforms;Frequency-domain analysis;Computational modeling;Signal processing;Attenuation;Feature extraction;Robustness;Graph neural networks";;;;22;IEEE;14 Nov 2025;30 June-5 July 2025;30 June-5 July 2025;IEEE;IEEE Conferences
Using Graph Neural Networks to Improve Generalization Capability of the Models for Deepfake Detection;"H. She; Y. Hu; B. Liu; J. Li; C. -T. Li";"School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China; School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China; School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China; School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China; School of Information Technology, Deakin University, Geelong, VIC, Australia";IEEE Transactions on Information Forensics and Security;23 Sep 2024;2024;19;;8414;8427;Deepfake detection plays a key role in preventing the misuses of artificial intelligence in video editing. Current deep learning-based deepfake detection methods often perform quite well in intra-dataset testing, but they may lose good performance in cross-dataset testing. In other words, generalization capability is still a crucial problem to be resolved. In this paper, we address deepfake detection by treating an image as non-Euclidean data and representing it as a graph so as to infer the informative connections between image patches/nodes to improve the detector’s generalization capability. Specifically, we propose a graph neural network-based paradigm that casts deepfake detection as a graph binary classification problem. First, we propose a dual-branch network to extract node features from both RGB images and their color difference images (CDIs) via the Transformer-based trainable node encoder module (TNEM). Second, we adopt the adjacency matrix to establish the connections of the nodes and further optimize the graph representation by applying the adaptive threshold to the adjacency matrix. Third, multi-head graph convolutional neural networks are carried out for node feature extraction. RGB node features and CDI node features are concatenated and separately fed into the graph classifier and node classifier for forgery detection and forgery localization. Experimental results demonstrate that our method can overall outperform other state-of-the-art methods on 7 popular benchmark datasets. Notably, our model achieves the highest AUC values of 96.19%, 80.99% and 87.68% on Celeb-DF-V2, DFDC and DFDCP in turn when trained on FF++ (C23). The visualization of node classification results also provides good interpretability of our proposed approach.;1556-6021;;10.1109/TIFS.2024.3451356;"Science and Technology Foundation of Guangzhou Huangpu Development District(grant numbers:2022GH15);";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10654318;"Deepfake detection;graph neural network;generalization;transformer;color difference;graph classification";"Deepfakes;Feature extraction;Faces;Forgery;Graph neural networks;Face recognition;Image edge detection";;10;;68;IEEE;28 Aug 2024;2024;;IEEE;IEEE Journals
A Novel Multi-Scale Spectral-Guided Graph Attention Network for DeepFake Video Detection;"M. Irfan; M. J. Lee; A. Neyaz; D. Nobayashi";"Department of Electrical Engineering, City College of New York, New York, NY, USA; Department of Electrical Engineering, City College of New York, New York, NY, USA; School of Computing and Data Science, Wentworth Institute of Technology, Boston, MA, USA; Department of Electrical and Electronic Engineering, Kyushu Institute of Technology, Fukuoka, Japan";2025 13th International Symposium on Digital Forensics and Security (ISDFS);2 Jun 2025;2025;;;1;7;The rapid advancement of deepfake technology presents significant challenges for video authenticity verification, necessitating robust detection mechanisms. This paper introduces a novel framework for deepfake video detection that integrates the Multi-Scale Spectral-Guided Graph Attention Network (MSG-GAT) with the Lightweight Assimilation-Elimination (Lite-ASEL) algorithm. By representing video frames as graphs, the framework effectively captures intricate pixel relationships, enabling the detection of subtle manipulations with enhanced precision. Additionally, the Lite-ASEL algorithm is employed for feature selection, balancing reduced computational complexity with high detection performance. Experimental results demonstrate the superiority of the proposed framework, achieving state-of-the-art performance with an AUC of 99.1 % and a detection accuracy of 99.3%. Furthermore, hyperparameter tuning confirms the framework's robustness and efficiency, consistently achieving an optimal objective score of 98.54%, validating its effectiveness for optimal feature selection and deepfake detection.;2768-1831;979-8-3315-0993-4;10.1109/ISDFS65363.2025.11011972;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11011972;"Graph Neural Network;Convolutional Neural Network;Content Manipulation;Deepfake Video Detection;Feature Selection";"Deepfakes;Accuracy;Scalability;Image edge detection;Feature extraction;Robustness;Graph neural networks;Synchronization;Security;Tuning";;1;;24;IEEE;2 Jun 2025;24-25 April 2025;24-25 April 2025;IEEE;IEEE Conferences
GC-ConsFlow: Leveraging Optical Flow Residuals and Global Context for Robust Deepfake Detection;"J. Chen; M. Hu; D. Zhang; J. Meng";"School of Computer Science and Technology, Changsha University of Science and Technology, Changsha, China; School of Computer Science and Technology, Changsha University of Science and Technology, Changsha, China; School of Computer Science and Technology, Changsha University of Science and Technology, Changsha, China; School of Computer Science and Technology, Changsha University of Science and Technology, Changsha, China";2025 IEEE International Conference on Multimedia and Expo (ICME);30 Oct 2025;2025;;;1;6;The rapid development of Deepfake technology has enabled the generation of highly realistic manipulated videos, posing severe social and ethical challenges. Existing Deepfake detection methods primarily focused on either spatial or temporal inconsistencies, often neglecting the interplay between the two or suffering from interference caused by natural facial motions. To address these challenges, we propose the global context consistency flow (GC-ConsFlow), a novel dual-stream framework that effectively integrates spatial and temporal features for robust Deepfake detection. The global grouped context aggregation module (GGCA), integrated into the global context-aware frame flow stream (GCAF), enhances spatial feature extraction by aggregating grouped global context information, enabling the detection of subtle, spatial artifacts within frames. The flow-gradient temporal consistency stream (FGTC), rather than directly modeling the residuals, it is used to improve the robustness of temporal feature extraction against the inconsistency introduced by unnatural facial motion using optical flow residuals and gradient-based features. By combining these two streams, GC-ConsFlow demonstrates the effectiveness and robustness in capturing complementary spatiotemporal forgery traces. Extensive experiments show that GC-ConsFlow outperforms existing state-of-the-art methods in detecting Deepfake videos under various compression scenarios.;1945-788X;979-8-3315-9495-4;10.1109/ICME59968.2025.11209351;"National Natural Science Foundation of China; Research and Development; Natural Science Foundation of Hunan Province; ";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11209351;"Deepfake Detection;Spatiotemporal Features;Optical Flow Residuals;Global Context Analysis";"Deepfakes;Ethics;Noise;Interference;Feature extraction;Robustness;Forgery;Spatiotemporal phenomena;Optical flow;Context modeling";;1;;21;IEEE;30 Oct 2025;30 June-4 July 2025;30 June-4 July 2025;IEEE;IEEE Conferences
Deepfake Detection Using Graph Representation with Multi-dimensional Features;"J. Chen; W. Lin; J. Xu";"School of Computer and Cyber Sciences Communication University of China, Beijing, China; School of Computer and Cyber Sciences Communication University of China, Beijing, China; School of Computer and Cyber Sciences Communication University of China, Beijing, China";2023 IEEE Smart World Congress (SWC);1 Mar 2024;2023;;;717;722;The proliferation of fake video poses a significant threat to the authority and authenticity of news across multiple domains. The most existing methods of deepfake detection primarily focus on identifying the face as a whole in a video, ignoring the correlation between the facial components. However, our investigation indicates that constituent potions of a face have different effects in deepfake detection. To address this issue, we divided the face in a video frame into several regions and explored the relationship between these regions. Our approach involves constructing a feature graph of this correlation, aiming to make use of the relationship and temporal characteristics between regions of a face in a deepfake video. To begin with, the features of each facial region are extracted through CNN. Subsequently, the feature graph of the entire video is constructed with these features being the vertices and the correlation being the edge. A graph neural network is finally utilized to determine whether the video has been tampered with. Our experiments on several publicly accessible datasets demonstrate that the proposed approach outperforms other state-of-the-art deepfake detection techniques in most scenarios.;;979-8-3503-1980-4;10.1109/SWC57546.2023.10449093;"Research and Development; ";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10449093;"graph representation;deepfake detection;temporal characteristics";"Deepfakes;Correlation;Image edge detection;Logic gates;Feature extraction;Graph neural networks;Faces";;3;;28;IEEE;1 Mar 2024;28-31 Aug. 2023;28-31 Aug. 2023;IEEE;IEEE Conferences
A Dual-Network Architecture with Uncertainty-Aware Multimodal Fusion for Deepfake Detection;Y. Guo;Dalhousie University, Halifax, Canada;2025 6th International Conference on Computer Engineering and Application (ICCEA);13 Aug 2025;2025;;;1809;1813;The detection of AI-generated content, particularly deepfakes, has become a critical issue due to the growing sophistication of generative models. This paper presents MUFDNet, a novel multimodal deepfake detection model that uses paired image and audio data for improved detection accuracy. The model integrates a Vision Transformer (ViT) for image feature extraction and a Graph Neural Network (GGCN) for audio spectrum analysis. By incorporating uncertainty-aware fusion and cross-modal attention mechanisms, MUF-DNet enhances the robustness and generalization of the detection process. Contrastive learning is employed to improve the semantic consistency between the visual and auditory features. Our experiments show that MUF-DNet outperforms existing models in terms of accuracy, precision, recall, and F1 score, demonstrating its potential for deepfake detection in real-world applications.;2159-1288;979-8-3315-4330-3;10.1109/ICCEA65460.2025.11103067;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11103067;"Deepfake detection;multimodal learning;uncertainty-aware fusion;Vision Transformer;Graph Neural Network;contrastive learning";"Deepfakes;Computer vision;Visualization;Accuracy;Uncertainty;Contrastive learning;Transformers;Robustness;Graph neural networks;Spectral analysis";;;;10;IEEE;13 Aug 2025;25-27 April 2025;25-27 April 2025;IEEE;IEEE Conferences
WaveGuard: Robust Deepfake Detection and Source Tracing via Dual-Tree Complex Wavelet and Graph Neural Networks;"Z. He; Z. Guo; L. Wang; G. Yang; Y. Diao; D. Ma";"College of Computer Science and Technology, Xinjiang University, Urumqi, China; College of Computer Science and Technology, Xinjiang University, Urumqi, China; College of Computer Science and Technology, Xinjiang University, Urumqi, China; College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; School of Computer Science, Hefei University of Technology, Hefei, China; College of Computer Science and Technology, Xinjiang University, Urumqi, China";IEEE Transactions on Circuits and Systems for Video Technology;;2025;PP;99;1;1;Deepfake technology has great potential in the field of media and entertainment, but it also brings serious risks, including privacy disclosure and identity fraud. To counter these threats, proactive forensic methods have become a research hotspot by embedding invisible watermark signals to build active protection schemes. However, existing methods are vulnerable to watermark destruction under malicious distortions, which leads to insufficient robustness. Moreover, embedding strong signals may degrade image quality, making it challenging to balance robustness and imperceptibility. Although watermarked images look natural, their underlying structures are often different from the original images, which is ignored by traditional watermarking methods. To address these issues, this paper proposes a proactive watermarking framework called WaveGuard, which explores frequency domain embedding and graph-based structural consistency optimization. In this framework, the watermark is embedded into the high-frequency sub-bands by dual-tree complex wavelet transform (DT-CWT) to enhance the robustness against distortions and deepfake forgeries. By leveraging joint sub-band correlations and selected sub-band combinations, the framework enables robust source tracing and semi-robust deepfake detection. To enhance imperceptibility, we propose a Structural Consistency Graph Neural Network (SC-GNN) that constructs graph representations of the original and watermarked images to ensure structural consistency and reduce perceptual artifacts. Experimental results show that the proposed method performs exceptionally well in face swap and face replay tasks. The code has been published at https://github.com/vpsg-research/WaveGuard.;1558-2205;;10.1109/TCSVT.2025.3628951;"National Natural Science Foundation of China(grant numbers:62302427,62462060); Natural Science Foundation of Xinjiang Uygur Autonomous Region(grant numbers:2023D01C175); Tianshan Talent Training Program(grant numbers:2022TSYCLJ0036);";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11224900;"Deepfake Detection;Source Tracing;Frequency-domain Embedding;Graph Neural Network (GNN)";"Watermarking;Deepfakes;Robustness;Distortion;Faces;Feature extraction;Perturbation methods;Graph neural networks;Training;Frequency-domain analysis";;1;;;IEEE;4 Nov 2025;;;IEEE;IEEE Early Access Articles
An Effective Approach for Deepfake Video Detection using Binarized Neural Network;"P. K; A. Pandey; B. Rudra";"Department of Information Technology, National Institute of Technology, Surathkal, Karnataka, India; Department of Information Technology, National Institute of Technology, Surathkal, Karnataka, India; Department of Information Technology, National Institute of Technology, Surathkal, Karnataka, India";2025 IEEE International Conference on Interdisciplinary Approaches in Technology and Management for Social Innovation (IATMSI);9 May 2025;2025;3;;1;6;The rise of DeepFake technologies, especially in audio and video, poses significant threats to information integrity, security, and privacy. Artificially driven Artificial Intelligence (AI) methods and their advancement make it difficult to trace synthetic media through deepfakes that closely approximate real speech, facial expressions, and body movements. Consequently, traditional methods of detecting these are losing the race because they cannot compete with the newly invented methods that are more advanced in comparison. This paper proposes a lightweight and scalable approach to deepfake video detection using Binarized Neural Networks (BNNs). We integrate BNNs with Convolutional Neural Networks (CNNs) and Multi-task Cascaded Convolutional Networks (MTCNN) to boost feature extraction and analysis while making sure that this is done at a computational efficiency, especially to be deployed in resource-constrained systems such as mobile and embedded devices. The binarization of network weights and activations naturally deals with the trade-off regarding detection accuracy and computational cost. Our approach introduces a practical solution for real-time deepfake detection, thus advancing toward more secure and trusted digital environments. Our proposed model has achieved an accuracy of 80%.;;979-8-3315-2169-1;10.1109/IATMSI64286.2025.10984516;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10984516;"Deepfake Detection;Convolutional Neural Networks;Binarized Neural Networks;Video Processing;Multitask Cascaded Convolutional Networks";"Deepfakes;Technological innovation;Accuracy;Neural networks;Streaming media;Real-time systems;Computational efficiency;Convolutional neural networks;Security;Artificial intelligence";;1;;14;IEEE;9 May 2025;6-8 March 2025;6-8 March 2025;IEEE;IEEE Conferences
Deepfake Detection with Spatio-Temporal Consistency and Attention;"Y. Chen; N. Akhtar; N. A. H. Haldar; A. Mian";"The University of Western Australia, Perth, Australia; The University of Western Australia, Perth, Australia; The University of Western Australia, Perth, Australia; The University of Western Australia, Perth, Australia";2022 International Conference on Digital Image Computing: Techniques and Applications (DICTA);10 Feb 2023;2022;;;1;8;Deepfake videos are causing growing concerns among communities due to their ever-increasing realism. Naturally, automated detection of forged Deepfake videos is attracting a proportional amount of interest of researchers. Current methods for detecting forged videos mainly rely on global frame features and under-utilize the spatio-temporal inconsistencies found in the manipulated videos. Moreover, they fail to attend to manipulation-specific subtle and well-localized pattern variations along both spatial and temporal dimensions. Addressing these gaps, we propose a neural Deepfake detector that focuses on the localized manipulative signatures of the forged videos at individual frame level as well as frame sequence level. Using a ResNet backbone, it strengthens the shallow frame-level feature learning with a spatial attention mechanism. The spatial stream of the model is further helped by fusing texture enhanced shallow features with the deeper features. Simultaneously, the model processes frame sequences with a distance attention mechanism that further allows fusion of temporal attention maps with the learned features at the deeper layers. The overall model is trained to detect forged content as a classifier. We evaluate our method on two popular large data sets and achieve significant performance over the state-of-the-art methods. Moreover, our technique also provides memory and computational advantages over the competitive techniques,;;978-1-6654-5642-5;10.1109/DICTA56598.2022.10034609;"ARC(grant numbers:DP190102443);";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10034609;"Attention;Deepfake;Detection;Video analysis";"Representation learning;Deepfakes;Fuses;Digital images;Detectors;Performance gain;Feature extraction;Time-domain analysis;Task analysis;Optical flow";;7;;59;IEEE;10 Feb 2023;30 Nov.-2 Dec. 2022;30 Nov.-2 Dec. 2022;IEEE;IEEE Conferences
Context-Preserving and Sparsity-Aware Temporal Graph Network for Unified Face Forgery Detection;"K. D. K. Yadav; I. Kavati; A. S. Kurella; S. Jain; Y. Katare";"National Institute of Technology Warangal, India; National Institute of Technology Warangal, India; National Institute of Technology Warangal, India; National Institute of Technology Warangal, India; National Institute of Technology Warangal, India";IEEE Transactions on Consumer Electronics;;2025;PP;99;1;1;Deepfakes and face forgeries continue to evolve, posing significant threats to consumer privacy, reputation, and public security. Existing deep learning approaches often focus on spatial inconsistencies but fail to capture relational context across facial regions and long-term temporal anomalies such as unnatural blinking or lip synchronization errors. We propose EDRL, a lightweight model that effectively captures spatiotemporal relational dependencies for robust face forgery detection. The architecture incorporates a Spatio-Temporal Attention (STA) module built upon a lightweight MC318 3D convolutional backbone, enabling motion-aware feature extraction and region-specific attention mapping. A Sparsity-Aware Edge Dropping Relation Learner (EDRL) constructs adaptive facial graphs by pruning redundant and less informative edges. A Temporal Adaptive Aggregation Network (TAAN) then aggregates frame-level features, ensuring that temporally significant representations are preserved even after edge pruning. Extensive evaluations show that EDRL achieves 98.4% accuracy on CASIA-FASD and reduces HTER by 6.2% on Replay-Attack compared to state-of-the-art baselines, while maintaining competitive results on digital forgery datasets. By enhancing robustness to diverse manipulations while reducing computational overhead, EDRL contributes towards a secure, lightweight, and deployable framework suitable for real-world applications.;1558-4127;;10.1109/TCE.2025.3633697;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11250982;"Spatio-Temporal attention;DeepFake detection;Face Forgery;graph convolution network;relation learning";"Forgery;Faces;Adaptation models;Robustness;Image edge detection;Transformers;Deepfakes;Computational modeling;Training;Feature extraction";;;;;IEEE;17 Nov 2025;;;IEEE;IEEE Early Access Articles
Aggregated Distinguishable Feature Learning for Generalized Deepfake Detection;"B. Yan; C. Xu; C. -T. Li";"School of Information Technology, Deakin University, Melbourne, Australia; Institute for Sustainable Industries Liveable Cities, Victoria University, Melbourne, Australia; School of Information Technology, Deakin University, Geelong, Australia";2025 International Joint Conference on Neural Networks (IJCNN);14 Nov 2025;2025;;;1;8;Deepfake detection is essential for mitigating the growing risks associated with the misuse of AI in video manipulation. While existing deep learning-based methods excel in intra-dataset settings, their performance often deteriorates significantly when applied to unseen datasets, underscoring the pressing challenge of improving generalization capability. To tackle this challenge, we focus on identitying discriminative regions by applying the principle of object detection, which locating forged clues. In this paper, we propose an aggregated distinguishable feature learning framework that innovatively incorporates object detector with a graph claasifier. Specifically, the proposed framework consists of three main components: 1) We employ a DEtection TRansformer (DETR) to learn intrinsic feature differences for capturing different discriminative regions. 2) To better utilize distinguishable features in these regions, we treat each local feature vector of the regions as node and design a node correlation generation module (NCGM) to establish the connections between the nodes by integrating the feature similarity and spatial location relationship. 3) we employ graph convolutional neural networks to aggregate the distinguishable features and learn the global connectivity pattern of the nodes for face forgery detection. Comprehensive experimental results on four benchmark datasets demonstrate that our method effectively improves generalization capability and outperforms other state-of-the-art approaches.;2161-4407;979-8-3315-1042-8;10.1109/IJCNN64981.2025.11228889;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11228889;"Deepfake detection;graph neural classifier;object detection;structural similarity;forgery localization";"Representation learning;Deepfakes;Correlation;Object detection;Detectors;Pressing;Feature extraction;Transformers;Forgery;Vectors";;;;43;IEEE;14 Nov 2025;30 June-5 July 2025;30 June-5 July 2025;IEEE;IEEE Conferences
Reduced Spatial Dependency for More General Video-level Deepfake Detection;"B. Chu; X. Xu; Y. Zhang; W. You; L. Zhou";"School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China; School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China; School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China; School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China; School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China";ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP);7 Mar 2025;2025;;;1;5;As one of the prominent AI-generated content, Deepfake has raised significant safety concerns. Although it has been demonstrated that temporal consistency cues offer better generalization capability, existing methods based on CNNs inevitably introduce spatial bias, which hinders the extraction of intrinsic temporal features. To address this issue, we propose a novel method called Spatial Dependency Reduction (SDR), which integrates common temporal consistency features from multiple spatially-perturbed clusters, to reduce the dependency of the model on spatial information. Specifically, we design multiple Spatial Perturbation Branch (SPB) to construct spatially-perturbed feature clusters. Subsequently, we utilize the theory of mutual information and propose a Task-Relevant Feature Integration (TRFI) module to capture temporal features residing in similar latent space from these clusters. Finally, the integrated feature is fed into a temporal transformer to capture long-range dependencies. Extensive benchmarks and ablation studies demonstrate the effectiveness and rationale of our approach.;2379-190X;979-8-3503-6874-1;10.1109/ICASSP49660.2025.10888190;"Research and Development; National Natural Science Foundation of China; Ministry of Justice; ";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10888190;"deepfake;deepfake detection;temporal consistency detection";"Deepfakes;Perturbation methods;Signal processing;Feature extraction;Transformers;Spatiotemporal phenomena;Safety;Data mining;Speech processing;Mutual information";;1;;24;IEEE;7 Mar 2025;6-11 April 2025;6-11 April 2025;IEEE;IEEE Conferences
Self-Supervised Graph Transformer for Deepfake Detection;"A. Khormali; J. -S. Yuan";"Department of Electrical and Computer Engineering, University of Central Florida, Orlando, FL, USA; Department of Electrical and Computer Engineering, University of Central Florida, Orlando, FL, USA";IEEE Access;29 Apr 2024;2024;12;;58114;58127;Deepfake detection methods have shown promising results in recognizing forgeries within a given dataset, where training and testing take place on the in-distribution dataset. However, their performance deteriorates significantly when presented with unseen samples. As a result, a reliable deepfake detection system must remain impartial to forgery types, appearance, and quality for guaranteed generalizable detection performance. Despite various attempts to enhance cross-dataset generalization, the problem remains challenging, particularly when testing against common post-processing perturbations, such as video compression or blur. Hence, this study introduces a deepfake detection framework, leveraging a self-supervised pre-training model that delivers exceptional generalization ability, withstanding common corruptions and enabling feature explainability. The framework comprises three key components: a feature extractor based on vision Transformer architecture that is pre-trained via self-supervised contrastive learning methodology, a graph convolution network coupled with a Transformer discriminator, and a graph Transformer relevancy map that provides a better understanding of manipulated regions and further explains the model’s decision. To assess the effectiveness of the proposed framework, several challenging experiments are conducted, including in-data distribution performance, cross-dataset & cross-manipulation generalization, and robustness against common post-production perturbations. The results achieved demonstrate the remarkable effectiveness of the proposed deepfake detection framework, surpassing the current state-of-the-art approaches.;2169-3536;;10.1109/ACCESS.2024.3392512;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10506700;"Deepfake detection;graph convolution networks;self-supervised contrastive learning;vision transformer";"Deepfakes;Transformers;Feature extraction;Self-supervised learning;Visualization;Task analysis;Rendering (computer graphics);Detection algorithms;Convolutional neural networks";;25;;81;CCBYNCND;22 Apr 2024;2024;;IEEE;IEEE Journals
Deepfake Detection in the Era of AI: State-Of-the-art Methods and Open Challenges;"D. Samad; K. C. Bandhu";"Department of Computer Science and Engineering, Medicaps University, Indore, India; Department of Computer Science and Engineering, Medicaps University, Indore, India";2025 IEEE International Conference on Advances in Computing Research On Science Engineering and Technology (ACROSET);16 Dec 2025;2025;;;1;7;Deepfake technology, fueled by advances in artificial intelligence technology, has been a revolutionary assistant as well as a tremendous security threat. Deepfakes have new uses in media, entertainment, and digital communication, their abuse can cause dangers such as misinformation, identity fraud, and political deception. This review discusses recent developments in deepfake detection methods and presents the contributions of deep learning, blockchain, and hybrid AI models. We discuss different methodologies ranging from convolutional neural networks (CNNs) and graph neural networks (GNNs) to federated learning and adversarial defense techniques. Despite significant advancements, major challenges persist, such as dataset biases, changing deep fake generation habits, and the requirement of real-time detection systems. This paper offers current research lacunae and proposes future avenues, pointing out the explainability requirements, privacy protection, and multimodal detection paradigms. Through the integration of results from different studies, this review presents an extensive view of the field and determines essential areas for future research.;;978-1-6654-5810-8;10.1109/ACROSET66531.2025.11281068;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11281068;"Deepfake Detection;digital image processing;Computer Vision Convolutional Neural Networks (CNN);Trans formers;Generalization;Cross-Dataset Validation;Model Evaluation";"Training;Deepfakes;Ethics;Reviews;Computational modeling;Transformers;Real-time systems;Blockchains;Convolutional neural networks;Computer security";;;;17;IEEE;16 Dec 2025;27-28 Sept. 2025;27-28 Sept. 2025;IEEE;IEEE Conferences
Evaluating Models for Deepfake Detection: A Comparative Study;"V. Krishna; P. S. Neha; V. P; H. Vidyasekaran";"Computer Science and Engineering, Amrita Vishwa Vidyapeetham, Chennai, India; Computer Science and Engineering, Amrita Vishwa Vidyapeetham, Chennai, India; Computer Science and Engineering, Amrita Vishwa Vidyapeetham, Chennai, India; Computer Science and Engineering, Amrita Vishwa Vidyapeetham, Chennai, India";2024 International Conference on IoT Based Control Networks and Intelligent Systems (ICICNIS);10 Jan 2025;2024;;;1381;1388;Deepfake detection poses a significant challenge in digital forensics due to increasingly advanced AI-generated videos. This study evaluates three models using the FaceForensics++ and DeeperForensics-1.0 datasets. The preprocessing involved video encoding, renaming, trimming, frame extraction, face detection, and data loading. The first model, a Convolutional Neural Network (CNN), achieved 84% accuracy. The second model, Xception, an efficient CNN with depth-wise separable convolutions and residual connections, attained 89% accuracy. The third model, combining CNN with a Recurrent Neural Network (RNN) and LSTM layers, significantly improved detection accuracy to 97%. This hybrid model highlights the importance of capturing spatial and temporal features in deepfake detection, demonstrating the efficacy of advanced deep learning techniques in addressing the deepfake threat.;;979-8-3315-1809-7;10.1109/ICICNIS64247.2024.10823264;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10823264;"Deepfake detection;CNN;Xception;hybrid model;CNN+RNN;classification";"Deepfakes;Accuracy;Recurrent neural networks;Loading;Feature extraction;Convolutional neural networks;Face detection;Intelligent systems;Long short term memory;Load modeling";;2;;17;IEEE;10 Jan 2025;17-18 Dec. 2024;17-18 Dec. 2024;IEEE;IEEE Conferences
GAN and ResNet based Combination Deep Learning Model for Recognizing Fake Faces;"K. Gowsic; R. Hariprasath; M. Guruprasad; M. Kabirajan; J. K. Sojan";"Department of Computer Science and Engineering, Mahendra Engineering College, Tamilnadu, India; Department of Computer Science and Engineering, Mahendra Engineering College, Tamilnadu, India; Department of Computer Science and Engineering, Mahendra Engineering College, Tamilnadu, India; Department of Computer Science and Engineering, Mahendra Engineering College, Tamilnadu, India; Department of Computer Science and Engineering, Mahendra Engineering College, Tamilnadu, India";2025 4th International Conference on Innovative Mechanisms for Industry Applications (ICIMIA);20 Oct 2025;2025;;;1061;1068;AI-driven deepfake technology has grown and matured to the point of rendering it more difficult to distinguish between real and manipulated photos or videos (e.g., altered faces). Deepfakes are built using a highly advanced neural network and they often share hyper-realistic visual properties that evade human perception. This study presents a hybrid deep learning model for robust, reliable, and efficient fake face detection using GANs and ResNet. The hybrid deep learning model takes advantage of GANs to navigate the generative processes inherent in deepfakes and also utilizes ResNet to extract the fine visual features of faces. In addition, CNNs are used to address spatial inconsistencies such as lighting differences, symmetrical facial differences, and textural manipulations. The system was trained on both real and manipulated photos, and several preprocessing techniques (e.g., normalization, dimension reduction) to provide robustness. The experimental results found that this hybrid model demonstrated measureable improvements over traditional methods (i.e., standalone) in accuracy, precision, and sensitivity. This hybrid model brings forth a cost-effective and scalable method for real-time deepfake detection in digital media security and authentication.;;979-8-3315-5386-9;10.1109/ICIMIA67127.2025.11200763;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11200763;"Convolutional Neural Networks;Deepfake Detection;Generative Adversarial Networks;Hybrid Model;Residual Networks;Visual Manipulation";"Deep learning;Deepfakes;Visualization;Sensitivity;Generative adversarial networks;Feature extraction;Real-time systems;Hybrid power systems;Faces;Residual neural networks";;;;15;IEEE;20 Oct 2025;3-5 Sept. 2025;3-5 Sept. 2025;IEEE;IEEE Conferences
PET: High-Frequency Temporal Self-Consistency Learning for Partially Deepfake Audio Localization;"J. He; J. Yi; J. Tao; S. Zeng";"State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Department of Automation, Tsinghua University, Beijing, China; State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China";ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP);7 Mar 2025;2025;;;1;5;Partially deepfake audio attacks have attracted the attention recently, and the demand for locating the manipulation regions of partially deepfake audio arises accordingly. However, existing methods are usually proposed based on frame-level authenticity detection or splicing boundaries detection, neglecting the temporal self-consistency of audio. In this paper, we propose a novel method for partially deepfake audio localization based on temporal self-consistency learning via high-frequency components, named as PET. The results demonstrates that, in ADD 2023 Track 2 eval set, it could achieve the segment F1-score at 0.7397 without any data augmentation strategies, which is 21.94% higher than that of the system ranked 1st on the leaderboard. It also confirms the effectiveness and well generalization ability of PET.;2379-190X;979-8-3503-6874-1;10.1109/ICASSP49660.2025.10889913;"National Natural Science Foundation of China; ";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10889913;"Partially deepfake audio localization;deepfake audio;anomaly detection;empirical wavelet transform";"Location awareness;Wavelet transforms;Deepfakes;Splicing;Signal processing;Data augmentation;Robustness;Acoustics;Speech processing";;1;;29;IEEE;7 Mar 2025;6-11 April 2025;6-11 April 2025;IEEE;IEEE Conferences
EVDO: An Enhanced Framework for Deepfake Detection in Videos Through Optical Flow and Temporal-Spatial Analysis;"M. M. Melouk; M. Shao; A. Basit; C. Abouzahir; R. Zhou; M. Shafique";"eBRAIN Laboratory, Division of Engineering, New York University (NYU) Abu Dhabi, Abu Dhabi, United Arab Emirates; eBRAIN Laboratory, Division of Engineering, New York University (NYU) Abu Dhabi, Abu Dhabi, United Arab Emirates; eBRAIN Laboratory, Division of Engineering, New York University (NYU) Abu Dhabi, Abu Dhabi, United Arab Emirates; eBRAIN Laboratory, Division of Engineering, New York University (NYU) Abu Dhabi, Abu Dhabi, United Arab Emirates; eBRAIN Laboratory, Division of Engineering, New York University (NYU) Abu Dhabi, Abu Dhabi, United Arab Emirates; eBRAIN Laboratory, Division of Engineering, New York University (NYU) Abu Dhabi, Abu Dhabi, United Arab Emirates";IEEE Access;2 Oct 2025;2025;13;;169367;169380;As generative AI advances, the realism of synthetic media has sparked serious concerns in security, privacy, and misinformation. This issue is particularly concerning with the rise of deepfake technologies that manipulate facial imagery, undermining media authenticity. While existing research has largely focused on image-based deepfake detection with specialized feature extractors, detecting deepfakes in video, especially with broad generalization across varied manipulation techniques, remains a substantial challenge. This paper introduces EVDO, a novel framework designed to detect deepfake videos by integrating temporal and spatial analysis for enhanced detection accuracy. Our approach leverages optical flow techniques to capture subtle temporal manipulation artifacts between video frames overlooked in spatial analysis. Using a FlowFormer++ model for temporal analysis, frame pairs are sampled to produce cost volumes that highlight essential motion regions and capture manipulation-specific artifacts through optical flow images which encode temporal dependencies. A flow-finetuned detector then extracts flow-level features indicative of deepfake manipulation. Complementing this, Xception-based spatial detectors analyze each frame individually, generating high-dimensional embeddings that capture frame-specific anomalies. Fusing these temporal and spatial embeddings enables comprehensive binary classification of deepfakes. Validated on the FaceForensics++ benchmark, EVDO significantly improves generalization. Our proposed temporal path contributes correct classifications to around 12% of datapoints. EVDO achieves a video AUC of 99.13% (99.43% of end-to-end SOTA methods) while enabling forensically verifiable manipulation detection.;2169-3536;;10.1109/ACCESS.2025.3614455;"NYU Abu Dhabi (NYUAD) Center for CyberSecurity (CCS); Tamkeen through the NYUAD Research Institute under Award G1104; NYUAD High Performance Computing (HPC) Center for providing Necessary Compute Resources for the Experiments;";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11179989;"Deepfake detection;temporal-spatial analysis;optical flow;deep-learning";"Deepfakes;Optical flow;Feature extraction;Detectors;Media;Faces;Analytical models;Motion artifacts;Privacy;Costs";;;;73;CCBY;25 Sep 2025;2025;;IEEE;IEEE Journals
Source Identification of DeepFake Videos in Social Media-like Networks using Centrality Measures;"A. Kumar; B. Raja; A. Furtado; A. Vemireddy; P. B. Honnavalli; S. V.M.";"Dept. of Computer Science Engineering, PES University, Bengaluru, India; Dept. of Computer Science Engineering, PES University, Bengaluru, India; Dept. of Computer Science Engineering, PES University, Bengaluru, India; Dept. of Computer Science Engineering, PES University, Bengaluru, India; Dept. of Computer Science Engineering, PES University, Bengaluru, India; Dept. of Computer Science Engineering, PES University, Bengaluru, India";2025 13th International Symposium on Digital Forensics and Security (ISDFS);2 Jun 2025;2025;;;1;7;The widespread occurrence of DeepFake videos on social media platforms makes it extremely difficult to pinpoint their source, which is essential for reducing their propagation and possible damage. This research uses centrality measurements in graph-based social networks to identify the primary accounts responsible for spread of misinformation. PageRank, Closeness, Betweenness, and Degree are some of the centrality metrics used to evaluate the influence and impact of nodes in the network. The approach combines a multi-criteria centrality evaluation, content similarity analysis, and graph pruning to determine the most likely source of detected DeepFake videos. The accuracy and resilience of the suggested framework in identifying sources and assessing information dispersion are shown by experimental findings obtained in a variety of network scenarios. Our results identify the deepfake content as well as determine the source account which released this content onto social media. Identifying and eliminating these accounts from a social media network would ensure safety and help users trust the information received online. Our research is an important first step in thwarting false information and boosting confidence in digital platforms.;2768-1831;979-8-3315-0993-4;10.1109/ISDFS65363.2025.11012119;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11012119;"deepfake detection;centrality measures;graph analysis;misinformation;source identification";"Measurement;Bridges;Deepfakes;Social networking (online);Digital forensics;Network analyzers;Safety;Security;Dispersion;Resilience";;;;16;IEEE;2 Jun 2025;24-25 April 2025;24-25 April 2025;IEEE;IEEE Conferences
Real-Time Ensemble-Based Deepfake Detection for Virtual Classrooms and Workspaces Using EfficientNet and Custom Attention-Enhanced CNN;"T. S. S. Manideep; S. Saragadam; G. Karthik; S. Hemanth; S. Palaniswamy";"Department of Computer Science & Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Bengaluru, India; Department of Computer Science & Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Bengaluru, India; Department of Computer Science & Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Bengaluru, India; Department of Computer Science & Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Bengaluru, India; Department of Computer Science & Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Bengaluru, India";2025 International Conference on Intelligent Computing and Knowledge Extraction (ICICKE);22 Sep 2025;2025;;;1;6;The rising threat of deepfake technology poses serious challenges to the credibility of virtual classrooms and professional workspaces. As manipulated video content becomes increasingly realistic, real-time detection systems are essential to preserve trust in remote interactions. This paper presents a hybrid deepfake detection framework combining EfficientNet for global feature extraction and a custom Convolutional Neural Network (CNN) augmented with spatial and channel attention mechanisms for fine-grained facial analysis. An ensemble learning strategy fuses outputs from both models, and a predictive smoothing approach stabilizes real-time predictions across video frames. Experiments conducted on benchmark datasets such as FaceForensics++ and Celeb-DF demonstrate that the proposed system achieves superior performance with 97.5% accuracy and a 0.98 ROC-AUC score. Real-time evaluations show low-latency, frame-level detection at 30 FPS. These results validate the model’s reliability and adaptability. The proposed solution offers a strong foundation for real-time, robust deepfake detection in modern virtual communication environments.;;979-8-3315-3681-7;10.1109/ICICKE65317.2025.11136248;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11136248;"Deepfake detection;real-time analysis;EfficientNet;attention-based CNN;ensemble learning";"Deepfakes;Accuracy;Smoothing methods;Attention mechanisms;Feature extraction;Real-time systems;Robustness;Convolutional neural networks;Ensemble learning;Low latency communication";;;;23;IEEE;22 Sep 2025;6-7 June 2025;6-7 June 2025;IEEE;IEEE Conferences
An Integrated Framework for Video-Based Deepfake Forensic Analysis;"B. M. Alsalami; R. Ikuesan";"Zayed University, College of Technological Innovation, Abu Dhabi, UAE; Zayed University, College of Technological Innovation, Abu Dhabi, UAE";2025 13th International Symposium on Digital Forensics and Security (ISDFS);2 Jun 2025;2025;;;1;5;Deepfakes represent one of the most significant digital advancements in recent years, utilizing artificial intelligence algorithms to replicate human voices, facial expressions, and behaviors with remarkable realism and precision. These technologies are the product of significant progress in machine learning techniques, particularly deep learning. Deepfakes have since emerged as a substantial risk originally conceived for entertainment purposes. Their capacity for accurate behavioral imitation poses dangers, as they can be exploited to deceive unsuspecting individuals, prompting serious ethical and security concerns. This research aims to investigate strategies to mitigate the potential detrimental effects of deepfakes, given that current methodologies appear insufficient to uphold the integrity of digital communications.;2768-1831;979-8-3315-0993-4;10.1109/ISDFS65363.2025.11012010;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11012010;"Deepfake detection;machine learning;forensic analysis;synthetic media;cybersecurity;generative adversarial networks (GANs);convolutional neural networks (CNNs);Deepfake;manipulation;security;AI;algorithms";"Training;Deepfakes;Visualization;Accuracy;Machine learning algorithms;Instruments;Refining;Media;Metadata;Human voice";;;;10;IEEE;2 Jun 2025;24-25 April 2025;24-25 April 2025;IEEE;IEEE Conferences
Dynamic and Static Features Extraction for Deepfake Detection;"H. Teng; C. -Y. Lin";"Department of Computer Science and Information Engineering, National Central University, Taoyuan, Taiwan; Department of Computer Science and Information Engineering, National Central University, Taoyuan, Taiwan";2024 International Conference on Consumer Electronics - Taiwan (ICCE-Taiwan);18 Sep 2024;2024;;;123;124;Deepfake has emerged as a significant concern due to its ability to generate fake images and synthesize realistic videos. The increasing development of new techniques for deep-fake creation raises concerns about the cross-forgery issue. Cross-forgery indicates that a model is initially trained to recognize a particular fake and must work against a different unknown forgery. Training a model needs substantial quantities of data, a challenge compounded if the deepfake generation technique is relatively new. Addressing cross-forgery is a critical and essential challenge that requires resolution. In order to solve cross-forgery, our effort presents a method that combines dynamic and static features to identify forgery. For the static component, we extract features similar to general deepfake detection techniques using a single RGB frame as input. Simultaneously, we utilize optical flow analysis to capture changes between consecutive frames for the dynamic part. Our experiments reveal a clear advantage in utilizing combined features, which is particularly evident in cross-forgery scenarios. Specifically, when encountering certain categories, the performance improvement is significant, demonstrating four times better than single-feature models.;2575-8284;979-8-3503-8684-4;10.1109/ICCE-Taiwan62264.2024.10674402;"National Science and Technology Council; ";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10674402;"Deepfake detection;optical flow;vision transformer;multimodel";"Training;Deepfakes;Visualization;Multimedia systems;Streaming media;Feature extraction;Transformers";;;;8;IEEE;18 Sep 2024;9-11 July 2024;9-11 July 2024;IEEE;IEEE Conferences
A Review of Deepfake Techniques: Architecture, Detection, and Datasets;"P. Edwards; J. -C. Nebel; D. Greenhill; X. Liang";"School of Computer Science and Mathematics, Kingston University, London, U.K.; School of Computer Science and Mathematics, Kingston University, London, U.K.; School of Computer Science and Mathematics, Kingston University, London, U.K.; School of Computer Science and Mathematics, Kingston University, London, U.K.";IEEE Access;28 Oct 2024;2024;12;;154718;154742;Driven by continuous advancements in artificial intelligence, especially deep learning, the level of realism associated with deepfake technology continues to improve year after year, which poses unprecedented challenges to the field of deepfake detection. The boundary between what we as humans can detect as real or fake becomes evermore blurred as new generations of algorithms such as Dall-E 3 and Stable Diffusion are released. This paper provides a comprehensive study into the landscape of deepfake detection, exploring in-depth the key challenges, recognising recent successes, and suggesting promising avenues for future research. A meta-literature review is conducted to identify the current challenges and future directions, which form the foundation of this work. They are investigated by analysing state-of-the-art research with a focus on the key components that are crucial to the design of a deepfake detector, i.e., the architecture, detection methods and datasets. A major challenge identified by this study is the lack of dataset diversity leading to unfair attribute representation. This must be addressed by improving standardisation on dataset ethics and privacy. This is one of the main reasons for the insufficient generalisation capability of current deepfake detectors as demonstrated by their unsatisfactory performance when faced with unseen data or data in the wild. This literature review provides deepfake detection researchers and practitioners with the latest information that will serve as a vital resource for their continued and important activity, now and in the future.;2169-3536;;10.1109/ACCESS.2024.3477257;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10711187;"Deepfakes;deepfake detection;generative AI;deep learning;machine learning;artificial intelligence;datasets;survey";"Deepfakes;Reviews;Bibliographies;Computer architecture;Scalability;Deep learning;Data models;Object recognition;Lighting;Feature extraction;Generative AI;Artificial intelligence;Machine learning";;17;;106;CCBY;9 Oct 2024;2024;;IEEE;IEEE Journals
Enhancing DeepFake Detection through Deep Learning and Explainable AI;"A. Wagh; R. Rane; L. Pinjarkar";"Department of Data Science and Analytics, Dr. Vishwanath Karad MIT World Peace University, Pune, India; Department of Computer Engineering and Technology, Dr. Vishwanath Karad MIT World Peace University, Pune, India; Symbiosis Institute of Technology Nagpur Campus, Symbiosis International (Deemed) University, Pune, India";2025 International Conference on Artificial Intelligence and Machine Vision (AIMV);21 Oct 2025;2025;;;1;6;DeepFake technologies powered by AI models like GANs and Auto-Encoders, with serious threats to privacy and security. Traditional detections methods struggled against Sophisticated DeepFakes. This paper reviews existing detection techniques, identifies research gaps and proposes a new framework integrating CNNs, Transformers, Bi-LSTM and Explainable AI (XAI) for detecting both images and videos and for better accuracy and interpretability.;;979-8-3315-2697-9;10.1109/AIMV66517.2025.11203343;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11203343;"DeepFake Detection;Explainable AI;Deep Learning;CNN;Transformer;Bi-LSTM;Grad-CAM";"Deep learning;Deepfakes;Analytical models;Accuracy;Explainable AI;Biological system modeling;Computational modeling;Predictive models;Transformers;Feature extraction";;;;21;IEEE;21 Oct 2025;16-17 Aug. 2025;16-17 Aug. 2025;IEEE;IEEE Conferences
DeepFake Detection with Multi-View Fusion and Graph Convolutional Network;"X. Xu; J. Chen; Y. Zhang; C. Li; A. K. Singh; Z. Lyu";"School of Software, Dalian University of Technology, Dalian, China; School of Software, Dalian University of Technology, Dalian, China; School of Computing and Artificial Intelligence, Jiangxi University of Finance and Economics, Nanchang, China; China Telecommunication Technology Laboratory, China Academy of Information and Communications Technology, Beijing, China; Computer Science and Engineering Department, National Institute of Technology Patna, Bihar, India; Department of Game Design, Faculty of Arts, Uppsala University, Visby, Sweden";IEEE Transactions on Multimedia;;2025;PP;99;1;14;Nowadays, massive amounts of facial images have been tampered with and then widely spread through social networks. Many studies have developed algorithms for frame-level DeepFake detection. However, they have low robustness due to their focus on tamper-independent features during training. To this end, we propose a framework, namely MIF-Net, based on multi-information fusion for robust frame-level DeepFake detection. Specifically, key landmarks and the facial area are first detected in the original frame. Then, the graph convolutional network constructs biometric information from these landmarks. Meanwhile, the facial region is processed into multi-view inputs by noise and edge enhancement algorithms. Finally, these products are encoded as high-level features and classified as real or fake. Five benchmark datasets are utilized for testing our model through within-dataset and cross-dataset validations. Extensive experiment results demonstrate that our proposed MIF-Net is robust and has advantages over peer algorithms.;1941-0077;;10.1109/TMM.2025.3618565;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11194129;"DeepFake Detection;Deep Learning;Multi-View Fusion;Graph Convolutional Network;Attention Mechanism";"Deepfakes;Feature extraction;Transformers;Faces;Noise;Forgery;Attention mechanisms;Image edge detection;Biological system modeling;Adaptation models";;;;;IEEE;6 Oct 2025;;;IEEE;IEEE Early Access Articles
AI Powered Multimodal Content Moderation for Online Safety in Social Media Platforms;"C. Kumar V; C. Gowda; C. G; D. B; L. P. D. Yadav; Vidya";"Computer Science and Engineering, Alva's Institute of Engineering And Technology, Moodbidri, India; Computer Science and Engineering, Alva's Institute of Engineering And Technology, Moodbidri, India; Computer Science and Engineering, Alva's Institute of Engineering And Technology, Moodbidri, India; Computer Science and Engineering, Alva's Institute of Engineering And Technology, Moodbidri, India; Computer Science and Engineering, Alva's Institute of Engineering And Technology, Moodbidri, India; Computer Science and Engineering, Alva's Institute of Engineering And Technology, Moodbidri, India";2025 6th International Conference on Inventive Research in Computing Applications (ICIRCA);31 Jul 2025;2025;;;1748;1758;In an era where social media platforms are inundated with diverse and complex content, moderation is the answer to sieving out toxic content. Platforms such as Twitter, Facebook, and Instagram enable global connectivity, but also have spaces for toxic content in the way of fake news, hate speech, cyberbullying, and deepfakes that impede mental health and generate economic losses. Sifting and screening such content is an urgent need. This paper presents a new approach to content moderation based on a Multimodal Social Media Content Moderation framework established by Hybrid Graph Theory and Bio-inspired Optimization (MSCMGTB). The model utilizes Convolutional Neural Networks (CNNs) for extracting visual features and Transformer-based models for text understanding. Multimodal inputs are dynamically aligned by a Bi-directional Attention Mechanism (BAM), whereas hyperparameters are optimized using Genetic Algorithms (GA). The model outperforms existing approaches, such as SGNN and CrediBot, with improved precision, accuracy, recall, AUC, specificity, and reduced response delays. In addition, the research explores image captioning as a content moderation task with a human-machine collaboration strategy. With training on Flickr30k and MS Coco, the model reduces review times by 13 %, where finetuning reduces it by 28 %. This recognizes the power of humanmachine collaboration in preventing review backlogs. The model also yields automatic region-based obfuscation with a top1 accuracy of 90.3 annotation. Simulations of real-world use demonstrate improved consistency of decisions, reduced variance of review time, and scalability in dynamic social media environments, exhibiting MSCMGTB's efficacy and usability for real-time application.;;979-8-3315-2142-4;10.1109/ICIRCA65293.2025.11089733;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11089733;"Content Moderation;Deep Learning;Multimodal Learning;Social Media;Deepfake Detection;NLP;CNN;Transformer Models";"Training;Measurement;Accuracy;Social networking (online);Reviews;Biological system modeling;Benchmark testing;Transformers;Convolutional neural networks;Genetic algorithms";;;;13;IEEE;31 Jul 2025;25-27 June 2025;25-27 June 2025;IEEE;IEEE Conferences
Spatio-Temporal Convolutional Neural Networks for Deepfake Detection: An Empirical Study;"V. K. Sharma; R. Garg; Q. Caudron";"Amity University, Noida, Uttar Pradesh, India; Amity University, Noida, Uttar Pradesh, India; Sound Agriculture, Emeryville, CA, United States";2023 Second International Conference on Informatics (ICI);8 Feb 2024;2023;;;1;7;As the creation of deepfakes becomes more prevalent and sophisticated, the need for accurate and robust detection methods intensifies. This paper presents a comprehensive empirical study on the efficacy of S patio-Temporal Convolutional Neural Networks (ST-CNNs) for deepfake detection. It explores how the rich spatio-temporal information contained within video frames can be exploited by ST-CNNs to distinguish between genuine and manipulated content. The study is underpinned by a robust testing framework, wherein a range of deepfake generation techniques are used to evaluate the detection model. It further investigates the effect of various layers and architectural elements on detection performance. The results demonstrate that ST-CNNs, by leveraging spatio-temporal correlations, can offer superior deepfake detection performance compared to the conventional CNN models. This work can guide the development of more efficient and effective deepfake detection strategies by providing empirical insights into the utilization of ST-CNNs.;;979-8-3503-4383-0;10.1109/ICI60088.2023.10420892;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10420892;"deepfake detection;spatio temporal;video forgery;convolutional neural network;synthetic media";"Deepfakes;Correlation;Media;Convolutional neural networks;Informatics;Testing";;6;;31;IEEE;8 Feb 2024;23-25 Nov. 2023;23-25 Nov. 2023;IEEE;IEEE Conferences
DeepFake Face Detection using Machine Learning with LSTM;"T. Vignesh; P. H. Tarun; R. Parthav; V. Bhargavi";"IT Department, B V Raju Institute of Technology, Narsapur, India; IT Department, B V Raju Institute of Technology, Narsapur, India; IT Department, B V Raju Institute of Technology, Narsapur, India; IT Department, B V Raju Institute of Technology, Narsapur, India";2024 10th International Conference on Communication and Signal Processing (ICCSP);6 Jun 2024;2024;;;1633;1638;Fake face images that are increasingly convincing and realistic can be created because to the development of face image manipulation (FIM) technologies like Face to Face and Deepfake, which can damage the legitimacy and trustworthiness of online content. Malicious uses of these technology include blackmailing people, posing as celebrities, and disseminating false information. As a result, creating trustworthy and strong techniques to identify FIM and safeguard the integrity of digital media is essential. Numerous current techniques utilize on models built on convolutional neural networks (CNNs), which are capable of detecting FIM by examining a face’s visual characteristics. But because these models are frequently tested and trained on certain datasets or circumstances. Furthermore, they might not be able to record the temporal information that is included in video data and can be used to identify irregularities or strange anomalies in FIM videos. We provide a novel method that uses both geographical and temporal information to detect FIM in order to get over these difficulties. We present a new type of residual network called CRNet, which is dependent on Convolutional Long Short-Term Memory (LSTM) and is capable of processing a series of consecutive pictures taken from a movie. The model can learn temporal information because to its design, which is essential for spotting oddities that occur in between frames of FIM movies. We performed extensive tests with several kinds of FIM videos from the Kaggle dataset.;2836-1873;979-8-3503-5306-8;10.1109/ICCSP60870.2024.10544299;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10544299;"Deepfake detection;Long-Short Term Memory (LSTM);Kaggle;Residual next convolution neural network (Xception CNN);Image manipulation";"Deepfakes;Visualization;Convolution;Transfer learning;Neural networks;Motion pictures;Data models";;1;;13;IEEE;6 Jun 2024;12-14 April 2024;12-14 April 2024;IEEE;IEEE Conferences
Unmasking the Reality: A Comprehensive Study of Deepfake Identification Techniques and Their Expanding Terrain;"S. Sharma; D. M. Pathak; D. Jain; S. Srivastava; P. Vats; G. M. Upadhyay";"Department of Computer Science, ABES Engineering College, Ghaziabad, U.P, India; Department of Computer Science, ABES Engineering College, Ghaziabad, U.P, India; Department of Computer Science Engineering-AIML, ABES Engineering College, Ghaziabad, U.P, India; Department of Computer Science, ABES Engineering College, Ghaziabad, U.P, India; Dept. of CSE, School of CSE, Manipal University Jaipur, Jaipur, Rajasthan, India; Dept. of Computer Application, Manipal University Jaipur, Jaipur, Rajasthan, India";2025 2nd International Conference on Computational Intelligence, Communication Technology and Networking (CICTN);26 Mar 2025;2025;;;293;298;The swift progression of deepfake-generating technologies has elicited much apprehension about their potential misuse in digital media, necessitating the development of efficient detection methods. This research aims to improve the precision of deepfake detection by the application of spatial-temporal feature engineering methods. A comparative comparison of advanced preprocessing techniques is performed to enhance the extraction of spatial and temporal indicators essential for detecting deepfake abnormalities. The study investigates the amalgamation of sophisticated machine learning and deep learning models with designed characteristics to get enhanced detection efficacy. Experimental assessments are conducted on benchmark datasets to verify the effectiveness of the suggested methodologies. The findings highlight the importance of effective preprocessing strategies in enhancing model generalizability and dependability, hence supporting the overarching goal of preserving digital authenticity.;;979-8-3315-3038-9;10.1109/CICTN64563.2025.10932620;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10932620;"Deepfake Detection;Spatial-Temporal Preprocessing;Deepfake detection;spatial-temporal features;preprocessing techniques;feature engineering;machine learning;deep learning;digital media authenticity;anomaly detection;benchmark datasets;detection accuracy;model generalizability";"Deep learning;Deepfakes;Accuracy;Computational modeling;Refining;Media;Benchmark testing;Feature extraction;Real-time systems;Resilience";;;;30;IEEE;26 Mar 2025;6-7 Feb. 2025;6-7 Feb. 2025;IEEE;IEEE Conferences
ConvNext-PNet: An interpretable and explainable deep-learning model for deepfakes detection;"H. Ilyas; A. Javed; K. M. Malik";"University of Engineering and Technology, Taxila, Pakistan; University of Engineering and Technology, Taxila, Pakistan; University of Michigan-Flint, MI, USA";2024 IEEE International Joint Conference on Biometrics (IJCB);11 Nov 2024;2024;;;1;9;The evolution of artificial intelligence (AI) techniques in recent years has increased the generation of fake content including AI-generated text, images, audio, and videos. Among which the fake visual content commonly known as deepfakes has imposed a great threat to society due to its negative impacts. To mitigate the adverse aspects of deepfakes, the research community has introduced various deepfakes detection methods. However, these deepfakes detection methods lack the interpretability and explainability of the decision-making process. The interpretable model increases trustworthiness as it provides the reasoning for classifying outcomes as real or fake. Therefore, in this paper, we have introduced ConvNext-PNet, which is a prototypical-based learning framework for the interpretable and explainable detection of visual deepfakes. In the proposed framework, prototype learning is incorporated into the modified ConvNext model that improves the discriminative features learning capability of the proposed framework along with the explainability aspect. The performance of ConvNext-PNet is evaluated on challenging datasets including FaceForensics++ (FF++), CelebDF, DFDC-P, and DeepFakeFace (DFF) datasets. The robustness of the proposed model is validated through various experiments along with the interpretability analysis. The quantitative results demonstrate the effectiveness of the model for the detection of visual manipulation, whereas the model interpretability and explainability aspect increases the trustworthiness via providing reasoning for the model predictions.;2474-9699;979-8-3503-6413-2;10.1109/IJCB62174.2024.10744484;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10744484;"ConvNext-PNet;ConvNext;ProtoPNet;Interpretable deepfakes detection;Explainable deepfakes detection";"Representation learning;Deepfakes;Visualization;Biological system modeling;Noise;Prototypes;Predictive models;Cognition;Robustness;Artificial intelligence";;1;;25;IEEE;11 Nov 2024;15-18 Sept. 2024;15-18 Sept. 2024;IEEE;IEEE Conferences
Deciphering Deception-LSTM Combats Deepfake Audios;"Y. Acharya; J. Tyagi; M. Jangid";"Department of Computer Science and Engineering, Manipal University Jaipur, Jaipur, India; Department of Computer Science and Engineering, Manipal University Jaipur, Jaipur, India; Department of Computer Science and Engineering, Manipal University Jaipur, Jaipur, India";2024 4th International Conference on Technological Advancements in Computational Sciences (ICTACS);21 Jan 2025;2024;;;1970;1975;It's safe to say that the proliferation of synthetically generated media, particularly Deepfakes, has raised significant concerns regarding privacy, security, and integrity of digital content. There is a lot of research to detect these deep-fakes, however we believe audio deepfake detection is an ever evolving technology which needs to conquer deepfake generation techniques. In this paper, we propose a Long Term Short Memory model to classify real and fake audios and discuss how different hyperparameters affect the results. Four models have been tested with four different optimisers each to conclude the best model and optimiser for deepfake audio detection.;;979-8-3503-8749-0;10.1109/ICTACS62700.2024.10841007;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10841007;"Deepfake Generation;Deepfake Audio Detection;LSTM Model;Optimisers";"Deepfakes;Privacy;Computational modeling;Media;Security";;;;12;IEEE;21 Jan 2025;13-15 Nov. 2024;13-15 Nov. 2024;IEEE;IEEE Conferences
Review of Deepfake Detection Techniques and Challenges;"N. S. Ahmad Sharawardi; S. -H. Liew; P. Turumugon; A. Subramaniam";"Faculty of Computing and Information Technology, Tunku Abdul Rahman University of Management and Technology Tanjung Bungah, Pulau Pinang, Malaysia; Faculty of Computer Science and Information Technology, Universiti Malaysia Sarawak (UNIMAS), Kota Samarahan, Sarawak, Malaysia; Faculty of Computing and Information Technology, Tunku Abdul Rahman University of Management and Technology Tanjung Bungah, Pulau Pinang, Malaysia; Faculty of Computing and Information Technology, Tunku Abdul Rahman University of Management and Technology Tanjung Bungah, Pulau Pinang, Malaysia";2025 IEEE International Conference on Computation, Big-Data and Engineering (ICCBE);28 Nov 2025;2025;;;867;872;The proliferation of deepfake technology, powered by advanced generative models such as generative adversarial networks (GANs), presents challenges in digital media authenticity, public trust, and cybersecurity. We reviewed recent advancements in deepfake detection across multiple modalities, including image, video, and audio. Benchmark datasets, such as FaceForensics++, the deepfake detection challenge (DFDC), and Celeb-deepfake (Celeb-DF), have been used to develop diverse detection models. These models encompass approaches based on EfficientNet-driven transfer learning, convolutional neural network-long short-term memory (CNN-LSTM) hybrids for temporal feature extraction, graph-based neural architectures, and ensemble methods that integrate deep learning with handcrafted features. Although certain models report detection accuracies as high as 99.99% on specific datasets, many exhibit limited generalizability across different benchmarks, particularly when confronted with compression artifacts. Additionally, real-time deployment remains constrained by substantial computational demands. Emerging threats, including adversarial perturbations and diffusion-based synthetic media, necessitate the development of more resilient detection strategies. Proactive countermeasures such as blockchain-based timestamping, digital watermarking, and cryptographic hashing have been adopted to enhance media integrity. The results of the review underscore the need for lightweight, interpretable, and multimodal detection frameworks to generalize the models' applicability across diverse domains, thereby supporting reliable and scalable media verification in increasingly complex digital environments.ion.;;979-8-3315-3244-4;10.1109/ICCBE65177.2025.11255645;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11255645;"deepfake detection;generative adversarial networks (GANs);convolutional neural networks (CNNs);hybrid models;spatial-temporal models";"Training;Deep learning;Deepfakes;Adaptation models;Accuracy;Computational modeling;Biological system modeling;Media;Benchmark testing;Real-time systems";;;;35;IEEE;28 Nov 2025;27-29 June 2025;27-29 June 2025;IEEE;IEEE Conferences
Advancements in Deepfake Detection: Leveraging Bi-LSTM-CNN Architecture for Robust Identification;"O. Tantawy; A. Elshafee";"Faculty of Computer Science October, University for Modern Sciences and Arts (MSA); University for Modern Sciences and Arts (MSA)";2024 6th Novel Intelligent and Leading Emerging Sciences Conference (NILES);22 Nov 2024;2024;;;525;528;In our modern era, the saying “visual evidence is conclusive” no longer holds true, presenting significant implications across various spheres of our lives. With the rapid advancement of technology, the creation of synthetic media, particularly deepfakes, has become remarkably facile. Some applications even facilitate the creation of deepfakes directly on handheld devices. The identification of deepfakes poses a formidable challenge as they can be imperceptible to the human eye. Nevertheless, researchers are actively engaged in developing methodologies to discern deepfakes. Deepfakes constitute media generated through AI algorithms. These algorithms assimilate attributes from a reference image and overlay them onto a source image. In our pursuit of identifying video deepfakes, we employ deep learning architectures such as Bi-LSTM integrated with CNN. Our approach capitalizes on 50 epochs of training to attain a remarkable accuracy of up to 98.7%. We leverage transfer learning to construct a robust deepfake detection model. Initially, we utilize a pretrained CNN, dubbed Bi-LSTM-CNN, to extract salient features and construct feature vectors. Subsequently, the Bi-LSTM layer is trained using these feature vectors. The resulting confusion matrix substantiates the efficacy of our model, with validation and testing accuracies reaching an impressive level.;;979-8-3503-7851-1;10.1109/NILES63360.2024.10753235;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10753235;"Advancements in Deepfake Detection;Leveraging Bi-LSTM-CNN Architecture for Robust Identification";"Training;Deepfakes;Visualization;Accuracy;Scalability;Transfer learning;Media;Feature extraction;Vectors;Testing";;1;;18;IEEE;22 Nov 2024;19-21 Oct. 2024;19-21 Oct. 2024;IEEE;IEEE Conferences
Real-Time Deepfake Detection using a Hybrid MobileNet-LSTM Model For Image and Video Analysis;"S. Ambika; Y. Harini; B. R. Sumanth";"Department of CSE, Vel Tech Rangarajan Dr. Sagunthala R&D Institute of Science and Technology, Chennai, India; Department of CSE, Vel Tech Rangarajan Dr. Sagunthala R&D Institute of Science and Technology, Chennai, India; Department of CSE, Vel Tech Rangarajan Dr. Sagunthala R&D Institute of Science and Technology, Chennai, India";2025 8th International Conference on Computing Methodologies and Communication (ICCMC);4 Sep 2025;2025;;;981;986;As deepfake technology has become more advanced, there is an urgent need for strengthening detection mechanisms that can help counter misinformation and online fraud. Deepfake media is manufactured using deep learning techniques. It has recently become increasingly sophisticated and the boundary between genuine and tampered content is often hard to see. This paper introduces a hybrid MobileNet-LSTM model, which is made for spotting deepfakes in both image and video.The deepfake identification system uses MobileNet to efficiently sample spatial features and LSTM to gather temporal dependencies, thereby improving the detection rate of tampered content. Meanwhile, this method is validated on standard datasets and that the accuracy is better, in terms of computational efficiency and that it is more robust than other types of manipulation.;;979-8-3315-1211-8;10.1109/ICCMC65190.2025.11140856;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11140856;"Deepfake Detection;Hybrid MobileNet-LSTM Model;Real-time Analysis;Machine Learning;MobileNet;LSTM;Computer Vision;Media Authentication";"Deep learning;Deepfakes;Analytical models;Computer vision;Computational modeling;Feature extraction;Real-time systems;Fraud;Long short term memory;Standards";;;;16;IEEE;4 Sep 2025;23-25 July 2025;23-25 July 2025;IEEE;IEEE Conferences
Supervised Learning Techniques for Deepfake Detection: Integrating ResNet50 and LSTM;"N. L. Mudegol; A. Urunkar";"Department of Computer Science and Enginneering, Walchand College of Engineering Sangli, Sangli, India; Department of Computer Science and Enginneering, Walchand College of Engineering Sangli, Sangli, India";2025 1st International Conference on AIML-Applications for Engineering & Technology (ICAET);26 Mar 2025;2025;;;1;6;Deepfake technology has garnered considerable scholarly interest owing to its capacity to generate exceptionally lifelike yet artificially constructed media artifacts, posing serious threats to various aspects of society, including privacy, security, and misinformation. In response to this growing concern, this project aims to develop an effective deepfake detection system using deep learning models. This paper focuses on leveraging supervised learning techniques to distinguish between authentic and deepfake videos. The proposed approach involves collecting a diverse dataset of both authentic and deepfake videos, covering various scenarios and manipulation techniques. Preprocessing techniques are applied to extract relevant features from the videos, preparing them for input to the deep learning models. Several neural network architectures, including Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and their combinations [13], are explored for their suitability in detecting deepfake content. Transfer learning methodologies are utilized to capitalize on models that have undergone prior training, such as those trained on ImageNet, as feature extractors or initializations for the network. The models are trained on the labeled dataset. The paper aims to detect deepfake in videos by using ResNet50 for feature extraction and training those features on the LSTM Model.;;979-8-3503-5561-1;10.1109/ICAET63349.2025.10932283;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10932283;"Deepfake Detection;CNN;RNN;Transfer Learning;ResNet50-LSTM";"Training;Deep learning;Deepfakes;Recurrent neural networks;Transfer learning;Supervised learning;Feature extraction;Convolutional neural networks;Long short term memory;Residual neural networks";;;;15;IEEE;26 Mar 2025;16-17 Jan. 2025;16-17 Jan. 2025;IEEE;IEEE Conferences
Deepfake Detection Based on LSTM Networks with Facial Geometric Features;"D. Xiong; Z. Wen; C. Zhang; P. Xiao; M. Wu";"School of Communication Engineering, Chengdu University of Information Technology, Chengdu, China; School of Communication Engineering, Chengdu University of Information Technology, Chengdu, China; School of Communication Engineering, Chengdu University of Information Technology, Chengdu, China; School of Communication Engineering, Chengdu University of Information Technology, Chengdu, China; School of Communication Engineering, Chengdu University of Information Technology, Chengdu, China";2025 4th International Conference on Electronics, Integrated Circuits and Communication Technology (EICCT);6 Aug 2025;2025;;;627;630;The increasing sophistication of Deepfake technology necessitates robust detection methods. This paper proposes a Deepfake detection approach utilizing Long ShortTerm Memory (LSTM) networks to analyze temporal variations in facial geometric features. By extracting precise facial landmark coordinates over video frames, we capture subtle dynamic inconsistencies characteristic of manipulated content. These landmark sequences are transformed into feature vectors, which are then fed into an LSTM network designed to model temporal patterns and distinguish between genuine and forged videos. The efficacy of our method is demonstrated through experiments on publicly available datasets. On the UADFV dataset, our approach achieves an accuracy of 90.45%, and on the FaceForensics++ (FF++) dataset, it reaches 93.50% accuracy, highlighting its potential for effective Deepfake detection.;;979-8-3315-3594-0;10.1109/EICCT65471.2025.11099876;"Sichuan Province Science and Technology Department, Sichuan Province(grant numbers:24JBGS0050);";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11099876;"Long Short-Term Memory;deepfake video detection;facial geometric features;Deepfake";"Integrated circuits;Deepfakes;Accuracy;Dynamics;Feature extraction;Vectors;Robustness;Real-time systems;Long short term memory;Manipulator dynamics";;;;11;IEEE;6 Aug 2025;11-13 July 2025;11-13 July 2025;IEEE;IEEE Conferences
AWaveFormer: Audio Wavelet Transformer Network for Generalized Audio Deepfake Detection;"R. Wang; Z. Chen; B. Wang; Z. Ba; K. Ren";"School of Information and Communication Engineering, Dalian University of Technology, Dalian, Liaoning, China; School of Information and Communication Engineering, Dalian University of Technology, Dalian, Liaoning, China; School of Information and Communication Engineering, Dalian University of Technology, Dalian, Liaoning, China; School of Cyber Science and Technology, Zhejiang University, Hangzhou, Zhejiang, China; School of Cyber Science and Technology, Zhejiang University, Hangzhou, Zhejiang, China";IEEE Transactions on Audio, Speech and Language Processing;2 Oct 2025;2025;33;;4020;4032;Rapid advancements in speech synthesis technology have made it easier to produce realistic synthetic speech, which poses serious threats to public privacy and security. Recent studies have investigated pre-trained models for feature extraction and adopted advanced architectures, including convolutional and graph neural networks, for deepfake detection. Although these methods improve detection performance to some extent, their generalization and robustness still face challenges. To address this issue, in this paper, we propose a forgery detection method based on the fusion of dual pre-trained features and an optimized Transformer architecture. Specifically, we use a cross-attention mechanism to fuse the audio features extracted from pre-trained Wav2vec 2.0 and WavLM, and replace the token mixer in the traditional Transformer architecture with wavelet transform and multi-scale pooling operations. By combining dual pre-trained features, we extract more comprehensive and discriminative features while optimizing the Transformer architecture, which not only reduces time complexity but also enhances detection performance. We conducted experiments on several datasets, and the results show that our model achieves impressive detection performance with EERs of 0.13%, 2.33%, 3.63%, 10.25%, 5.15%, and 0.21% on the ASVspoof 2019LA, ASVspoof 2021LA, ASVspoof 2021DF, In-the-Wild, Fake-or-Real, and ASVspoof 2015LA evaluation datasets, respectively.;2998-4173;;10.1109/TASLPRO.2025.3611229;"National Natural Science Foundation of China(grant numbers:62372452); Youth Innovation Promotion Association of the Chinese Academy of Sciences;";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11168216;"Audio deepfake detection;multi-scale learning;Wav2Vec 2.0;WavLM;wavelet transform";"Feature extraction;Deepfakes;Wavelet transforms;Transformers;Computer architecture;Speech processing;Speech synthesis;Computational efficiency;Computational modeling;Training";;;;54;IEEE;17 Sep 2025;2025;;IEEE;IEEE Journals
A Hybrid Xception-LSTM Model with Channel and Spatial Attention Mechanism for Deepfake Video Detection;"D. Dagar; D. K. Vishwakarma";"Dept. of Information Technolgy, Delhi Technological University (DTU), Delhi, India; Dept. of Information Technolgy, Delhi Technological University (DTU), Delhi, India";2023 3rd International Conference on Mobile Networks and Wireless Communications (ICMNWC);22 Feb 2024;2023;;;1;5;"The great strides taken in recent times in image and video manipulation have raised serious concerns. Deepfake technology uses deep learning approaches to create highly realistic, astonishing content. Detecting such videos is the only promising defense against such fraudulent data. To counter the malicious intent of the user, a deepfake detection model is proposed that employs channel and spatial attention mechanisms(CBAM) along with Xception and LSTM pretrained models. Xception uses depthwise separable convolution to capture the latent spatial artifacts. LSTM captures the discrepancies among the manipulated sequences; hence, this hybrid ensembling of models allows the learning of powerful features. The evaluation is performed on the recently proposed Div-DF dataset consisting of varied video manipulation like face swap, facial reenactment, and lip-sync. It shows that the model works well (Accuracy~ 93 % & AUC ~ 0.98) on the diversified dataset and easily beats the score of various state-of-the-art deepfake detection and image classification models.";;979-8-3503-1702-2;10.1109/ICMNWC60182.2023.10435983;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10435983;"deepfake detection;deepfake dataset;video manipulation detection;channel attention;spatial attention";"Wireless communication;Deep learning;Deepfakes;Image coding;Convolution;Faces;Image classification";;7;;31;IEEE;22 Feb 2024;4-5 Dec. 2023;4-5 Dec. 2023;IEEE;IEEE Conferences
Multi-Label Deepfake Classification;"I. P. Singh; N. Mejri; V. D. Nguyen; E. Ghorbel; D. Aouada";"Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Luxembourg";2023 IEEE 25th International Workshop on Multimedia Signal Processing (MMSP);8 Dec 2023;2023;;;1;5;In this paper, we investigate the suitability of current multi-label classification approaches for deepfake detection. With the recent advances in generative modeling, new deepfake detection methods have been proposed. Nevertheless, they mostly formulate this topic as a binary classification problem, resulting in poor explainability capabilities. Indeed, a forged image might be induced by multi-step manipulations with different properties. For a better interpretability of the results, recognizing the nature of these stacked manipulations is highly relevant. For that reason, we propose to model deepfake detection as a multi-label classification task, where each label corresponds to a specific kind of manipulation. In this context, state-of-the-art multi-label image classification methods are considered. Extensive experiments are performed to assess the practical use case of deepfake detection.;2473-3628;979-8-3503-3893-5;10.1109/MMSP59012.2023.10337658;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10337658;"Deepfake detection;Multi-Label Classification;Stacked Manipulations";"Deepfakes;Annotations;Conferences;Signal processing;Benchmark testing;Object recognition;Task analysis";;4;;20;IEEE;8 Dec 2023;27-29 Sept. 2023;27-29 Sept. 2023;IEEE;IEEE Conferences
Quantitative Dissection of Spatial, Temporal, and Frequency Features in Deepfake Detection;"Y. Tiwari; D. Saxena; F. -R. Hsu; A. Yadav";"Department of Computer Science and Engineering, IET, DSMNRU, Lucknow, U.P, India; Department of Computer Science and Engineering, Chandigarh University, Mohali, Punjab, India; Department of Computer Science and Information Engineering, Feng Chia University, Taichung, Taiwan; Department of Computer Science and Engineering, IET, DSMNRU, Lucknow, U.P, India";2025 IEEE International Conference on Computer, Electronics, Electrical Engineering & their Applications (IC2E3);24 Sep 2025;2025;;;1;6;Deepfake detection models have achieved remarkable accuracies yet remain opaque in their decision processes. In this study, we dissect the feature hierarchies exploited by four state-of-the-art deepfake detectors—Xception, ResNet50, EfficientNet-B4, and Vision Transformer (ViT), using advanced explainability methods (Grad-CAM, LIME, SHAP) on the FaceForensics++ dataset across various compression levels. Our experiments demonstrate that localized spatial artifacts, temporal discontinuities, and frequency-based anomalies are critical for discrimination. For instance, occluding the mouth region reduces Xception’s accuracy from 92.5% to 55.3% (a 37.2% drop), while blurring the eye region induces a 28% accuracy reduction for Xception and 35% for EfficientNet-B4. Temporal perturbation via inter-frame Gaussian smoothing decreases EfficientNet-B4’s performance from 95.2% to 64.7% (a 30.5% drop), underscoring its reliance on micro-motion cues. Moreover, Fourier analysis reveals that real videos exhibit 31.2% high-pass energy in the forehead region versus 22.8% in deepfakes, and filtering these features lowers EfficientNet-B4’s accuracy from 94.1% to 66.4%. These quantifiable metrics confirm that deepfake models integrate spatial, temporal, and frequency-domain features for classification. Our work provides a reproducible framework for interpretable deepfake detection, paving the way for more robust cross-dataset generalization and enhanced trustworthiness in media forensics.;;979-8-3315-2439-5;10.1109/IC2E365635.2025.11166815;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11166815;"Deepfake Detection;Explainable AI;Grad-CAM;LIME;SHAP;Xception;ResNet50;EfficientNet-B4;Vision Transformer;Feature Attribution";"Deepfakes;Computer vision;Accuracy;Smoothing methods;Perturbation methods;Mouth;Media;Feature extraction;Transformers;Residual neural networks";;;;21;IEEE;24 Sep 2025;15-16 May 2025;15-16 May 2025;IEEE;IEEE Conferences
DIP: Diffusion Learning of Inconsistency Pattern for General DeepFake Detection;"F. Nie; J. Ni; J. Zhang; B. Zhang; W. Zhang";"School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; School of Cyber Science and Technology, Sun Yat-sen University, Shenzhen, China; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; Department of Networks, Pengcheng Laboratory, Shenzhen, China; School of Cyberspace Science, Harbin Institute of Technology, Harbin, China";IEEE Transactions on Multimedia;4 Apr 2025;2025;27;;2155;2167;With the advancement of deepfake generation techniques, the importance of deepfake detection in protecting multimedia content integrity has become increasingly obvious. Recently, temporal inconsistency clues have been explored to improve the generalizability of deepfake video detection. According to our observation, the temporal artifacts of forged videos in terms of motion information usually exhibits quite distinct inconsistency patterns along horizontal and vertical directions, which could be leveraged to improve the generalizability of detectors. In this paper, a transformer-based framework for Diffusion Learning of Inconsistency Pattern (DIP) is proposed, which exploits directional inconsistencies for deepfake video detection. Specifically, DIP begins with a spatiotemporal encoder to represent spatiotemporal information. A directional inconsistency decoder is adopted accordingly, where direction-aware attention and inconsistency diffusion are incorporated to explore potential inconsistency patterns and jointly learn the inherent relationships. In addition, the SpatioTemporal Invariant Loss (STI Loss) is introduced to contrast spatiotemporally augmented sample pairs and prevent the model from overfitting nonessential forgery artifacts. Extensive experiments on several public datasets demonstrate that our method could effectively identify directional forgery clues and achieve state-of-the-art performance.;1941-0077;;10.1109/TMM.2024.3521766;"National Natural Science Foundation of China(grant numbers:U23B2022,U22A2030); Guangdong Major Project of Basic and Applied Basic Research(grant numbers:2023B0303000010); Major Key Project of PCL(grant numbers:PCL2023A05);";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10814697;"Deepfake detection;vision transformer;graph diffusion learning";"Deepfakes;Spatiotemporal phenomena;Forgery;Electronics packaging;Transformers;Feature extraction;Optical flow;Robustness;Nickel;Image color analysis";;1;;61;IEEE;25 Dec 2024;2025;;IEEE;IEEE Journals
Deepfake Detection Using Robust Spatial and Temporal Features from Facial Landmarks;"M. Li; B. Liu; Y. Hu; L. Zhang; S. Wang";"South China University of Technology, Guangzhou, China; South China University of Technology, Guangzhou, China; South China University of Technology, Guangzhou, China; GRGBanking, Guangzhou, China; City University of Hong Kong, Hong Kong, China";2021 IEEE International Workshop on Biometrics and Forensics (IWBF);29 Jun 2021;2021;;;1;6;Most current deepfake detectors may suffer the decrease of detection accuracy under common video processing like compression. To deal with this issue, we proposed a new way of using biometric features for robust deepfake detection. Our biometric features are derived from a set of selected facial landmarks. We first presented a metric to select robust facial landmarks, and then constructed facial feature vectors with the selected landmarks. The spatial angles and the temporal rotation angles are introduced to facilitate the construction of the SVM feature vector. In essence, we use the spatial angles and temporal rotation angles to characterize the inherent consistency of facial landmarks at both frame level and video level. Experimental results have demonstrated that our detector has the best robustness compared with 6 current methods. It also has good scores in AUC (Area Under the Receiver Operating Characteristic Curve) and detection accuracy.;;978-1-7281-9556-8;10.1109/IWBF50991.2021.9465076;"Research and Development; Fundamental Research Funds for the Central Universities; ";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9465076;"Deepfake detection;Facial landmarks;Spatial features;Temporal features;Robustness";"Support vector machines;Measurement;Biometrics (access control);Forensics;Detectors;Receivers;Feature extraction";;13;;15;IEEE;29 Jun 2021;6-7 May 2021;6-7 May 2021;IEEE;IEEE Conferences
Emergent Capability in Audio Deepfake Detection;"Y. Deng; A. Laprevotte; R. Dunn; P. Khorrami; C. Dagli; P. Torres-Carrasquillo";"MIT Lincoln Laboratory, Lexington, MA, USA; California Institute of Technology, Pasadena, CA, USA; MIT Lincoln Laboratory, Lexington, MA, USA; MIT Lincoln Laboratory, Lexington, MA, USA; MIT Lincoln Laboratory, Lexington, MA, USA; MIT Lincoln Laboratory, Lexington, MA, USA";2025 13th International Workshop on Biometrics and Forensics (IWBF);15 Aug 2025;2025;;;1;6;Given the latest advances in generative AI, the quality of synthetic and cloned voice has improved dramatically. With the release of many generative AI tools to the open-source domain, the generation of high-quality voice targeted toward a particular person is widely accessible to the public. This is becoming a significant AI security issue. While many existing works have shown good detection accuracy on a particular dataset, models trained on a particular dataset often generalize poorly to new datasets, which sometimes results in close to random performance on new datasets. This work is motivated by the recent advances in AI, such as large language models, where a model shows emergent generalization capability to new datasets by having a very large training dataset. By collecting deepfake detection datasets from the public domain, enhanced by in-house automatic synthetic speech data generation, we built one of the largest deepfake detection datasets, in terms of Text-to-Speech (TTS) algorithm coverage. Our evaluation shows models trained on our large training sets exhibit emergent generalization capability toward out-of-domain, In-the-Wild, and an unforeseen newly-published TTS systems. Our system reduced baseline equal error rate (EER) by over an order of magnitude on unforeseen TTS data test.;;979-8-3315-3715-9;10.1109/IWBF63717.2025.11113428;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11113428;"Audio deepfake;deepfake detection;Text to Speech (TTS);Voice Conversion (VC);deepfake detection generalization";"Training;Deepfakes;Generative AI;Error analysis;Large language models;Forensics;Conferences;Data collection;Text to speech;Security";;;;36;IEEE;15 Aug 2025;24-25 April 2025;24-25 April 2025;IEEE;IEEE Conferences
Masked Relation Learning for DeepFake Detection;"Z. Yang; J. Liang; Y. Xu; X. -Y. Zhang; R. He";"Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Center for Research on Intelligent Perception and Computing, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Center for Research on Intelligent Perception and Computing, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Center for Research on Intelligent Perception and Computing, Institute of Automation, Chinese Academy of Sciences, Beijing, China";IEEE Transactions on Information Forensics and Security;6 Mar 2023;2023;18;;1696;1708;DeepFake detection aims to differentiate falsified faces from real ones. Most approaches formulate it as a binary classification problem by solely mining the local artifacts and inconsistencies of face forgery, which neglect the relation across local regions. Although several recent works explore local relation learning for DeepFake detection, they overlook the propagation of relational information and lead to limited performance gains. To address these issues, this paper provides a new perspective by formulating DeepFake detection as a graph classification problem, in which each facial region corresponds to a vertex. But relational information with large redundancy hinders the expressiveness of graphs. Inspired by the success of masked modeling, we propose Masked Relation Learning which decreases the redundancy to learn informative relational features. Specifically, a spatiotemporal attention module is exploited to learn the attention features of multiple facial regions. A relation learning module masks partial correlations between regions to reduce redundancy and then propagates the relational information across regions to capture the irregularity from a global view of the graph. We empirically discover that a moderate masking rate (e.g., 50%) brings the best performance gain. Experiments verify the effectiveness of Masked Relation Learning and demonstrate that our approach outperforms the state of the art by 2% AUC on the cross-dataset DeepFake video detection. Code will be available at https://github.com/zimyang/MaskRelation.;1556-6021;;10.1109/TIFS.2023.3249566;"National Natural Science Foundation of China(grant numbers:U2003111,U21B2045,62276256); Beijing Nova Program(grant numbers:Z211100002121108); Chinese Association for Artificial Intelligence (CAAI)-Huawei MindSpore Open Fund;";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10054130;"Multimedia forensics;DeepFake detection;masked learning;relation feature";"Deepfakes;Faces;Feature extraction;Forgery;Image edge detection;Correlation;Visualization";;93;;94;IEEE;27 Feb 2023;2023;;IEEE;IEEE Journals
Capsule Networks and LSTM Models for Robust Deepfake Detection in Audio and Video;"A. M. B.; J. W. Kathrine; S. Kushmitha";"Department of Computer Science and Engineering, Karunya Institute of Technology and Sciences, Coimbatore, India; Department of Computer Science and Engineering, Karunya Institute of Technology and Sciences, Coimbatore, India; Department of Computer Science and Engineering, Karunya Institute of Technology and Sciences, Coimbatore, India";2024 International Conference on IoT Based Control Networks and Intelligent Systems (ICICNIS);10 Jan 2025;2024;;;1569;1576;Due to the fast advancement of deepfakes, notable difficulties have been presented by deepfake innovation in confirming the believability of computerized content, especially on the audio and video front. This paper introduces a new hierarchical model that articulates Capsule Networks within LSTM for the effective and robust deepfake detection in both audio-video frameworks. It is argued that using Capsule Networks, spatial mindfulness capabilities enable the detection of subtle spatial objects in video outlines, whereas, LSTM models capture transient objects in audio arrangements and video frames over time. Thus, our approach implements two designs at once that reached progressed discovery accuracy, addressing spatial and temporary disorders, inherent in deepfake media. It is discovered from the outcomes that this model is very much effective on several datasets suggesting its better generalizing capability in different types of Deepfake media. In its current form, the design of this approach seems capable of being used for the real-time detection task. In this regard, this research provides practical insights into the development of media forensics offering an approach that can be more effective in the role of dissemination of fake news prevention, and fills the gap in the current literature, thus advancing the overall understanding of media forensics.;;979-8-3315-1809-7;10.1109/ICICNIS64247.2024.10823109;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10823109;"Deepfake Detection;Capsule Networks;LSTM Networks;Audio Deepfake;Video Deepfake;Face-Swapping;Voice Synthesis;Data Pre-processing;Feature Extraction;Sequence Analysis;Audio Pre-processing;Video Frame Extraction;Digital Content Authenticity;Long-Term Memory;Face and Voice Manipulation";"Deepfakes;Technological innovation;Social networking (online);Computational modeling;Forensics;Streaming media;Transformers;Real-time systems;Transient analysis;Long short term memory";;;;15;IEEE;10 Jan 2025;17-18 Dec. 2024;17-18 Dec. 2024;IEEE;IEEE Conferences
XLSR-Mamba: A Dual-Column Bidirectional State Space Model for Spoofing Attack Detection;"Y. Xiao; R. K. Das";"Fortemedia, Singapore; Fortemedia, Singapore";IEEE Signal Processing Letters;26 Mar 2025;2025;32;;1276;1280;Transformers and their variants have achieved great success in speech processing. However, their multi-head self-attention mechanism is computationally expensive. Therefore, one novel selective state space model, Mamba, has been proposed as an alternative. Building on its success in automatic speech recognition, we apply Mamba for spoofing attack detection. Mamba is well-suited for this task as it can capture the artifacts in spoofed speech signals by handling long-length sequences. However, Mamba's performance may suffer when it is trained with limited labeled data. To mitigate this, we propose combining a new structure of Mamba based on a dual-column architecture with self-supervised learning, using the pre-trained wav2vec 2.0 model. The experiments show that our proposed approach achieves competitive results and faster inference on the ASVspoof 2021 LA and DF datasets, and on the more challenging In-the-Wild dataset, it emerges as the strongest candidate for spoofing attack detection.;1558-2361;;10.1109/LSP.2025.3547861;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10909468;"Mamba;state space model;anti-spoofing;spoofing attack detection;deepfake detection";"Computational modeling;Training;Transformers;Convolution;Feature extraction;Predictive models;Measurement;Attention mechanisms;Speech recognition;Speech enhancement";;12;;37;IEEE;4 Mar 2025;2025;;IEEE;IEEE Journals
Deepfake detection based on Spatio-Temporal Fusion;"T. Chen; J. Hu; S. Yang";"College of Computer Science & Technology, Chengdu University of Information Technology, Chengdu, China; College of Computer Science & Technology, Chengdu University of Information Technology, Chengdu, China; College of Computer Science & Technology, Chengdu University of Information Technology, Chengdu, China";2025 International Conference on Information Management and Computing Technology (ICIMCT);8 Oct 2025;2025;;;77;82;To address the limitations of existing detection algorithms that utilize temporal information but are weak in extracting local information of forged traces, this paper introduces a detection algorithm for forged faces which based on spatiotemporal feature fusion. The algorithm comprises a spatial-frequency domain hybrid feature enhancement module and a frequency-aware dynamic gating unit module. Through the frequency domain, the high-frequency components of forged traces are enhanced to capture the global spatial and local frequency-domain cues. Subsequently, the frequency-aware dynamic gating unit is employed to amplify subtle cues in the temporal dimension that are difficult to discern. These cues from both dimensions are then integrated through an information fusion module to obtain a more comprehensive feature representation. Experimental results demonstrate that the proposed algorithm exhibits superior generalization performance on datasets in the forged domain.;;979-8-3315-8501-3;10.1109/ICIMCT.2025.00024;"China Meteorological Administration; ";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11185707;"deepfake detection;Feature Enhancement;Spatiotemporal Feature Fusion";"Deepfakes;Heuristic algorithms;Frequency-domain analysis;Computational modeling;Logic gates;Feature extraction;Robustness;Spatiotemporal phenomena;Information management;Detection algorithms";;;;46;IEEE;8 Oct 2025;9-11 May 2025;9-11 May 2025;IEEE;IEEE Conferences
ForgeryDetect: AI-driven Deep Fake Identification;"A. Bharti; V. K. Sinha; J. S. P. Peter; P. E. B";"Department of Computer Science and Engineering, SRMIST, Chennai, India; Department of Computer Science and Engineering, SRMIST, Chennai, India; Department of Computer Science and Engineering, SRMIST, Chennai, India; Department of Mechatronics, SRMIST, Chennai, India";2024 International Conference on Recent Innovation in Smart and Sustainable Technology (ICRISST);20 Mar 2025;2024;;;1;5;The rise of deepfake videos presents substantial obstacles in guaranteeing the genuineness and reliability of visual media material. This study focuses on the crucial problem of identifying deepfake content by introducing a sophisticated method that combines ResNext CNNs along with LSTM models, utilizing transfer learning approaches. Employed a comprehensive approach by using a wide array of datasets such as FaceForensics++, Celeb-DF, and the Deepfake Detection Challenge. Utilizing transfer learning, a ResNext CNN that has been pre-trained is employed to extract complex features from video frames. This enables the subsequent training of an LSTM layer to identify temporal patterns and distinctive cues that are exclusive to modified videos. The effectiveness of fusion model has been demonstrated through extensive experimentation and validation on these rich datasets. It demonstrates a strong ability to reliably distinguish between authentic and manipulated movies, regardless of the different facial alteration techniques, environmental variables, and complex situations seen in real-life situations. The integration of ResNext-based feature extraction with LSTM-based temporal modeling shows substantial progress in the detection of deepfake videos. The efficacy of approach is highly promising, since it provides both dependability and scalability. This study makes a significant contribution to the field of deepfake identification by offering a powerful collection of techniques to tackle the growing concerns surrounding disinformation and manipulation in visual media.;;979-8-3503-0914-0;10.1109/ICRISST59181.2024.10922001;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10922001;"Deepfake detection;ResNext;LSTM;Transfer learning;Video manipulation;FaceForensics++;Celeb-DF;Deepfake Detection Challenge;Convolutional neural networks (CNNs);long short-term memory (LSTM)";"Training;Deepfakes;Visualization;Technological innovation;Scalability;Transfer learning;Feature extraction;Motion pictures;Convolutional neural networks;Long short term memory";;;;15;IEEE;20 Mar 2025;15-16 March 2024;15-16 March 2024;IEEE;IEEE Conferences
Enhancing Deepfake Video Detection: A Hybrid CNN-LSTM Approach;"D. Singh; P. Singh; R. Bhandari";"Chandigarh University, India; Chandigarh University, India; Chandigarh University, India";2024 First International Conference on Technological Innovations and Advance Computing (TIACOMP);10 Jul 2025;2024;;;130;135;Deepfake progress exhibits serious issue to the existing of digital data by generating hyper-realistic videos wich are fake. This work offers a combined Deep Learning (DL) model that utilises Convolutional Neural Networks (CNNs) along with Long Short-Term Memory Networks (LSTMs) to detect and analyse deepfakes videos. CNNs get spatial characteristics from different frames, meanwhile LSTMs showcases temporal connections among frames. This paper tackles the alarming problem of deepfake technique's danger to authenticity of digital media by suggesting a strong solution. This work presents combined DL model, which combines CNNs and LSTMs, captures spatial and temporal variations in video data accurately, allowing for exact deepfake identification. This model performs exceptionally well on actual and fake video datasets, with a precision of 0.67, F1 score of 0.80 and recall of 1.00. Using both spatial and temporal clues, this technique provides a strong defence against the spread of altered material in digital domains. Future endeavours will prioritise dataset extension and model refining to ensure greater applicability and accuracy for deepfake detection attempts.;;979-8-3503-9211-1;10.1109/TIACOMP64125.2024.00031;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10742777;"CNNs;Video analysis;Spatial-temporal features;Machine learning;Digital media integrity;Neural network fusion;LSTMs;Deepfake detection;Misinformation detection";"Deep learning;Deepfakes;Technological innovation;Computational modeling;Refining;Media;Feature extraction;Data models;Convolutional neural networks;Long short term memory";;3;;;IEEE;10 Jul 2025;29-30 June 2024;29-30 June 2024;IEEE;IEEE Conferences
Fighting Malicious Media Data: A Survey on Tampering Detection and Deepfake Detection;"J. Wang; Z. Li; C. Zhang; J. Chen; Z. Wu; L. S. Davis; Y. -G. Jiang";"Institute of Trustworthy Embodied AI, Fudan University, Shanghai, China; Institute of Trustworthy Embodied AI, Fudan University, Shanghai, China; Institute of Trustworthy Embodied AI, Fudan University, Shanghai, China; Institute of Trustworthy Embodied AI, Fudan University, Shanghai, China; Institute of Trustworthy Embodied AI, Fudan University, Shanghai, China; Center for Automation Research, University of Maryland, College Park, MD, USA; Institute of Trustworthy Embodied AI, Fudan University, Shanghai, China";Proceedings of the IEEE;28 Jul 2025;2025;113;3;287;311;Online media data, in the form of images and videos, are becoming mainstream communication channels. However, recent advances in deep learning (DL), particularly deep generative models, open the doors for producing perceptually convincing images and videos at a low cost, which not only poses a serious threat to the trustworthiness of digital information but also has severe societal implications. This motivates a growing interest in research in media tampering detection (TD), i.e., using DL techniques to examine whether media data have been maliciously manipulated. Depending on the content of the targeted images, media forgery could be divided into image tampering and Deepfake techniques. The former typically moves or erases the visual elements in ordinary images, while the latter manipulates the expressions and even the identity of human faces. Accordingly, the means of defense include image TD and Deepfake detection (DFD), which share a wide variety of properties. In this article, we provide a comprehensive review of the current media TD approaches and discuss the challenges and trends in this field for future research.;1558-2256;;10.1109/JPROC.2025.3576367;"National Natural Science Foundation of Project(grant numbers:62072116);";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11048678;"Deepfake detection (DFD);media forensics;tampering detection (TD)";"Media;Deepfakes;Surveys;Forgery;Forensics;Visualization;Training;Fake news;Social networking (online);Information integrity";;;;384;IEEE;23 Jun 2025;March 2025;;IEEE;IEEE Journals
ExplaNET: A Descriptive Framework for Detecting Deepfakes With Interpretable Prototypes;"F. Khalid; A. Javed; K. M. Malik; A. Irtaza";"Faculty of Computer Science and Engineering, GIK Institute of Engineering Sciences and Technology, Topi, Pakistan; Department of Software Engineering, University of Engineering and Technology-Taxila, Taxila, Pakistan; College of Innovation and Technology, University of Michigan-Flint, Flint, MI, USA; Department of Computer Science, University of Engineering and Technology-Taxila, Taxila, Pakistan";IEEE Transactions on Biometrics, Behavior, and Identity Science;25 Nov 2024;2024;6;4;486;497;The emergence of deepfake videos presents a significant challenge to the integrity of visual content, with potential implications for public opinion manipulation, deception of individuals or groups, and defamation, among other concerns. Traditional methods for detecting deepfakes rely on deep learning models, lacking transparency and interpretability. To instill confidence in AI-based deepfake detection among forensic experts, we introduce a novel method called ExplaNET, which utilizes interpretable and explainable prototypes to detect deepfakes. By employing prototype-based learning, we generate a collection of representative images that encapsulate the essential characteristics of both real and deepfake images. These prototypes are then used to explain the decision-making process of our model, offering insights into the key features crucial for deepfake detection. Subsequently, we utilize these prototypes to train a classification model that achieves both accuracy and interpretability in deepfake detection. We also employ the Grad-CAM technique to generate heatmaps, highlighting the image regions contributing most significantly to the decision-making process. Through experiments conducted on datasets like FaceForensics++, Celeb-DF, and DFDC-P, our method demonstrates superior performance compared to state-of-the-art techniques in deepfake detection. Furthermore, the interpretability and explainability intrinsic to our method enhance its trustworthiness among forensic experts, owing to the transparency of our model.;2637-6407;;10.1109/TBIOM.2024.3407650;"Punjab Higher Education Commission (PHEC) Pakistan(grant numbers:PHEC/ARA/PIRCA/20527/21); National Science Foundation (NSF)(grant numbers:2231619); Michigan Transnational Research and Commercialization (MTRAC), Advanced Computing Technologies (ACT)(grant numbers:292883);";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10542403;"Deepfakes detection;DFDC;ExplaNET;explainability;FaceForensics++;interpretability;prototype learning;xAI";"Deepfakes;Prototypes;Feature extraction;Decision making;Biometrics (access control);Explainable AI;Deep learning";;8;;20;IEEE;30 May 2024;Oct. 2024;;IEEE;IEEE Journals
Deepfake Video Detection by Combining Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN);"Y. Al-Dhabi; S. Zhang";"College of Software, Northeastern University, Shenyang, Liaoning, China; College of Software, Northeastern University, Shenyang, Liaoning, China";2021 IEEE International Conference on Computer Science, Artificial Intelligence and Electronic Engineering (CSAIEE);4 Oct 2021;2021;;;236;241;Nowadays, people are facing an emerging problem called deepfake videos. These videos were created using deep learning technology. Some are created just for fun, while others are trying to manipulate your opinions, cause threats to your privacy, reputation, and so on. Sometimes, deepfake videos created using the latest algorithms can be hard to distinguish with the naked eye. That's why we need better algorithms to detect deepfake. The system we are going to present is based on a combination of CNN and RNN, as research shows that using CNN and RNN combined achieve better results. We are going to use a pre-trained CNN model called Resnext50. Using this, we save the time of training the model from scratch. The proposed system uses Resnext pretrained model for Feature Extraction and these extracted features are used to train the Long short-term memory (LSTM). Using CNN and RNN combined, we capture the inter frames as well as intra frames features which will be used to detect if the video is real or fake. We evaluated our method using a large collection of deepfake videos gathered from a variety of distribution sources. We demonstrate how our system may obtain competitive results while utilizing a simplistic architecture.;;978-1-6654-2204-8;10.1109/CSAIEE54046.2021.9543264;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9543264;"Deep learning;Deepfake Detection;convolutional Neural Network (CNN);Recurrent Neural Network (RNN)";"Training;Privacy;Recurrent neural networks;Computer architecture;Feature extraction;Solids;Convolutional neural networks";;38;;23;IEEE;4 Oct 2021;20-22 Aug. 2021;20-22 Aug. 2021;IEEE;IEEE Conferences
Content-Invariant Spatio-Temporal Neural Framework for Forgery Detection in Image Sequences;"V. Buzovsky; J. Prinosil; K. Riha; Z. Smekal";"Dept. of Telecommunications, FEEC Brno University of Technology, Brno, Czech Republic; Dept. of Telecommunications, FEEC Brno University of Technology, Brno, Czech Republic; Dept. of Telecommunications, FEEC Brno University of Technology, Brno, Czech Republic; Dept. of Telecommunications, FEEC Brno University of Technology, Brno, Czech Republic";2025 17th International Congress on Ultra Modern Telecommunications and Control Systems and Workshops (ICUMT);3 Dec 2025;2025;;;240;245;The increasing prevalence of deepfake videos underscores the need for effective and reliable detection methods. In this study, we propose a hybrid deepfake detection framework that integrates a static image forgery detector with a recurrent neural network (RNN) to exploit both spatial and temporal features. Specifically, we utilize an existing frame-level detector that identifies common forgery artifacts within individual frames. This is followed by a Long Short-Term Memory (LSTM) network that models temporal dependencies across frames, enabling detection of inconsistencies that are overlooked in frame-by-frame analysis. Experimental results demonstrate that temporal modeling significantly improves accuracy over frame-level baselines. Our contributions are twofold: (i) we provide empirical evidence that deepfake videos exhibit detectable temporal signatures, and (ii) we construct a compact, real-world evaluation set of deepfake videos. Notably, detection performance on this dataset is lower than on standard benchmarks, suggesting a domain gap between commonly used training data and real-world deepfakes.;2157-023X;979-8-3315-7675-2;10.1109/ICUMT67815.2025.11268794;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11268794;"deepfake detection;computer vision;spatiotemporal features;recurrent neural networks;image manipulation";"Deepfakes;Recurrent neural networks;Training data;Detectors;Feature extraction;Forgery;Telecommunications;Telecommunication network reliability;Long short term memory;Standards";;;;19;IEEE;3 Dec 2025;3-5 Nov. 2025;3-5 Nov. 2025;IEEE;IEEE Conferences
Research on Real-Time Deepfake Image Detection System Based on a Self-Supervised Learning Framework;"Z. Guo; Z. Li; Y. Peng; X. Kong";"School of Computer Science and Technology, Xinjiang University, Urumqi, China; School of Computer Science and Technology, Xinjiang University, Urumqi, China; School of Computer Science and Technology, Xinjiang University, Urumqi, China; School of Computer Science and Technology, Xinjiang University, Urumqi, China";2024 6th International Academic Exchange Conference on Science and Technology Innovation (IAECST);21 Aug 2025;2024;;;631;634;The rapid evolution of deepfake technology raises significant security and ethical concerns, as its potential misuse could lead to the spread of disinformation. In this study, we propose an advanced real-time deepfake image detection system based on a self-supervised learning framework. The model is based on the most advanced visual transformers (ViTs) and integrates contrastive representation learning in order to effectively distinguish between manipulated content and real images. Furthermore, we have incorporated a temporal consistency module that leverages subtle temporal artefacts to enhance the precision of detection, particularly in video frame sequences. The architectural design is devised to capture spatial and temporal anomalies, thereby ensuring robust detection performance in real-time scenarios. The experimental outcomes on benchmark datasets of Celeb-DF demonstrate that the proposed model exhibits a notable superiority to the existing deepfake detection methods in terms of accuracy and efficiency.;;979-8-3315-0713-8;10.1109/IAECST64597.2024.11118130;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11118130;"Deepfake detection;self-supervised learning;Visual Transformers;Contrast means learning";"Representation learning;Deepfakes;Visualization;Technological innovation;Self-supervised learning;Transformers;Real-time systems;Calibration;Security;Reliability";;;;10;IEEE;21 Aug 2025;6-8 Dec. 2024;6-8 Dec. 2024;IEEE;IEEE Conferences
Model-Agnostic Method: Exposing Deepfake Using Pixel-Wise Spatial and Temporal Fingerprints;"J. Yang; Y. Sun; M. Mao; L. Bai; S. Zhang; F. Wang";"Department of Computer Science and Technology, Tongji University, Shanghai, China; Department of Computer Science and Technology, Tongji University, Shanghai, China; Department of Computer Science and Technology, Tongji University, Shanghai, China; Department of Computer Science and Technology, Tongji University, Shanghai, China; Department of Computer Science and Technology, Tongji University, Shanghai, China; Department of Computer Science, Brunel University, Uxbridge, U.K.";IEEE Transactions on Big Data;10 Nov 2023;2023;9;6;1496;1509;Deepfake poses a serious threat to the reliability of judicial evidence and intellectual property protection. Existing detection methods either blindly utilize deep learning or use biosignal features, but neither considers spatial and temporal relevance of face features. These methods are increasingly unable to resist the growing realism of fake videos and lack generalization. In this paper, we identify a reliable fingerprint through the consistency of AR coefficients and extend the original PPG signal to 3-dimensional fingerprints to effectively detect fake content. Using these reliable fingerprints, we propose a novel model-agnostic method to expose Deepfake by analyzing temporal and spatial faint synthetic signals hidden in portrait videos. Specifically, our method extracts two types of faint information, i.e., PPG features and AR features, which are used as the basis for forensics in temporal and spatial domains, respectively. PPG allows remote estimation of the heart rate in face videos, and irregular heart rate fluctuations expose traces of tampering. AR coefficients reflect pixel-wise correlation and spatial traces of smoothing caused by up-sampling in the process of generating fake faces. Furthermore, we employ two ACBlock-based DenseNets as classifiers. Our method provides state-of-the-art performance on multiple deep forgery datasets and demonstrates better generalization.;2332-7790;;10.1109/TBDATA.2023.3284272;"National Key R&D Program of China(grant numbers:2019YFC1906201); National Natural Science Foundation of China(grant numbers:91748122); Xianyang Key R&D Program(grant numbers:S2021ZDYF-SF-0739); China Scholarship Council;";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10146470;"Auto-regressive (AR);deep learning;deepfake detection;fingerprint;photoplethysmography (PPG);temporal and spatial";"Fingerprint recognition;Feature extraction;Faces;Deepfakes;Heart rate;Biological system modeling;Skin";;9;;63;IEEE;8 Jun 2023;Dec. 2023;;IEEE;IEEE Journals
Enhancing Accuracy in Image Recognition for Deepfaked Images using Convolutional Networks Compared with LSTM Algorithm;"C. A. S; S. R; S. Krishnan";"Department of Computer Science and Engineering, Saveetha School of Engineering, Saveetha Institute of Medical and Technical Science, Chennai, India; Department of Computer Science and Engineering, Saveetha School of Engineering, Saveetha Institute of Medical and Technical Science, Chennai, India; Department of Computer Science and Engineering, Saveetha School of Engineering, Saveetha Institute of Medical and Technical Science, Chennai, Tamilnadu";2025 7th International Conference on Innovative Data Communication Technologies and Application (ICIDCA);16 Dec 2025;2025;;;1868;1873;The rapid development of deepfake technologies has brought serious questions about the authenticity of digital content and the creation of effective detection tools is required. The proposed study will increase the precision of deepfake image recognition by comparing the results of Convolutional Neural Networks (CNNs) with Long Short-Term Memory (LSTM) algorithms. A Kaggle dataset of real and synthetically generated deepfake images under different conditions was used as a training and evaluation dataset. Two experimental groups were created, Group 1 used CNNs and Group 2 used LSTM models, and 20 samples in each group (N = 40). A priori evaluation by ClinCalc.com determined an 80 percent statistical power, which meets the behavioral science significance (0.05, 0.2) criteria. The outcome showed that CNNs had a higher accuracy of 97.15 that was much higher in comparison to the LSTM model that had 57.33. Statistical significance was confirmed by a two-tailed significance test (p = 0.001, p < 0.05), which revealed the higher ability of CNNs to extract and analyze visual features to detect deepfakes. Such results highlight the potential of CNNs to detect manipulated images and serve as a basis to develop more resistant and dependable deepfake detectors based on the state- of-the-art feature extraction and transfer learning methods.;;979-8-3315-1414-3;10.1109/ICIDCA66325.2025.11280513;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11280513;"Deepfake Detection;Image Recognition;Convolutional Neural Networks (CNN);LSTM Algorithm;Accuracy Improvement;Transfer Learning;Adversarial Attack";"Resistance;Training;Deepfakes;Visualization;Accuracy;Image recognition;Transfer learning;Feature extraction;Convolutional neural networks;Long short term memory";;;;20;IEEE;16 Dec 2025;6-8 Oct. 2025;6-8 Oct. 2025;IEEE;IEEE Conferences
A Hybrid MobileNet-LSTM Model for Enhanced Detection of Deepfake Media in Real-Time Image and Video Analysis;"N. Subhasri; M. Gangadhar; M. Divakar; N. E. Bhanu Chandra Goud; M. Ramaraju; K. Sreenivasulu";"Department of Computer Applications, SREC, Nandyal, AP, India; Department of Computer Applications, SREC, Nandyal, AP, India; Department of Computer Applications, SREC, Nandyal, AP, India; Department of Computer Applications, SREC, Nandyal, AP, India; Department of Computer Applications, SREC, Nandyal, AP, India; Department of Computer Applications, SREC, Nandyal, AP, India";2025 5th International Conference on Expert Clouds and Applications (ICOECA);13 Aug 2025;2025;;;1099;1106;Deepfakes, or Al-generated manipulated media, pose a significant threat to media integrity, privacy, and public trust. Detecting deepfakes effectively remains a challenge due to their increasingly sophisticated nature. This research addresses the issue of detecting both spatial and temporal inconsistencies in deepfake images and videos by proposing a hybrid MobileNet-LSTM model. The MobileNet component extracts spatial features such as texture anomalies and facial misalignments, while the LSTM component analyzes temporal dependencies to identify inconsistencies in video sequences, such as unnatural facial expressions or motion patterns. The hybrid model is trained on a large and diverse dataset of real and deepfake media, ensuring its adaptability to emerging deepfake techniques. The outcome of this research is a highly accurate, real-time deepfake detection system that performs with an accuracy of 91.8%, achieving improved precision (89.4%), recall (90.5%), and F1-score (89.9%) compared to existing baseline models. The model’s lightweight design ensures real-time performance, making it suitable for deployment in social media monitoring, digital forensics, and law enforcement. This work contributes to the ongoing efforts in combating misinformation and enhancing digital media authenticity by providing a scalable and efficient deepfake detection solution.;;979-8-3315-2447-0;10.1109/ICOECA66273.2025.00188;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11113971;"Media integrity;real-time detection;temporal modeling;image analysis;video analysis;mobilenet lstm;real time detection;deepfake detection";"Deepfakes;Adaptation models;Analytical models;Privacy;Accuracy;Social networking (online);Video sequences;Media;Feature extraction;Real-time systems";;;;20;IEEE;13 Aug 2025;6-7 March 2025;6-7 March 2025;IEEE;IEEE Conferences
Advancements in Deepfake Detection: A Comprehensive Review of AI-Driven Approaches;"D. L. R; B. B. Sujitha";"Department of Computer Science and Engineering, Noorul Islam Centre for Higher Education, Tamil Nadu, India; Department of Computer Science and Engineering, Noorul Islam Centre for Higher Education, Tamil Nadu, India";2025 International Conference on Machine Learning and Autonomous Systems (ICMLAS);25 Apr 2025;2025;;;1007;1011;The significant developments in artificial neural network (ANN)-based technologies are crucial for manipulating multimedia content. Although technology has predominantly been used for purposes, such as education, some individuals have exploited it for unlawful or harmful activities. This literature review offers a comprehensive analysis of the advancements in deepfake detection. This study explores state-of-the-art approaches, including convolutional neural network (CNNs), transformers, ensemble model, and binary neural network, that leverage both spatial and temporal feature for effective detection. In addition, the review examines the role of data augmentation, artifact attention, and multi-modal analysis in enhancing detection accuracy across diverse datasets. By analyzing current methodologies and evaluating their strengths and limitations, this paper provides insights into the evolving landscape of deepfake detection by analyzing current methodologies and highlights key challenges such as the need for robust datasets and cross-domain generalization. Future directions are also outlined, emphasizing the potential of self-supervised learning, ensemble approaches, and advancements in artifact detection for more reliable and scalable solutions.;;979-8-3315-0574-5;10.1109/ICMLAS64557.2025.10967658;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10967658;"Deepfake detection;Deep Learning methods;Ensemble methods;Temporal and Local Consistency Detection;Machine Learning-Based Techniques";"Deep learning;Deepfakes;Privacy;Computational modeling;Self-supervised learning;Transformers;Ensemble learning;Reliability;Security;Systematic literature review";;1;;12;IEEE;25 Apr 2025;10-12 March 2025;10-12 March 2025;IEEE;IEEE Conferences
DeepGuard: A Hybrid CNN-LSTM Framework for Robust Deepfake Video Detection with Spatiotemporal Analysis;"M. A. Cyril; J. Prakash Sunkavalli; D. Prasanth";"Dept. of Information Technology, Velagapudi Ramakrishna Siddhartha Engineering COllege, Kanuru, India; Dept. of Information Technology, Velagapudi Ramakrishna Siddhartha Engineering COllege, Kanuru, India; Dept. of Information Technology, Velagapudi Ramakrishna Siddhartha Engineering COllege, Kanuru, India";2025 3rd International Conference on Sustainable Computing and Data Communication Systems (ICSCDS);24 Sep 2025;2025;;;2071;2076;Deepfake technology has developed very quickly, allowing highly realistic artificial media to be created that causes serious risks to privacy, security, and disinformation. This paper introduces a deep learning method for identifying deepfake videos by applying a hybrid Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) model. The proposed model takes advantage of spatial information learned by a CNN (Xception backbone) and temporal relationships learned by an LSTM in order to label videos as real or fake. The model was trained on the FaceForensics++ dataset and evaluated on the Celeb-DF dataset with an accuracy of 82%. A web application was also implemented for real-time deepfake detection. The outcome proves the efficacy of the suggested architecture in detecting manipulated videos with challenges and future enhancements;;979-8-3315-1250-7;10.1109/ICSCDS65426.2025.11166809;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11166809;"Deepfake detection;CNN-LSTM;FaceForensics++;Celeb-DF;Xception;Temporal modelin)";"Deep learning;Deepfakes;Privacy;Real-time systems;Data models;Spatiotemporal phenomena;Convolutional neural networks;Security;Data communication;Long short term memory";;;;16;IEEE;24 Sep 2025;6-8 Aug. 2025;6-8 Aug. 2025;IEEE;IEEE Conferences
Enhancing Deepfake Detection with a Hybrid CNN-BiLSTM Approach;"H. K. Verma; I. Kumar";"Department of Computer Science and Engineering, Dr. B.R Ambedkar National Institute of Technology, Jalandhar, India; Department of Computer Science and Engineering, Dr. B.R Ambedkar National Institute of Technology, Jalandhar, India";2024 11th International Conference on Soft Computing & Machine Intelligence (ISCMI);28 Jan 2025;2024;;;351;356;Rapid improvements in deepfake technology have created serious threats to the integrity of digital information. Deepfakes have the potential to be employed for intimidating or blackmailing specific public figures, as well as for deceiving the general public. Concurrently, the advancement in deepfake technology has led to notable progress in developing detection algorithms. Primarily, these algorithms concentrate on analyzing images rather than delving into the temporal progression within video content. In the information era of today, detecting deepfakes has become more important than ever. The paper posits a pioneering hybrid approach for detecting deepfake videos, combining the scrutiny of human eye blinking patterns, utilizing Xception image characteristics, and implementing a Bidirectional Long Short Term Memory network (Bi-LSTM). This methodology leverages Convolutional Neural Networks(CNN) to extract image attributes and Bi-LSTM networks to scrutinize sequences consecutively. Moreover, it utilizes an adaptive spatio-temporal attention mechanism to concentrate on pertinent frames in the video sequences. The dataset used for experimental purposes includes both authentic and artificially generated videos from the Celeb-DF dataset. The proposed framework attained an accuracy rate of 86% in classification with an area under curve of 0.90, showcasing its efficacy in the identification of deepfake videos.;2640-0146;979-8-3315-1812-7;10.1109/ISCMI63661.2024.10851512;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10851512;"Deepfake;Deep Learning;Xception;Facial Landmark Detection;Eye Blink;Bi-LSTM;Adaptive Spatio-Temporal Attention Network (ASTAN)";"Deepfakes;Attention mechanisms;Accuracy;Video sequences;Bidirectional long short term memory;Convolutional neural networks;Detection algorithms;Machine intelligence;Digital information";;;;34;IEEE;28 Jan 2025;22-23 Nov. 2024;22-23 Nov. 2024;IEEE;IEEE Conferences
Cascaded ResNet50-LSTM Architecture for Deepfake Video Identification;"J. Rout; M. Mishra";"P.G. Department of Computer Science, Fakir Mohan University, Balasore, Odisha, India; P.G. Department of Computer Science, Fakir Mohan University, Balasore, Odisha, India";2025 7th International Conference on Energy, Power and Environment (ICEPE);5 Sep 2025;2025;;;1;6;With the increasing sophistication of AI-generated content, detecting fake videos has become a critical challenge in digital media forensics. Such fake videos can cause loss to individuals and organizations in terms of fiscal matters, goodwill, societal status, etc. Traditional detection methods such as frame-by-frame analysis, motion inconsistencies, etc., were timeconsuming, subjective, and prone to human bias. This research presents a hybrid deep learning framework that combines Convolutional Neural Networks (CNNs) for spatial feature extraction with Long-Short-Term Memory (LSTM) networks for modeling temporal relationships. The proposed model is designed to efficiently differentiate between authentic and AI-generated videos by leveraging both spatial and sequential patterns within video frames. The model is trained and evaluated on the Celeb-DF (v2) dataset. The preprocessing phase involves frame extraction, resizing, and normalization to enhance feature representation. The experimental findings indicate that the proposed model delivers robust performance in the test set: 94. 98% accuracy, 98. 06% precision, 96. 08% recall, 97. 06% F1 score and 98. 32% AUC-ROC. Further evaluation using a confusion matrix and loss accuracy curves highlights the robustness of the model in detecting AI-generated content. This research contributes to improving deepfake detection techniques, ensuring improved security and reliability in multimedia authentication systems.;2832-8973;979-8-3315-9706-1;10.1109/ICEPE65965.2025.11139778;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11139778;"AI-Generated Video Detection;Deepfake Detection;Fake Video Identification;Forgery Detection;CNNs;LSTM";"Deepfakes;Accuracy;Multimedia systems;Organizations;Streaming media;Media;Feature extraction;Robustness;Security;Long short term memory";;;;25;IEEE;5 Sep 2025;9-11 May 2025;9-11 May 2025;IEEE;IEEE Conferences
Incorporating Psychological and Behavioral Cues for Enhanced Deepfake Detection;"P. Agrawal; A. Shaikh; K. Bajaj; J. Mahajan";"Dept. of Computer Technology, Pune Institute of Computer Technology, Pune, India; Dept. of Computer Technology, Pune Institute of Computer Technology, Pune, India; Dept. of Computer Technology, Pune Institute of Computer Technology, Pune, India; Dept. of Computer Technology, Pune Institute of Computer Technology, Pune, India";2025 4th OPJU International Technology Conference (OTCON) on Smart Computing for Innovation and Advancement in Industry 5.0;14 Jul 2025;2025;;;1;5;The growing challenge of detecting deepfakes as generative models continues to advance, making traditional detection methods based on spatial inconsistencies less effective. We aim to harness machine learning techniques to identify subtle human responses that deepfake algorithms find difficult to mimic. We review existing detection techniques, pinpoint gaps in current approaches, and demonstrate why emphasizing temporal features—those related to physiological and behavioral responses—can offer a more resilient solution than relying solely on spatial anomalies. Additionally, we propose an implementation for advanced deepfake detection using a combination of pre-trained CNN models and LSTM networks to analyze the spatial and temporal aspects of videos. We also provide insights for future developments in this proposed approach.;;979-8-3315-3536-0;10.1109/OTCON65728.2025.11071123;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11071123;"Deepfake Detection;Behavioral Analysis;Micro-expressions;Temporal Cues;Psychological Signals;Machine Learning;CNN;LSTM";"Deepfakes;Technological innovation;Accuracy;Sensitivity;Reviews;Psychology;Training data;Media;Feature extraction;Physiology";;;;8;IEEE;14 Jul 2025;9-11 April 2025;9-11 April 2025;IEEE;IEEE Conferences
AVT$^{2}$-DWF: Improving Deepfake Detection With Audio-Visual Fusion and Dynamic Weighting Strategies;"R. Wang; D. Ye; L. Tang; Y. Zhang; J. Deng";"Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, Wuhan, China; Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, Wuhan, China; Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, Wuhan, China; Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, Wuhan, China; Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, Wuhan, China";IEEE Signal Processing Letters;2 Aug 2024;2024;31;;1960;1964;With the continuous improvements of deepfake methods, forgery messages have transitioned from single-modality to multi-modal fusion, posing new challenges for existing forgery detection algorithms. In this letter, we propose AVT$^{2}$-DWF, the Audio-Visual dual Transformers grounded in Dynamic Weight Fusion, which aims to amplify both intra- and cross-modal forgery cues, thereby enhancing detection capabilities. AVT$^{2}$-DWF adopts a dual-stage approach to capture both spatial characteristics and temporal dynamics of facial expressions. This is achieved through a face transformer with an $n$-frame-wise tokenization strategy encoder and an audio transformer encoder. Subsequently, it uses multi-modal conversion with dynamic weight fusion to address the challenge of heterogeneous information fusion between audio and visual modalities. Experiments on DeepfakeTIMIT, FakeAVCeleb, and DFDC datasets indicate that AVT$^{2}$-DWF achieves state-of-the-art performance intra- and cross-dataset Deepfake detection.;1558-2361;;10.1109/LSP.2024.3433596;"National Natural Science Foundation of China(grant numbers:62072343,61932011); Fundamental Research Funds for the Central Universities(grant numbers:2042023kf0228); National Key Research and Development Program of China(grant numbers:2019QY(Y)0206);";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10609529;"Audio-visual;deepfake detection;dynamic weight fusion";"Feature extraction;Transformers;Visualization;Training;Faces;Deepfakes;Forgery";;18;;22;IEEE;25 Jul 2024;2024;;IEEE;IEEE Journals
Enhancing Deepfake Detection Through Hybrid MobileNet-LSTM Model with Real-Time Image and Video Analysis;"V. S. Anandhasivam; A. K. Anusri; M. Logeshwar; R. Gopinath";"Computer Science and Engineering, K. S. Rangasamy College of Technology, Tiruchengode, India; Computer Science and Engineering, K. S. Rangasamy College of Technology, Tiruchengode, India; Computer Science and Engineering, K. S. Rangasamy College of Technology, Tiruchengode, India; Computer Science and Engineering, K. S. Rangasamy College of Technology, Tiruchengode, India";2024 4th International Conference on Ubiquitous Computing and Intelligent Information Systems (ICUIS);13 Feb 2025;2024;;;1989;1995;The race to crush information integrity and public trust is being won by one thing: deepfakes, AI manipulated media. The goal is to enhance the Deepfake detection using MobileNet V3 and LSTM network. MobileNet's lightweight CNN architecture is able to induce the visual features in an image by an image and in a video and can pick up the slight visual clues of textures and facial structure. Some temporal inconsistencies that cannot be seen by image base methods are then analyzed using an LSTM network. The hybrid model is trained on real and deepfake media datasets, and is thus adaptable to emerging deepfake techniques. This has a user face interface to analyze the real time and fly media to get the analysis and analysis score and visual feedback of the identified artifacts. Unique to this system is its versatility for images and videos, and its real time capability, making it a suitable choice for practical use in social media, journalism, and law enforcement combating the spread of misinformation with a guarantee of digital media authenticity;;979-8-3315-2963-5;10.1109/ICUIS64676.2024.10867159;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10867159;"media integrity;real-time detection;temporal modeling;image analysis;video analysis;mobilenet-lstm;deepfake detection";"Deepfakes;Visualization;Analytical models;Adaptation models;Accuracy;Social networking (online);Media;Streaming media;Real-time systems;Long short term memory";;1;;19;IEEE;13 Feb 2025;12-13 Dec. 2024;12-13 Dec. 2024;IEEE;IEEE Conferences
Investigating voiced and unvoiced regions of speech for audio deepfake detection;"G. Sivaraman; H. Tak; E. Khoury";"Pindrop, Atlanta, USA; Pindrop, Atlanta, USA; Pindrop, Atlanta, USA";ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP);7 Mar 2025;2025;;;1;5;Deep neural network based deepfake detection systems have achieved high levels of accuracy on benchmark datasets and competitions. However, most models lack interpretability. It is challenging to extract reasoning from the network that can convince the human evaluator to trust the decision. Humans often rely on acoustic cues like unnatural pitch jitter, robotic intonation, acoustic artifacts, and unnatural sounding fricatives to judge the quality of the synthetic audio. This study explores the role played by the voiced and unvoiced regions of speech in discriminating synthetic from bonafide speech. A measure of signal periodicity is used to analyze speech into voiced and unvoiced components. Then, the graph attention based AASIST detection system is trained independently on each component. This work compares the accuracy of deepfake detection system using voiced and unvoiced components and analyzes the results on the MLAAD dataset. Our results show that unvoiced regions are particularly more effective in distinguishing synthetic (deepfake) speech from bonafide, and achieves an equal error rate of 6.62%. When combined with voice regions through score-level fusion, the overall performance improves further, yielding a 5.82% EER, a relative improvement of 49% over the baseline system that uses the full audio.;2379-190X;979-8-3503-6874-1;10.1109/ICASSP49660.2025.10890861;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10890861;"spoofing countermeasure;audio deepfake detection;unvoiced phones";"Deepfakes;Accuracy;Error analysis;Signal processing;Jitter;Benchmark testing;Acoustics;Cognition;Speech synthesis;Robots";;;;42;IEEE;7 Mar 2025;6-11 April 2025;6-11 April 2025;IEEE;IEEE Conferences
STC-CapsNet: Detecting Audio Deepfakes with Spatio-Temporal Convolutions and Capsule Networks;"T. M. Wani; S. A. A. Qadri; I. Amerini";"Sapienza University of Rome, Italy; National Tsing Hua University, Taiwan; Sapienza University of Rome, Italy";2025 IEEE Symposium on Computational Intelligence in Image, Signal Processing and Synthetic Media (CISM);8 Jul 2025;2025;;;1;7;Capsule networks are a powerful architecture designed to capture hierarchical relationships in data, making them effective for complex classification tasks. In audio deepfake detection, these networks effectively distinguish between real and synthetic audio by capturing subtle time and frequency patterns. Their ability to model intricate dependencies across both domains makes capsule networks especially suited for this challenging task. This study introduces the novel Spatio-Temporal Convolutional Capsule Network (STC-CapsNet), which utilizes mel-spectrograms and grayscale spectrograms for feature extraction. After preprocessing steps like noise reduction and segmentation, temporal and spectral convolutions are applied, followed by capsule layers with dynamic routing to enhance feature representation. The model is evaluated on the FoR dataset, achieving an F1-Score of 98.4% and a low EER of 2.8% using mel-spectrograms, outperforming grayscale spectrograms in both accuracy and error rate.;;979-8-3315-0835-7;10.1109/CISM64958.2025.11060861;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11060861;"Audio Deepfake Detection;Mel-spectrograms;Grayscale spectrogram;Spatio-Temporal Convolutional Capsule Network";"Deepfakes;Time-frequency analysis;Accuracy;Convolution;Noise reduction;Gray-scale;Media;Routing;Feature extraction;Spectrogram";;;;22;IEEE;8 Jul 2025;17-20 March 2025;17-20 March 2025;IEEE;IEEE Conferences
Video Normalization in Identifying Fake Videos Using a Long Short-Term Memory Model;"K. Thakkar; D. Lo";"Wheeler High School, Marietta, Georgia; Computer Science, Kennesaw State University, Marietta, Georgia";SoutheastCon 2023;8 May 2023;2023;;;266;270;As the misinformation crisis continues, it creates a generation more politically divided than ever before. One of the most concerning types of misinformation are Deepfake videos, which use Generative Adversarial Networks to replace an existing video with another person’s face. Deepfake videos can interfere with diplomatic relations, reduce trust in journalism, and can tamper with court video evidence, which is why it is imperative to detect these videos accurately. Long Short-Term Memory models (LSTMs) are a type of Recurrent Neural Network, meaning that they are able to remember sequential information, which is helpful for processing the frames of a video. LSTMs are special in that they can account for lags between frames of a video, which makes them perfect for Deepfake video detection. One of the potential ways to increase the accuracy of a neural network is normalization, which ensures the input data are on the same scale, so the machine has to process a lower range of data. Because the effect of normalization varies for each dataset, in this study, image normalization was used- each pixel of the frames of Deepfake videos were converted to an RGB value of 0 to 255 to see if this can increase the accuracy of the LSTM model for Deepfake detection. First, a baseline LSTM model was created for Deepfake detection with the Pytorch library, and a classification accuracy of 88.191% was achieved. After that, the first ten frames of the Deepfake videos in the dataset were passed through an image normalization algorithm. This yielded an accuracy of 94.274%, illustrating that the addition of a video normalization algorithm to Deepfake videos increased the accuracy of the Deepfake detection LSTM model by 6.083%. This is a substantial improvement, and the study showed that video normalization can be very beneficial for Deepfake video detection.;1558-058X;978-1-6654-7611-9;10.1109/SoutheastCon51012.2023.10115139;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10115139;"Deepfake Detection;Long Short-term Memory (LSTM);Video Normalization";"Deepfakes;Recurrent neural networks;Journalism;Generative adversarial networks;Libraries;Classification algorithms;Long short term memory";;4;;18;IEEE;8 May 2023;1-16 April 2023;1-16 April 2023;IEEE;IEEE Conferences
AI-Powered Real-Time Misinformation Detection a Deep Learning Framework for Combating Fake News and Deepfakes;"D. N. Rao; K. Mouneshwari; P. R. Kiran; Y. J. N. Kumar; A. Soy; T. Srihari";"Department of CSE, CMR Technical Campus, Hyderabad, Telangana, India; Department of Computer Science and Engineering, CMR Institute of Technology, Hyderabad; Department of ECE, CMR College of Engineering & Technology, CMR College of Engineering & Technology, Hyderabad; Department of Information Technology, Gokaraju Rangaraju Institute of Engineering and Technology, Hyderabad, Telangana, India; Department of CS & IT, Kalinga University, Raipur, India; Department of Electrical and Electronics Engineering, Saveetha Institute of Medical and Technical Sciences, Chennai, Tamilnadu, India";2025 International Conference on Metaverse and Current Trends in Computing (ICMCTC);17 Oct 2025;2025;;;1;4;The existing detection methods mostly rely on either text-based fact-checking or image/video processing but the performance in many cases was not in real-time and multimodal. The invention of this paper is Hybrid Multimodal Verification System (HMVS), an AI technology, that leverages Natural language processing (NLP), Computer vision, and blockchain technology to improve misinformation detection. For example, on the text analysis side, the framework uses transformer-based models, on the deepfake detection side, they use GAN fingerprinting and optical flow inconsistencies, and on the integrity side, a blockchain-powered, decentralized credibility ledger necessarily has to be there. An adaptive real-time fact-checking AI also creates and trains real-time detection models dynamically using reinforcement learning. One develops a novel truth ranking algorithm based on a credibility score for news sources based on past accuracy and propagation pathways. The system includes a user alert module with real-time misinformation warnings through browser extensions and mobile applications. It is empirically shown that HMVS significantly achieves in terms of accuracy, efficiency, and adversarial attack robustness over other methods. Thus, a scalable and transparent solution to curtail fake news and deepfakes can be provided through integration with deep learning over decentralized verification mechanisms. The study will be further extended to explore the designing of explainability and the method of reducing biases in the misinformation detection model.;;979-8-3315-3821-7;10.1109/ICMCTC62214.2025.11196119;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11196119;"Misinformation Detection;Deepfake Detection;AI;Blockchain;Fake News;Multimodal Verification;Explainable AI";"Deep learning;Deepfakes;Adaptation models;Accuracy;Explainable AI;Transformers;Real-time systems;Natural language processing;Browsers;Blockchains";;;;16;IEEE;17 Oct 2025;10-11 April 2025;10-11 April 2025;IEEE;IEEE Conferences
Enhanced Deepfake Detection with LSTM and ResNeXt Integration;"H. Singh; R. Kumar; M. Gupta; N. Y. Joshi";"Department of CSE, Chandigarh University, Mohali, India; Department of CSE, Chandigarh University, Mohali, India; Department of CSE, Chandigarh University, Mohali, India; Fiserv, Atlanta, Georgia, USA";2025 3rd International Conference on Disruptive Technologies (ICDT);13 May 2025;2025;;;783;787;Created from advanced artificial intelligence (AI), Deepfakes are privacy, security, and trust shattering to digital media needs. In this work, we propose a novel deepfake detection model based on ResNext followed by Long Short Term Memory (LSTM) networks to achieve extraction of spatial features and temporal sequence analysis, respectively. Our approach combines the strengths of the two architectures and minimizes the investment in model size by retaining only a small portion of that which is accurate. On the Celeb-DF (v2) dataset, our model reached a detection accuracy of 93.59%, beating baseline methods. The demonstrated robustness and reliability of the proposed method make it a promising method to fight deepfakes in real world situations.;;979-8-3315-1958-2;10.1109/ICDT63985.2025.10986702;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10986702;"Deepfake Detection;Convolutional Neural Network (CNN);Digital Deception;Image Manipulation;Artificial Intelligence (AI);Machine Learning;Multimedia Forensics;Video Analysis;Face Recognition;Image Authentication";"Deepfakes;Analytical models;Adaptation models;Accuracy;Computational modeling;Computer architecture;Feature extraction;Transformers;Convolutional neural networks;Long short term memory";;;;28;IEEE;13 May 2025;7-8 March 2025;7-8 March 2025;IEEE;IEEE Conferences
Audio Deepfake Detection: End-to-End training with powerful pretrained ASR;"K. H. Mansoor; M. Alam";"Fast School of Computing, National University of Computer and Emerging Sciences, Islamabad, Pakistan; Fast School of Computing, National University of Computer and Emerging Sciences, Islamabad, Pakistan";2024 26th International Multi-Topic Conference (INMIC);16 May 2025;2024;;;1;6;The advancements in audio deepfake generation raise significant concerns about its potential misuse, with implications ranging from personal reputation damage to global repercussions. While efforts are being made to mitigate this threat, the results so far are not particularly impressive. Many proposed solutions falter when tested on datasets that differ substantially from the ones on which they were trained. In our approach, we utilize Meta's MMS-300m pretrained ASR model as a feature extractor and train it end-to-end (E2E) alongside various classifiers (ResNet-18, MesoNet, AASIST, MLP, and SLP). We train on a small subset of the widely recognized ASVSpoof2021 DF dataset and conduct cross-dataset evaluations on the In-The-Wild (ITW) dataset, a standard benchmark. The E2E training of the robust ASR model yields a significant improvement, with all our models surpassing the current state of the art. Our best-performing model achieves an Equal Error Rate (EER) of 0.0342%, representing an impressive 55.48% improvement.;2835-8864;979-8-3315-0721-3;10.1109/INMIC64792.2024.11004412;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11004412;"audio deepfake detection;end-to-end;pretrained ASR;Meta MMS-300m";"Training;Deepfakes;Error analysis;Benchmark testing;Feature extraction;Data models;Distance measurement;Standards";;;;39;IEEE;16 May 2025;30-31 Dec. 2024;30-31 Dec. 2024;IEEE;IEEE Conferences
Flexible Multi-Modality Deepfake Identification with Dynamic Learning and Cross-Modality Inconsistency;"E. J. J; K. K. P; M. S. M; R. J";"Department of Information Technology, Velammal College of Engineering & Technology, Madurai, India; Department of Information Technology, Velammal College of Engineering & Technology, Madurai, India; Department of Information Technology, Velammal College of Engineering & Technology, Madurai, India; Department of Information Technology, Velammal College of Engineering & Technology, Madurai, India";2025 3rd International Conference on Advancements in Electrical, Electronics, Communication, Computing and Automation (ICAECA);2 Jun 2025;2025;;;1;6;Rapid advances in generative models, that produce hyper-realistic modifications of photos and videos, have contributed to deepfake detection more difficult. Current detection approaches are very costly, making real-time detection difficult, and they often suffer with generalization, particularly when faced with unknown deepfake techniques. An Adaptive Multi-Modality Framework is proposed, presenting a unique set of methods for reliable and effective deepfake detection in order to overcome these drawbacks. The framework incorporates Self-Supervised Patch-Based Learning for smooth detection of localized manipulations, Dynamic Discriminator Learning (DDL) in adaptively evolve against new deepfake generation techniques, and Cross-Modality Inconsistency Scoring (CMIS) to detect anomalies across spatial, temporal, and audio-visual domains. The Inconsistency Score (IS), a novel metric that measures the probability of modified material, unifies these elements. This method allows for real-time application, improves detection accuracy, and guarantees flexibility in response to new threats. The investigations reveal that the proposed method has the potential to transform fake identification techniques by surpassing state-of-the-art techniques.;;979-8-3315-2543-9;10.1109/ICAECA63854.2025.11012276;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11012276;"Cross-Modality Inconsistency Scoring;Adaptive Deepfake Detection;Dynamic Discriminator Learning";"Training;Deepfakes;Accuracy;Transforms;Self-supervised learning;Real-time systems;Telecommunication computing;Security;Reliability;Standards";;;;15;IEEE;2 Jun 2025;4-5 April 2025;4-5 April 2025;IEEE;IEEE Conferences
Deep Learning Based Deepfake Video Detection System;"A. K. Jha; A. K. Yadav; A. K. Dubey; A. Kumar; A. Sharma";"CSE Department, Greater Noida Institute of Technology, Greater Noida, Uttar Pradesh, India; CSE Department, Greater Noida Institute of Technology, Greater Noida, Uttar Pradesh, India; CSE Department, Greater Noida Institute of Technology, Greater Noida, Uttar Pradesh, India; CSE Department, Greater Noida Institute of Technology, Greater Noida, Uttar Pradesh, India; CSE Department, Greater Noida Institute of Technology, Greater Noida, Uttar Pradesh, India";2025 3rd International Conference on Disruptive Technologies (ICDT);13 May 2025;2025;;;408;412;Deepfake technology involves the tampering or creation of synthetic media, the technology can be highly effective in undermining trust in digital content because it exploits developments in machine learning. A new algorithm is proposed with a hybrid deepfake detection framework that integrates CNNs and RNNs with the functionalities of spatial and temporal inconsistency detection. The proposed method, using FaceForensics++ and the Deepfake Detection Challenge (DFDC), comes with a detection accuracy of 92.5%. The study addresses challenges including bias in the dataset and computational efficiency as well as model generalization. The study contributes to applications in security, content verification, and real-time monitoring on social platforms.;;979-8-3315-1958-2;10.1109/ICDT63985.2025.10986738;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10986738;"Deepfake Detection;Deep Learning;Convolutional Neural Networks (CNNs);Hybrid Models;FaceForensics++;Deepfake Detection Challenge (DFDC);Generative Adversarial Networks (GANs);Real-Time Detection;Dataset Bias;Ethical AI;Feature Extraction;Generalization;Recurrent Neural Networks (RNNs)";"Deep learning;Deepfakes;Accuracy;Computational modeling;Streaming media;Feature extraction;Real-time systems;Hybrid power systems;Computational efficiency;Convolutional neural networks";;;;23;IEEE;13 May 2025;7-8 March 2025;7-8 March 2025;IEEE;IEEE Conferences
Review: DeepFake Detection Techniques using Deep Neural Networks (DNN);"H. Chotaliya; M. A. Khatri; S. Kanojiya; M. Bivalkar";"Department of Computer Engineering, K J Somaiya Institute of Technology, Mumbai, Mumbai, India; Department of Computer Engineering, K J Somaiya Institute of Technology, Mumbai, Mumbai, India; Department of Computer Engineering, K J Somaiya Institute of Technology, Mumbai, Mumbai, India; Department of Computer Engineering, K J Somaiya Institute of Technology, Mumbai, Mumbai, India";2023 6th International Conference on Advances in Science and Technology (ICAST);4 Mar 2024;2023;;;480;484;In the age of advanced digital manipulation, deepfake videos pose a significant threat to society by allowing the creation of highly convincing counterfeit footage. The application of deep learning has proven instrumental in tackling an extensive array of practical issues and real-world applications. However, alongside its substantial benefits, there exist certain disadvantages. Deepfake videos involve the substitution of one person's characteristics with those of another, achieved through the application of advanced Deep Learning techniques. This technology can be exploited with harmful intentions, leading to the dissemination of misinformation, manipulation, and persuasive content. This paper explores multiple deep learning techniques designed for detecting deep fake images and videos. It conducts a comparative analysis of these techniques, including CNN models like ResNet, VGG16, and Efficient Net, along with RNN models like LSTM, to assess their effectiveness in deepfake video detection.;;979-8-3503-5981-7;10.1109/ICAST59062.2023.10454938;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10454938;"DeepFake detection;CNN;GAN;RNN;LSTM";"Deep learning;Training;Deepfakes;Analytical models;Reviews;Motion pictures;Long short term memory";;6;;13;IEEE;4 Mar 2024;8-9 Dec. 2023;8-9 Dec. 2023;IEEE;IEEE Conferences
A Deepfake detection technique using Recurrent Neural Network and EfficientNet;"S. P. Koritala; M. Chimata; S. N. Polavarapu; B. S. Vangapandu; T. K. Gogineni; V. M. Manikandan";"Department of Computer Science and Engineering, SRM University Mangalagiri, Andhra Pradesh, India; Department of Computer Science and Engineering, SRM University Mangalagiri, Andhra Pradesh, India; Department of Computer Science and Engineering, SRM University Mangalagiri, Andhra Pradesh, India; Department of Computer Science and Engineering, SRM University Mangalagiri, Andhra Pradesh, India; Department of Computer Science and Engineering, SRM University Mangalagiri, Andhra Pradesh, India; Department of Computer Science and Engineering, SRM University Mangalagiri, Andhra Pradesh, India";2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT);4 Nov 2024;2024;;;1;6;A deepfake is a computer-generated image or video that appears to be real but is a fabricated representation created to make an individual appear to be saying or doing something that did not occur. Deepfakes generate misleading or deceptive information by manipulating and superimposing faces onto pre-existing footage using artificial intelligence. This paper introduces a novel approach for deepfake detection through a combination of EfficientNet and Recurrent Neural Networks (RNNs). This method enhances detection efficiency by leveraging the hierarchical features acquired by EfficientNet and employing RNNs, specifically Long Short-Term Memory (LSTM) networks, to capture temporal dependencies. Application of this approach to the Celeb-DF dataset resulted in an accuracy of $\mathbf{9 9. 9 8 \%}$.;2473-7674;979-8-3503-7024-9;10.1109/ICCCNT61001.2024.10723875;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10723875;"EfficientNet;Recurrent Neural Network(RNN);LSTM;Deepfake detection";"Deepfakes;Accuracy;Recurrent neural networks;Scalability;Feature extraction;Real-time systems;Artificial intelligence;Long short term memory;Faces";;4;;20;IEEE;4 Nov 2024;24-28 June 2024;24-28 June 2024;IEEE;IEEE Conferences
Detecting Deepfake Videos using Face Recognition and Neural Networks;"M. A. Murugan; T. Mathu; S. J. Priya";"Computer Science and Engineering, Karunya Institute of Technology and Sciences, Coimbatore, India; Data Science and Cyber Security, Karunya Institute of Technology and Sciences, Coimbatore, India; Computer Science and Engineering, Karunya Institute of Technology and Sciences, Coimbatore, India";2024 International Conference on Cognitive Robotics and Intelligent Systems (ICC - ROBINS);21 May 2024;2024;;;289;293;Deepfake videos created using advanced artificial intelligence techniques, pose a significant threat to digital media credibility. This project introduces a holistic strategy for identifying these videos, incorporating face recognition, feature extraction, and an innovative deep-learning model. The methodology involves pre-processing video data, extracting facial features using the face recognition library, and training a neural network model on processed face-only videos. The project filters videos based on frame count, extracts face, and creates a curated dataset for the detection model. Face-only videos are loaded and pre-processed to train a custom neural network model, which combines a pre-trained ResNext CNN with an LSTM layer for temporal feature extraction. The model is trained using Adam optimization with a cross-entropy loss function, and after completion, it has an accuracy of 95% and is capable of differentiate between fake and real videos using a confidence score.;;979-8-3503-7274-8;10.1109/ICC-ROBINS60238.2024.10534025;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10534025;"Deepfake video detection;celeb-df;face-recognition;LSTM;ResneXt";"Training;Deepfakes;Recurrent neural networks;Face recognition;Media;Feature extraction;Real-time systems";;2;;14;IEEE;21 May 2024;17-19 April 2024;17-19 April 2024;IEEE;IEEE Conferences
Deep Fake Detection using Adversarial Ensemble Techniques;"B. V. Chowdary; M. Prabhakar; M. Akhil; K. Pavan; B. P. T. Reddy";"Dept of IT, Vignan Institute of Technology and Science (A), Hyderabad; Dept of IT, Vignan Institute of Technology and Science (A), Hyderabad; Dept of IT, Vignan Institute of Technology and Science (A), Hyderabad; Dept of IT, Vignan Institute of Technology and Science (A), Hyderabad; Dept of IT, Vignan Institute of Technology and Science (A), Hyderabad";2024 8th International Conference on Inventive Systems and Control (ICISC);19 Sep 2024;2024;;;201;204;The rise of deepfake technology has resulted in unprecedented challenges in the field of digital media verification, posing significant threats to personal security, misinformation, and trust in digital content. In response to this pressing issue, this study presents an advanced deepfake detection system using deep learning approach. Specifically, the proposed system integrates ResNeXt and Long Short-Term Memory (LSTM) architectures to accurately identify the manipulated content. By leveraging the spatial-temporal features captured by these combined architectures, the proposed system aims to enhance the detection rate of deepfakes across various media formats. The proposed approach offers a robust solution to counteract the evolving sophistication of deepfake technology, thereby enhancing the integrity and authenticity of digital media content.;;979-8-3503-8657-8;10.1109/ICISC62624.2024.00041;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10677707;"Deepfake Detection;Deep Learning;ResNeXt;LSTM;Digital Media Verification";"Deep learning;Training;Deepfakes;Accuracy;Memory architecture;Pressing;Feature extraction";;1;;14;IEEE;19 Sep 2024;29-30 July 2024;29-30 July 2024;IEEE;IEEE Conferences
Deepfake Detection: Demodulate Synthetic Videos Using Deep Learning Models;"P. Hirpara; H. Valangar; V. Kachhadiya; U. Chauhan";"Department of Computer Engineering, Vishwakarma Government Engineering College, Gujarat, India; Department of Computer Engineering, Vishwakarma Government Engineering College, Gujarat, India; Department of Computer Engineering, Vishwakarma Government Engineering College, Gujarat, India; Department of Computer Engineering, Vishwakarma Government Engineering College, Gujarat, India";2025 12th International Conference on Computing for Sustainable Global Development (INDIACom);21 Aug 2025;2025;;;1;6;A deepfake detection system that uses machine learning (ML) and deep learning (DL) models to detect manipulated videos and images is presented in the study. Being aware of such synthetic content is crucial considering the emergence of deepfake technology, which might alter photos, videos, and audio for malevolent objectives including fraud, extortion, and disinformation. Deepfake technology has been applied to solve various real-time problems but is also exploited for unethical and illegal purposes. As a result, developing research and detection models is crucial to prevent its misuse. We proposed a CNN-LSTM hybrid model for analysis of cropped images to improve the performance of fake video detection. The suggested method focuses on identifying fake videos using the Celeb-DF dataset, which consists of 1203 videos (795 fake, 408 real). Moreover, the benefits and drawbacks of the various deepfake detection techniques are examined. The paper indicates potential improvements in model accuracy through more datasets and improved architectures, and it emphasizes the significance of sophisticated detection techniques to mitigate the negative consequences of deepfakes. With cropped video frames and deep learning techniques, the model's accuracy increased from 79.06% with the original dataset to $\mathbf{8 6. 8 2 \%}$ with cropped videos.;;978-93-80544-60-1;10.23919/INDIACom66777.2025.11115707;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11115707;"Deepfake Detection;Deep Learning;Artificial Intelligence;Face Manipulation;CNN-LSTM";"Deep learning;Deepfakes;Analytical models;Accuracy;Computational modeling;Computer architecture;Real-time systems;Fraud;Faces";;;;32;;21 Aug 2025;2-4 April 2025;2-4 April 2025;IEEE;IEEE Conferences
Hybrid Deepfake Detection System: Leveraging AlexNet and LSTM Networks for Enhanced Video Authentication;"A. B. Ghodake; D. B. Yewale; T. D. Katariya; B. S. Khobare; A. S. Shidore";"Department of Computer Engineering, Shri Chhatrapati Shivaji Maharaj College Of Engineering, Nepti, Ahmednagar, Maharashtra; Department of Computer Engineering, Shri Chhatrapati Shivaji Maharaj College Of Engineering, Nepti, Ahmednagar, Maharashtra; Department of Computer Engineering, Shri Chhatrapati Shivaji Maharaj College Of Engineering, Nepti, Ahmednagar, Maharashtra; Department of Computer Engineering, Shri Chhatrapati Shivaji Maharaj College Of Engineering, Nepti, Ahmednagar, Maharashtra; Department of Computer Engineering, Shri Chhatrapati Shivaji Maharaj College Of Engineering, Nepti, Ahmednagar, Maharashtra";2025 International Conference on Emerging Systems and Intelligent Computing (ESIC);16 Apr 2025;2025;;;283;287;The rapid proliferation of deepfake technology has presented significant challenges in ensuring the authenticity of digital media, posing security risks in various domains, including social media, politics, and corporate communications. This paper proposes a hybrid deepfake detection system that integrates AlexNet, a powerful convolutional neural network (CNN), and Long Short-Term Memory (LSTM) networks to enhance video authentication. The proposed system lever-ages AlexNet's strong capabilities in feature extraction to analyze spatial features within video frames, while LSTM networks process temporal sequences, capturing the dependencies across frames in video streams. By combining these models, our approach delivers an effective deepfake detection system that is robust to subtle manipulations and capable of identifying deepfakes with high precision. Experiments were conducted on publicly available datasets to evaluate the performance of the hybrid model against standalone models and other baseline approaches. The results indicate significant improvements in detection accuracy, with the hybrid system achieving a higher recall and precision rate compared to traditional CNN and RNN-based methods. Furthermore, the proposed system demonstrated resilience against a wide range of deepfake techniques, including facial reenactment and voice synchronization. This work highlights the importance of combining spatial and temporal analysis for reliable video authentication, paving the way for advanced deepfake mitigation strategies in both public and private sectors. The integration of AlexNet and LSTM networks offers a scalable solution for real-time video analysis, providing critical support in com-bating the spread of disinformation and enhancing trust in digital media.;;979-8-3315-2210-0;10.1109/ESIC64052.2025.10962665;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10962665;"Deepfake detection;AlexNet;LSTM networks;video authentication;hybrid model";"Location awareness;Deepfakes;Accuracy;Authentication;Streaming media;Feature extraction;Real-time systems;Convolutional neural networks;Reliability;Long short term memory";;;;42;IEEE;16 Apr 2025;8-9 Feb. 2025;8-9 Feb. 2025;IEEE;IEEE Conferences
Frame-to-Utterance Convergence: A Spectra-Temporal Approach for Unified Spoofing Detection;"A. Khan; K. M. Malik; S. Nawaz";"Department of Computer Science and Engineering, Oakland University, Rochester, Michigan, USA; Department of Computer Science and Engineering, Oakland University, Rochester, Michigan, USA; Johannes Kepler University, Linz, Austria";ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP);18 Mar 2024;2024;;;10761;10765;Voice spoofing attacks pose a significant threat to automated speaker verification systems. Existing anti-spoofing methods often simulate specific attack types, such as synthetic or replay attacks. However, in real-world scenarios, the countermeasures are unaware of the generation schema of the attack, necessitating a unified solution. Current unified solutions struggle to detect spoofing artefacts, especially with recent spoofing mechanisms. For instance, the spoofing algorithms inject spectral or temporal anomalies, which are challenging to identify. To this end, we present a spectra-temporal fusion leveraging frame-level and utterance-level coefficients. We introduce a novel local spectral deviation coefficient (SDC) for frame-level inconsistencies and employ a bi-LSTM-based network for sequential temporal coefficients (STC), which capture utterance-level artifacts. Our spectra-temporal fusion strategy combines these coefficients, and an auto-encoder generates spectra-temporal deviated coefficients (STDC) to enhance robustness. Our proposed approach addresses multiple spoofing categories, including synthetic, replay, and partial deepfake attacks. Extensive evaluation on diverse datasets (ASVspoof2019, ASVspoof2021, VSDC, partial spoofs, and in-the-wild deepfakes) demonstrated its robustness for a wide range of voice applications.;2379-190X;979-8-3503-4485-1;10.1109/ICASSP48485.2024.10447500;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10447500;"Voice Spoofing Detection;Spectral Temporal;Audio Deepfake Detection;Unified spoofing detection";"Deepfakes;Signal processing algorithms;Signal processing;Robustness;Acoustics;Speech processing;Convergence";;6;;20;IEEE;18 Mar 2024;14-19 April 2024;14-19 April 2024;IEEE;IEEE Conferences
Video Integrity Detection with Deep Learning;"C. R; A. V. R; P. R";"St. Joseph's Institute of Technology, Chennai, Tamil Nadu, India; St. Joseph's Institute of Technology, Chennai, Tamil Nadu, India; St. Joseph's Institute of Technology, Chennai, Tamil Nadu, India";2024 10th International Conference on Advanced Computing and Communication Systems (ICACCS);23 Oct 2024;2024;1;;1288;1292;In today's digital age, ensuring information integrity against deepfakes is essential. This project addresses this challenge by developing a scalable video integrity detection system through the fusion of convolutional neural networks (CNNs) for analyzing video frames and recurrent neural networks (RNNs) for temporal behavior. The model incorporates advanced architectures designed to capture subtle inconsistencies and manipulation artifacts, leveraging cutting-edge techniques for enhanced detection compared to traditional methods. Its adaptability is enhanced through the utilization of domain adaptation and adversarial training strategies, ensuring durability against evolving manipulation techniques. Designed for real-time capabilities, the system is optimized for efficient inference, enabling proactive identification and mitigation of manipulated content on online platforms. Expected outcomes include achieving high accuracy in discriminating real from manipulated videos, promoting improved trust and transparency in the digital media landscape. By providing a reliable means to verify the integrity of video content, the system contributes to a more trustworthy and secure digital ecosystem. This multi-modal fusion approach, coupled with advanced architectures, effectively addresses the necessity for identifying and controlling the spread of manipulated video content.;2575-7288;979-8-3503-8436-9;10.1109/ICACCS60874.2024.10717096;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10717096;"Deep learning;Video integrity detection;Convolutional neural networks (CNNs);Recurrent neural networks (RNNs);Deepfake (DF);Adversarial training;Long Short-Term Memory (LSTM);ResNeXt";"Training;Deepfakes;Accuracy;Ecosystems;Computer architecture;Streaming media;Media;Real-time systems;Convolutional neural networks;Reliability";;1;;22;IEEE;23 Oct 2024;14-15 March 2024;14-15 March 2024;IEEE;IEEE Conferences
ResNeXt-50 and LSTM for Deepfake Detection;"F. Kamil; E. M. Maharani; R. Rahmania";"Computer Science Department, School of Computer Science, Bina Nusantara University, Bandung, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Bandung, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Bandung, Indonesia";2025 IEEE International Conference on Artificial Intelligence for Learning and Optimization (ICoAILO);16 Sep 2025;2025;;;113;118;Deepfake technology presents a significant threat to digital security due to its increasing sophistication and potential for misuse. This research proposes a Deepfake detection model combining ResNeXt-50 32×4d for spatial feature extraction and Long Short-Term Memory (LSTM) networks for temporal analysis. A video processing pipeline was implemented to isolate and retain facial regions from each frame in the dataset. Videos were decomposed into frames, with faces detected using a pre-trained model of face recognition and frames containing faces were cropped, resized to 256×256 pixels, and saved. Only the first 150 frames per video were processed to maintain temporal order for sequential analysis, with the dataset split into training, validation, and test sets (70%, 20%, 10%). The processed frames were then passed through the ResNeXt-50 for spatial feature extraction and LSTM for temporal dependencies. Evaluated on the Celeb-DF and FaceForensics++ datasets, the model achieved peak accuracies of 99.90% and 99.13%, respectively. Future research will focus on integrating multimodal data and leveraging Explainable AI to further improve detection accuracy and interpretability.;;979-8-3315-6928-0;10.1109/ICoAILO66760.2025.11156046;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11156046;"Deepfake Detection;ResNeXt-5032x4d;LSTM;Celeb-DF;FaceForensics++";"Training;Deepfakes;Sequential analysis;Accuracy;Pipelines;Feature extraction;Security;Long short term memory;Faces;Optimization";;;;42;IEEE;16 Sep 2025;7-9 Aug. 2025;7-9 Aug. 2025;IEEE;IEEE Conferences
DEFENDAI: Enhancing Deepfake Detection with Hybrid Architectures using EfficientNet, XceptionNet, Vision Transform and LSTM;"M. Kavitha; R. Raushan; Priya; R. Kumar";"Department of CSE, Vel Tech Rangarajan Dr. Sagunthala R&D Institute of Science and Technology, Chennai, India; Department of CSE, Vel Tech Rangarajan Dr. Sagunthala R&D Institute of Science and Technology, Chennai, India; Department of CSE, Vel Tech Rangarajan Dr. Sagunthala R&D Institute of Science and Technology, Chennai, India; Department of CSE, Vel Tech Rangarajan Dr. Sagunthala R&D Institute of Science and Technology, Chennai, India";2025 3rd International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS);21 Jul 2025;2025;;;952;958;The rapid evolution of deepfake technologies presents a significant threat to digital authenticity and societal trust. This research introduces DEFENDAI, a hybrid deepfake detection system integrating EfficientNet, XceptionNet, Vision Transformers (ViT), and Long Short-Term Memory (LSTM) networks to harness both spatial and temporal features. Trained on a curated subset of the DFDC dataset, the system uses a multi-stage pipeline involving frame extraction, resizing, normalization, and augmentation for preprocessing. Feature extraction is performed using CNNs and ViTs, while LSTM captures sequential dependencies across frames. A web-based implementation using FastAPI and Streamlit enables real-time user interaction and deployment. Comparative results show the hybrid model significantly outperforms standalone models in precision, recall, and generalization. Future work aims at extending datasets, integrating adversarial robustness, and refining real-time detection pipelines for broader applicability.;;979-8-3315-3884-2;10.1109/ICSSAS66150.2025.11081343;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11081343;"Deepfake Detection;Vision Transformers;EfficientNet;XceptionNet;LSTM;DFDC;FastAPI;Streamlit;AI Security";"Training;Deepfakes;Computer vision;Pipelines;Transforms;Feature extraction;Transformers;Real-time systems;Artificial intelligence;Long short term memory";;;;16;IEEE;21 Jul 2025;11-13 June 2025;11-13 June 2025;IEEE;IEEE Conferences
Eff-YNet: A Dual Task Network for DeepFake Detection and Segmentation;"E. Tjon; M. Moh; T. -S. Moh";"Department of Computer Science, San José State University, San José, CA, USA; Department of Computer Science, San José State University, San José, CA, USA; Department of Computer Science, San José State University, San José, CA, USA";2021 15th International Conference on Ubiquitous Information Management and Communication (IMCOM);17 Mar 2021;2021;;;1;8;Advances in generative models and manipulation techniques have given rise to digitally altered videos known as deepfakes. These videos are difficult to identify for both humans and machines. Modern detection methods exploit various weaknesses in deepfake videos, such as visual artifacts and inconsistent posing. In this paper, we describe a novel architecture called Eff-YNet designed to detect visual differences between altered and unaltered areas. The architecture combines an EfficientNet encoder and a U-Net with a classification branch into a model capable of both classifying and segmenting deepfake videos. The task of segmentation helps train the classifier and also produces useful segmentation masks. We also implement ResNet 3D to detect spatiotemporal inconsistencies. To test these models, we run experiments against the Deepfake Detection Challenge dataset and show improvements over baseline classification models. Furthermore, we find that an ensemble of these two approaches improves performance over a single approach alone.;;978-1-6654-2318-2;10.1109/IMCOM51814.2021.9377373;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9377373;"Deepfake detection;computer vision;deep learning;image segmentation;image classification;U-Net";"Visualization;Three-dimensional displays;Spatiotemporal phenomena;Information management;Task analysis;Videos;Information integrity";;9;;24;IEEE;17 Mar 2021;4-6 Jan. 2021;4-6 Jan. 2021;IEEE;IEEE Conferences
A Dual-Stream CNN-LSTM Framework with ELA Preprocessing for Deepfake Detection;"N. N. Nadarajan; A. R. Trivedi; S. K; M. M; G. Kolagatla; S. Rana; N. M";"SCOPE, VIT-AP University, Amaravati, India; SCOPE, VIT-AP University, Amaravati, India; SCOPE, VIT-AP University, Amaravati, India; School of Electronics Engineering, VIT-AP University, Amaravati, India; SCOPE, VIT-AP University, Amaravati, India; SCOPE, VIT-AP University, Amaravati, India; School of Electronics Engineering, VIT-AP University, Amaravati, India";2025 International Conference on Sensors and Related Networks (SENNET) Special Focus on Digital Healthcare(64220);29 Aug 2025;2025;;;1;6;The proliferation of deepfake content presents critical threats to digital authenticity, privacy, and information integrity. This paper proposes a hybrid deepfake detection framework that integrates Error Level Analysis (ELA) with the ResNet-50 convolutional neural network to identify manipulated images. The system employs a dual-stream architecture that processes both raw frames and ELA-transformed inputs, enhancing spatial and temporal feature extraction through Long Short-Term Memory (LSTM) layers. Evaluated on both general-purpose and celebrity-based datasets, the proposed model demonstrates superior classification accuracy and robust generalization, particularly in detecting forgeries involving high-profile individuals. Experimental results affirm the model’s effectiveness in capturing compression inconsistencies and subtle manipulations, positioning it as a scalable and reliable solution for deepfake detection in real-world scenarios.;;979-8-3315-9746-7;10.1109/SENNET64220.2025.11135952;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11135952;"Deepfake detection;Error Level Analysis (ELA);ResNet-50;LSTM;image forensics;digital media authenticity;deep learning;multimedia security";"Deepfakes;Accuracy;Sensitivity;Media;Feature extraction;Sensors;Convolutional neural networks;Security;Reliability;Long short term memory";;;;17;IEEE;29 Aug 2025;24-27 July 2025;24-27 July 2025;IEEE;IEEE Conferences
A Deepfake Detection Model Based on the Integration of ResNet50 and LSTM;"X. Huang; Y. Zheng; X. Jiang";"Maynooth International Engineering College, Fuzhou University, Fuzhou, China; Maynooth International Engineering College, Fuzhou University, Fuzhou, China; Maynooth International Engineering College, Fuzhou University, Fuzhou, China";2025 IEEE 5th International Conference on Electronic Technology, Communication and Information (ICETCI);24 Jul 2025;2025;;;561;565;Video processing has consistently been a focal point of interest in both the media industry and academia, particularly against the backdrop of continuous advancements in digital signal processing technology. These videos are sometimes misused to disseminate false information or damage reputations. This paper aims to develop a video authenticity recognition system using advanced deep learning models. In terms of technical implementation, the ResNet50 model is employed for image feature extraction to detect subtle inconsistencies and artifacts, such as unnatural facial movements and irregular lighting variations in videos. Additionally, LSTM is used to capture the temporal sequence features of the video. Experimental results indicate that the model achieves an accuracy rate of 81.25% in detecting deepfake videos. Additionally, the model achieved a recall rate of 1, which holds significant practical value. This achievement provides strong support for the accurate detection and labeling of videos, playing a crucial role in preserving information authenticity and ensuring media security.;;979-8-3315-3372-4;10.1109/ICETCI64844.2025.11084255;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11084255;"Computer Vision;Deepfake Detection;ResNet50;LSTM";"Deepfakes;Accuracy;Forensics;Media;Performance metrics;Neural radiance field;Feature extraction;Long short term memory;Residual neural networks;Resilience";;;;6;IEEE;24 Jul 2025;23-25 May 2025;23-25 May 2025;IEEE;IEEE Conferences
DAF-Net: A Data-Analytics-Driven Adaptive Framework for Deepfake Detection Using Hybrid Deep Learning Models;R. PushpaLakshmi;Department of CSE(Cyber Security), PSNA College of Engineering and Technology, Dindigul, India;2025 IEEE International Conference on Advances in Computing Research On Science Engineering and Technology (ACROSET);16 Dec 2025;2025;;;1;7;The emergence of deepfake technology, which is driven by sophisticated Generative Adversarial Networks (GANs), has presented a significant cybersecurity threat. Cybercrimes including identity theft, social engineering, and disinformation now use deepfakes, which are artificially modified videos, pictures, or sounds. Because these synthetic dangers are constantly changing, traditional detection techniques sometimes fall short. The unique multi-modal system DAF-Net (Data-Analytics-Driven Adaptive Framework for Deepfake Detection), which integrates contextual data analytics and deep learning, is proposed in this research. DAF-Net combines a Transformer encoder for temporal inconsistencies, a Convolutional Neural Network (EfficientNet) for spatial features, and Wav2Vec 2.0 for audio-based manipulation detection. Together, these models provide highly accurate deepfake detection across modalities. One of DAF-Net's unique features is its Data Analytics and Visualisation Module, which assigns a Contextual Risk Score and identifies spreading trends using metadata. Tested on datasets like FaceForensics++, DFDC, and ASVspoof 2021, DAF-Net outperformed current techniques with an accuracy of 93.6% for video and 91.2% for audio deepfakes. 87% of high-impact threats have their priorities accurately determined by risk scoring. DAF-Net provides a scalable, intelligent defence solution for practical cybersecurity applications by fusing data analytics and adaptive deep learning.;;978-1-6654-5810-8;10.1109/ACROSET66531.2025.11280662;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11280662;"deepfake detection;adaptive deep learning;cybersecurity;data analytics;transformer networks;risk scoring";"Deep learning;Deepfakes;Adaptation models;Data analysis;Accuracy;Adaptive systems;Computational modeling;Transformers;Feature extraction;Load modeling";;;;30;IEEE;16 Dec 2025;27-28 Sept. 2025;27-28 Sept. 2025;IEEE;IEEE Conferences
Robust AI-Synthesized Speech Detection Using Feature Decomposition Learning and Synthesizer Feature Augmentation;"K. Zhang; Z. Hua; Y. Zhang; Y. Guo; T. Xiang";"School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, Guangdong, China; School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, Guangdong, China; School of Computing and Artificial Intelligence, Jiangxi University of Finance and Economics, Nanchang, Jiangsu, China; Alibaba Group, Hangzhou, Zhejiang, China; College of Computer Science, Chongqing University, Chongqing, China";IEEE Transactions on Information Forensics and Security;10 Jan 2025;2025;20;;871;885;AI-synthesized speech, also known as deepfake speech, has recently raised significant concerns due to the rapid advancement of speech synthesis and speech conversion techniques. Previous works often rely on distinguishing synthesizer artifacts to identify deepfake speech. However, excessive reliance on these specific synthesizer artifacts may result in unsatisfactory performance when addressing speech signals created by unseen synthesizers. In this paper, we propose a robust deepfake speech detection method that employs feature decomposition to learn synthesizer-independent content features as complementary for detection. Specifically, we propose a dual-stream feature decomposition learning strategy that decomposes the learned speech representation using a synthesizer stream and a content stream. The synthesizer stream specializes in learning synthesizer features through supervised training with synthesizer labels. Meanwhile, the content stream focuses on learning synthesizer-independent content features, enabled by a pseudo-labeling-based supervised learning method. This method randomly transforms speech to generate speed and compression labels for training. Additionally, we employ an adversarial learning technique to reduce the synthesizer-related components in the content stream. The final classification is determined by concatenating the synthesizer and content features. To enhance the model’s robustness to different synthesizer characteristics, we further propose a synthesizer feature augmentation strategy that randomly blends the characteristic styles within real and fake audio features and randomly shuffles the synthesizer features with the content features. This strategy effectively enhances the feature diversity and simulates more feature combinations. Experimental results on four deepfake speech benchmark datasets demonstrate that our model achieves state-of-the-art robust detection performance across various evaluation scenarios, including cross-method, cross-dataset, and cross-language evaluations.;1556-6021;;10.1109/TIFS.2024.3520001;"National Key Research and Development Program of China(grant numbers:2022YFB3103500); National Natural Science Foundation of China(grant numbers:62071142); Guangdong Basic and Applied Basic Research Foundation(grant numbers:2024A1515012299);";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10806877;"Deepfake speech detection;feature decomposition;feature augmentation;robust detection";"Synthesizers;Deepfakes;Feature extraction;Voice activity detection;Vocoders;Training;Robustness;Spectrogram;Multitasking;Transformers";;5;;61;IEEE;18 Dec 2024;2025;;IEEE;IEEE Journals
Deepfake Audio Detection: a Multi Model, Multi Dataset Performance Study Using Deep Learning Architectures;A. Bhardwaj;Dept. of EECE, SSES Sharda University, Greater Noida, India;2025 International Conference on Intelligent Communication Networks and Computational Techniques (ICICNCT);18 Nov 2025;2025;;;1;6;As AI-generated content rapidly increases, deepfake audio presents a significant risk to digital security and reliability. To address this issue, a hybrid deep learning approach is implemented by integrating convolutional neural networks (CNN) with long short-term memory (LSTM) networks. The framework utilizes both Mel spectrogram and MFCC features to capture intricate spectral and temporal patterns in audio. The model is trained and evaluated on various iterations of a publicly available deepfake audio dataset, which included genuine, normalized, short-length, and re-recorded samples, to guarantee strong performance across different scenarios. The results demonstrate that the CNN+LSTM model reliably exceeds the performance of individual CNN, RNN, LSTM and Transformer models, attaining improved accuracy and reduced error rates. This underscores the advantages of hybrid models in real-world audio forensics and suggests directions for future research focused on enhancing generalization, resilience to noise, and defense against adversarial attacks.;;979-8-3315-8623-2;10.1109/ICICNCT66124.2025.11232782;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11232782;"deepfake audio;deep learning;fake speech detection;CNN;RNN;LSTM;transformers";"Deep learning;Deepfakes;Accuracy;Error analysis;Transformers;Convolutional neural networks;Reliability;Security;Long short term memory;Spectrogram";;;;15;IEEE;18 Nov 2025;5-6 Sept. 2025;5-6 Sept. 2025;IEEE;IEEE Conferences
Deepfake Video Detection: Analysis for Deep Learning models using Transfer Learning;"S. Altamimi; W. Salameh";"Cyber Security Department, Princess Sumaya University for Technology, Amman, Jordan; Computer Science Department, Princess Sumaya University for Technology, Amman, Jordan";2024 25th International Arab Conference on Information Technology (ACIT);17 Feb 2025;2024;;;1;9;The unchecked spread of deepfake videos jeopardizes public trust, national security, and media credibility. The capacity to recognize falsified videos is critical for protecting privacy and combatting misinformation. The article seeks to illustrate the usage of Deep Learning (DL) approaches for recognizing deepfake videos, including Recurrent Neural Networks (RNN), Long Short-Term Memory (LSTM) networks, and an RNN-LSTM combination with Transfer Learning. The research used the LSTM model to examine the efficacy of temporal correlations between video frames in the Deepfake Detection Challenge (DFDC) dataset of deep fake videos, and it claimed complete success in both the training and testing stages. In addition, the study used frame level masks and characteristics that were created throughout the research's pre-processing steps. The findings show that the model had a train loss of 0.021 and a test loss of 0.813, suggesting that it was extremely resilient. Other crucial indicator measures, such as Mean Squared Error (MSE) and Structural Similarity Index Measure (SSIM), aid in evaluating the model's performance and validate its high accuracy in recognizing deepfake material. This study is very important since it greatly contributes to the body of knowledge in the early phases of deepfake identification and aids in the mitigation of the risks connected with manipulated media.;2831-4948;979-8-3315-4001-2;10.1109/ACIT62805.2024.10877153;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10877153;"Deepfake;Video Detection;Deepfake Detection Challenge;Long Short-Term Memory and Recurrent Nural Networks";"Deep learning;Deepfakes;Accuracy;Recurrent neural networks;Measurement uncertainty;Transfer learning;Mean square error methods;Data models;Indexes;Long short term memory";;1;;28;IEEE;17 Feb 2025;10-12 Dec. 2024;10-12 Dec. 2024;IEEE;IEEE Conferences
Deep fake Image Detection Based on Deep Learning Using a Hybrid CNN-LSTM with Machine Learning Architectures as Classifier;"O. A. H. H. Al-Dulaimi; S. Kurnaz";"Department of Electrical & Computer Engineering Institute of Graduate Studies, Altinbas University, Istanbul, Turkey; Department of Electrical & Computer Engineering Institute of Graduate Studies, Altinbas University, Istanbul, Turkey";2024 International Congress on Human-Computer Interaction, Optimization and Robotic Applications (HORA);12 Jun 2024;2024;;;1;7;One of the most important and difficult subjects in social communication is detecting deepfake images and videos. Deepfake techniques have developed widely, making this technology quite available and proficient enough so that there is worry about its bad application. Considering this issue, discovering fake faces is very important for ensuring security and preventing sociopolitical issues on a private and general level. Deep learning provides higher performance than typical image processing approaches when it comes to deepfake detection. This work presents construction of an artificial intelligence system, which is capable of detecting deepfake from more than one dataset. This study proposes neural network models based on deep learning using random forest (RF) and support vector machines (SVM) as classifier for deepfake detection. The use of two classifiers (RF) and (SVM) and their combination with a convolutional neural network is the first study of its kind in the field of deepfake detection in images from three open-source datasets (FaceForensics++, FaceAntiSpoofing, and iFakeFaceDB). This proposed method shows an accuracy of 96%, 87% and 52% in iFakeFaceDB, CelebA-Spoof, FaceForensics++ and respectively.;;979-8-3503-9463-4;10.1109/HORA61326.2024.10550728;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10550728;"Convolutional neural network;DeepFake detection;Machine learning";"Support vector machines;Deep learning;Training;Deepfakes;Soft sensors;Data models;Convolutional neural networks";;4;;34;IEEE;12 Jun 2024;23-25 May 2024;23-25 May 2024;IEEE;IEEE Conferences
Investigating the Impact of Visual Attention Models in Face Forgery Detection;"A. Yadav; D. K. Vishwakarma";"Department of Information Technology, Delhi Technological University, Delhi, India; Department of Information Technology, Delhi Technological University, Delhi, India";2023 International Conference on Applied Intelligence and Sustainable Computing (ICAISC);9 Aug 2023;2023;;;1;7;With the recent rise of realistic face manipulation methods, building robust face tampering detection methods has become more important than ever before. Visual attention has played an important role in highlighting discriminative regions within input which is important for making accurate predictions. This manuscript presents a comparative study of several recently proposed visual attention models for the problem of face forgery detection. Specifically, five visual attention models namely, coordinate, selective kernel, triplet, CoT, and shuffle attention have been tested by integrating with a baseline deep learning model. The modified visually attentive architectures are trained and tested on popular public benchmark dataset FaceForensics++. The experimental results achieved by different attention approaches are compared. Additionally, the computational costs involved in each type of attention have also been discussed specifying the accuracy and computation tradeoff. Experimental results prove that Triplet Attention performs best by achieving accuracy scores of 0.9543 and 0.7190 on DF and NT categories of the FF++ dataset. Triplet attention is also extremely lightweight with only 1200 trainable parameters compared to the other attention modules under study.;;979-8-3503-2379-5;10.1109/ICAISC58445.2023.10199338;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10199338;"Visual attention;Face forgery;Face tampering;deepfake;attention;detection";"Deep learning;Visualization;Computational modeling;Computer architecture;Benchmark testing;Forgery;Computational efficiency";;2;;39;IEEE;9 Aug 2023;16-17 June 2023;16-17 June 2023;IEEE;IEEE Conferences
No Matter Small or Big Lip Motion: DeepFake Detection with Regularized Feature Learning on Semantic Information;"Z. Yang; L. -p. Chau; B. Wen";"Nanyang Technological University; The Hong Kong Polytechnic University; Nanyang Technological University";2023 IEEE 6th International Conference on Multimedia Information Processing and Retrieval (MIPR);22 Sep 2023;2023;;;1;6;The use of DeepFake technologies to create hyper-realistic faces has sparked serious security concerns. Recent advances on DeepFake detection showed promise on algorithm generalization to unseen manipulation methods by identifying high-level semantic irregularities. However, the extracted features are not always robust, as the sample variations such as different motion magnitudes can easily degrade the feature-vector representations of their semantic information. In this work, we propose DTNet, a novel deep method that further regularizes feature learning toward more robust DeepFake Detection. To be specific, the proposed DTNet contains Deviation Regularization that penalizes samples with deviated motion magnitudes in the loss function, and Temporal Continuity Preservation, which helps keep and learn patterns of temporal continuity in feature space regardless of motion magnitudes. Experimental results show that our method effectively mitigates the impact of motion magnitudes on feature vectors, thereby improving the generalization ability.;2770-4319;979-8-3503-0781-8;10.1109/MIPR59079.2023.00034;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10254427;"Deepfake detection;semantic information;regularization;loss function";"Representation learning;Deepfakes;Lips;Semantics;Information processing;Feature extraction;Security";;;;24;IEEE;22 Sep 2023;30 Aug.-1 Sept. 2023;30 Aug.-1 Sept. 2023;IEEE;IEEE Conferences
EfficientNetB0 Ensemble Model for Unified Deepfakes Detection;"S. A. Minhas; S. Mushtaq; A. Javed";"Software Engineering Department, University of Engineering and Technology, Taxila, Pakistan; Software Engineering Department, University of Engineering and Technology, Taxila, Pakistan; Software Engineering Department, University of Engineering and Technology, Taxila, Pakistan";2023 17th International Conference on Open Source Systems and Technologies (ICOSST);31 Jan 2024;2023;;;1;5;In recent years, we have witnessed the generation of exceptional authentic deepfake images and videos due to the availability of cutting-edge Artificial Intelligence and deep learning techniques. Deepfakes represent synthetic multimedia content used to propagate disinformation for defamation, political unrest, manipulating elections, committing crimes, etc. In this paper, we present a novel ReLU-Swish EfficientNet (RSE-Net) for deepfakes detection. Our proposed RSE-Net is capable of reliably detecting deepfakes videos that are generated using different techniques. Our model leverages an ensemble of EfficientNet architectures, which are combined using a fusion technique to enhance the model’s performance in detecting deepfakes. We suggested the ReLU activation in conv2D layers in place of regular Swish activation in EfficientNetB0 first variant as ReLU is computationally more efficient and reduces the risk of overfitting. We evaluated our model on two large-scale challenging deepfake datasets: FaceForensics ++ and CelebDF. Our RSE-Net attained an average accuracy of 99.7% on the FaceForensics++ dataset, and 96.09% on the CelebDF dataset. Furthermore, our model generalizes well and effectively detects deepfake videos in realworld scenarios. Thus, it is a valuable tool for analyzing and detecting potentially manipulated content.;2770-8225;979-8-3503-8132-0;10.1109/ICOSST60641.2023.10414228;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10414228;"Deepfake detection;Celeb-DF;FaceForensics ++;Ensemble model;Fused-EfficientNet";"Deep learning;Deepfakes;Computational modeling;Voting;Computer architecture;Media;Streaming media";;;;20;IEEE;31 Jan 2024;20-21 Dec. 2023;20-21 Dec. 2023;IEEE;IEEE Conferences
XWSB: A Blend System Utilizing XLS-R and Wavlm With SLS Classifier Detection System for SVDD 2024 Challenge;"Q. Zhang; S. Wen; F. Yan; T. Hu; J. Li";"College of Intelligent Systems Science and Engineering, Hubei Minzu University, Enshi, China; School of Mathematics and Statistics, Hubei Minzu University, Enshi, China; College of Intelligent Systems Science and Engineering, Hubei Minzu University, Enshi, China; College of Intelligent Systems Science and Engineering, Hubei Minzu University, Enshi, China; College of Intelligent Systems Science and Engineering, Hubei Minzu University, Enshi, China";2024 IEEE Spoken Language Technology Workshop (SLT);16 Jan 2025;2024;;;788;794;This paper introduces the model structure used in the SVDD 2024 Challenge. The SVDD 2024 challenge has been introduced this year for the first time. Singing voice deepfake detection (SVDD) which faces complexities due to informal speech intonations and varying speech rates. In this paper, we propose the XWSB system, which achieved SOTA performance in the SVDD challenge. XWSB stands for XLS-R, WavLM, and SLS Blend, representing the integration of these technologies for the purpose of SVDD. Specifically, we used the best performing model structure XLS-R&SLS from the ASVspoof DF dataset, and applied SLS to WavLM to form the WavLM&SLS structure. Finally, we integrated two models to form the XWSB system. Experimental results show that our system demonstrates advanced recognition capabilities in the SVDD challenge, specifically achieving an EER of 2.32% in the CtrSVDD track. The code and data can be found at https://github.com/QiShanzhang/XWSB_for_ SVDD2024.;;979-8-3503-9225-8;10.1109/SLT61566.2024.10832183;"Natural Science Foundation of Hubei Province; ";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10832183;"Singing Voice Deepfake Detection;Audio deepfake detection;WavLM;XLS-R";"Training;Adaptation models;Deepfakes;Codes;Conferences;Data models;Complexity theory;Faces";;2;;25;IEEE;16 Jan 2025;2-5 Dec. 2024;2-5 Dec. 2024;IEEE;IEEE Conferences
Critical Information Only: a Content Privacy-Preserving Framework for Detecting Audio Deepfakes;"X. Li; Y. Zheng; C. Yan; K. Li; C. Zeng; X. Ji; W. Xu";"College of Computing and Data Science, Nanyang Techno logical University, Singapore; College of Electrical Engineering and the Ubiquitous System Security Lab (USSLab), Zhejiang University, Hangzhou, China; College of Electrical Engineering and the Ubiquitous System Security Lab (USSLab), Zhejiang University, Hangzhou, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; National Institute of Informatics, Tokyo, Japan; College of Electrical Engineering and the Ubiquitous System Security Lab (USSLab), Zhejiang University, Hangzhou, China; College of Electrical Engineering and the Ubiquitous System Security Lab (USSLab), Zhejiang University, Hangzhou, China";IEEE Transactions on Dependable and Secure Computing;;2025;PP;99;1;18;Text-to-Speech (TTS) and Voice Conversion (VC) models have exhibited remarkable performance in generating realistic and natural audio. However, their dark side, audio deepfake poses a significant threat to both society and individuals. Existing countermeasures largely focus on determining the genuineness of speech based on complete original audio recordings, which however often contain private content. This oversight may refrain deepfake detection from many applications, particularly in scenarios involving sensitive information like business secrets. In this paper, we propose SafeEar, a novel framework that aims to detect deepfake audios without relying on accessing the speech content within. Our key idea is to devise a neural audio codec into a novel decoupling model that well separates the semantic and acoustic information from audio samples, and only use the acoustic information (e.g., prosody and timbre) for deepfake detection. In this way, no semantic content will be exposed to the detector. To overcome the challenge of identifying diverse deepfake audio without semantic clues, we enhance our deepfake detector with real-world augmentation, such as codecs and reverbs. Extensive experiments conducted on five benchmark datasets demonstrate SafeEar's effectiveness in detecting various deepfake techniques with an equal error rate (EER) down to 2.41%. Simultaneously, it shields five-language speech content from being deciphered by both machine and human auditory analysis, demonstrated by word error rates (WERs) all above 93.74% and our user study. Furthermore, our benchmark constructed for anti-deepfake and anti-content recovery evaluation helps provide a basis for future research in the realms of audio privacy preservation and deepfake detection.;1941-0018;;10.1109/TDSC.2025.3624972;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11216043;"Content Privacy Preservation;Audio Deepfake Detection";"Deepfakes;Acoustics;Semantics;Detectors;Privacy;Feature extraction;Codecs;Benchmark testing;Protection;Pipelines";;;;;IEEE;23 Oct 2025;;;IEEE;IEEE Early Access Articles
Comparative Evaluation of Xception and DenseNet121 for Robust Deepfake Detection;"K. Yesugade; R. Jadhav";"Department of Computer Engineering, Bharati Vidyapeeth (Deemed to be University), College of Engineering, Pune, India; Department of Computer Engineering, Bharati Vidyapeeth (Deemed to be University), College of Engineering, Pune, India";2025 12th International Conference on Computing for Sustainable Global Development (INDIACom);21 Aug 2025;2025;;;1;5;Generative adversarial networks (GANs) have led to rapid advancement of deepfake technology, the authenticity of which poses a major challenge to digital media. In this study, two deep learning architectures, Xception and DenseNet121, are evaluated in terms of how well they can differentiate real and fake faces. The models were trained on normalized and augmented data using a curated dataset of $\mathbf{1 4 0, 0 0 0}$ images, half real faces from the Flickr dataset, the other half-synthetic faces generated by StyleGAN. With a training accuracy of 86.31 % and a test accuracy of 73.00 %, Xception model also shows strong feature extraction power. Validation accuracy (77.00 %) of DenseNet121 was slightly better than in validation accuracy (76.00 %) but more sensitive to dataset conditions. Performance graphs served to further illustrate the complementary strengths of the two models, lending support for the applicability of ensemble methods to improve detection robustness. This study highlights the benefits of advanced architectures, data preparation rigour, and ensemble approaches to combat deepfake. Future work should concentrate on improving generalization, interpretability, robustness to evolving challenges in the area of digital media authentication.;;978-93-80544-60-1;10.23919/INDIACom66777.2025.11115841;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11115841;"Deepfake detection;Xception;DenseNet121;Deep learning;Digital media authenticity;GAN";"Deep learning;Deepfakes;Accuracy;Media;Feature extraction;Data models;Robustness;Ensemble learning;Web sites;Faces";;;;23;;21 Aug 2025;2-4 April 2025;2-4 April 2025;IEEE;IEEE Conferences
Hiding Faces in Plain Sight: Defending DeepFakes by Disrupting Face Detection;"D. Zhu; Y. Li; B. Wu; J. Zhou; Z. Wang; S. Lyu";"School of Computer Science and Technology, Ocean University of China, Qingdao, China; School of Computer Science and Technology, Ocean University of China, Qingdao, China; School of Data Science, Chinese University of Hong Kong, Shenzhen, China; School of Computer Science and Technology, Ocean University of China, Qingdao, China; School of Cyber Science and Technology, Zhejiang University, Hangzhou, China; University at Buffalo, Getzville, NY, USA";IEEE Transactions on Dependable and Secure Computing;12 Nov 2025;2025;22;6;7010;7024;Face-swapping DeepFakes have become an escalating societal concern, attracting increasing attention in recent years. To counter this, we investigate a new proactive defense framework to prevent individuals from being victimized in DeepFake videos. The core idea of this framework is to contaminate the inputs of DeepFake models by disrupting face detectors, based on the observation that face detectors are commonly used to automatically extract victim faces in most DeepFake techniques. Once the face detectors malfunction, the faces will not be correctly extracted, thereby impairing the training or synthesis stages of DeepFake models. To achieve this, we describe a strategy named FacePoison, which fools face detectors by adding dedicated adversarial perturbations to video frames. Building upon this, we introduce VideoFacePoison, an extended strategy that can efficiently propagate FacePoison across video frames instead of applying it individually to each frame, thus significantly reducing the computational overhead while retaining favorable attack performance. This framework is validated on five face detectors, and extensive experiments against eleven different DeepFake models demonstrate the effectiveness of disrupting face detectors to hinder DeepFake generation.;1941-0018;;10.1109/TDSC.2025.3592230;"National Natural Science Foundation of China(grant numbers:62402464); Natural Science Foundation of Shandong Province(grant numbers:ZR2024QF035); China Postdoctoral Science Foundation(grant numbers:2021TQ0314,2021M703036); Sanya Science and Technology Special Fund(grant numbers:2022KJCX92); National Natural Science Foundation of China(grant numbers:62102380); Natural Science Foundation of Shandong Province(grant numbers:ZR2021QF095,ZR2024MF083); Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2024B1515020095); National Natural Science Foundation of China(grant numbers:62076213); Shenzhen Science and Technology Program(grant numbers:RCYX20210609103057050);";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11106399;"DeepFake defense;multimedia forensics;face detection";"Faces;Deepfakes;Detectors;Training;Face detection;Perturbation methods;Iterative methods;Forgery;Forensics;Toxicology";;;;89;IEEE;31 Jul 2025;Nov.-Dec. 2025;;IEEE;IEEE Journals
ADA-FInfer: Inferring Face Representations From Adaptive Select Frames for High-Visual-Quality Deepfake Detection;"J. Hu; J. Liang; Z. Qin; X. Liao; W. Zhou; X. Lin";"College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; Department of Computing, The Hong Kong Polytechnic University, Hong Kong; College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; CAS Key Laboratory of Electromagnetic Space Information, University of Science and Technology of China, Anhui, China; School of Computer Science, University of Guelph, Guelph, ON, Canada";IEEE Transactions on Dependable and Secure Computing;14 May 2025;2025;22;3;3011;3027;Interpretable deepfake detection is gaining attention for providing explainable, trustworthy results, avoiding the limitations of ‘black-box’ models. Current interpretable methods focus on visible artifacts in low-visual-quality deepfakes, but these artifacts become less apparent in high-visual-quality deepfakes generated by advanced models. With advancements in deep generative models, producing high-visual-quality deepfakes has become a strategy to evade detection. To address this, we propose ${\sf ADA-FInfer}$ADA-FInfer, an adaptive frame selection and interpretable face representation inference method for detecting high-visual-quality deepfakes. ${\sf ADA-FInfer}$ADA-FInfer adaptively selects frames by analyzing optical flow to reveal manipulations. We also introduce an adaptive attack method that manipulates specific frames, and our adaptive selection strategy shows resistance to such attacks. ${\sf ADA-FInfer}$ADA-FInfer uses an encoder to learn face representations from source and target faces, applying a representation-prediction loss to maximize the distinction between real and fake videos. To provide further insights, we employ the joint entropy, mutual information, and conditional entropy analyses to explain the method's effectiveness. Extensive experiments and ablation studies demonstrate that ${\sf ADA-FInfer}$ADA-FInfer achieves promising performance in detecting high-visual-quality deepfakes.;1941-0018;;10.1109/TDSC.2024.3523289;"National Natural Science Foundation of China(grant numbers:U22A2030,U20A20174,61972142,62402062); National Key Research and Development Program of China(grant numbers:2024YFF0618800,2022YFB3103500); Science Fund for Distinguished Young Scholars of Hunan Province(grant numbers:2024JJ2025); Natural Science Foundation of Changsha City, China(grant numbers:kq2402031); MOE AcRF TIER 3(grant numbers:MOE-MOET32022-0001);";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10818493;"Adaptive frame selection;deepfake detection;high-visual-quality deepfake videos;inferring face representations";"Deepfakes;Faces;Feature extraction;Entropy;Predictive models;Color;Biological system modeling;Adaptation models;Training;Prediction algorithms";;3;;74;IEEE;30 Dec 2024;May-June 2025;;IEEE;IEEE Journals
Hybrid Deepfake Detection Utilizing MLP and LSTM;"J. Mallet; N. Krueger; R. Dave; M. Vanamala";"Department of Computer Science, University of Wisconsin – Eau Claire, Eau Claire, WI, USA; Department of Computer Science, University of Wisconsin – Eau Claire, Eau Claire, WI, USA; Department of Computer Information Science, Minnesota State University, Mankato Mankato, MN, USA; Department of Computer Science, University of Wisconsin – Eau Claire, Eau Claire, WI, USA";2023 3rd International Conference on Electrical, Computer, Communications and Mechatronics Engineering (ICECCME);22 Sep 2023;2023;;;1;5;The growing reliance of society on social media for authentic information has done nothing but increase over the past years. This has only raised the potential consequences of the spread of misinformation. One of the growing methods in popularity is to deceive users through the use of a deepfake. A deepfake is a new invention that has come with the latest technological advancements, which enables nefarious online users to replace one's face with a computer-generated, synthetic face of numerous powerful members of society. Deepfake images and videos now provide the means to mimic important political and cultural figures to spread massive amounts of false information. Models that are able to detect these deepfakes to prevent the spread of misinformation are now of tremendous necessity. In this paper, we propose a new deepfake detection schema utilizing two deep learning algorithms: long short-term memory and multilayer perceptron. We evaluate our model using a publicly available dataset named 140k Real and Fake Faces to detect images altered by a deepfake with accuracies achieved as high as 74.7%.;;979-8-3503-2297-2;10.1109/ICECCME57830.2023.10252552;"University of Wisconsin-Eau Claire; ";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10252552;"Deepfake;Machine Learning;Fake Image Detection;Long Short-Term Memory;Multilayer Perceptron";"Deep learning;Deepfakes;Technological innovation;Mechatronics;Social networking (online);Computational modeling;Multilayer perceptrons";;16;;22;IEEE;22 Sep 2023;19-21 July 2023;19-21 July 2023;IEEE;IEEE Conferences
BMNet: Enhancing Deepfake Detection Through BiLSTM and Multi-Head Self-Attention Mechanism;"D. Xiong; Z. Wen; C. Zhang; D. Ren; W. Li";"School of Communication Engineering, Chengdu University of Information Technology, Chengdu, China; School of Communication Engineering, Chengdu University of Information Technology, Chengdu, China; School of Communication Engineering, Chengdu University of Information Technology, Chengdu, China; School of Communication Engineering, Chengdu University of Information Technology, Chengdu, China; School of Communication Engineering, Chengdu University of Information Technology, Chengdu, China";IEEE Access;5 Feb 2025;2025;13;;21547;21556;When forgery techniques can generate highly realistic videos, traditional convolutional neural network (CNN)-based detection models often struggle to capture subtle forgery features and temporal dependencies. Most existing models focus on feature extraction from static frames, neglecting the temporal correlation in videos, which decreases accuracy in detecting dynamic forged videos. Furthermore, the ability to detect localized forgery features remains insufficient. To address these limitations, we propose a deep forgery detection framework named BiLSTM Multi-Head Self-Attention Network (BMNet). By leveraging the Bi-Directional Long Short-Term Memory Network (BiLSTM) for modeling temporal dependencies between video frames, and the Multi-Head Self-Attention Mechanism (MHSA) for capturing features from different regions of an image, BMNet more effectively identifies dynamic and local forgery features. In our experiments, we extract features from 68 facial landmarks of each video frame and evaluate detection performance on four datasets: UADFV, FF++, Celeb-DF and DFDC. The results show significant improvements over traditional methods. We further validate the necessity of each network component through ablation studies, demonstrating that BMNet achieves accuracies of 95.54%, 92.18%, 80.20% and 84.72% on the FF++, UADFV, Celeb-DF and DFDC datasets, respectively, indicating its superior performance in deep forgery detection.;2169-3536;;10.1109/ACCESS.2025.3533653;"Sichuan Province Science and Technology Department; Sichuan Province Major Science and Technology Project(grant numbers:24JBGS0050); Sichuan Province Philosophy and Social Science Research Project(grant numbers:SC23TJ006); Undergraduate Education and Teaching Research and Reform Project of Chengdu University of Information Technology(grant numbers:JYJG2023169,JYJG2023046); Industry-School Cooperative Education Project of Ministry of Education(grant numbers:202002230010,202101014067,202101291013,220500643270506);";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10852294;"Deepfake;deepfake video detection;bi-directional long short-term memory network;multi-head self-attention mechanism";"Deepfakes;Forgery;Feature extraction;Bidirectional long short term memory;Mouth;Face recognition;Solid modeling;Deep learning;Physiology;Faces";;9;;35;CCBY;24 Jan 2025;2025;;IEEE;IEEE Journals
A Detailed Exploration to Deepfake: A Cybersecurity Threat;"G. Kasera; M. Solanki; H. Kaur; K. Shah";"Computer Science and Engineering, Pandit Deendayal Energy University, Gandhinagar, India; Computer Science and Engineering, Pandit Deendayal Energy University, Gandhinagar, India; Computer Science and Engineering, Pandit Deendayal Energy University, Gandhinagar, India; Computer Science and Engineering, Pandit Deendayal Energy University, Gandhinagar, India";2025 IEEE International Students' Conference on Electrical, Electronics and Computer Science (SCEECS);2 Apr 2025;2025;;;1;6;The advancement of AI-technologies has brought both innovation and considerable challenges particularly with the emergence of deep fakes-realistic but false images, videos or audios created using deep learning algorithms. These deepfakes pose a serious threat as they can spread misleading information or content which are utilized for malicious purposes. This paper focuses on the creation of deepfake and emphasizing on various models like GANs, CNNs, and LSTMs. This paper also provides a comparative analysis of various deepfake detection techniques and prevention measures to take into considerations.;2688-0288;979-8-3315-2983-3;10.1109/SCEECS64059.2025.10940812;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10940812;"Deepfake;Generative Adversarial Networks (GANs);Convolutional Neural Networks (CNNs);Recurrent Neural Networks;Long Short-Term Memory (LSTM);Deepfake Detection;Cybercrime;Fake Media Prevention;Misinformation";"Deep learning;Computer science;Deepfakes;Technological innovation;Recurrent neural networks;Prevention and mitigation;Generative adversarial networks;Convolutional neural networks;Computer crime;Long short term memory";;;;20;IEEE;2 Apr 2025;18-19 Jan. 2025;18-19 Jan. 2025;IEEE;IEEE Conferences
DeepFakeGuard: Real-Time Deepfake Video Detection Leveraging Celeb-DF Dataset and CNN-LSTM Framework;"V. S R; P. K. M; A. S. V N G; S. G";"Department of Information Technology, Velammal College of Engineering and Technology, Madurai, Tamilnadu; Department of Information Technology, Velammal College of Engineering and Technology, Madurai, Tamilnadu; Department of Information Technology, Velammal College of Engineering and Technology, Madurai, Tamilnadu; Department of Information Technology, Velammal College of Engineering and Technology, Madurai, Tamilnadu";2025 5th International Conference on Expert Clouds and Applications (ICOECA);13 Aug 2025;2025;;;744;750;Deepfake technology has significantly eroded the veracity of digital media across the world, raising concerns of misinformation and media manipulation. To counteract this, we have developed DeepFakeGuard, a powerful deepfake detection system with robust deep learning algorithms present on the web. The system works to identify deepfake videos by checking each subsequent frame for irregularities, for instance, unbalanced lip movements, abrupt light changes, or unnatural cuts. DeepFakeGuard has been pre-trained on a wide variety of datasets primarily focused on the Celeb-DF dataset with high-quality and challenging-to-detect deepfake content. This provides the system with flexibility and precision for multiple applications such as short-form broadcast, high-definition video streams, and live streams. The initial step was preprocessing of data meticulously with focus on neatness and elimination of data noise to ensure the model works at its best. We then employed the latest deep learning architectures, a combination of Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs), to detect the slightest disparities between subsequent frames. Our models have been exhaustively tested to identify tampered content from real media at high accuracy levels. The web-based system provides real-time detection of deepfake, with the ability to upload media files to be detected in real-time. In addition, its robust backend infrastructure for processing video prevents disruption in smooth processing, making DeepFakeGuard deployable on a wide variety of environments such as content moderation, digital forensics, and media verification. The result of our work is evidence of how DeepFakeGuard can enhance digital media security through effective deepfake content detection.;;979-8-3315-2447-0;10.1109/ICOECA66273.2025.00133;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11113856;"Deepfake detection;Deep learning algorithms;Celeb-DF dataset;Real-time detection;Convolutional Neural Networks (CNNs);Recurrent Neural Networks (RNNs)";"Deep learning;Deepfakes;Recurrent neural networks;Accuracy;Lips;Media;Real-time systems;Robustness;Convolutional neural networks;Long short term memory";;;;15;IEEE;13 Aug 2025;6-7 March 2025;6-7 March 2025;IEEE;IEEE Conferences
Improving Generalization in Facial Manipulation Detection Using Image Noise Residuals and Temporal Features;"M. Atamna; I. Tkachenko; S. Miguet";"CNRS, INSA Lyon, UCBL, Centrale Lyon, LIRIS, UMR5205, Univ Lyon, Univ Lyon 2, Bron, France; CNRS, INSA Lyon, UCBL, Centrale Lyon, LIRIS, UMR5205, Univ Lyon, Univ Lyon 2, Bron, France; CNRS, INSA Lyon, UCBL, Centrale Lyon, LIRIS, UMR5205, Univ Lyon, Univ Lyon 2, Bron, France";2023 IEEE International Conference on Image Processing (ICIP);11 Sep 2023;2023;;;3424;3428;The high visual quality of modern deepfakes raises significant concerns about the trustworthiness of digital media and makes facial tampering detection more challenging. Although current deep learning-based deepfake detectors achieve excellent results when tested on deepfake images or image sequences generated using known methods, generalization—where a trained model is tasked with detecting deepfakes created with previously unseen manipulation techniques—is still a major challenge. In this paper, we investigate the impact of training spatial and spatio-temporal deep learning network architectures in the image noise residual domain using spatial rich model (SRM) filters on generalization performance. To this end, we conduct a series of tests on the manipulation methods of the FaceForensics++, DeeperForensics-1.0 and Celeb-DF datasets, demonstrating the value of image noise residuals and temporal feature exploitation in tackling the generalization task.;;978-1-7281-9835-4;10.1109/ICIP49359.2023.10222043;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10222043;"Deepfake detection;video manipulation detection;image forensics;steganalysis features";"Training;Deep learning;Deepfakes;Visualization;Sensitivity;Video compression;Feature extraction";;5;;19;IEEE;11 Sep 2023;8-11 Oct. 2023;8-11 Oct. 2023;IEEE;IEEE Conferences
Beyond Accuracy: Explainable Multimodal Deepfake Detection Through Cross-Modal Feature Analysis and Dynamic Attention Weighting;"T. Rahman; R. Chakma; T. Mahmud";"Department of Computer Science and Engineering, Rangamati Science and Technology University; Department of Computer Science and Engineering, Rangamati Science and Technology University; Department of Computer Science and Engineering, Rangamati Science and Technology University";2025 International Conference on Quantum Photonics, Artificial Intelligence, and Networking (QPAIN);29 Sep 2025;2025;;;1;6;The advent of deepfake technology in recent years has significantly transformed the domain of video synthesis, facilitating the production of convincing synthetic films. The study explains a method for detecting deepfakes that uses both visual and sound analysis with special neural networks and a technique that combines the two types of information. We have a system that uses an EfficientNetB0- based CNN to analyze face images and a bidirectional LSTM to process audio features, showing that combining both types of data makes detection stronger than using just one type. Our research on the AVLips dataset shows that different types of data learn in different ways-visual features help with quick learning at first but are more likely to overfit, while audio features lead to a more consistent learning process. Using explainable AI methods, we find that visual deepfake signs are mainly seen around the eyes and mouth, while specific MFCC coefficients (specifically 2 and 9) offer important distinguishing information in the audio part. The fusion model attains an accuracy of 87.25 %, surpassing the visual-only model at 85.25 % and the audio-only model at 81 %. In addition to performance measurements, our study offers important information regarding feature relevance across modalities and illustrates how attention mechanisms may adjust modality contributions depending on the reliability of individual samples. This study improves the field by highlighting the benefits of understanding multimodal methods and identifying specific patterns across different types of data that characterize deepfake content.;;979-8-3315-9694-1;10.1109/QPAIN66474.2025.11171737;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11171737;"CNN;EfficientNetBO;LSTM;MFCC;AVLips;Deepfake Detection;Multimodal";"Deepfakes;Visualization;Accuracy;Attention mechanisms;Mouth;Production;Media;Feature extraction;Robustness;Mel frequency cepstral coefficient";;;;24;IEEE;29 Sep 2025;31 July-2 Aug. 2025;31 July-2 Aug. 2025;IEEE;IEEE Conferences
It Wasn’t Me: Irregular Identity in Deepfake Videos;"H. Liu; P. Bestagini; L. Huang; W. Zhou; S. Tubaro; W. Zhang; N. Yu";"University of Science and Technology of China, Hefei, China; Politecnico di Milano, Milan, Italy; Politecnico di Milano, Milan, Italy; University of Science and Technology of China, Hefei, China; Politecnico di Milano, Milan, Italy; University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China";2023 IEEE International Conference on Image Processing (ICIP);11 Sep 2023;2023;;;2770;2774;"With the rapid development in media generation technologies, the creation of DeepFake videos is within everyone’s reach. As the widespread diffusion of DeepFakes can lead to severe consequences (e.g., defamation, fake news spreading, etc.), detecting DeepFakes is becoming a crucial task within the forensic community. However, most of the existing DeepFake detectors suffer from two issues: i) they are hardly explainable as they build upon black-box data-driven techniques rather than interpretable features; ii) they are often tailored to low-level texture features, failing to generalize on low-quality DeepFake videos. In this work we propose a video DeepFake detector that aims at solving these issues. The proposed detector relies on the fact that most DeepFake generators work on a frame-by-frame basis, thus breaking the temporal consistency of facial features across frames. In particular, we noticed that facial identity features tend to be less stable in time on DeepFake videos than original ones. We therefore propose a framework trained on time series of facial identity features. The use of high-level semantic features makes the detector interpretable and robust against low-quality DeepFake videos. Extensive experiments show that our method achieves outstanding performance on low-quality DeepFake video and obtains promising results on unseen dataset evaluation. The code is available at https://github.com/HongguLiu/Identity-Inconsistency-DeepFake-Detection";;978-1-7281-9835-4;10.1109/ICIP49359.2023.10222654;"China Scholarship Council; University of Science and Technology of China; ";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10222654;"DeepFake Detection;Identity Inconsistency;Interpretability;Robustness";"Deepfakes;Image coding;Forensics;Semantics;Time series analysis;Detectors;Feature extraction";;4;;31;IEEE;11 Sep 2023;8-11 Oct. 2023;8-11 Oct. 2023;IEEE;IEEE Conferences
Advanced Temporal Analysis for Deepfake Detection using XceptionNet in Media Forensics;"K. M; L. S; K. S; A. D. J";"Department of CSE, Karpagam Academy of Higher Education, Coimbatore, India; Department of CSE, Karpagam Academy of Higher Education, Coimbatore, India; Department of CSE, Karpagam Academy of Higher Education, Coimbatore, India; Department of CSE, Faculty of Engineering, Karpagam Academy of Higher Education, Coimbatore, India";2025 8th International Conference on Computing Methodologies and Communication (ICCMC);4 Sep 2025;2025;;;1224;1228;Deepfakes videos through advanced AI models, pose a significant threat due to their deceptive realism. This paper presents a deepfake detection framework based on XceptionNet, which provides depthwise separable convolutions for fine-grained image analysis. The proposed system processes both static images and video by detecting and aligning faces, enabling consistent frame-level analysis. Furthermore, for videos, each frame is analyzed using XceptionNet, followed by temporal feature extraction through LSTM and CNN to capture subtle facial expressions and motion variations. The model was evaluated on multiple datasets, achieving strong precision, recall, and F1-scores at both frame and video levels. Results show that the XceptionNet-based approach reliably distinguishes real from manipulated content. However, limitations remain due to dataset diversity and computational complexity, highlighting directions for future research.;;979-8-3315-1211-8;10.1109/ICCMC65190.2025.11140668;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11140668;"Deepfake Detection;Media Forensics. XceptionNet;Generative Models;Artificial Intelligence;Synthetic Media;Face Detection;Temporal Feature Analysis";"Deepfakes;Computational modeling;Forensics;Media;Feature extraction;Real-time systems;Face detection;Computational complexity;Artificial intelligence;Long short term memory";;;;15;IEEE;4 Sep 2025;23-25 July 2025;23-25 July 2025;IEEE;IEEE Conferences
Development of AI/ML-based solution for detection of face-swap based deepfake videos and AI-generated videos;"S. Jayanth Sai Chethan; J. Chand; K. Bhakta; M. J. K. Bhai; P. Piruthiviraj";"Department of Information Science and Engineering, HKBK College of Engineering, Bangalore, India; Department of Information Science and Engineering, HKBK College of Engineering, Bangalore, India; Department of Information Science and Engineering, HKBK College of Engineering, Bangalore, India; Department of Information Science and Engineering, HKBK College of Engineering, Bangalore, India; Department of Information Science and Engineering, HKBK College of Engineering, Bangalore, India";2025 IEEE International Conference on Contemporary Computing and Communications (InC4);1 Dec 2025;2025;;;1;6;The increasing sophistication of deep learning techniques has led to a surge in hyper-realistic deepfake videos and AI-generated media, raising significant concerns about digital security, privacy, and content integrity. Addressing this challenge, we propose an advanced AI/ML-based framework for detecting manipulated media with high precision. Our approach integrates Convolutional Neural Networks (CNNs) for spatial feature extraction, Long Short-Term Memory (LSTM) networks for capturing temporal inconsistencies, and transformer architectures, such as Vision Transformers (ViTs), for enhanced feature extraction. To enhance model robustness, we employ transfer learning and ensemble learning, training on comprehensive datasets such as FaceForensics++, Celeb-DF, and the Deepfake Detection Challenge (DFDC). Our system achieves an accuracy of $95 \%$ while maintaining a low false positive rate, demonstrating superior generalizability across different compression levels and deepfake creation techniques. Beyond detection, this research has crucial implications for digital forensics, misinformation mitigation, and automated content moderation. Future enhancements will focus on multimodal detection, incorporating audio analysis and efficiency optimizations for real-time applications.;;979-8-3315-2118-9;10.1109/InC465408.2025.11256330;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11256330;"Deepfake Video Detection;AI-Generated Video Detection;Convolutional Neural Network (CNN);Recurrent Neural Network (RNN)";"Training;Deepfakes;Recurrent neural networks;Transfer learning;Computer architecture;Transformers;Feature extraction;Convolutional neural networks;Surges;Long short term memory";;;;13;IEEE;1 Dec 2025;14-15 March 2025;14-15 March 2025;IEEE;IEEE Conferences
Short And Low Resolution Deepfake Video Detection Using CNN;"A. Rahman; N. Siddique; M. J. Moon; T. Tasnim; M. Islam; M. Shahiduzzaman; S. Ahmed";"Dept. of CSE, BUBT, Dhaka, Bangladesh; Dept. of CSE, BUBT, Dhaka, Bangladesh; Dept. of CSE, BUBT, Dhaka, Bangladesh; Dept. of CSE, BUBT, Dhaka, Bangladesh; Dept. of CSE, BUBT, Dhaka, Bangladesh; Dept. of CSE, BUBT, Dhaka, Bangladesh; Dept. of CSE, BUBT, Dhaka, Bangladesh";2022 IEEE 10th Region 10 Humanitarian Technology Conference (R10-HTC);3 Nov 2022;2022;;;259;264;Recently, convincing deepfake videos are growing very fast that can delude even the trained experts. These deepfake videos have huge impacts all over the world covering the political, social, and personal lives. The state-of-the-art machine learning studies are demonstrating noticeable success to detect fake videos in high resolution and long-time video data while the same performance is not observed in low resolution and short-time clips. In this work, we have trained a convolutional neural network (CNN) that demonstrates mentionable accuracy in detecting fake videos in low-resolution and short-time video data. We have exploited Kaggle Deepfake Detection Challenge (DFDC) and the Face Forensics++ datasets in our experiment. Our model shows 94.93% accuracy in detecting fake videos for the DFDC dataset while the same is 93.2% for FaceForensics++ Dataset. We evaluated our models by different performance metrics and compared the performance with state-of-the-art methods. Our model demonstrates comparable performance.;2572-7621;978-1-6654-0156-2;10.1109/R10-HTC54060.2022.9929719;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9929719;"Deepfake Video;Machine-Learning;dlib;Convolutional Neural Network(CNN);Deepfake-Detection-Challenge(DFDC);FaceForensics++";"Measurement;Deep learning;Deepfakes;Media;Convolutional neural networks;Faces;IEEE Regions";;13;;36;IEEE;3 Nov 2022;16-18 Sept. 2022;16-18 Sept. 2022;IEEE;IEEE Conferences
Hybrid Recurrent Deep Learning Model for DeepFake Video Detection;G. Jaiswal;ICT Research Lab, Department of Computer Science, University of Lucknow, Lucknow, India;2021 IEEE 8th Uttar Pradesh Section International Conference on Electrical, Electronics and Computer Engineering (UPCON);10 Jan 2022;2021;;;1;5;Nowadays deepfake videos are concern with social ethics, privacy and security. Deepfake videos are synthetically generated videos that are generated by modifying the facial features and audio features to impose one person’s facial data and audio to other videos. These videos can be used for defaming and fraud. So, counter these types of manipulations and threats, detection of deepfake video is needed. This paper proposes multilayer hybrid recurrent deep learning models for deepfake video detection. Proposed models exploit the noise-based temporal facial convolutional features and temporal learning of hybrid recurrent deep learning models. Experiment results of these models demonstrate its performance over stacked recurrent deep learning models.;2687-7767;978-1-6654-0962-9;10.1109/UPCON52273.2021.9667632;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9667632;"Deepfake detection;Hybrid Recurrent model;Deep learning;Deepfake video;video temporal feature";"Deep learning;Privacy;Computational modeling;Stacking;Nonhomogeneous media;Security;Task analysis";;12;;32;IEEE;10 Jan 2022;11-13 Nov. 2021;11-13 Nov. 2021;IEEE;IEEE Conferences
A Measurement Study on Gray Channel-based Deepfake Detection;"S. B. Son; S. H. Park; Y. K. Lee";"Department of Information Security Seoul Women's University, Seoul, Republic of Korea; Department of Information Security Seoul Women's University, Seoul, Republic of Korea; Department of Information Security Seoul Women's University, Seoul, Republic of Korea";2021 International Conference on Information and Communication Technology Convergence (ICTC);7 Dec 2021;2021;;;428;430;Deepfake detection techniques have been widely studied to resolve security issues. However, existing techniques mainly focused on RGB channel-based analysis, which still shows incomplete detection accuracy. In this paper, we validate the performance of Gray channel-based deepfake detection. To compare RGB channel-based analysis and Gray channel-based analysis in deepfake detection, we quantitatively measured the performance by using popular CNN models, deepfake datasets, and evaluation indicators. Our experimental results confirm that Gray channel-based deepfake detection outperforms RGB channel-based deepfake detection in terms of accuracy and analysis time.;2162-1233;978-1-6654-2383-0;10.1109/ICTC52510.2021.9621082;"MIST(Ministry of Science, ICT)(grant numbers:2016-0-00022);";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9621082;"deepfake detection;gray-channel analysis;deep learning;deepfake";"Deep learning;Analytical models;Brightness;Information and communication technology;Security;Videos;Information integrity";;2;;26;IEEE;7 Dec 2021;20-22 Oct. 2021;20-22 Oct. 2021;IEEE;IEEE Conferences
Deepfake Detection using a Two-Stream Capsule Network;"Z. Joseph; C. Nyirenda";"Department of Computer Science, University of the Western Cape, Robert Sobukwe Road, Bellville, South Africa; Department of Computer Science, University of the Western Cape, Robert Sobukwe Road, Bellville, South Africa";2021 IST-Africa Conference (IST-Africa);26 Oct 2021;2021;;;1;8;This paper aims to address the problem of Deepfake Detection using a Two-Stream Capsule Network. First we review methods used to create Deepfake content, as well as methods proposed in the literature to detect such Deepfake content. We then propose a novel architecture to detect Deepfakes, which consists of a two-stream Capsule network running in parallel that takes in both RGB images/frames as well as Error Level Analysis images. Results show that the proposed approach exhibits the detection accuracy of 73.39 % and 57.45 % for the Deepfake Detection Challenge (DFDC) and the Celeb-DF datasets respectively. These results are, however, from a preliminary implementation of the proposed approach. As part of future work, population-based optimization techniques such as Particle Swarm Optimization (PSO) will be used to tune the hyper parameters for better performance.;2576-8581;978-1-905824-67-0;;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9577010;"Deepfake;Deepfake detection;face tampering;deep learning;convolutional neural networks;Capsule networks;Error Level Analysis";"Training;Analytical models;Computational modeling;Neural networks;Computer architecture;Particle swarm optimization;Optimization";;1;;21;;26 Oct 2021;10-14 May 2021;10-14 May 2021;IEEE;IEEE Conferences
Leveraging Deep Learning Methods for Detecting Deepfake Speeches;"R. A. Samiha; M. T. Alom; R. Hossain; R. Islam; A. Sultana";"Dept. of Computer Science & Eng., World University of Bangladesh, Dhaka, Bangladesh; Dept. of Computer Science & Eng., World University of Bangladesh, Dhaka, Bangladesh; Dept. of Computer Science & Eng., World University of Bangladesh, Dhaka, Bangladesh; Dept. of Software Eng., Daffodil International University, Dhaka, Bangladesh; School of Computer Science & Technology, Algoma University, Brampton, ON, Canada";2025 IEEE 4th International Conference on Computing and Machine Intelligence (ICMI);8 Sep 2025;2025;;;1;5;Synthetic speeches, infamously known as Audio Deepfakes (AD), can easily become a menacing tool if they fall into the wrong hands. Moreover, social networks, which are highly vulnerable to deepfake attacks, can potentially cause social chaos. In order to tackle any potential harm, the misuse of deepfakes needs to be prevented. Especially for deepfake audio, detection methods are crucial to tackling the spread of deepfake speeches. In this study, we proposed a deep learning (DL) framework, the Convolutional Neural Network (CNN), to detect deepfake Bengali speeches. Through this study, we contributed to the resolution of certain research gaps, such as the limited number of dedicated researches and the scarcity of Bengali audio datasets comprising the Bengali domain in this field. The proposed model was applied on a set of primary self-created Bengali audio data. As a result, the CNN framework achieved the highest score of 98.24%, compared to a one-dimensional representation foundational CNN model.;;979-8-3315-0913-2;10.1109/ICMI65310.2025.11141035;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11141035;"deepfake;audio classification;artificial intelligence;deep learning;synthetic speech;deepfake detection";"Deep learning;Training;Deepfakes;Accuracy;Recurrent neural networks;Social networking (online);Computer architecture;Feature extraction;Convolutional neural networks;Speech synthesis";;;;15;IEEE;8 Sep 2025;5-6 April 2025;5-6 April 2025;IEEE;IEEE Conferences
MVFNet: Multipurpose Video Forensics Network using Multiple Forms of Forensic Evidence;"T. D. Nguyen; M. C. Stamm";"Drexel University, Philadelphia, PA, USA; Drexel University, Philadelphia, PA, USA";2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV);8 Apr 2025;2025;;;2207;2217;While videos can be falsified in many different ways, most existing forensic networks are specialized to detect only a single manipulation type (e.g. deepfake, inpainting). This poses a significant issue as the manipulation used to falsify a video is not known a priori. To address this problem, we propose MVFNet - a multipurpose video forensics network capable of detecting multiple types of manipulations including inpainting, deepfakes, splicing, and editing. Our network does this by extracting and jointly analyzing a broad set of forensic feature modalities that capture both spatial and temporal anomalies in falsified videos. To re-liably detect and localize fake content of all shapes and sizes, our network employs a novel Multi-Scale Hierarchi-cal Transformer module to identify forensic inconsistencies across multiple spatial scales. Experimental results show that our network obtains state-of-the-art performance in general scenarios where multiple different manipulations are possible, and rivals specialized detectors in targeted scenarios.;2642-9381;979-8-3315-1083-1;10.1109/WACV61041.2025.00221;"National Science Foundation(grant numbers:2320600);";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10943483;"video forensics;forensics;deepfake detection;inpainting detection;splicing detection;editing detection;general solution;computer vision";"Deepfakes;Computer vision;Shape;Forensics;Splicing;Detectors;Transformers;Feature extraction";;;;77;IEEE;8 Apr 2025;26 Feb.-6 March 2025;26 Feb.-6 March 2025;IEEE;IEEE Conferences
Towards Spatio-temporal Collaborative Learning: An End-to-End Deepfake Video Detection Framework;"W. Guo; S. Du; H. Deng; Z. Yu; L. Feng";"Dalian University of Technology, Dalian, China; Dalian University of Technology, Dalian, China; Dalian University of Technology, Dalian, China; Dalian University of Technology, Dalian, China; School of Innovation and Entrepreneurship, Dalian University of Technology, Dalian, China";2023 International Joint Conference on Neural Networks (IJCNN);2 Aug 2023;2023;;;1;8;With the rapid development of facial tampering techniques, the deepfake detection task has attracted widespread social concerns. Most existing video-based methods adopt temporal convolution to learn temporal discontinuities directly, where they might neglect to explore both local detail mutation and inconsistent global expression semantics in the temporal dimension. This makes it difficult to learn more discriminative forgery cues. To mitigate this issue, we introduce a novel deepfake video detection framework specifically designed to capture fine-grained traces of tampering. Concretely, we first present a Multi-layered Feature Extraction module (MFE) that constructs comprehensive spatio-temporal representations by stitching different levels of features together. Afterward, we propose a Bidirectional temporal Artifact Enhancement module (BAE), which exploits local differences between adjacent frames to enhance frame-level features. Moreover, we present a Cross temporal Stride Aggregation strategy (CSA) to mine inconsistent global semantics and adaptively obtain multi-timescale representations. Extensive experiments on several benchmarks demonstrate that the proposed method outperforms state-of-the-art performance compared to other competitive approaches.;2161-4407;978-1-6654-8867-9;10.1109/IJCNN54540.2023.10191479;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10191479;"Deepfake Detection;Spatio-temporal Modeling;Face Forensics;Deep Learning";"Deepfakes;Visualization;Federated learning;Semantics;Neural networks;Detectors;Benchmark testing";;1;;27;IEEE;2 Aug 2023;18-23 June 2023;18-23 June 2023;IEEE;IEEE Conferences
Comparative Study: Deepfake Detection in Tamil Speech using Hybrid Convolutional Networks;"M. F. M; B. M. G.";"Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Chennai; Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Chennai";2025 International Conference on Wireless Communications Signal Processing and Networking (WiSPNET);19 May 2025;2025;;;1;5;In today’s digital landscape, the rise of deepfake content poses a serious challenge to maintaining trust and authenticity online. This paper focuses on detecting deepfake Tamil speech by leveraging advanced machine-learning techniques. Our dataset consists of two classes: ’fake’ and ’real,’ representing synthetic and authentic Tamil speech recordings, respectively. We use simple yet effective methods like Chromagram, MFCC, and Mel spectrogram to extract key features from the audio data. These features are then fed into two models: a Convolutional Neural Network-Long Short-Term Memory (CNN-LSTM) and a Support Vector Machine (SVM). The CNN-LSTM excels at identifying patterns in spectrogram data, while the SVM handles classification tasks efficiently. Our experiments demonstrate the effectiveness of our approach in accurately distinguishing between genuine and falsified Tamil speech, achieving a validation accuracy of 0.9742 for the CNN-LSTM model and 0.96 for the CNN-GRU model. This research contributes to enhancing the security and credibility of digital content in Tamil-speaking communities. By employing straightforward machine learning techniques, we aim to combat the spread of synthetic media manipulation and foster a safer online environment for all users.;;979-8-3315-2422-7;10.1109/WiSPNET64060.2025.11005318;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11005318;"Deepfake Detection;Chromagram;MFCC;Mel Spectrogram;CNN-LSTM;SVM;Audio Feature Extraction";"Support vector machines;Wireless communication;Training;Deepfakes;Accuracy;Media;Feature extraction;Convolutional neural networks;Mel frequency cepstral coefficient;Spectrogram";;;;21;IEEE;19 May 2025;20-22 March 2025;20-22 March 2025;IEEE;IEEE Conferences
Deepfakes Examiner: An End-to-End Deep Learning Model for Deepfakes Videos Detection;"H. Ilyas; A. Irtaza; A. Javed; K. M. Malik";"Software Engineering Department, University of Engineering and Technology, Taxila, Pakistan; Computer Science Department, University of Engineering and Technology, Taxila, Pakistan; Software Engineering Department, University of Engineering and Technology, Taxila, Pakistan; Computer Science and Engineering Department, Oakland University Rochester, MI, USA";2022 16th International Conference on Open Source Systems and Technologies (ICOSST);18 Jan 2023;2022;;;1;6;Deepfakes generation approaches have made it possible even for less technical users to generate fake videos using only the source and target images. Thus, the threats associated with deepfake video generation such as impersonating public figures, defamation, and spreading disinformation on media platforms have increased exponentially. The significant improvement in the deepfakes generation techniques necessitates the development of effective deepfakes detection methods to counter disinformation threats. Existing techniques do not provide reliable deepfakes detection particularly when the videos are generated using different deepfakes generation techniques and contain variations in illumination conditions and diverse ethnicities. Therefore, this paper proposes a novel hybrid deep learning framework, InceptionResNet-BiLSTM, that is robust to different ethnicities and varied illumination conditions, and able to detect deepfake videos generated using different techniques. The proposed InceptionResNet-BiLSTM consists of two components: customized InceptionResNetV2 and Bidirectional Long-Short Term Memory (BiLSTM). In our proposed framework, faces extracted from the videos are fed to our customized InceptionResNetV2 for extracting frame-level learnable features. The sequences of features are then used to train a temporally aware BiLSTM to classify between the real and fake video. We evaluated our proposed approach on the diverse, standard, and largescale FaceForensics++ (FF++) dataset containing videos manipulated using different techniques (i.e., DeepFakes, FaceSwap, Face2Face, FaceShifter, and NeuralTextures) and the FakeA VCeleb dataset. Our method achieved an accuracy greater than 90% on DeepFakes, FaceSwap, and Face2Face subsets. Performance and generalizability evaluation highlights the effectiveness of our method for detecting deepfake videos generated through different techniques on diverse FF++ and FakeA VCeleb datasets.;2770-8225;978-1-6654-6477-2;10.1109/ICOSST57195.2022.10016871;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10016871;"Bidirectional LSTM;Deepfakes Detection;FaceForensics++;FakeAVCeleb;InceptionResNetV2;Puppet-master;Face-swap";"Deep learning;Deepfakes;Visualization;Lighting;Media;Feature extraction;Robustness";;15;;27;IEEE;18 Jan 2023;14-15 Dec. 2022;14-15 Dec. 2022;IEEE;IEEE Conferences
The Impact of Data Augmentation on Deepfake Detection: A Comparative Study of CNN and Transformer Models;"N. H. Abdul Ameer; M. Al-Taee; A. S. T. Hussain; A. Hussian; H. Ali";"University of Technology, Baghdad, Iraq; Al-Farahidi University, Baghdad, Iraq; Department of Medical Instrumentation Techniques Engineering, Technical Engineering College, Al-Kitab University, Altun Kupri, Kirkuk, Iraq; Technical Computer Engineering Department, Al-Kunooze University College, Basrah, Iraq; Department of Cybersecurity and Cloud Computing Technical Engineering, Uruk University, Baghdad, Iraq";2025 IEEE 4th International Conference on Computing and Machine Intelligence (ICMI);8 Sep 2025;2025;;;1;6;As AI becomes increasingly prevalent in our daily lives, the rise of deepfake technology presents a significant challenge for digital forensics and security, necessitating the development of robust detection models to help distinguish between real and fake media. In this work, We study the effect of data augmentation on deepfake classification performance using CNN-based and Transformer based networks. XceptionNet, ResNet-50, EfficientNet-B3, ViT-B/16, and ConvNeXt-Small are evaluated on the Deepfake Detection Challenge (DFDC) dataset and augmentation operations consist of rotating, color jitter, Gaussian noise and random erasing. The results also indicate that CNN-based models exceed the performance of Transformer-based architectures, as XceptionNet achieves an accuracy score of 94% and an F1-score of 0.94, while ViT-B/16 performs poorly, achieving an accuracy of 82%. These show that augmentation helps improve robustness for CNN models, while Transformer models show a less effective performance in this setup. The paper offered guidance on optimizing data preprocessing approaches for deepfake identification and proposed further investigation of hybrid CNN-Transformer architectures that could empower models to be more effective in detecting fake images.;;979-8-3315-0913-2;10.1109/ICMI65310.2025.11141228;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11141228;"Deepfake Detection;Data Augmentation;XceptionNet;ResNet-50;Vision Transformers;Hybrid CNNTransformer Models;Deepfake Detection Challenge (DFDC)";"Training;Deepfakes;Accuracy;Computational modeling;Transformers;Data augmentation;Data models;Robustness;Real-time systems;Security";;;;22;IEEE;8 Sep 2025;5-6 April 2025;5-6 April 2025;IEEE;IEEE Conferences
Advancing Generalization in Deepfake Detection: Supervised Contrastive Representation Learning With Dual Stream Spatio-Temporal Features;"S. Son; W. Kim";"Department of Industrial Engineering, Yonsei University, Seodaemun-gu, Seoul, South Korea; Department of Industrial Engineering, Yonsei University, Seodaemun-gu, Seoul, South Korea";IEEE Access;28 Aug 2025;2025;13;;148646;148667;Deepfake technologies have rapidly evolved, enabling highly realistic facial manipulations that are increasingly difficult to detect. However, existing detection models remain limited in their ability to generalize beyond the manipulation techniques used during training. As deepfake generation methods continue to diversify, enhancing generalization has become critical for deployment in real-world scenarios. To address this challenge, this paper proposes a robust and generalizable deepfake detection framework based on supervised contrastive learning. Rather than overfitting to generation-specific artifacts, the proposed method learns discriminative representations by integrating domain- and similarity-aware contrastive loss with distributional regularization. The framework adopts a dual-stream architecture consisting of a 3D CNN (I3D with Non-Local Blocks) to capture temporal dynamics and a 2D CNN (ResNet) for spatial features. The extracted features are fused and passed to a support vector machine (SVM) classifier to refine decision boundaries. Extensive experiments on FaceForensics++, Celeb-DF, and DFDC datasets demonstrate that the proposed model achieves superior generalization performance across diverse and unseen deepfake generation techniques, outperforming existing methods in cross-dataset settings. Additionally, explainability analyses validate the model’s focus on meaningful facial regions. Appendix experiments also highlight its potential for efficient deployment with minimal performance loss.;2169-3536;;10.1109/ACCESS.2025.3598782;"Industrial Strategic Technology Development Program-Advanced Technology Center Plus (ATC+) (Development of Life Cycle Management Platform by Providing Artificial Intelligence-Based Real-Time Model Observability and Explainability) funded by the Ministry of Trade, Industry and Energy (MOTIE), South Korea(grant numbers:20023280); financially supported by the Korea Ministry of Land, Infrastructure and Transport (MOLIT) as the Innovative Talent Education Program for Smart City;";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11124838;"Attention mechanisms;contrastive learning;cross-dataset evaluation;deepfake;deepfake detection;explainable artificial intelligence;feature extraction;generalization";"Deepfakes;Faces;Feature extraction;Training;Anomaly detection;Accuracy;Computational modeling;Visualization;Unsupervised learning;Image reconstruction";;;;53;CCBY;14 Aug 2025;2025;;IEEE;IEEE Journals
Deepfake Generation, Detection and Datasets: a Rapid-review;"A. KoÇak; M. Alkan";"Electrical Electronics Engineering, Gazi University, Ankara, Turkey; Electrical Electronics Engineering, Gazi University, Ankara, Turkey";2022 15th International Conference on Information Security and Cryptography (ISCTURKEY);4 Nov 2022;2022;;;86;91;Deepfake is the general expression of fake images or videos. Images and videos created with Deep Neural Networks (DNN) can cause both personal and national problems. Deepfake technology has been making progress day by day. Accordingly, both the detection methods and the diversity of the data sets to be trained are increasing. In this article, datasets created in deepfake technology and applications that use datasets for deepfake detection are evaluated. The data sets used are produced with different models. There exist both traditional and deep learning-based detection methods for deepfake detection. Due to the recent malicious use of deepfake technology, detection methods and methods to be used in applications are of great importance. When the detection methods are compared, the accuracy of the deep learning-based detection method is higher for each data set. The method that provides the highest accuracy among two different data sets is the Xception method.;;978-1-6654-5603-6;10.1109/ISCTURKEY56345.2022.9931802;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9931802;"Deepfake;DNN;traditional detection method;deep learning-based detection method;Xception";"Deep learning;Deepfakes;Neural networks;Genetic expression;Psychology;Information security;Entertainment industry";;4;;38;IEEE;4 Nov 2022;19-20 Oct. 2022;19-20 Oct. 2022;IEEE;IEEE Conferences
Deepfake Detection Using AI And Machine Learning Algorithms;"G. Chandel; A. Kumar; K. Malik; K. Gurani; K. Gahlawat; S. K. Saini";"ECE Department, Chandigarh University, Punjab, India; Mechanical Department, Chandigarh University, Punjab, India; Mechanical Department, Chandigarh University, Punjab, India; Mechanical Department, Chandigarh University, Punjab, India; Mechanical Department, Chandigarh University, Punjab, India; ECE Department, Chandigarh University, Punjab, India";2025 IEEE International Conference on Computer, Electronics, Electrical Engineering & their Applications (IC2E3);24 Sep 2025;2025;;;1;6;Deepfake technology has rapidly evolved, which makes it difficult to differentiate between real and AI-generated content. The malicious use of deep fake technology has raised some serious concerns. Deepfake face-swapping is commonly practiced across the internet and has raised a huge number of concerns in society. How to detect deepfake content is nowadays a very popular research topic. This paper presents a comprehensive study of deep fake detection techniques using Artificial intelligence (AI) and machine learning (ML) algorithms. In this work, various detection techniques have been analysed using different approaches, including audio, image, and video-based deepfake detection models. The study highlights recent advancements, challenges, methods and potential future research directions. Furthermore, the legal concerns about using deepfake technology in unethical ways have been discussed. Additionally, this paper also examines the effectiveness of different datasets and benchmarks in detecting deepfake content.;;979-8-3315-2439-5;10.1109/IC2E365635.2025.11167331;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11167331;"Deepfake;Deep Learning;Machine Learning;Video Forensics;Generative Adversarial Networks (GANs);Deep-fake Detection;Cross-Modal Detection";"Deepfakes;Machine learning algorithms;Text analysis;Forensics;Self-supervised learning;Media;Benchmark testing;Transformers;Forgery;Standards";;;;18;IEEE;24 Sep 2025;15-16 May 2025;15-16 May 2025;IEEE;IEEE Conferences
A Survey on Deepfake Video Detection Techniques Using Deep Learning;"A. Das; K. S. A. Viji; L. Sebastian";"M-Tech Scholar Dept. of Computer Science and Engg, College of Engineering, Kidangoor, Kerala, India; Dept. of Computer Science and Engg, College of Engineering, Kidangoor, Kerala, India; Dept. of Computer Science and Engg, College of Engineering, Kidangoor, Kerala, India";2022 Second International Conference on Next Generation Intelligent Systems (ICNGIS);30 Mar 2023;2022;;;1;4;Deep learning is an effective technology that has been widely used in different ways. ‘DeepFake’ videos are generated using deep learning technology called generative adversarial network where the videos are created with swaped faces in a video, altered facial expressions, change of gender, creation of fake video content and altered facial features. Fake videos are used in the situations like extortion of money, terrorism events or create political agitation. The deepfake technologies are used for positive purposes, such as film-making and virtual reality. The good quality results from deepfakes are very hard to recognised with people eyes. Many deep learning techniques are built to detect deepfake content in images and videos. A comparative study of the performance of various deepfake videos detection models in the deep learning is preseted in this paper. Convolutional Neural Network (CNN) models include ResNet, VGG16, Efficientnet etc.. Recurrent Neural Network (RNN) model includes Long Short-Term Memory LSTM.;;978-1-6654-6792-6;10.1109/ICNGIS54955.2022.10079802;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10079802;"Deepfake video detection;Convolutional neural network (CNN);Recurrent neural network (RNN);Support vector machine (SVM)";"Deep learning;Deepfakes;Solid modeling;Recurrent neural networks;Terrorism;Support vector machine classification;Virtual reality";;10;;15;IEEE;30 Mar 2023;29-31 July 2022;29-31 July 2022;IEEE;IEEE Conferences
Detection of Deepfake Video using Deep Learning and MesoNet;"L. Rebello; L. Tuscano; Y. Shah; A. Solomon; V. Shrivastava";"Computer Engineering Department, SFIT, Mumbai; Computer Engineering Department, SFIT, Mumbai; Computer Engineering Department, SFIT, Mumbai; Computer Engineering Department, SFIT, Mumbai; Computer Engineering Department, SFIT, Mumbai";2023 8th International Conference on Communication and Electronics Systems (ICCES);1 Aug 2023;2023;;;1022;1026;Fraudsters are increasingly using evidence tampering to evade criminal charges and the acquisition of personal data for identity-related offenses. Deepfake is one of the most common strategies used today for identity theft and reputation defamation. To prevent the spread of these crimes, we need a system that can tell the difference between real and deep fake videos. Deep Neural Networks will be used in our system to identify and mark films as legitimate or manipulated, as well as the altered sections, by running the video through our trained Sequence Model, which can detect any discrepancies or alterations as a sequence of frames. LSTM will be used for temporal sequence analysis, and CNN will be employed for frame feature extraction. MesoNet is a neural network built primarily to identify deep fakes, but it would also be used for other purposes. MesoNet manages the noise produced by low-quality video processing, which impedes analysis. DeepFakes jeopardizes facial recognition and internet content. This deception is risky and can be exploited to impersonate a legitimate user. Our approach will propose a temporal-aware method for automatically detecting deepfake videos.;;979-8-3503-9663-8;10.1109/ICCES57224.2023.10192854;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10192854;"DeepFake Detection;Deep Learning;Neural Networks;Convolution Neural Network;Recurrent Neural Network;Long Short-Term Memory;MesoNet";"Deepfakes;Freeware;Sequences;Limiting;Social networking (online);Films;Face recognition";;4;;15;IEEE;1 Aug 2023;1-3 June 2023;1-3 June 2023;IEEE;IEEE Conferences
Deepfake Image Detection Using Yolov8;"P. Sathe; V. Sabane; C. Undale; A. Uttarkar; V. Chavhan; N. P. Sable; A. Yenkikar";"Department of CSE – Artificial Intelligence, Vishwakarma Institute of Information Technology, Pune, India; Department of CSE – Artificial Intelligence, Vishwakarma Institute of Information Technology, Pune, India; Department of CSE – Artificial Intelligence, Vishwakarma Institute of Information Technology, Pune, India; Department of CSE – Artificial Intelligence, Vishwakarma Institute of Information Technology, Pune, India; Department of CSE – Artificial Intelligence, Vishwakarma Institute of Information Technology, Pune, India; Department of CSE – Artificial Intelligence, Vishwakarma Institute of Information Technology, Pune, India; Department of CSE – Artificial Intelligence, Vishwakarma Institute of Information Technology, Pune, India";2024 IEEE Pune Section International Conference (PuneCon);27 Feb 2025;2024;;;1;5;Due to growing number of fake media and the possible problems with misinformation and identity theft, deepfake image recognition has become a hot topic. In order to evaluate the efficacy of widely recognized deep learning models in detecting and classifying deepfake images, we compare and contrast YOLO (You Only Look Once) V8, CNN (Convolutional Neural Network), combination of LSTM (Long Short-Term Memory) with CNN and ResNet in this paper. The capacity to recognize photos that have been manipulated effectively is essential for maintaining trust regarding digital media and preventing the spread of deceptive data. The objective of our research is to explain each model's abilities, limitations and performance in the context of deepfake image recognition. We evaluated each model's accuracy, precision, and F1-scores using a dataset of 190402 images, half real and half fake that cover a wide spectrum of deep fake images. Based on the evaluation metrics, each model was ranked in terms of its ability to separately describe and determine original versus generated photos with focus on detecting subtle changes eluding human senses. The comparison research shows each model's nuanced capabilities, offering light on the implications for applications in the real world like detecting and controlling the spread of deep fake information across numerous internet platforms. Our findings help towards building deep fake detection systems, further understanding the comparative performance of state of the art deep architectures. This study shall inform more effective deep fake detection systems that can guarantee trust and security in digital media environments. Accuracy achieved by model is 96%, precision score was 94%, recall value is 0.98, F1 score has a value of 0.95.;2831-5022;979-8-3315-2782-2;10.1109/PuneCon63413.2024.10895706;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10895706;"Deepfake detection;Image classification;YOLOV8;Long Short-Term Memory;Convolutional Neural Network;ResNet;Deep Learning";"YOLO;Deepfakes;Accuracy;Image recognition;Computational modeling;Scalability;Computer architecture;Convolutional neural networks;Security;Long short term memory";;;;22;IEEE;27 Feb 2025;13-15 Dec. 2024;13-15 Dec. 2024;IEEE;IEEE Conferences
CNN based Deep Learning model for Deepfake Detection;"V. Jolly; M. Telrandhe; A. Kasat; A. Shitole; K. Gawande";"Computer Engineering Department, Sardar Patel Institute of Technology, Mumbai, India; Computer Engineering Department, Sardar Patel Institute of Technology, Mumbai, India; Computer Engineering Department, Sardar Patel Institute of Technology, Mumbai, India; Computer Engineering Department, Sardar Patel Institute of Technology, Mumbai, India; Computer Engineering Department, Sardar Patel Institute of Technology, Mumbai, India";2022 2nd Asian Conference on Innovation in Technology (ASIANCON);11 Oct 2022;2022;;;1;5;In the recent period there has been massive progress in synthetic image generation and manipulation which significantly raises concerns for its ill applications towards society. This would result in spreading false information, leading to loss of trust in digital content. This paper introduces an automated and effective approach to get facial expressions in videos, and especially focused on the latest method used to produce hyper realistic fake videos: Deepfake. Using faceforenc++ dataset for training our model, we achieved more that 99% successful detection rate in Deepfake, Face2Face, faceSwap and neural texture. Regular image forensics techniques are usually not very useful, because of the strong deterioration of data due to the compression. Thus, this paper follows a layered approach with first detecting the subject with the help of existing facial recognition networks followed by extracting facial features using CNN, then passing through the LSTM layer, where we make use of our temporal sequence for face manipulation between frames. Finally use of the Recycle-GAN which internally makes use of generative adversarial networks to merge spatial and temporal data.;;978-1-6654-6851-0;10.1109/ASIANCON55314.2022.9908862;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9908862;"Face Detection;FaceForensics++;DeepFake;Face2Face;FaceSwap;Neural Texture;Convolutional Neural Network (CNN);Long Short-Term Memory (LSTM)";"Training;Deepfakes;Technological innovation;Social networking (online);Face recognition;Transfer learning;Training data";;18;;10;IEEE;11 Oct 2022;26-28 Aug. 2022;26-28 Aug. 2022;IEEE;IEEE Conferences
Comparative Analysis and Evaluation of CNN Models for Deepfake Detection;"P. Ritter; D. Lucian; Anderies; A. Chowanda";"Computer Science Departement, School of Computer Science Bina Nusantara University, Jakarta, Indonesia; Computer Science Departement, School of Computer Science Bina Nusantara University, Jakarta, Indonesia; Computer Science Departement, School of Computer Science Bina Nusantara University, Jakarta, Indonesia; Computer Science Departement, School of Computer Science Bina Nusantara University, Jakarta, Indonesia";2023 4th International Conference on Artificial Intelligence and Data Sciences (AiDAS);23 Oct 2023;2023;;;250;255;Deepfake technology has become a significant concern due to its ability to create highly realistic fake videos and images, leading to the potential deception of individuals. Detecting deepfakes has become a critical research area in computer vision and multimedia forensics. This paper presents a comparative analysis of deepfake detection models, focusing on evaluating their accuracy and robustness. Four CNN models, namely ResNet-152, MobilenetV3, Convnext Large, and EffecientNetB7, were implemented and trained using a custom dataset obtained from FaceForensics++. The models were evaluated based on training accuracy, average loss, and testing accuracy. An LSTM layer was also incorporated into each model's architecture to leverage sequential information. The results demonstrate varying performance among the models, with EfficientNet B7 achieving the highest testing accuracy of 75%. The findings of this study provide insights for future research in this critical area.;;979-8-3503-1843-2;10.1109/AiDAS60501.2023.10284611;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10284611;"deepfake detection;CNN models;comparative analysis;accuracy;LSTM layer";"Training;Deepfakes;Analytical models;Computational modeling;Forensics;Focusing;Streaming media";;9;;22;IEEE;23 Oct 2023;6-7 Sept. 2023;6-7 Sept. 2023;IEEE;IEEE Conferences
A Robust Deepfake Video Detection Method based on Continuous Frame Face-swapping;"D. Liu; Z. Yang; R. Zhang; J. Liu";"School of Cyberspace Security Beijing University of Posts and Telecommunications, Beijing, China; School of Cyberspace Security Beijing University of Posts and Telecommunications, Beijing, China; School of Cyberspace Security Beijing University of Posts and Telecommunications, Beijing, China; School of Cyberspace Security Beijing University of Posts and Telecommunications, Beijing, China";2022 International Conference on Artificial Intelligence, Information Processing and Cloud Computing (AIIPCC);27 Mar 2023;2022;;;188;191;Detection of deepfake videos faces serious generalization problem in real world application scenarios. Existing robust deepfake detection methods can only works on single frame image but not continuous frame videos. In this paper, we propose a robust deepfake video detection method based on continuous frame face-swapping. We design our face-swapping dataset with Delaunay triangulation and piecewise affine transform to achieve continuous frame face-swapping. We design a feature enhancement module with facial and background information covered to make the method focus on the mask fusion zone. We build our detection model with Efficient Net to extract intra-frame fusion feature and LSTM to extract inter-frame time feature. Cross-domain experiments show that our method achieves better detection AUC than existing methods, which proves our method is robust because of generalization.;;978-1-6654-6287-7;10.1109/AIIPCC57291.2022.00048;"National Natural Science Foundation of China(grant numbers:U1936216,U21B2020,62002197);";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10070215;"deepfake detection;continuous frame face-swapping;generalization;Efficient Net;LSTM";"Deepfakes;Cloud computing;Computational modeling;Transforms;Information processing;Feature extraction;Artificial intelligence";;4;;10;IEEE;27 Mar 2023;19-21 Aug. 2022;19-21 Aug. 2022;IEEE;IEEE Conferences
Leveraging Acoustic Features and Deep Neural Architectures for Audio Deepfake Detection;"V. Sundaram; B. S; S. Vekkot";"Department of Electronics and Communication Engineering, Amrita School of Engineering, Bengaluru, Amrita Vishwa Vidyapeetham, India; Department of Electronics and Communication Engineering, Amrita School of Engineering, Bengaluru, Amrita Vishwa Vidyapeetham, India; Department of Electronics and Communication Engineering, Amrita School of Engineering, Bengaluru, Amrita Vishwa Vidyapeetham, India";2024 11th International Conference on Advances in Computing and Communications (ICACC);22 Jan 2025;2024;;;1;6;This research presents a comparative analysis of various audio features and high-level architectures for deefake detection with emphasis on computational efficiency. Several light-weight models are proposed as opposed to GAN-based approaches in literature for evaluating custom-generated deep-fakes. The model is trained on Fake or Real dataset and achieved commendable performance using MFCC-Conformer and MFCC-LSTM feature-model combinations by achieving 87.61% and 87.52% accuracy, respectively. Specifically, the MFCC-Conformer recorded a TN of 526 and a FN of 18, along with an AUC score of 0.96, while the MFCC-DenseNet achieved a TN of 535, an FN of 9, and an AUC score of 0.96, underscoring their effectiveness in identifying fake audios. The outcomes underscore the effectiveness of the proposed models in combating the proliferation of misleading media content.;2766-2829;979-8-3503-7913-6;10.1109/ICACC63692.2024.10845392;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10845392;"Audio Deepfake detection;Audio features;MFCC;Conformer;LSTM;DenseNet";"Deepfakes;Accuracy;Computational modeling;Computer architecture;Media;Feature extraction;Acoustics;Computational efficiency";;1;;25;IEEE;22 Jan 2025;6-8 Nov. 2024;6-8 Nov. 2024;IEEE;IEEE Conferences
Visual Deepfake Detection: Review of Techniques, Tools, Limitations, and Future Prospects;"N. Ur Rehman Ahmed; A. Badshah; H. Adeel; A. Tajammul; A. Daud; T. Alsahfi";"Department of Computing, Hamdard University, Islamabad Campus, Islamabad, Pakistan; Department of Software Engineering, University of Sargodha, Sargodha, Pakistan; Department of Computing, Hamdard University, Islamabad Campus, Islamabad, Pakistan; U.S.-Pakistan Center for Advanced Studies in Water, Mehran University of Engineering and Technology, Jamshoro, Sindh, Pakistan; Faculty of Resilience, Rabdan Academy, Abu Dhabi, United Arab Emirates; Department of Information Systems and Technology, College of Computer Science and Engineering, University of Jeddah, Jeddah, Saudi Arabia";IEEE Access;3 Jan 2025;2025;13;;1923;1961;In recent years, rapid advancements in deepfakes (incorporating Artificial Intelligence (AI), machine, and deep learning) have updated tools and techniques for manipulating multimedia. Though technology has primarily been utilized for beneficial purposes, such as education and entertainment, it is also used for malicious or unethical tasks to spread disinformation or ruin someone’s dignity, even if it encompasses harassing and blackmailing victims. Deepfakes refer to high-quality and realistic multimedia-manipulated content that has been digitally modified or synthetically generated. We conducted a systematic literature review of deepfake detection to offer an updated overview of existing research work that initially describes the widely accessible deepfake generation tools, classifications, and detection process. We highlighted recent techniques in visual deepfake detection based on the feature representations, grouped into four domains: spatial, temporal, frequency, and spatio-temporal, including their key features and limitations by providing details of existing datasets, together with the potentials of deepfake and its future directions. This study tried to add an updated repository of technological change in deepfake, which could help researchers to develop robust deepfake models.;2169-3536;;10.1109/ACCESS.2024.3523288;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10816641;"Deepfake detection;machine learning;deep learning;deepfake applications;deepfake datasets;deepfake generation tools";"Deepfakes;Face recognition;Deep learning;Faces;Training;Generators;Decoding;Social networking (online);Generative adversarial networks;Feature extraction";;9;;282;CCBY;27 Dec 2024;2025;;IEEE;IEEE Journals
FakeFormer: Transformer-Based Lightweight Deepfake Video Detection Model;"X. Wang; G. Zhong; Q. Song";"College of Computer Science and Technology, Ocean University of China, Qingdao, China; College of Computer Science and Technology, Ocean University of China, Qingdao, China; Bureau of Natural Resources, Qingdao West Coast New Area, Qingdao, China";2025 7th International Conference on Information Science, Electrical and Automation Engineering (ISEAE);24 Jun 2025;2025;;;856;859;In recent years, deepfake videos become increasingly realistic, making them nearly indistinguishable from the naked eye. The misuse of these deepfake videos poses a major threat to information security, leading researchers to develop effective deepfake video detection models. Video temporal features often contain rich and valuable information for identifying the authenticity of videos. Given that transformers have proven highly effective at modeling these features, researchers have been prompted to develop transformer-based detection models. However, due to the high-dimensional nature of video data, the efficiency of such models is often compromised, making it a challenging problem. In this paper, we propose a specialized transformer-based model for deepfake video detection, called FakeFormer. FakeFormer is a lightweight video-level detection model that maintains high efficiency, despite using a sequence of video frames as direct input. Additionally, FakeFormer fully integrates the strengths of convolutional neural networks and transformers, enabling it to effectively model both the temporal and spatial features of videos to accurately assess their authenticity. Numerous experiments validate the effectiveness of FakeFormer, including intra-dataset evaluation, cross-dataset evaluation and ablation study.;;979-8-3315-1038-1;10.1109/ISEAE64934.2025.11042069;"National Natural Science Foundation of China; Natural Science Foundation of Shandong Province; Ocean University of China; ";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11042069;"Deepfake detection;Spatio-temporal feature;Lightweight video transformer";"Deepfakes;Information science;Electric potential;Information security;Transformer cores;Transformers;Feature extraction;Forgery;Data models;Convolutional neural networks";;1;;13;IEEE;24 Jun 2025;18-20 April 2025;18-20 April 2025;IEEE;IEEE Conferences
Swin-BiLSTM with Attention for Face Swap Detection in Deepfake Videos;"N. F. Lukitania; V. Suryani";"School of Computing, Telkom University, Bandung, Indonesia; School of Computing, Telkom University, Bandung, Indonesia";2025 International Conference on Information and Communication Technology (ICoICT);14 Oct 2025;2025;;;1;6;Digital manipulation tools like deepfakes have advanced in sophistication because to the quick development of deep learning and artificial intelligence. Face swapping, in which one person’s face is swapped out for another, is one of the most alarming types of deepfakes. This technique produces incredibly lifelike movies that may deceive viewers. Detecting these manipulated videos is crucial to mitigating their negative impact on privacy and security. This paper proposes an ensemble approach to detecting face swap deepfakes by combining the Swin Transformer and Bidirectional Long Short-Term Memory (BiLSTM) with an attention mechanism. The Swin Transformer is employed for spatial feature extraction, while the BiLSTM captures temporal patterns between frames, and the attention mechanism focuses on the most relevant timesteps. The model is evaluated on the FaceForensics++ dataset, achieving a validation accuracy of 93.81% with a validation loss of 0.19, outperforming the Long Short-Term Memory (LSTM), Fully Convolutional Network (FCN), and Convolutional Neural Network - Bidi-rectional Long Short-Term Memory (CNN-BiLSTM) models. Experimental results demonstrate the superior ability of the Swin-BiLSTM With Attention model to accurately detect face swap manipulations, even under varying facial poses, lighting conditions, and motion variations. The proposed method shows promise in addressing the challenges of deepfake detection, offering potential applications in privacy protection, misinformation prevention, and security. Future work may explore the integration of additional data modalities or advanced techniques to further enhance detection accuracy and robustness.;;979-8-3315-0323-9;10.1109/ICoICT66265.2025.11192953;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11192953;"Deepfake Detection;Face Swap;Swin Transformer;BiLSTM;Attention Mechanism";"Deepfakes;Privacy;Attention mechanisms;Accuracy;Bidirectional long short term memory;Transformers;Robustness;Security;Convolutional neural networks;Faces";;;;18;IEEE;14 Oct 2025;30-31 July 2025;30-31 July 2025;IEEE;IEEE Conferences
Guardian AI: Synthetic Media Forensics through Multimodal Fusion and Advanced Machine Learning;"K. K; S. R; D. S; D. S";"Department of Computer Science and Business Systems, K.S.Rangasamy College of Technology, Namakkal, Tamil Nadu, India; Department of Computer Science and Business Systems, K.S.Rangasamy College of Technology, Namakkal, Tamil Nadu, India; Department of Computer Science and Business Systems, K.S.Rangasamy College of Technology, Namakkal, Tamil Nadu, India; Department of Computer Science and Business Systems, K.S.Rangasamy College of Technology, Namakkal, Tamil Nadu, India";2024 International Conference on Cognitive Robotics and Intelligent Systems (ICC - ROBINS);21 May 2024;2024;;;226;232;"The burgeoning spread of synthetic media disrupts content verification and threatens online trust. This research proposes Guardian AI, a robust deepfake detection system achieving 93% accuracy by harnessing the synergistic power of facial recognition, image forensics, and machine learning. Guardian AI extracts diverse features from videos: facial recognition models analyze landmarks, expressions, and lip-syncing for inconsistencies; image forensics algorithms detect manipulated pixels, lighting patterns, and compression artifacts; and temporal analysis captures unnatural head movements and frame-to-frame motion discrepancies. These multifaceted features are then fused and fed into a rigorously trained deep learning model on multi-modal datasets of real and deepfake videos. Guardian AI classifies video inputs as real or fake, providing a confidence score for its prediction. By leveraging facial recognition's subtle inconsistency detection, image forensics' manipulation artifact identification, and machine learning's robust multi-cue integration, Guardian AI achieves exceptional accuracy and generalizability, adapting to evolving deepfake creation techniques with its diverse training data. This study signifies a significant contribution to content verification by delivering a high accuracy deepfake detection system, paving the way for a more reliable and trustworthy online environment.";;979-8-3503-7274-8;10.1109/ICC-ROBINS60238.2024.10533980;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10533980;"Deepfake Detection;Facial Recognition;Image Forensics;Machine Learning;Multimodal Fusion;Content Verification";"Deepfakes;Image forensics;Ethics;Explainable AI;Face recognition;Feature extraction;Real-time systems";;1;;10;IEEE;21 May 2024;17-19 April 2024;17-19 April 2024;IEEE;IEEE Conferences
Neuro-Behavioral Deepfake Detection: Leveraging Human Micro-Expression Analysis for High-Precision Forgery Identification;"T. N. Kumar; A. GV; A. D; G. P; J. S";"Department of Computer Science and Engineering, Mahendra Engineering College, Tamil Nadu, India; Department of Computer Science and Engineering, Mahendra Engineering College, Tamil Nadu, India; Department of Computer Science and Engineering, Mahendra Engineering College, Tamil Nadu, India; Department of Computer Science and Engineering, Mahendra Engineering College, Tamil Nadu, India; Department of Computer Science and Engineering, Mahendra Engineering College, Tamil Nadu, India";2025 4th International Conference on Innovative Mechanisms for Industry Applications (ICIMIA);20 Oct 2025;2025;;;1155;1161;The swift advancement of deepfake technology has escalated concerns about the integrity of digital media, demanding innovative and robust detection strategies. Traditional methods, which primarily target visual inconsistencies such as unnatural facial movements or blending artifacts, are increasingly ineffective against sophisticated deepfake algorithms. This paper introduces the Micro-Expression Assisted Deepfake Detection (ME-ADD) model, a novel approach that enhances forgery detection by analyzing human micro-expressions—fleeting, involuntary facial movements that reveal authentic emotions and are difficult for AI to replicate accurately. By integrating a hierarchical convolutional recurrent neural network (HCRNN) for micro-expression recognition with established deepfake detection frameworks like XceptionNet, ME-ADD exploits subtle neuro-behavioral cues to achieve superior detection precision. This model combines temporal analysis of micro-expressions with spatial feature extraction to identify inconsistencies in manipulated videos, offering a significant advancement in media forensics. The proposed neuro-behavioral methodology not only addresses the limitations of conventional approaches but also provides a resilient solution to combat the growing threat of high-quality deepfakes in diverse applications, from social media to security.;;979-8-3315-5386-9;10.1109/ICIMIA67127.2025.11200578;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11200578;"Deepfake Detection;Micro-Expression Recognition;Neuro-Behavioral Analysis;Convolutional Neural Networks;Media Forensics";"Deepfakes;Analytical models;Visualization;Recurrent neural networks;Social networking (online);Forensics;Biological system modeling;Media;Feature extraction;Forgery";;;;18;IEEE;20 Oct 2025;3-5 Sept. 2025;3-5 Sept. 2025;IEEE;IEEE Conferences
Deepfake Facial Recognition for Video Clips;"Adarsh; N. Bhaal; G. Padmapriya";"Department of Computing Technologies, SRM Institute of Science and Technology, Kattankulathur, Chennai, India; Department of Computing Technologies, SRM Institute of Science and Technology, Kattankulathur, Chennai, India; Department of Computing Technologies, SRM Institute of Science and Technology, Kattankulathur, Chennai, India";2024 Parul International Conference on Engineering and Technology (PICET);21 Oct 2024;2024;;;1;6;The accessibility of deep learning tools has fueled the rise of convincing Deepfake videos. This research focuses on developing and evaluating an advanced Deepfake Facial Recognition system, integrating Long Short-Term Memory (LSTM) and ResNeXt CNNs. Utilizing CNNs for frame-level facial feature extraction and LSTM for temporal dependencies, the system excels in discerning nuanced manipulations. Extensively tested on diverse Deepfake content, our findings demonstrate the system's considerable accuracy in distinguishing between authentic and manipulated facial features. The integrated LSTM enhances sensitivity to subtle manipulations often overlooked by frame-based methods, while the ResNeXt CNN architecture improves overall precision. Rigorously evaluated on a diverse set of Deepfake-containing video clips, the system proves highly effective. The research also addresses challenges in Deepfake facial recognition, exploring potential countermeasures and contributing valuable insights to the development of robust systems mitigating risks associated with manipulated video content. The FaceForensic++ dataset model stands out with its remarkable precision, achieving an impressive accuracy rate of 97.76%. Meanwhile, the Celeb-DF dataset model has also performed admirably, boasting a competitive accuracy score of 93.97%.;;979-8-3503-6974-8;10.1109/PICET60765.2024.10716129;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10716129;"Deepfake Video Detection;ResNext CNN;LSTM";"Deep learning;Deepfakes;Accuracy;Sensitivity;Face recognition;Focusing;Streaming media;Feature extraction;Long short term memory;Facial features";;;;15;IEEE;21 Oct 2024;3-4 May 2024;3-4 May 2024;IEEE;IEEE Conferences
MRE-Net: Multi-Rate Excitation Network for Deepfake Video Detection;"G. Pang; B. Zhang; Z. Teng; Z. Qi; J. Fan";"School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; AI Laboratory, Lenovo Research, Beijing, China";IEEE Transactions on Circuits and Systems for Video Technology;3 Aug 2023;2023;33;8;3663;3676;The current social media is flooded with hyper realistic face-synthetic videos due to the explosion of DeepFake technology that has brought a serious impact on human society security, which calls for further exploring on deepfake video detection methods. Existing methods attempt to isolated capture spatial artifacts or extract the homogeneous temporal inconsistency to detect deepfake video, but little attention has been paid to the exploitation of dynamic spatial-temporal inconsistency. To mitigate this issue, in this paper, we propose a novel Multi-Rate Excitation Network (MRE-Net) to effectively excite dynamic spatial-temporal inconsistency from the perspective of multiple rates for deepfake video detection. The proposed MRE-Net is composed of two components: Bipartite Group Sampling (BGS) and multiple rate branches. The BGS draws the entire video into multiple bipartite groups with different rates to cover various face motion dynamic evolution. We further design multiple rate branches to capture both short-term and long-term spatial-temporal inconsistency from corresponding bipartite groups of BGS. Concretely, for the early stages of the multi-rate branches, Momentary Inconsistency Excitation (MIE) module is developed to encode the spatial artifacts and intra-group short-term temporal inconsistency. Meanwhile, for the last stages of the multi-rate branches, Longstanding Inconsistency Excitation (LIE) module is constructed to perceive inter-group long-term temporal dynamics. Extensive experiments and visualizations conducted on four popular datasets demonstrate the effectiveness of the proposed method against state-of-the-art deepfake detection methods.;1558-2205;;10.1109/TCSVT.2023.3239607;"Fundamental Research Funds for the Central Universities of China(grant numbers:2022JBMC009); Natural Science Foundation of China(grant numbers:61972027); Beijing Municipal Natural Science Foundation(grant numbers:4212041);";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10025759;"Deepfake detection;momentary inconsistency;longstanding inconsistency";"Deepfakes;Faces;Forgery;Feature extraction;Social networking (online);Three-dimensional displays;Frequency-domain analysis";;50;;60;IEEE;25 Jan 2023;Aug. 2023;;IEEE;IEEE Journals
DefakeHop: A Light-Weight High-Performance Deepfake Detector;"H. -S. Chen; M. Rouhsedaghat; H. Ghani; S. Hu; S. You; C. . -C. Jay Kuo";"University of Southern California, Los Angeles, California, USA; University of Southern California, Los Angeles, California, USA; University of Southern California, Los Angeles, California, USA; Army Research Laboratory, Adelphi, Maryland, USA; Army Research Laboratory, Adelphi, Maryland, USA; University of Southern California, Los Angeles, California, USA";2021 IEEE International Conference on Multimedia and Expo (ICME);9 Jun 2021;2021;;;1;6;A light-weight high-performance Deepfake detection method, called DefakeHop, is proposed in this work. State-of-the-art Deepfake detection methods are built upon deep neural networks. DefakeHop uses the successive subspace learning (SSL) principle to extracts features automatically from various parts of face images. The features are extracted by channel-wise (c/w) Saab transform and further processed by our feature distillation module using spatial dimension re-duction and soft classification for each channel to get a more concise description of the face. Extensive experiments are conducted to demonstrate the effectiveness of the proposed DefakeHop method. With a small model size of 42,845 parameters, DefakeHop achieves state-of-the-art performance with the area under the ROC curve (AUC) of 100%, 94.95%, and 90.56% on UADFV, Celeb-DF v1, and Celeb-DF v2 datasets, respectively. Our codes are available on GitHub 1.;1945-788X;978-1-6654-3864-3;10.1109/ICME51207.2021.9428361;"Army Research Laboratory; ";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9428361;"Light-weight;Deepfake detection;Successive subspace learning (SSL)";"Training;Neural networks;Transforms;Detectors;Streaming media;Feature extraction;Faces";;64;;20;IEEE;9 Jun 2021;5-9 July 2021;5-9 July 2021;IEEE;IEEE Conferences
Forensics and Analysis of Deepfake Videos;"M. T. Jafar; M. Ababneh; M. Al-Zoube; A. Elhassan";"Princess Sumaya University for Technology, Amman, Jordan; Princess Sumaya University for Technology, Amman, Jordan; Princess Sumaya University for Technology, Amman, Jordan; Princess Sumaya University for Technology, Amman, Jordan";2020 11th International Conference on Information and Communication Systems (ICICS);27 Apr 2020;2020;;;53;58;The spread of smartphones with high quality digital cameras in combination with easy access to a myriad of software apps for recording, editing and sharing videos and digital images in combination with deep learning AI platforms has spawned a new phenomenon of faking videos known as Deepfake. We design and implement a deep-fake detection model with mouth features (DFT-MF), using deep learning approach to detect Deepfake videos by isolating, analyzing and verifying lip/mouth movement. Experiments conducted against datasets that contain both fake and real videos showed favorable classification performance for DFT-MF model especially when compared with other work in this area.;2573-3346;978-1-7281-6227-0;10.1109/ICICS49469.2020.239493;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9078989;"Deep Learning;Python;Deepfake;Videos;Digital Forensics;Manipulation;Detection;Classification;Segmentation";"Deep learning;Forensics;Digital images;Teeth;Performance gain;Feature extraction;Smart phones";;63;;22;IEEE;27 Apr 2020;7-9 April 2020;7-9 April 2020;IEEE;IEEE Conferences
Using Deep Learning to Detecting Deepfakes;"J. Mallet; R. Dave; N. Seliya; M. Vanamala";"Department of Computer Science, University of Wisconsin – Eau Claire, Eau Claire, WI, USA; Department of Computer Information Science, Minnesota State University, Mankato, Mankato, MN, USA; Department of Computer Science, University of Wisconsin – Eau Claire, Eau Claire, WI, USA; Department of Computer Science, University of Wisconsin – Eau Claire, Eau Claire, WI, USA";2022 9th International Conference on Soft Computing & Machine Intelligence (ISCMI);21 Mar 2023;2022;;;1;5;In the recent years, social media has grown to become a major source of information for many online users. This has given rise to the spread of misinformation through deepfakes. Deepfakes are videos or images that replace one person's face with another computer-generated face, often a more recognizable person in society. With the recent advances in technology, a person with little technological experience can generate these videos. This enables them to mimic a power figure in society, such as a president or celebrity, creating the potential danger of spreading misinformation and other nefarious uses of deepfakes. To combat this online threat, researchers have developed models that are designed to detect deepfakes. This study looks at various deepfake detection models that use deep learning algorithms to combat this looming threat. This survey focuses on providing a comprehensive overview of the current state of deepfake detection models and the unique approaches many researchers take to solving this problem. The benefits, limitations, and suggestions for future work will be thoroughly discussed throughout this paper.;2640-0146;979-8-3503-2088-6;10.1109/ISCMI56532.2022.10068449;"University of Wisconsin-Eau Claire's Office of Research; ";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10068449;"deep learning;deepfake;fake detection";"Deep learning;Deepfakes;Image recognition;Social networking (online);Face recognition;Machine intelligence";;14;;40;IEEE;21 Mar 2023;26-27 Nov. 2022;26-27 Nov. 2022;IEEE;IEEE Conferences
A Spatio- Temporl Deepfake Video Detection Method Based on TimeSformer-CNN;"Z. Chen; S. Wang; D. Yan; Y. Li";"Institute of Information and Network Security, People's Public Security University of China, Beijing, China; Institute of Criminal Investigation, People's Public Security University of China, Beijing, China; Institute of National Security, People's Public Security University of China, Beijing, China; Institute of Public Economics and Administration, Shanghai University of Finance and Economics, Shanghai, China";2024 Third International Conference on Distributed Computing and Electrical Circuits and Electronics (ICDCECE);12 Jun 2024;2024;;;1;6;In order to improve the accuracy of real-time deepFake video detection, this paper proposes a method based on the EfficientNet-TimeSformer model. Firstly, we use the transfer Xi method to use a pre-trained convolutional network for spatial feature extraction, and introduce a lightweight network for exploration, with an accuracy of 95.26% and an AUC of 95.52, which is very impressive. At the same time, the trainable parameters of the model are only 5,234,124, which is significantly higher than that of other models. Then, we optimize the model through data augmentation such as pre-training and dataset sizing to accommodate larger image sizes and longer video input sequences, so as to enhance the model's ability to process complex video data. The empirical results show that our model performs well in high-resolution videos and longer video sequences, significantly outperforming the performance of traditional convolutional neural networks, taking into account GPU memory limitations. At the same time, some limitations in the study are noted, such as the failure to test video clips longer than 96 frames and some limitations on the Celeb-DF dataset. Future research directions include in-depth research on the interpretability and generalizability of the model, as well as verifying its performance in a wider range of application scenarios.;;979-8-3503-1860-9;10.1109/ICDCECE60827.2024.10549278;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549278;"deepfake;real-time detection;lightweight;efficientnet-timesformer network";"Deepfakes;Video sequences;Graphics processing units;Streaming media;Real-time systems;Robustness;Data models";;10;;10;IEEE;12 Jun 2024;26-27 April 2024;26-27 April 2024;IEEE;IEEE Conferences
Implementation of Deep Learning Method for Forgery Detection on Social Media;"A. Kohapare; K. Dhongade; R. Sukare; P. Maidamwar";"Department of Computer Science and Engineering, G H Raisoni College of Engineering, Nagpur, India; Department of Computer Science and Engineering, G H Raisoni College of Engineering, Nagpur, India; Department of Computer Science and Engineering, G H Raisoni College of Engineering, Nagpur, India; Department of Computer Science and Engineering, G H Raisoni College of Engineering, Nagpur, India";2024 2nd International Conference on Intelligent Data Communication Technologies and Internet of Things (IDCIoT);22 Mar 2024;2024;;;1579;1583;In recent years, the surge in misinformation and rapid technological advancements has significantly increased the prevalence of media manipulation. The advent of AI-altered videos and sophisticated news content poses a serious threat to media integrity, particularly as these manipulations proliferate on social media platforms, creating challenges in discerning authenticity. The accessibility and user-friendliness of deepfake technology have compounded the issue, making the distinction between genuine and fabricated content increasingly challenging. This presents substantial risks, ranging from the dissemination of false information to fostering a general sense of scepticism toward online visuals. This research aims to comprehensively analyze the process of creating deepfakes and assess their broader societal impact, while also proposing potential solutions to mitigate this problem. The methodology employed has achieved accuracy of 87% that involves utilizing ResN ext, a CNN architecture with LS TM, to analyse fake videos, and error level analysis followed by CNN algorithm to analyse fake images, this research outlines the specific steps and procedures involved in this analytical process.;;979-8-3503-2753-3;10.1109/IDCIoT59759.2024.10467237;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10467237;"Convolutional Neural Network;Deepfake Detection;Erroe Level Analysis;ResNext";"Deepfakes;Visualization;Technological innovation;Social networking (online);Clustering algorithms;Classification algorithms;Convolutional neural networks";;6;;23;IEEE;22 Mar 2024;4-6 Jan. 2024;4-6 Jan. 2024;IEEE;IEEE Conferences
Preserving Integrity: A Binary Classification Approach to Unmasking Artificially Generated Voices in the Age of Deepkakes;"V. Kumar; A. Kapoor; R. R. Chaudhary; L. Gupta; D. Khokhar";"Department of CSE, BVCOE, Delhi, India; Department of CSE, BVCOE, Delhi, India; Department of CSE, BVCOE, Delhi, India; Department of CSE, BVCOE, Delhi, India; Department of CSE, BVCOE, Delhi, India";2024 11th International Conference on Computing for Sustainable Global Development (INDIACom);18 Apr 2024;2024;;;1449;1454;Generative AI uses machine learning techniques like semi-supervised or unsupervised learning algorithms for the creation of digital content such as images, audio, and videos. There are ethical concerns arising from generative AI’s impact on speech technology, specifically, voice cloning and real-time voice conversion. To mitigate the associated risks of privacy breaches and misrepresentation, the research utilizes a DEEP-VOICE dataset that comprises audio clips from eight notable figures, converted using Retrieval-based Voice Conversion to detect Deepfake audio files. Framed as a binary classification problem, statistical analysis reveals significantly different distributions of temporal audio features between real and AI-generated speech. The experimental results show that the Random Forest Classifier over the 5-fold Cross-Validation technique results in a classification accuracy of 98.574%.;;978-93-80544-51-9;10.23919/INDIACom61295.2024.10499177;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10499177;"Artificial Intelligence;Machine Learning;Binary Classification;Deepfake;Audio Detection";"Ethics;Deepfakes;Statistical analysis;Pressing;Privacy breach;Real-time systems;Security";;2;;16;;18 Apr 2024;28 Feb.-1 March 2024;28 Feb.-1 March 2024;IEEE;IEEE Conferences
Fooling the Forgers: A Multi-Stage Framework for Audio Deepfake Detection;"G. S. Kashyap; Z. H. Siddiqui; M. A. Azeez; R. Ali; S. Kumar; N. Kamuni; J. Gao";"Jamia Hamdard, New Delhi, India; Jamia Hamdard, New Delhi, India; Jamia Hamdard, New Delhi, India; DSEU, New Delhi, India; Amazon, Seattle, USA; Tech Mahindra Americas, Texas, USA; University of Virginia, Virginia, USA";ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP);7 Mar 2025;2025;;;1;5;Audio deepfakes represent a risk to society as they can deteriorate society’s trust in any audio. In this paper, we present a novel approach for audio deepfake detection using Generative Adversarial Networks (GANs) and contrastive learning in a multi-stage detection framework. In our process, we apply the Pre-trained Models (PTM) to extract all suitable audio phonetics, speaker identity, and other spatial prosodic features or contents, which are crucial for the model. We enhance the model’s performance by utilizing a GAN data augmentation strategy in combination with HiFi-GAN. The Contrastive learning approach is then used for improving the model’s ability to discriminate real speech from fake speech. Our experiments demonstrate that this method is superior to existing methodologies in detection and robustness.;2379-190X;979-8-3503-6874-1;10.1109/ICASSP49660.2025.10888175;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10888175;"Audio Deepfake Detection;Generative Adversarial Networks;Pre-trained Models;Deep Learning;Machine Learning";"Deepfakes;Contrastive learning;Signal processing;Phonetics;Generative adversarial networks;Feature extraction;Data augmentation;Robustness;Data models;Speech processing";;1;;22;IEEE;7 Mar 2025;6-11 April 2025;6-11 April 2025;IEEE;IEEE Conferences
Comprehensive Analysis of Deepfake Detection Models;"M. Khatoon; C. Jaiswal; S. Sokhi; T. Tripathi; U. A. Jogalekar; R. Agrawal";"Department of Computer Science & Engineering, Symbiosis Institute of Technology, Pune Symbiosis International (Deemed University), Pune, India; Department of Computer Science & Engineering, Symbiosis Institute of Technology, Pune Symbiosis International (Deemed University), Pune, India; Department of Computer Science & Engineering, Symbiosis Institute of Technology, Pune Symbiosis International (Deemed University), Pune, India; Department of Computer Science & Engineering, Symbiosis Institute of Technology, Pune Symbiosis International (Deemed University), Pune, India; Department of Computer Science & Engineering, Symbiosis Institute of Technology, Pune Symbiosis International (Deemed University), Pune, India; Department of Computer Science & Engineering, Symbiosis Institute of Technology, Pune Symbiosis International (Deemed University), Pune, India";2025 International Conference on Emerging Trends in Industry 4.0 Technologies (ICETI4T);26 Aug 2025;2025;;;1;6;Deepfake technology being constantly developed at a fast pace, poses a great danger to the authenticity of media content, and thus prompt detection frameworks are required. This paper reviews the state of the art in deepfake detection systems focusing on four shallow deep learning CNN models, XceptionNet, EfficientNetV2M, EfficientNetV2S, InceptionResNetV2. This paper focuses on the datasets and model architectures. The selected metrics are explained which concretize the relevance and versatility of these approaches. The research applies a deep learning method that is resource efficient and cost effective, to resolve important problems such as imbalance in data. The tested cases prove the effectiveness of the models in deepfake detection in regard to several cases. The XceptionNet model recorded 98% accuracy in the classification task using the CelebDF-V2 dataset, while the InceptionResNetV2 model achieved 94% accuracy on the FaceForensics++ dataset.;;979-8-3315-0696-4;10.1109/ICETI4T63625.2025.11132138;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11132138;"Deepfake Detection;XceptionNet;EfficientNet;InceptionResNetV2;Convolutional Neural Networks;Deep Learning;Digital Media Integrity;Algorithm Evaluation";"Deep learning;Measurement;Deepfakes;Accuracy;Reviews;Focusing;Media;Market research;Fourth Industrial Revolution;Convolutional neural networks";;;;16;IEEE;26 Aug 2025;6-7 June 2025;6-7 June 2025;IEEE;IEEE Conferences
Improving Fairness in Synthetic Speech Detectors;"A. K. Singh Yadav; K. Bhagtani; P. Bestagini; E. J. Delp";"Video and Image Processing Lab (VIPER), School of Electrical and Computer Engineering, Purdue University, West Lafayette, Indiana, USA; Video and Image Processing Lab (VIPER), School of Electrical and Computer Engineering, Purdue University, West Lafayette, Indiana, USA; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy; Video and Image Processing Lab (VIPER), School of Electrical and Computer Engineering, Purdue University, West Lafayette, Indiana, USA";2024 58th Asilomar Conference on Signals, Systems, and Computers;4 Apr 2025;2024;;;362;366;Many methods have been proposed which can effectively detect synthetic speech. However, a recent study demonstrates that they exhibit bias and a higher false positive rate for bona fide speech from speakers with stuttering speech-impairment as compared to fluent speakers. This limits deploy-ment of these detectors, as this bias can have significant societal and political consequences and can erode the reputation of social platforms using such detectors. This bias may have arisen from the bias in training data used for these detectors. Creating synthetic and bona fide speech with stuttering, and adding it to the training set for mitigating bias, can be time-consuming. In this work, we propose StutterAug, a set of augmentations that simulate three major types of stuttering in speech, namely repetition, prolongation and blocks. We test StutterAug on 3 synthetic speech detectors and examine bias on stuttering speech using more than 28K bona fide stuttering speech. Our results show that detectors trained with StutterAug have on average 13% less bias relative to detector trained without StutterAug. StutterAug also leads to an average relative improvement of 27.96% in detection performance on ASVspoof2019 dataset and 11.27% in generalization performance on In-the-Wild dataset compared to baseline detectors trained without StutterAug.;2576-2303;979-8-3503-5405-8;10.1109/IEEECONF60004.2024.10942853;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10942853;"speech forensics;synthetic speech detection;deepfake;fairness;stuttering";"Training;Computers;Deepfakes;Forensics;Training data;Detectors;Speech synthesis";;;;43;IEEE;4 Apr 2025;27-30 Oct. 2024;27-30 Oct. 2024;IEEE;IEEE Conferences
Deepfaceguard: A Lightweight CNN Framework for Robust Face Manipulation Detection;"M. Tauseef; L. S. Viji; J. Fenwick";"School of ECE, REVA University, Bengaluru, India; School of ECE, REVA University, Bengaluru, India; School of ECE, REVA University, Bengaluru, India";2025 Third International Conference on Networks, Multimedia and Information Technology (NMITCON);10 Oct 2025;2025;;;1;6;The rapid proliferation of deep-fake technology threatens the credibility of digital media, with face-swap deep fakes posing significant detection challenges due to their high visual fidelity. This paper presents Deep Faceguard, a lightweight CNN-based deepfake detection framework optimized for high accuracy, cross-dataset generalization, and real-time edge deployment. Unlike prior models limited to single-dataset performance, Deep Faceguard integrates transfer learning with Efficient Net and XceptionNet backbones, combined with OpenCV-based facial region alignment to enhance artifact localization. The system effectively detects subtle manipulation artifacts such as illumination inconsistencies, blending anomalies, and edge discontinuities. Trained on FaceForensics ++ and DFDC, it achieves 96.5 % accuracy, 95.8 % precision, 97.2 % recall, and a ROC AUC of 0.982, while cross-dataset testing yields 88.2 % accuracy, indicating robustness to domain shift. Optimized via TensorFlow Lite, Deep Faceguard sustains 45 FPS real-time inference and reduces the model size by 40 % without accuracy loss, making it suitable for scalable and deployment-ready deepfake detection applications.;;979-8-3315-1308-5;10.1109/NMITCON65824.2025.11188219;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11188219;"Deepfake detection;Convolutional Neural Net works (CNNs);face-swap manipulation;digital media forensics;cross-dataset generalization;TensorFlow Lite;real-time infer ence;edge deployment";"Deepfakes;Visualization;Accuracy;Image edge detection;Transfer learning;Media;Real-time systems;Robustness;Convolutional neural networks;Testing";;;;15;IEEE;10 Oct 2025;1-2 Aug. 2025;1-2 Aug. 2025;IEEE;IEEE Conferences
Deepfake Circumvention Using Machine Learning;"M. S; R. D; S. J. A; S. G; A. M";"Department of Computer Science and Engineering, Sri Sairam Institute of Technology, Chennai, India; Department of Computer Science and Engineering, Sri Sairam Institute of Technology, Chennai, India; Department of Computer Science and Engineering, Sri Sairam Institute of Technology, Chennai, India; Department of Computer Science and Engineering, Sri Sairam Institute of Technology, Chennai, India; Department of Computer Science and Engineering, Sri Sairam Institute of Technology, Chennai, India";2024 International Conference on Power, Energy, Control and Transmission Systems (ICPECTS);12 Dec 2024;2024;;;1;6;"Deepfake is an AI-based technology that creates videos which are quite genuine but fake, and propagates massive threats to media credibility and public trust. This paper presents a new deepfake detection system that employs the Vision Transformer (ViT) model that can be easily accessed through web interface built with Streamlit. The strategy is aimed at differentiating fake and original video content with a high degree of efficiency, thus offering the efficient tool for real-time content verification. The addition of confidence scores improves interpretability of the system and as such ideal for application in media authenticity and countering fake news. The platform is easy to use with further plans to enhance the features of the platform such as; ability to notify authorities automatically, real-time video processing, ability to work with multiple languages and ways to share the content through Social media, to add to its uses in protecting the content.";;979-8-3315-0884-5;10.1109/ICPECTS62210.2024.10780152;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10780152;"Deepfake detection;Machine Learning;Online Security;Digital Manipulation;Vision Transformers;Data Pre-processing;Computer Vision";"Deepfakes;Technological innovation;Feedback loop;Computer vision;Social networking (online);Machine learning;Transformers;Control systems;Real-time systems;Reliability";;;;10;IEEE;12 Dec 2024;8-9 Oct. 2024;8-9 Oct. 2024;IEEE;IEEE Conferences
Real-Time Deepfake Video Detection using Machine Learning: A CNN-based Authentication Framework;"S. Babitha; Y. K; D. H. J. V; H. J";"Information Technology, Hindustan Institute of Technology and Science, Chennai; Information Technology, Hindustan Institute of Technology and Science, Chennai; Information Technology, Hindustan Institute of Technology and Science, Chennai; Information Technology, Hindustan Institute of Technology and Science, Chennai";2025 Third International Conference on Augmented Intelligence and Sustainable Systems (ICAISS);24 Jun 2025;2025;;;134;138;Deepfake technology presents significant threats to digital security, misinformation, and privacy. A Convolutional Neural network-based deepfake video detection in real time using optimization techniques to increase the accuracy and computational efficiency is proposed in this paper. The model is trained on the dataset of 15,000 images and uses feature extraction, adaptive loss function, and real-time processing optimization to achieve better performance. The experimental results give competitive results in terms of accuracy, precision, and recall compared to state-of-the-art models like EfficientNet and Xception. The framework is tolerant to adversarial attacks and compression effects. The work done in this direction will be further extended in the future to build transformer-based models for better generalization and adversarial resilience in deepfake detection.;;979-8-3315-0724-4;10.1109/ICAISS61471.2025.11041947;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11041947;"Deepfake Detection;Convolutional Neural Networks (CNNs);Real-Time Video Authentication;Optimization Techniques;Adversarial Robustness";"Deepfakes;Accuracy;Computational modeling;Streaming media;Feature extraction;Transformers;Real-time systems;Robustness;Convolutional neural networks;Optimization";;;;13;IEEE;24 Jun 2025;21-23 May 2025;21-23 May 2025;IEEE;IEEE Conferences
Deepfake Voice Detection: Countering Deepfake Audio with Deep Learning Architectures;"K. K. Ko; S. Wai Wai Tun; M. T. Kyaw; T. Thet Zin";"University of Information Technology, Yangon, Myanmar; University of Information Technology, Yangon, Myanmar; University of Information Technology, Yangon, Myanmar; Faculty of Computer Science, University of Information Technology, Yangon, Myanmar";2025 6th International Conference on Advanced Information Technologies (ICAIT);18 Nov 2025;2025;;;1;6;The active development of the Text-to-Speech (TTS) technology as well as the Voice Conversion (VC) has posed an outstanding danger to the digital security. To overcome this obstacle, this paper will compare and contrast systematically three different deep learning structures, a hybrid CNN-RNN framework that aims to conduct both spectral and temporal artifact processing, a CNN-LSTM ensemble framework exploring the distinctive capabilities of the spatial and temporal processing, and a state-of-the-art system with Wav2Vec2 as a pre-trained feature extractor and as a Light Convolutional Neural Network (LCNN) to make predictions. Although all these architectures operate on the basis of known elements, they are new in the way that they specifically aim at deepfake detection and also they are assessed and evaluated in an unprecedented way in parallel. With experiments on a wide variety of benchmark datasets, such as ASVspoof 2019, WaveFake and FoR, this paper compares the trade-offs between feature-engineered and self-supervised methods. As the results show, CNN + LSTM-based platform can deliver better results, its analysis accuracy is 99.81, because it is able to get deep, context-sensitive representations of unprocessed audio. The present study highlights the symbiosis of organizing various deep learning techniques and establishes a complete reference in future studies in resilient equipment of deepfake voice detecting.;;979-8-3315-7272-3;10.1109/ICAIT68809.2025.11236771;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11236771;"Deepfake;Voice Detection;Wav2Vec2;CNN-RNN;Ensemble Learning";"Deep learning;Deepfakes;Accuracy;Computational modeling;Computer architecture;Feature extraction;Transformers;Data models;Convolutional neural networks;Security";;1;;21;IEEE;18 Nov 2025;3-3 Nov. 2025;3-3 Nov. 2025;IEEE;IEEE Conferences
Detection of Real and Manipulated Videos using the Transfer Learning Approach of Deep-Learning Models;"B. R. Reddy; D. C. Rup; M. Rohith; M. Belwal";"Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Bengaluru, India; Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Bengaluru, India; Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Bengaluru, India; Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Bengaluru, India";2024 5th IEEE Global Conference for Advancement in Technology (GCAT);20 Mar 2025;2024;;;1;7;Deepfake (manipulated images and videos) identification is critical in multimedia forensics, as it can spread misinformation, threaten privacy, and have legal implications. To address this problem, researchers and practitioners are developing deepfake detection techniques that use deep-learning models and computer vision algorithms to analyse the authenticity of images and videos. This study proposes a novel approach providing robust and scalable deepfake detection by using transfer learning in feature extraction and deep-learning models to train features extracted from the video dataset. The transfer-learning has been experimented with the ResNet, XceptionNet, and VGG16 models for feature extractions. Further, the deep-learning models Long short-term memory (LSTM) and Bidirectional long short-term memory (Bi-LSTM) have been experimented with to train the extracted features. To rigorously test the proposed approach, the data set under the experiment combined the three benchmark datasets - The Deepfake Detection Challenge (DFDC), Celeb-DF, and Face-Forensics++ datasets. The prediction rate achieved was 96 % and above on average by the proposed approach for the datasets under consideration for the experiments. The proposed approach performs better than the state-of-the-art techniques, gaining a higher accuracy of 96% and above.;;979-8-3503-7668-5;10.1109/GCAT62922.2024.10924003;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10924003;"Computer Vision;XceptionNet;ResNet;VGG16;Deepfake Detection;Deep Learning;Transfer Learning";"Deep learning;Deepfakes;Computer vision;Privacy;Computational modeling;Forensics;Transfer learning;Streaming media;Feature extraction;Long short term memory";;;;35;IEEE;20 Mar 2025;4-6 Oct. 2024;4-6 Oct. 2024;IEEE;IEEE Conferences
Blockchain Based Deepfake Video Detection Using Deep Learning;"B. Colaco; B. Patil; S. Gharat; S. Gawande";"Department Of Computer Engineering, Vidyavardhini’s College of Engineering and Technology, India; Department Of Computer Engineering, Vidyavardhini’s College of Engineering and Technology, India; Department Of Computer Engineering, Vidyavardhini’s College of Engineering and Technology, India; Department Of Computer Engineering, Vidyavardhini’s College of Engineering and Technology, India";2025 International Conference on Emerging Trends in Industry 4.0 Technologies (ICETI4T);26 Aug 2025;2025;;;1;7;Deepfake identification has become an essential issue in the digital world as AI generated manipulated videos are being utilized more and more maliciously. In order to provide a trustworthy technique for detecting deep-fake video, proposed system employs an integrated deep learning method involving Long Short-Term Memory (LSTM), ResNeXt, and Convolutional Neural Networks (CNN). CNN and ResNeXt are used to analyze video frames and extract spatial data, whereas LSTM analyzes the temporal dynamics between frames. These obtained features are employed to determine the variations and irregularities frequently found in deepfake movies. The Python and PyTorch frameworks used in the model’s development and implementation provide high accuracy and efficiency. The results are verified as well and safely saved on blockchain, offering an infallible, transparent way to identify deepfakes. The fields of media integrity, digital forensics, and cybersecurity are greatly advanced by this program’s helpful tool for preventing online fraud and disinformation.;;979-8-3315-0696-4;10.1109/ICETI4T63625.2025.11132246;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11132246;"Deepfake Detection;Deep Learning (DL);convolutional Neural Network (CNN);ResNeXt;Long Short-Term Memory (LSTM);Blockchain (BC);Temporal Analysis;Video Processing(VP);PyTorch";"Deep learning;Deepfakes;Social networking (online);Motion pictures;Market research;Spatial databases;Blockchains;Convolutional neural networks;Long short term memory;Python";;;;15;IEEE;26 Aug 2025;6-7 June 2025;6-7 June 2025;IEEE;IEEE Conferences
Deepfake Generation and Detection: Case Study and Challenges;"Y. Patel; S. Tanwar; R. Gupta; P. Bhattacharya; I. E. Davidson; R. Nyameko; S. Aluvala; V. Vimal";"Department of Computer Science and Engineering, Institute of Technology, Nirma University, Ahmedabad, Gujarat, India; Department of Computer Science and Engineering, Institute of Technology, Nirma University, Ahmedabad, Gujarat, India; Department of Computer Science and Engineering, Institute of Technology, Nirma University, Ahmedabad, Gujarat, India; Department of Computer Science and Engineering, Amity School of Engineering and Technology, Amity University, Kolkata, India; Department of Electrical, Electronic and Computer Engineering, African Space Innovation Center, Cape Peninsula University of Technology, Bellville, South Africa; Department of Electrical, Electronic and Computer Engineering, African Space Innovation Center, Cape Peninsula University of Technology, Bellville, South Africa; Department of Computer Science and Artificial Intelligence, SR University, Warangal, Telangana, India; Department of Computer Science and Engineering, Graphic Era Hill University, Dehradun, India";IEEE Access;22 Dec 2023;2023;11;;143296;143323;In smart communities, social media allowed users easy access to multimedia content. With recent advancements in computer vision and natural language processing, machine learning (ML), and deep learning (DL) models have evolved. With advancements in generative adversarial networks (GAN), it has become possible to create fake images/audio/and video streams of a person or use some person’s audio and visual details to fit other environments. Thus, deepfakes are specifically used to disseminate fake information and propaganda on social circles that tarnish the reputation of an individual or an organization. Recently, many surveys have focused on generating and detecting deepfake images, audio, and video streams. Existing surveys are mostly aligned toward detecting deepfake contents, but the generation process is not suitably discussed. To address the survey gap, the paper proposes a comprehensive review of deepfake generation and detection and the different ML/DL approaches to synthesize deepfake contents. We discuss a comparative analysis of deepfake models and public datasets present for deepfake detection purposes. We discuss the implementation challenges and future research directions regarding optimized approaches and models. A unique case study, IBMM is discussed, which presents a multi-modal overview of deepfake detection. The proposed survey would benefit researchers, industry, and academia to study deepfake generation and subsequent detection schemes.;2169-3536;;10.1109/ACCESS.2023.3342107;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10354308;"Artificial intelligence;Deepfake generation;Deepfake detection;fake content;generative adversarial networks";"Deepfakes;Generative adversarial networks;Feature extraction;Artificial intelligence;Convolutional neural networks;Surveys;Fake news";;101;;113;CCBYNCND;12 Dec 2023;2023;;IEEE;IEEE Journals
Improving Generalization of Deepfake Detection With Data Farming and Few-Shot Learning;"P. Korshunov; S. Marcel";"Biometrics Security and Privacy Group, Idiap Research Institute, Martigny, Switzerland; Biometrics Security and Privacy Group, Idiap Research Institute, Martigny, Switzerland";IEEE Transactions on Biometrics, Behavior, and Identity Science;19 Jul 2022;2022;4;3;386;397;Recent advances in automated video and audio editing tools, generative adversarial networks (GANs), and social media allow creation and fast dissemination of high quality tampered videos, which are generally called deepfakes. Typically, in these videos, a face is swapped with someone else’s using GANs. Accessible open source software and apps for the face swapping led to a wide and rapid dissemination of the generated deepfakes, posing a significant technical challenge for their detection and filtering. In response to the threat, which deepfake videos can pose to our trust in video evidence, several large datasets of deepfake videos and several methods to detect them were proposed recently. However, the proposed methods suffer from a problem of overfitting on the training data and the lack of the generalization across different databases and the generative models. Therefore, in this paper, we investigate the techniques for improving the generalization of deepfake detection methods that can be employed in practical settings. We have selected two popular state of the art deepfake detectors: based on Xception and EfficientNet models, and we use five databases: from Google and Jigsaw, FaceForensics++, DeeperForensics, Celeb-DF, and our own publicly available large dataset DF-Mobio. To improve generalization, we apply different augmentation strategies used during training, including a proposed aggressive ‘data farming’ technique based on random patches. We also tested two few-shot tuning methods, when either a first convolutional layer or a last layer of a pre-trained model is tuned on 100 seconds from a training set of the test database. The experimental results clearly expose the generalization problem of deepfake detection methods, since the accuracy drops significantly when a model is trained on one dataset and evaluated on another. However, the silver lining is that an aggressive augmentation during training and a few-shot tuning on the test database can improve the accuracy of the detection methods in a cross-database scenario. As a side observation, we show the importance of database selection for training and evaluation, as FaceForensics++ is found to be better to use for training, while DeeperForensics is found to be significantly more challenging as a test database.;2637-6407;;10.1109/TBIOM.2022.3143404;"Hasler Foundation’s VERIFAKE Project; Swiss Center for Biometrics Research and Testing; ";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9684526;"Deepfakes detection;generalization;evaluation;deepfake dataset";"Videos;Information integrity;Databases;Faces;Training;Internet;Social networking (online)";;32;;41;IEEE;18 Jan 2022;July 2022;;IEEE;IEEE Journals
FSSPOTTER: Spotting Face-Swapped Video by Spatial and Temporal Clues;"P. Chen; J. Liu; T. Liang; G. Zhou; H. Gao; J. Dai; J. Han";"Chinese Academy of Sciences, Institute of Information Engineering, Beijing, China; Chinese Academy of Sciences, Institute of Information Engineering, Beijing, China; Chinese Academy of Sciences, Institute of Information Engineering, Beijing, China; Chinese Academy of Sciences, Institute of Information Engineering, Beijing, China; Chinese Academy of Sciences, Institute of Information Engineering, Beijing, China; Chinese Academy of Sciences, Institute of Information Engineering, Beijing, China; Chinese Academy of Sciences, Institute of Information Engineering, Beijing, China";2020 IEEE International Conference on Multimedia and Expo (ICME);9 Jun 2020;2020;;;1;6;Recent advances in face generation and manipulation have enabled the creation of sophisticated face-swapped videos, also known as DeepFakes, which brings great potential threats to our society. Hence, it is crucial to develop effective approaches to distinguish them. Currently, face-swapped videos produced by existing methods are prone to exhibit some subtle spatial and temporal manipulated traces, which can be utilized as distinctive clues for face-swapped video detection. In this paper, we propose a unified framework, named FSSpotter, to explore rich spatial and temporal information in the video simultaneously. It consists of a Spatial Feature Extractor (SFE), which aims to discover spatial evidences within a single frame, and a Temporal Feature Aggregator (TFA), which is responsible for capturing temporal inconsistencies between frames. Moreover, a novel data processing strategy is adopted to highlight the inconsistencies of forged face with its surrounding regions. The evaluations on Deepfakes of FaceForensics++, DeepfakeTIMIT, UADFV and Celeb-DF datasets demonstrate that the proposed approach achieves better or comparable performance on AUC scores.;1945-788X;978-1-7281-1331-9;10.1109/ICME46284.2020.9102914;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9102914;"DeepFakes;Face-swapped video;DeepFakes detection;Face Forensics";"Face;Feature extraction;Lighting;Agriculture;Training;Training data";;28;;24;IEEE;9 Jun 2020;6-10 July 2020;6-10 July 2020;IEEE;IEEE Conferences
Deepfake Detection using GAN Discriminators;"S. A. Aduwala; M. Arigala; S. Desai; H. J. Quan; M. Eirinaki";"Computer Engineering Department, San José State University (SJSU), San José, CA, USA; Computer Engineering Department, San José State University (SJSU), San José, CA, USA; Computer Engineering Department, San José State University (SJSU), San José, CA, USA; Computer Engineering Department, San José State University (SJSU), San José, CA, USA; Computer Engineering Department, San José State University (SJSU), San José, CA, USA";2021 IEEE Seventh International Conference on Big Data Computing Service and Applications (BigDataService);18 Oct 2021;2021;;;69;77;Deepfake videos are videos where the features of a person are replaced with the features of another person. Videos can be manipulated using powerful Deep Learning techniques. This technology may be used maliciously as a means of misinformation, manipulation, and persuasion. There are currently not many solutions to identify products of Deepfake technology, although there is significant research being conducted to tackle this problem. One often researched deep learning technology is the Generative Adversarial Network (GAN). These networks are commonly used to generate Deepfake videos but not used for their detection. In this work, we explore solutions based on GAN discriminators as a means to detect Deepfake videos. Using MesoNet as a baseline, we train a GAN and extract the discriminator as a dedicated module to detect Deepfakes. We test several discriminator architectures using multiple datasets to explore how the efficacy of the discriminator varies with different setups and training methods. Finally, we propose a model to boost the efficacy of a group of GAN discriminators using ensemble methods. Our results show that GAN discriminators, even augmented by ensemble methods, do not perform well on videos from unknown sources.;;978-1-6654-3483-6;10.1109/BigDataService52369.2021.00014;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9564096;"Deepfake Detection;Generative Adversarial Networks;GAN;Discriminator;Deepfake Videos;Deep Learning;Image Processing;Feature Recognition";"Training;Deep learning;Conferences;Detectors;Computer architecture;Big Data;Generative adversarial networks";;10;;25;IEEE;18 Oct 2021;23-26 Aug. 2021;23-26 Aug. 2021;IEEE;IEEE Conferences
Temporal surface frame anomalies for deepfake video detection;"A. Ciamarra; R. Caldelli; A. D. Bimbo";"University of Florence, Florence, Italy; CNIT, Florence, Italy; University of Florence, Florence, Italy";2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW);27 Sep 2024;2024;;;3837;3844;Looking at a video sequence where a foreground person is represented is not as time ago anymore. Deepfakes have revolutionized our way to watch at such contents and nowadays we are more often used to wonder if what we are seeing is real or is just a mystification. In this context of generalized disinformation, the need for reliable solutions to help common users, and not only, to make an assessment on this kind of video sequences is strongly upcoming. In this paper, a novel approach which leverages on temporal surface frame anomalies in order to reveal deepfake videos is introduced. The method searches for possible discrepancies, induced by deepfake manipulation, in the surfaces belonging to the captured scene and in their evolution along the temporal axis. These features are used as input of a pipeline based on deep neural networks to perform a binary assessment on the video itself. Experimental results witness that such a methodology can achieve significant performance in terms of detection accuracy.;2160-7516;979-8-3503-6547-4;10.1109/CVPRW63382.2024.00388;"Horizon Europe; ";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10678101;"Deepfake;Deepfake Video Detection;Surface Frame;Temporal Surface Frame;Scene Acquisition Manipulation";"Deepfakes;Accuracy;Instruments;Video sequences;Pipelines;Watches;Pattern recognition";;10;;30;IEEE;27 Sep 2024;17-18 June 2024;17-18 June 2024;IEEE;IEEE Conferences
Improving DeepFake Video Detection Performance with a Noval Deep Learning Approach;"M. A. Fouda; W. El-Shafai; E. -S. M. El-Rabaie";"Department of Electronics and Electrical Communications Engineering, Faculty of Electronic Engineering, Menoufia University, Menouf, Egypt; Department of Electronics and Electrical Communications Engineering, Faculty of Electronic Engineering, Menoufia University, Menouf, Egypt; Department of Electronics and Electrical Communications Engineering, Faculty of Electronic Engineering, Menoufia University, Menouf, Egypt";2023 3rd International Conference on Electronic Engineering (ICEEM);21 Nov 2023;2023;;;1;8;With the rise in both the quantity and sophistication of deepfake videos, the need for robust detection systems to identify potentially misleading content on social media and the internet has become paramount. However, current automated face forgery detection systems still face limitations, often demonstrating bias towards the training dataset. This research paper addresses this issue by proposing a novel approach for detecting deepfake media. We introduce a custom Visual Geometry Group (VGG16) deepfake detection method that leverages convolutional neural network architectures. To evaluate the effectiveness of our approach, we utilize the deepfake detection challenge (DFDC) dataset on Kaggle to build network models and compare the performance of our custom VGG16 method against the standard VGG16. Additionally, we investigate the impact of data augmentation techniques on the performance of Convolutional Neural Network (CNN)-based deepfake detectors, examining their effect on both VGG16 and our custom VGG16 approach using the DFDC dataset. Our results demonstrate a high level of accuracy, with precision, recall, and f1-score values of 0.983, 0.975, and 0.979, respectively, and an overall accuracy of 0.986 for deepfake detection. This study presents a promising approach to enhance the accuracy of deepfake video detection, representing a crucial step towards mitigating the potential negative impacts of deepfake technology.;;979-8-3503-2351-1;10.1109/ICEEM58740.2023.10319524;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10319524;"Deepfake;Deep learning;CNN;Data Augmentation;Deepfake Detection;and VGG16";"Training;Geometry;Deepfakes;Visualization;Social networking (online);Media;Forgery";;1;;23;IEEE;21 Nov 2023;7-8 Oct. 2023;7-8 Oct. 2023;IEEE;IEEE Conferences
Implementation of Robust Deepfake Detection via 3D Residual Attention Densenet with Pyramid Dilation Network;"T. Rajesh; S. Maruthuperumal";"Department of Computer Science and Engineering, Bharath Institute of Higher Education and Research, Chennai, Tamil Nadu, India; Department of CSE, Bharath Institute of Higher Education and Research, Chennai, Tamil Nadu, India";2025 5th International Conference on Soft Computing for Security Applications (ICSCSA);25 Sep 2025;2025;;;1425;1433;Artificial intelligence is used in deepfake technology to produce realistic-looking but fake films, audios, and videos. The popularity and use of videos have increased dramatically in recent years due to the proliferation of social networks and mobile devices. In recent days, most of the high-budget movies were accompanied by intelligent techniques and tools for video manipulation, such as FaceSwap and Deepfake. In live streaming, deepfakes frequently use context-dependent changes that test the flexibility of models that were previously trained on static datasets. The complexities of live-streaming deepfakes may be too complex for traditional methods to fully capture. The validity of visual content is seriously threatened by deepfake technology, especially in live-stream situations when detection speed is critical. Due to the shortcomings and difficulties of current Deepfake detection techniques, more reliable and accurate solutions are required. In this work, advanced deep learning approaches are utilized for detecting deepfake videos to enhance security and trust in digital media. The necessary videos for the deepfake detection are collected from the standard datasets. The gathered video sequences are processed through the proposed deep learning model named as 3D Residual Attention Densenet with Pyramid Dilation (3DRAD-PD). The designed approach can capture multi-scale context information from input videos to improve the accuracy of deepfake detection. It helps to identify the manipulated videos to avoid the spread of misinformation in social media. Extensive experiments are conducted to demonstrate the robustness of the designed framework against different types of deepfake videos.;;979-8-3315-9491-6;10.1109/ICSCSA66339.2025.11171276;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11171276;"Deepfake Detection;Deepfake Videos;3D Residual Attention Densenet with Pyramid Dilation Network";"Deep learning;Deepfakes;Solid modeling;Visualization;Three-dimensional displays;Accuracy;Social networking (online);Computational modeling;Security;Context modeling";;;;27;IEEE;25 Sep 2025;4-6 Aug. 2025;4-6 Aug. 2025;IEEE;IEEE Conferences
AI-Manipulated Reality: Generation and Detection of Deepfake Content;"B. A. Csanky; S. A. Laczi; V. Póser";"John von Neumann Faculty of Informatics, Óbuda University, Budapest, Hungary; Doctoral School of Applied Infromatics and Applied Mathematics, Óbuda University, Budapest, Hungary; John von Neumann Faculty of Informatics, Óbuda University, Budapest, Hungary";2025 IEEE 19th International Symposium on Applied Computational Intelligence and Informatics (SACI);23 Jun 2025;2025;;;571;576;The development of artificial intelligence (AI) has fundamentally reshaped various applications in computer vision and deep learning. Alongside these benefits, however, it has also introduced significant challenges, particularly with the emergence of deepfake technology. Deepfakes leverage neural networks to manipulate audio and visual content, producing hyper-realistic yet fake images and videos that pose threats in areas such as manipulation, extortion, and disinformation. This review provides an overview of the fundamental methods behind deepfake creation, including autoencoders, generative adversarial networks (GANs), and audio manipulations. It also addresses the technology's harmful uses and the related societal challenges. Furthermore, it offers a detailed discussion of potential defense strategies against deepfake content, such as traditional visual and physiological analyses, as well as deep learning-based detection methods that rely on identifying temporal inconsistencies, visual anomalies, and characteristic patterns of generative networks. The analysis aims to highlight the dangers of deepfake technology and the necessity for developing reliable detection tools, thereby contributing to the reduction of manipulated content proliferation.;2765-818X;979-8-3315-1547-8;10.1109/SACI66288.2025.11030130;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11030130;"Deepfake;Face and voice manipulation;GAN;Deepfake content detection";"Deep learning;Deepfakes;Visualization;Accuracy;Reviews;Semisupervised learning;Reliability theory;Generative adversarial networks;Physiology;Artificial intelligence";;;;35;IEEE;23 Jun 2025;19-24 May 2025;19-24 May 2025;IEEE;IEEE Conferences
AI/ML-Based Solution for Detecting Face-Swap Deepfakes;"S. S. Patil; A. M; P. M; P. P. C";"Dept. Of Computer Science And Engineering, Sri Venkateshwara College Of Engineering, Bengaluru; Dept. Of Computer Science And Engineering, Sri Venkateshwara College Of Engineering, Bengaluru; Dept. Of Computer Science And Engineering, Sri Venkateshwara College Of Engineering, Bengaluru; Dept. Of Computer Science And Engineering, Sri Venkateshwara College Of Engineering, Bengaluru";2025 International Conference on Emerging Trends in Industry 4.0 Technologies (ICETI4T);26 Aug 2025;2025;;;1;7;The rapid advancement of deepfake technology, particularly in face-swap applications, poses significant challenges to the integrity of digital media and personal security. This research introduces a hybrid system using Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) to detect deepfakes. The model combines spatial and temporal feature analysis to spot inconsistencies in manipulated media. Facial landmarks are detected using the Dlib library, while classifiers like Support Vector Machines (SVM) and Artificial Neural Networks (ANN) enhance detection accuracy. Data augmentation and bidirectional LSTM processing improve the system’s robustness in real-world scenarios. By leveraging AI-driven techniques, the model offers a reliable solution to counter the growing misuse of deepfake technology, ensuring high precision and adaptability.;;979-8-3315-0696-4;10.1109/ICETI4T63625.2025.11132146;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11132146;"deepfake detection;face-swap;Convolutional Neural Networks (CNNs);Recurrent Neural Networks (RNNs);Support Vector Machines (SVM);Artificial Neural Networks (ANN);AI/ML";"Support vector machines;Deepfakes;Ethics;Adaptation models;Technological innovation;Computational modeling;Collaboration;Data augmentation;Convolutional neural networks;Security";;;;20;IEEE;26 Aug 2025;6-7 June 2025;6-7 June 2025;IEEE;IEEE Conferences
Hybrid Federated Deepfake Detection via Residual-Aware Temporal Modeling and Privacy-Preserving Learning;"A. Bhatnagar; R. C. Pandey; V. Vishal; A. Singh";"Dept. of Information Technology, Rajkiya Engineering College, Ambedkar Nagar, India; Dept. of Information Technology, Rajkiya Engineering College, Ambedkar Nagar, India; Dept. of Information Technology, Rajkiya Engineering College, Ambedkar Nagar, India; Dept. of Information Technology, Rajkiya Engineering College, Ambedkar Nagar, India";2025 IEEE International Conference on Advances in Computing Research On Science Engineering and Technology (ACROSET);16 Dec 2025;2025;;;1;6;The rapid advancement of deepfake technology has emerged as a significant challenge to the integrity of digital media, decreasing public trust along with compromising privacy and making forensic investigations complex. Current detection methods though effective in controlled settings, struggle to maintain accuracy under privacy-preserving requirements, evolving manipulation strategies or novel synthetic artifacts. To overcome these limitations this paper introduces an innovative detection architecture combining three core components: (A) Anomaly detection through variational autoencoder-derived residual analysis, (B) Sequential pattern recognition via bidirectional LSTM networks and (C) Decentralized model training through federated learning protocols. This multi-modal framework analyses visual inconsistencies and temporal irregularities while maintaining strict data confidentiality simultaneously. Rigorous testing across widely recognized dataset FaceForensics++(FF++) and some others reveal enhanced & effective adaptability to quality degradation, signal interference and domain-shift scenarios compared to conventional approaches. The proposed framework achieves 84.1% to 96.2% detection accuracy under cross- dataset evaluation demonstrating both technical efficacy and practical viability. These advancements address critical gaps in digital content authentication, offering a scalable solution for combating sophisticated synthetic media in real-world applications.;;978-1-6654-5810-8;10.1109/ACROSET66531.2025.11280626;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11280626;"Deepfake Detection;Federated Learning;Residual Learning;BiLSTM;Privacy Preservation;Face Forgery;Temporal Modeling";"Training;Deepfakes;Privacy;Visualization;Accuracy;Federated learning;Face recognition;Computational modeling;Bidirectional long short term memory;Media";;;;34;IEEE;16 Dec 2025;27-28 Sept. 2025;27-28 Sept. 2025;IEEE;IEEE Conferences
DeepShield: AI-Powered Deepfake Detection;"S. Sharma; K. Gupta";"Department of Computer Science Engineering, Sharda School of Engineering and Technology, Sharda University, Greater Noida, India; Department of Computer Science Engineering, Sharda School of Engineering and Technology, Sharda University, Greater Noida, India";2025 5th International Conference on Intelligent Technologies (CONIT);24 Sep 2025;2025;;;1;7;The growing pervasiveness of deepfake technology is enormous in its threats to digital integrity, cybersecurity, and the diffusion of misinformation. Public opinion can be manipulated by deepfake media, identity authentication can be challenged, and digital trust can be harmed. To curb such threats, we introduce DeepShield, a new AI-powered deepfake detection system that combines spatial and temporal analysis for strong forgery detection. Our approach integrates a ResNeXt-based Convolutional Neural Network (CNN) for extracting spatial features and a Long Short-Term Memory (LSTM) network for detecting temporal abnormalities between video frames. DeepShield is trained on benchmark datasets such as FaceForensics++ and DFDC and reaches an accuracy of $\mathbf{8 1. 9 7 \%}$ with $\mathbf{8 3. 4 \%}$ recall and $\mathbf{8 0. 4 \%}$ F1-score, all while having good generalization. Though not surpassing state-of-the-art models in bare accuracy, DeepShield prioritizes scalability, robustness against unseen manipulations, and deployability. We also provide future directions such as transformer-based architecture and multimodal detection, thus positioning DeepShield as a step towards robust real-time video authentication in digital forensics and cybersecurity.;;979-8-3315-2233-9;10.1109/CONIT65521.2025.11167853;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11167853;"Deepfake detection;Convolutional Neural Networks (CNN);Long Short-Term Memory (LSTM);ResNeXt;Video Authentication";"Deepfakes;Accuracy;Computational modeling;Authentication;Computer architecture;Feature extraction;Transformers;Robustness;Convolutional neural networks;Long short term memory";;;;25;IEEE;24 Sep 2025;20-22 June 2025;20-22 June 2025;IEEE;IEEE Conferences
Identifying Machine Generated Tweets: Deepfake Detection on Social Media;"N. F. Shrene Shifna; K. Baalaji; P. Niharika; P. Swathi; P. R. Krishna; R. Leena";"Department of Computer Science and Engineering, Bharath Institute of Higher Education and Research, Chennai, India; Department of Computer Science and Engineering, Bharath Institute of Higher Education and Research, Chennai, India; Department of Computer Science and Engineering, Bharath Institute of Higher Education and Research, Chennai, India; Department of Computer Science and Engineering, Bharath Institute of Higher Education and Research, Chennai, India; Department of Computer Science and Engineering, Bharath Institute of Higher Education and Research, Chennai, India; Department of Computer Science and Engineering, Bharath Institute of Higher Education and Research, Chennai, India";2024 3rd Edition of IEEE Delhi Section Flagship Conference (DELCON);11 Feb 2025;2024;;;1;5;In the digital age, the expansion of machine-generated content poses significant challenges to the integrity of online communications. This project addresses the critical issue of detecting fake tweets on Social networking websites platforms by utilizing modern advanced deep learning algorithms and fast text embedded data. Deep fakes, particularly machine-generated text, are becoming increasingly sophisticated, making it essential to develop robust methods for identifying such content. This approach integrates current deep learning models with fast text embedding techniques to differentiate between human-written and machine-generated tweets. These models are fine-tuned to classify tweets based on semantic and syntactic features captured through pre-trained embeddings. Specifically, quick text embeddings in conjunction with convolutional neural networks (CNN) and long short-term memory networks (LSTM) are used to propose a novel approach to deepfake detection using deep learning techniques in this study. Rapid text embeddings strengthen the model's capacity to distinguish between real and fake information by capturing semantic subtleties and contextual linkages in textual data. In order to extract hierarchical features from tweet sequences and to capture temporal dependencies, our approach combines these embeddings with CNNs and LSTMs. Using a dataset of tweets, the suggested method was assessed and found to perform better than conventional techniques in identifying content that was created by machines.;;979-8-3315-1859-2;10.1109/DELCON64804.2024.10866921;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10866921;"Deepfake Detection;Machine-generated content;Fake tweets;Deep learning;Text embeddings;CNN;LSTM;semantic analysis;syntactic features;rapid text embeddings";"Deep learning;Deepfakes;Social networking (online);Text recognition;Semantics;Syntactics;Feature extraction;Vectors;Convolutional neural networks;Long short term memory";;;;15;IEEE;11 Feb 2025;21-23 Nov. 2024;21-23 Nov. 2024;IEEE;IEEE Conferences
Voices of Deception - Detecting AI-Synthesized Speech Using Spectrotemporal Features and Hybrid Learning Models;"K. Vaghchhipawala; P. Nadkarni; A. Pai; A. Trivedi; S. Bollavarapu";"Department of Computer Engineering, NMIMS University, MPSTME, Mumbai, Maharashtra, India; Department of Computer Engineering, NMIMS University, MPSTME, Mumbai, Maharashtra, India; Department of Computer Engineering, NMIMS University, MPSTME, Mumbai, Maharashtra, India; Department of Computer Engineering, NMIMS University, MPSTME, Mumbai, Maharashtra, India; Department of Computer Engineering, NMIMS University, MPSTME, Mumbai, Maharashtra, India";2025 IEEE 6th India Council International Subsections Conference (INDISCON);2 Dec 2025;2025;;;1;6;With the advent of highly realistic AIsynthesized voice, the risk of deepfake voices has increased immensely, giving rise to grave concerns in domains such as fraud, impersonation, and digital trust. There is a gap in reliable, real-time detection solutions since current detection systems typically fall short when faced with a variety of accents, speaker styles, or complex synthesis approaches. This work proposes a hybrid deepfake voice detection framework that merges both machine learning and deep learning techniques with spectrotemporal features. A tailor-made dataset was collected from three significant sources- actual speech from the Speech Accent Archive, artificially created samples using Google Text-to-Speech, and cloned voices from the DEEP-VOICE dataset. Mel-Frequency Cepstral Coefficients (MFCCs) were utilized to extract relevant features from each audio sample. Two models were created and tested: a Voting Classifier that merges SVM, Random Forest, and Gradient Boosting, and a CNN-LSTM deep learning model that is capable of learning spatial and temporal speech patterns. The two models were accurate and above $95 \%$ and were incorporated into a user-friendly Gradio web interface to test in real-time. The findings show that combining multiple approaches with robust audio features yields a scalable and efficient solution for AI-generated voice identification. The system is highly suitable for use in security, media authentication, voice-based verification, and fraud prevention online.;;979-8-3315-1504-1;10.1109/INDISCON66021.2025.11252158;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11252158;"Deepfake audio;voice synthesis;CNN-LSTM;Voting Classifier;MFCC;real-time detection;audio forensics";"Deep learning;Deepfakes;Feature extraction;Real-time systems;Fraud;Text to speech;Security;Reliability;Usability;Random forests";;;;25;IEEE;2 Dec 2025;21-23 Aug. 2025;21-23 Aug. 2025;IEEE;IEEE Conferences
Preserving the Veracity of Digital Media using Neural Network Based Detection of Deepfake Videos;"P. Bire; O. Ambalkar; R. Bagade; P. Mehta; A. Yenkikar";"Computer Science Engineering (Artificial Intelligence), Vishwakarma Institute of Information Technology, Pune; Computer Science Engineering (Artificial Intelligence), Vishwakarma Institute of Information Technology, Pune; Computer Science Engineering (Artificial Intelligence), Vishwakarma Institute of Information Technology, Pune; Computer Science Engineering (Artificial Intelligence), Vishwakarma Institute of Information Technology, Pune; Computer Science Engineering (Artificial Intelligence), Vishwakarma Institute of Information Technology, Pune";2024 IEEE International Conference on Blockchain and Distributed Systems Security (ICBDS);17 Jan 2025;2024;;;1;6;"Free deep learning applications have made it easier to create similar to humans synthesized videos in the past couple of years, a trend known as ""deep fakes."" Over many years, it has been possible to manipulate digital videos through the skilful use of visual effects. However, the simplicity with which fake content can be created and its realism have both increased dramatically due to recent advancements in deep learning. It is easy to imagine scenarios in which people are blackmailed, political unrest is caused, or events involving terrorism are fabricated using these realistic face-swapping deepfakes. This project proposal describes an exciting deep learning-based method that effectively recognizes real videos from ones produced by artificial intelligence. The use of artificial intelligence (AI) to combat AI is mentioned in the proposed model. The proposed method extracts frame-level features utilizing a Res-Next Convolution neural network. These attributes are then used to train an LSTM-based Recurrent Neural Network (RNN) to identify videos based on whether they have been altered or not, i.e., whether they are deepfake or real. The Deepfake Detection Challenge and Celeb-DF are two examples of the many available datasets that are combined to create a big, balanced, and mixed dataset that the model's performance on real-time data and apply it to real-world scenarios.";;979-8-3503-5434-8;10.1109/ICBDS61829.2024.10837046;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10837046;"Deepfake Video Detection;Res-Next;Convolution neural network;Recurrent Neural Network (RNN);Long Short-Term Memory (LSTM)";"Deep learning;Deepfakes;Recurrent neural networks;Terrorism;Feature extraction;Visual effects;Market research;Real-time systems;Proposals;Long short term memory";;;;25;IEEE;17 Jan 2025;17-19 Oct. 2024;17-19 Oct. 2024;IEEE;IEEE Conferences
DDEM: Deepfake Detection Enhanced Model for Image Forgery Detection Combat Academic Misconduct;"J. Ding; J. Liu; J. Shi; X. Hu; X. Qiao; H. E";"School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China; Beijing Wanfang Data Co., Ltd., Beijing, China; School of Artificial Intelligence, Beijing University of Posts and Telecommunications, Beijing, China; School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China; Beijing Wanfang Data Co., Ltd., Beijing, China; School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China";2024 11th International Conference on Behavioural and Social Computing (BESC);12 Dec 2024;2024;;;1;6;Image forgery, as a classic form of academic mis-conduct, has garnered increasing interest from researchers in the field of research integrity. Concurrently, automated detection and localization methods for image forgery have been making steady progress. However, the rapid advancement of image generation and image inpainting methods based on diffusion models presents new threats to the task of image forgery detection. Existing approaches are finding it difficult to identify forgery images that have been spliced by deepfake images and authentic photographs. To tackle this challenge, we propose the Deepfake Detection Enhanced Model (DDEM), which learns image features from both the RGB domain and frequency domain using the HRNet backbone. Furthermore, we introduce diffusion reconstruction error to enhance deepfake detection capabilities in our model. Fi-nally, we conduct experiments on public datasets and a self-made dataset generated by the image inpainting model, demonstrating that our proposed method outperforms the state-of-the-art in terms of image tampering detection and localization.;2689-8284;979-8-3315-3190-4;10.1109/BESC64747.2024.10780724;"Ministry of Science and Technology(grant numbers:GXCZ-D-21070106);";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10780724;"Research Integrity;Image Forgery Detection;Deepfake Detection;Image Splicing Detection";"Location awareness;Deepfakes;Visualization;Social computing;Image synthesis;Frequency-domain analysis;Splicing;Feature extraction;Forgery;Image reconstruction";;1;;41;IEEE;12 Dec 2024;16-18 Aug. 2024;16-18 Aug. 2024;IEEE;IEEE Conferences
Deepfake Detection using Multi-Stream Convolutional Neural Networks with Attention-based Fusion;"M. Sankaran; M. Alwbaidy; L. K. R; S. D. Govardhan; P. P. Selvam";"USA; Department of Computers Techniques Engineering, College of Technical Engineering, The Islamic University, Najaf, Iraq; Department of Electronics and Communication Engineering, Nitte Meenakshi Institute of Technology, Nitte (Deemed to be University), Bengaluru, India; Department of Electronics and Communication Engineering, Dhanalakshmi Srinivasan College of Engineering and Technology, Mamallapuram, India; Doctoral Studies and Intellectual Property Rights, Meenakshi Academy of Higher Education & Research (Deemed to be University), Chennai, India";2025 International Conference on Intelligent Communication Networks and Computational Techniques (ICICNCT);18 Nov 2025;2025;;;1;6;In recent years, DeepFake technology has rapidly evolved by enabling the development of highly realistic forged facial videos that pose serious threats to digital trust and security. Traditional deep learning approaches, although effective in image classification, usually struggle to generalize against subtle manipulation artifacts, compression noise, and temporal inconsistencies. To address these challenges, a MultiStream Convolutional Neural Network (MS-CNN) framework is proposed for robust deepfake detection. Initially, utilizes the FaceForensics++ dataset which is a widely recognized benchmark containing authentic and manipulated facial videos. Preprocessing incorporates face detection, alignment, and the generation of complementary modalities, which include frequency-domain representations, residual noise maps, and temporal signals, such as rPPG and optical flow. These multimodal inputs were passed through parallel CNN streams for feature extraction to capture spatial, spectral, and temporal inconsistencies. The extracted features are combined using an attention-based adaptive fusion mechanism that dynamically learns the relative importance of each modality. Finally, a fully connected softmax classifier produces end-to-end predictions that differentiate between real and fake videos. The experimental results show that the MS-CNN obtains higher accuracy (99.77 %), precision (98.95 %), recall (98.45 %), and F1score (98.76 %) when compared with the existing CNN model, which improves detection robustness and generalization in different manipulation techniques.;;979-8-3315-8623-2;10.1109/ICICNCT66124.2025.11232837;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11232837;"deepfake detection;multi-stream convolutional neural networks;residual noise maps;softmax classifier;temporal signals";"Training;Deepfakes;Accuracy;Computational modeling;Noise;Feature extraction;Transformers;Robustness;Convolutional neural networks;Security";;;;15;IEEE;18 Nov 2025;5-6 Sept. 2025;5-6 Sept. 2025;IEEE;IEEE Conferences
Emerging Innovations in Deep Learning for Video DeepFake Detection: A Comprehensive Review;"M. K. Makwana; D. K. Singh; S. Shukla";"IT Department, PIET Parul University, Vadodara, India; IT Department, PIET Parul University, Vadodara, India; IT Department, PIET Parul University, Vadodara, India";2025 4th International Conference on Sentiment Analysis and Deep Learning (ICSADL);27 Mar 2025;2025;;;1242;1246;The fast growth of artificial intelligence technology allowed researchers to develop highly believable deepfake media that causes significant privacy breaches while being used for legitimate educational and entertainment purposes. Modern deep generative models are evolving at a fast pace so detecting manipulated media has emerged as an essential requirement. An analysis examines the latest advancements in deepfake detection through an assessment of machine learning (ML) and deep learning (DL) methods particularly outlined by transfer learning and transformer-based systems. The evaluation analyzes modern approaches that detect artificial auditory and visual abnormalities which also solve problems with restricted datasets and the challenges of cross-manipulation and adversarial resistance. This study merges current scholarly research to show how modern detection systems perform yet stresses that more trustworthy detection solutions with enhanced efficiency need to develop. The rise of digital media in society demands sustained investment for research and technology development in video security protection. The progress of advanced deepfakes calls for organization-wide innovations in detection frameworks using AI-based solutions that must be developed to minimize their threats to digital content protection.;;979-8-3315-2392-3;10.1109/ICSADL65848.2025.10933018;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10933018;"DeepFake detection;video forensics;deep learning;generative models;adversarial attacks";"Deep learning;Deepfakes;Technological innovation;Visualization;Computational modeling;Transforms;Media;Transformers;Real-time systems;Protection";;;;18;IEEE;27 Mar 2025;18-20 Feb. 2025;18-20 Feb. 2025;IEEE;IEEE Conferences
Deepfake Detection Using Advanced Learning Frameworks and Benchmark Evaluation;"M. B; J. N; N. P; T. J; T. Mohapatra";"Artificial Intelligence & Data Science, K.S. School of Engineering and Management, Bengaluru, India; Artificial Intelligence & Data Science, K.S. School of Engineering and Management, Bengaluru, India; Artificial Intelligence & Data Science, K.S. School of Engineering and Management, Bengaluru, India; Artificial Intelligence & Data Science, K.S. School of Engineering and Management, Bengaluru, India; Artificial Intelligence & Data Science, K.S. School of Engineering and Management, Bengaluru, India";2025 IEEE International Conference on Compute, Control, Network & Photonics (ICCCNP);14 Nov 2025;2025;;;1;6;Recent advances in generative AI have produced highly realistic fake images and videos, exacerbating misinformation and security risks. Deepfake detection methods can be categorized into traditional ML (e.g. SVMs, decision trees with handcrafted features), supervised deep learning (CNNs, RNNs/LSTMs, EfficientNet, etc.), and self-supervised learning techniques (e.g. contrastive learning with attention mechanisms). Popular benchmarks – FaceForensics++, Celeb-DF, DFDC and others – provide large video datasets for evaluation, but they embed specific artifacts and demographic biases. In practice, detectors also face challenges of overfitting, large model size, computational cost, and dependence on extensive labeled data, all of which hinder real-time deployment. Emerging solutions aim to overcome these gaps. For example, attention-based and transformer models (often lightweight) have been used to capture subtle spatiotemporal inconsistencies, improving robustness to post-processing. Multimodal fusion (combining visual, audio, or textual cues) and domain-adaptive training have also been explored to reduce bias and enhance generalization. This survey synthesizes these trends – outlining a structured taxonomy of approaches, reviewing benchmark datasets and their limits, and highlighting challenges (generalization, bias, performance) and promising directions (attention mechanisms, multimodal and domain-adaptive learning) in deepfake detection.;;979-8-3315-3539-1;10.1109/ICCCNP63914.2025.11233705;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11233705;"Deepfake detection;GAN;CNN;LSTM;FaceForensics++;DFDC";"Training;Surveys;Deepfakes;Visualization;Attention mechanisms;Computational modeling;Taxonomy;Benchmark testing;Transformers;Spatiotemporal phenomena";;;;20;IEEE;14 Nov 2025;18-19 Sept. 2025;18-19 Sept. 2025;IEEE;IEEE Conferences
Deepfake Video Detection Using Spatiotemporal Convolutional Network and Photo Response Non Uniformity;"S. J. Pipin; R. Purba; M. F. Pasha";"Master of Information Technology Universitas Mikroskil, Medan, Indonesia; Master of Information Technology Universitas Mikroskil, Medan, Indonesia; School of Information Technology Monash University, Penang, Malaysia";2022 IEEE International Conference of Computer Science and Information Technology (ICOSNIKOM);13 Feb 2023;2022;;;1;6;It is important to improve the detection of deepfake videos to differentiate between real and fake videos that cause disinformation in the digital age so that a high level of accuracy is required. The purpose of deepfake video detection is to aid digital content consumers to surmount disinformation and sever real videos from fake ones. Limited by the number and quality of datasets, the time required for detection, and consistent performance evaluation i.e., the detection model cannot detect videos detected with video editing tools. This study provides a solution to this problem by using the Spatiotemporal Convolutional Network (SCN) method and Photo-Response Non-Uniformity (PRNU) analysis. The dataset used will go through pre-processing stages, extract per-frame video, detect face parts, and face cropping. Then the data is spread and modeled using RestNext50 and LSTM. This study produced 10 models using the FaceForensic, CelebDF, and DFDC datasets, and a mixture of these datasets which can then be used to analyze deepfake videos. The test results show that the deepfake detection process is faster and more accurate with an accuracy rate of up to 97.89%.;;979-8-3503-9907-3;10.1109/ICOSNIKOM56551.2022.10034890;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10034890;"deepfake;deepfake video detection;SCN;photo-response non uniformity (PRNU)";"Performance evaluation;Training;Deepfakes;Analytical models;Face recognition;Computational modeling;Media";;11;;17;IEEE;13 Feb 2023;19-21 Oct. 2022;19-21 Oct. 2022;IEEE;IEEE Conferences
Deepfake Detection for Enhanced Security in Workplace Environments Using Deep Learning Techniques;"M. Asaduzzaman; M. M. Hassan; T. Bhuiyan";"Department of Software Engineering, Daffodil International University, Dhaka, Bangladesh; Dept. of Computer Science & Engineering, Southeast University, Bangladesh; School of IT, Washington University of Science & Technology, Virginia, USA";2025 8th International Conference on Information and Computer Technologies (ICICT);3 Jul 2025;2025;;;173;179;Deepfake technology's widespread use poses serious risks to workplace security by eroding confidence and making it easier for nefarious actions including identity theft, data breaches, and disinformation. Even while current detection techniques make use of sophisticated deep learning models, their generalisability, computing efficiency, and resilience to hostile attacks sometimes cause them to fail in practical applications. In order to improve identification accuracy and liveness verification, this study presents a unique hybrid detection framework that combines face and speech features with feature-level fusion and multimodal biometric analysis. The suggested system is excellent at identifying subtle deepfake changes because it integrates convolutional neural networks (CNNs) for feature extraction and a Bi-LSTM-based classifier for temporal analysis. Additionally, the framework uses a multi-task learning approach that makes it possible to detect and locate deepfake artefacts simultaneously, enhancing the performance and interpretability of the model. Tested on extensive datasets, including DeepfakeTIMIT and AVSpeech, the system obtained a detection accuracy of 98.7%, exceeding state-of-the-art approaches. This strategy shows a lot of promise for implementation in work settings, offering strong defence against new threats while maintaining user privacy and operational scalability. Future research will examine real-time deployment and edge computing technologies for extensive workplace applications.;2769-4542;979-8-3315-0518-9;10.1109/ICICT64582.2025.00033;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11058521;"Deepfake Detection;Workplace Security;Deep Learning Techniques;Multimodal Biometrics;CNN-RNN Hybrid Model;Liveness Detection;Adversarial Resilience";"Deep learning;Biometrics;Deepfakes;Accuracy;Computational modeling;Biological system modeling;Employment;Feature extraction;Real-time systems;Resilience";;;;22;IEEE;3 Jul 2025;14-16 March 2025;14-16 March 2025;IEEE;IEEE Conferences
A Comprehensive Review of Deepfake Detection In Advanced Neural Network Architectures and Deep Learning Strategies;"D. Singh; P. Singh; R. Bhandari";"Dept. Of CSE Chandigarh University, Mohali, India; Dept. Of CSE Chandigarh University, Mohali, India; Dept. Of CSE Chandigarh University, Mohali, India";2024 International Conference on Artificial Intelligence and Emerging Technology (Global AI Summit);9 Apr 2025;2024;;;1147;1152;The proliferation of deepfakes, facilitated by advancements in machine learning and artificial intelligence, poses a significant challenge to online security and information integrity. This study reviews current deep fake detection techniques, focusing on methodologies for identifying manipulated content in images, audio, and video. 17 articles were selected for this study using Prisma guidelines. The function of sophisticated machine learning models, such as Long Short-Term Memory (LSTM) networks and (CNNs), is highlighted for automating detection processes. The review also examines notable algorithms and datasets, including FaceForensics++, MesoNet, and XceptionNet, and their effectiveness in enhancing detection accuracy. A case study using frame extraction and resizing techniques demonstrates a detection accuracy of 62%, with precision at 61 %, recall at 63%, and an F1 score of 62% is also included. The findings underscore the need for ongoing refinement and adaptation of detection systems to counteract the evolving nature of deepfake technologies. The study providing thorough overview of the state-of-the-art in deepfake detection, offering insights into effective methodologies and future research directions.;;979-8-3503-7971-6;10.1109/GlobalAISummit62156.2024.10947978;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10947978;"CNNs;Generative adversarial networks(GAN);Deepfake detection;DL;Misinformation detection;Video analysis;Spatial-temporal features;Machine learning;Neural network fusion;LSTMs;Introduction;Digital media integrity";"Deepfakes;Accuracy;Machine learning algorithms;Reviews;Neural networks;Focusing;Security;Long short term memory;Information integrity;Guidelines";;;;20;IEEE;9 Apr 2025;4-6 Sept. 2024;4-6 Sept. 2024;IEEE;IEEE Conferences
Scene and Texture Based Feature Set for DeepFake Video Detection;"A. N. Ramkissoon; V. Rajamanickam; W. Goodridge";"Department of Computing & Information Technology, The University of the West Indies at St Augustine, St Augustine, Trinidad & Tobago; Department of Computing & Information Technology, The University of the West Indies at St Augustine, St Augustine, Trinidad & Tobago; Department of Computing & Information Technology, The University of the West Indies at St Augustine, St Augustine, Trinidad & Tobago";2022 IEEE International Conference on Data Mining Workshops (ICDMW);8 Feb 2023;2022;;;90;97;The existence of fake videos is a problem that is challenging today's social media-enabled world. There are many classifications for fake videos with one of the most popular being DeepFakes. Detecting such fake videos is a challenging issue. This research attempts to comprehend the characteristics that belong to DeepFake videos. In attempting to understand DeepFake videos this work investigates the characteristics of the video that make them unique. As such this research uses scene and texture detection to develop a unique feature set containing 19 data features which is capable of detecting whether a video is a DeepFake or not. This study validates the feature set using a standard dataset of the features relating to the characteristics of the video. These features are analysed using a classification machine learning model. The results of these experiments are examined using four evaluation methodologies. The analysis reveals positive performance with the use of the ML method and the feature set. From these results, it can be ascertained that using the proposed feature set, a video can be predicted as a DeepFake or not and as such prove the hypothesis that there exists a correlation between the characteristics of a video and its genuineness, i.e., whether or not a video is a DeepFake.;2375-9259;979-8-3503-4609-1;10.1109/ICDMW58026.2022.00021;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10029383;"Classification;DeepFakes;Features;Scene Detection;Texture Detection";"Deepfakes;Analytical models;Correlation;Conferences;Machine learning;Feature extraction;Prediction algorithms";;2;;36;IEEE;8 Feb 2023;28 Nov.-1 Dec. 2022;28 Nov.-1 Dec. 2022;IEEE;IEEE Conferences
Comparative Analyais of CNN Architectures for Deep Fake Detection;"P. Wani; S. Chavan; S. Paithankar; D. Ghusse; S. Barve";"School of Computer Engineering, MIT Academy of Engineering, Pune, India; School of Computer Engineering, MIT Academy of Engineering, Pune, India; School of Computer Engineering, MIT Academy of Engineering, Pune, India; School of Computer Engineering, MIT Academy of Engineering, Pune, India; School of Computer Engineering, MIT Academy of Engineering, Pune, India";2025 3rd International Conference on Intelligent Systems, Advanced Computing and Communication (ISACC);22 Apr 2025;2025;;;1119;1125;DeepFake technology, driven by advanced generative models, threatens online authenticity and privacy. This paper presents a comparative analysis of three convolutional neural network (CNN) architectures—VGGFace16, DenseNet-121, and a custom CNN model—for DeepFake image detection. The study utilizes the 140k Faces Dataset, comprising 70,000 real and 70,000 synthetic images, and the Real and Fake Face Detection Dataset from Yonsei University, ensuring a diverse and well-balanced training set while accounting for computational constraints. Feature extraction from the final convolutional layers, dimensionality reduction via Principal Component Analysis (PCA), and classification with a Support Vector Machine (SVM) using a polynomial kernel form the core methodology. DenseNet-121 achieved the highest accuracy (97%) on grayscaled images, while the augmented custom CNN balanced accuracy (86%) and interpretability, attaining a Receiver Operating Characteristic Area Under the Curve (ROC-AUC) score of 0.953. PCA visualizations confirmed the models’ ability to distinguish real from fake images. The findings underscore dataset selection’s role in model performance and the necessity of resource-efficient training. Future work will expand dataset diversity, explore cross-dataset validation, and leverage advanced computational resources to enhance generalization, contributing to more robust DeepFake detection systems.;;979-8-3315-2389-3;10.1109/ISACC65211.2025.10969171;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10969171;"DeepFake detection;convolutional neural networks (CNN);VGGFace16;DenseNet-121;custom CNN;140k Faces Dataset;Real and Fake Face Detection Dataset;feature extraction;Principal Component Analysis (PCA);Support Vector Machine (SVM);polynomial kernel;ROC-AUC";"Support vector machines;Training;Deepfakes;Accuracy;Computational modeling;Computer architecture;Feature extraction;Polynomials;Convolutional neural networks;Principal component analysis";;1;;20;IEEE;22 Apr 2025;27-28 Feb. 2025;27-28 Feb. 2025;IEEE;IEEE Conferences
Decoding Voice Authenticity: An Exploration of Deep Learning and Audio Feature Techniques;"S. T. Yalla; M. G. P. Raju; D. Nagaraju; M. F. Ali";"Department of AI & Data Science, CBIT, Hyderabad, India; Department of AI & Data Science, CBIT, Hyderabad, India; Department of AI & Data Science, CBIT, Hyderabad, India; Department of AI & Data Science, CBIT, Hyderabad, India";2025 3rd International Conference on Intelligent Data Communication Technologies and Internet of Things (IDCIoT);13 Mar 2025;2025;;;1722;1729;The increasing sophistication of spoofing, mimicry, and deepfake technologies exposes critical vulnerabilities in voice authentication systems, including the inability to generalize across diverse attack types, reliance on narrow feature sets, and a lack of interpretability, which seriously limits their applicability in the real world. This review will analyze the state-of-the-art techniques for Logical Access, Presentation Attacks, and Deepfake manipulations. It points out the limitations of the traditional models and progress based on modern frameworks. It explores using advanced audio features Mel-Spectrogram and MFCC along with LightGBM classifiers and incorporates SHAP (Shapley Additive Explanations) for model transparency and cosine similarity matrices for mimicry detection. The study identifies a dual-layered framework that attains high accuracy and robustness across datasets while ensuring adaptability to emerging attack strategies. It addresses the critical need for scalable, interpretable, and adaptive voice authentication solutions and provides a foundation for effectively mitigating evolving audio spoofing threats.;;979-8-3315-2754-9;10.1109/IDCIOT64235.2025.10914906;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10914906;"Voice Spoof Detection;Presentation Attacks (PA);Logical Access (LA);Deepfake Detection (DF);Cosine Similarity Matrix;Voice Authentication;Machine Learning Models;Voice Feature Extraction;Secure Voice Communication";"Deepfakes;Adaptation models;Reviews;Virtual assistants;Authentication;Feature extraction;Robustness;Real-time systems;Multilingual;Security";;;;21;IEEE;13 Mar 2025;5-7 Feb. 2025;5-7 Feb. 2025;IEEE;IEEE Conferences
Deepfake Content Detection using Deep Learning Techniques;"H. Devarajan; I. S. V. Palli; A. Ahammed; H. R. Kolagatla";"Department of Computer Science and Engineering, Vel Tech Rangarajan Dr. Sagunthala R&D Institute of Science and Technology, Chennai, India; Department of Computer Science and Engineering, Vel Tech Rangarajan Dr. Sagunthala R&D Institute of Science and Technology, Chennai, India; Department of Computer Science and Engineering, Vel Tech Rangarajan Dr. Sagunthala R&D Institute of Science and Technology, Chennai, India; Department of Computer Science and Engineering, Vel Tech Rangarajan Dr. Sagunthala R&D Institute of Science and Technology, Chennai, India";2025 3rd International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS);21 Jul 2025;2025;;;1561;1568;The rapid advancement of deep learning has led to the widespread use of deepfake technology, enabling realistic media manipulations that pose significant ethical and security challenges. This paper presents a novel deepfake detection framework leveraging the usage of deep learning techniques i.e, Vision Transformers (ViTs) for Image classification, Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) for Video Classification, Librosa and Mel-Frequency Cepstral Coefficients (MFCCs) for audio classification with enhanced computational efficiency and detection accuracy. The proposed models possessed 98 percent accuracy in detecting the fake content. By optimizing deep neural network models with hardware acceleration (leveraging the use of GPU), the system effectively distinguishes between authentic and manipulated media. This research contributes to the development of robust AI-driven security measures to counter misinformation and safeguard digital integrity.;;979-8-3315-3884-2;10.1109/ICSSAS66150.2025.11081378;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11081378;"Deepfake Detection;Vision Transformers (ViTs);Convolutional Neural Networks (CNNs);Recurrent Neural Networks (RNNs);TensorFlow;Librosa;Mel-Frequency Cepstral Coefficients (MFCCs);Deep Learning;Images;Videos;Audios;real-time detection";"Deep learning;Deepfakes;Computer vision;Accuracy;Recurrent neural networks;Cepstral analysis;Computational modeling;Transformers;Convolutional neural networks;Reliability";;;;25;IEEE;21 Jul 2025;11-13 June 2025;11-13 June 2025;IEEE;IEEE Conferences
A Computer Vision Model to Identify Deepfakes to Combat Misinformation During Political Events;"A. Narayan; S. Fox";"Computer Vision Research Concentration, Pioneer Academics, Bengaluru, India; Mathematics, Statistics, and Computer Science, Macalester College, St Paul, USA";2024 IEEE 11th Uttar Pradesh Section International Conference on Electrical, Electronics and Computer Engineering (UPCON);12 May 2025;2024;;;1;11;"With rampant use of technology, deepfake videos have emerged as a critical issue in today's global landscape of rapid information dissemination, leading to new dimensions of influence and power. Political events frequently fall victim to misinformation; emphasizing that the authenticity of such propagated media is paramount. The aim of this paper is to utilize advanced AI and ML algorithms to combat the rising challenge of deepfakes - hyper-realistic videos that appear convincingly genuine to the human eye. This work utilizes Error Level Analysis to detect compression inconsistencies between frames and compares this approach with a modified CNN architecture. The modified InceptionResnetVl model that was created achieved a training accuracy of 78% and a validation accuracy of 75% when tested on the DeepFake Detection Challenge dataset. This was also tested with the Presidential Deepfake Dataset. A potential extension of this paper would be the integration of ELA with the modified CNN model significantly improving training efficiency and achieving a higher accuracy while also increasing computational simplicity.";2687-7767;979-8-3503-7872-6;10.1109/UPCON62832.2024.10983603;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10983603;"Deepfake Detection;CNN;Error-Level Analysis;Hyper-realistic frame detection;Media authenticity verification;Political Misinformation";"Training;Deepfakes;Visualization;Accuracy;Image analysis;Computational modeling;Lighting;Computer architecture;Optimization;Context modeling";;;;27;IEEE;12 May 2025;29 Nov.-1 Dec. 2024;29 Nov.-1 Dec. 2024;IEEE;IEEE Conferences
Preventing DeepFake Attacks on Speaker Authentication by Dynamic Lip Movement Analysis;"C. -Z. Yang; J. Ma; S. Wang; A. W. -C. Liew";"School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Information and Communication Technology, Griffith University, Gold Coast, QLD, Australia";IEEE Transactions on Information Forensics and Security;5 Jan 2021;2021;16;;1841;1854;Recent research has demonstrated that lip-based speaker authentication systems can not only achieve good authentication performance but also guarantee liveness. However, with modern DeepFake technology, attackers can produce the talking video of a user without leaving any visually noticeable fake traces. This can seriously compromise traditional face-based or lip-based authentication systems. To defend against sophisticated DeepFake attacks, a new visual speaker authentication scheme based on the deep convolutional neural network (DCNN) is proposed in this paper. The proposed network is composed of two functional parts, namely, the Fundamental Feature Extraction network (FFE-Net) and the Representative lip feature extraction and Classification network (RC-Net). The FFE-Net provides the fundamental information for speaker authentication. As the static lip shape and lip appearance is vulnerable to DeepFake attacks, the dynamic lip movement is emphasized in the FFE-Net. The RC-Net extracts high-level lip features that discriminate against human imposters while capturing the client's talking style. A multi-task learning scheme is designed, and the proposed network is trained end-to-end. Experiments on the GRID and MOBIO datasets have demonstrated that the proposed approach is able to achieve an accurate authentication result against human imposters and is much more robust against DeepFake attacks compared to three state-of-the-art visual speaker authentication algorithms. It is also worth noting that the proposed approach does not require any prior knowledge of the DeepFake spoofing method and thus can be applied to defend against different kinds of DeepFake attacks.;1556-6021;;10.1109/TIFS.2020.3045937;"National Natural Science Foundation of China(grant numbers:61771310);";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9298826;"DeepFake spoofs;dynamic lip movement;lip biometrics;liveness detection;multi-task learning";"Lips;Videos;Information integrity;Authentication;Faces;Feature extraction;Password";;70;;69;IEEE;18 Dec 2020;2021;;IEEE;IEEE Journals
Interactive Two-Stream Network Across Modalities for Deepfake Detection;"J. Wu; B. Zhang; Z. Li; G. Pang; Z. Teng; J. Fan";"School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; AI Laboratory, Lenovo Research, Beijing, China";IEEE Transactions on Circuits and Systems for Video Technology;26 Oct 2023;2023;33;11;6418;6430;As face forgery techniques have become more mature, the proliferation of deepfakes may threaten the security of human society. Although existing deepfake detection methods achieve good performance for in-dataset evaluation, it remains to be improved in the generalization ability, where the representation of the imperceptible artifacts plays a significant role. In this paper, we propose an Interactive Two-Stream Network (ITSNet) to explore the discriminant inconsistency representation from the perspective of cross-modality. In particular, the patch-wise Decomposable Discrete Cosine Transform (DDCT) is adopted to extract fine-grained high-frequency clues, and information from different modalities communicates with each other via a designed interaction module. To perceive the temporal inconsistency, we first develop a Short-term Embedding Module (SEM) to refine subtle local inconsistency representation between adjacent frames, and then a Long-term Embedding Module (LEM) is designed to further refine the erratic temporal inconsistency representation from the long-range perspective. Extensive experimental results conducted on three public datasets show that ITSNet outperforms the state-of-the-art methods both in terms of in-dataset and cross-dataset evaluations.;1558-2205;;10.1109/TCSVT.2023.3269841;"Fundamental Research Funds for the Central Universities of China(grant numbers:2022JBMC009); National Natural Science Foundation of China(grant numbers:61972027); Beijing Municipal Natural Science Foundation(grant numbers:42120411);";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10107603;"Deepfake detection;inconsistency representation;cross-modality learning";"Forgery;Faces;Frequency-domain analysis;Feature extraction;Deepfakes;Convolution;Discrete cosine transforms";;22;;53;IEEE;24 Apr 2023;Nov. 2023;;IEEE;IEEE Journals
Deepfake Detection Using EfficientNet and XceptionNet;"B. Yasser; J. Hani; S. El-Gayar; O. Amgad; N. Ahmed; H. M. Ebied; H. Amr; M. Salah";"Software Engineering Faculty of Computer and Information Sciences, Ain Shams University, Cairo, Egypt; Software Engineering Faculty of Computer and Information Sciences, Ain Shams University, Cairo, Egypt; Computer Science Department, Faculty of Computer and Information Sciences, Ain Shams University, Cairo, Egypt; Software Engineering Faculty of Computer and Information Sciences, Ain Shams University, Cairo, Egypt; Software Engineering Faculty of Computer and Information Sciences, Ain Shams University, Cairo, Egypt; Scientific Computing Department, Faculty of Computer and Information Sciences, Ain Shams University, Cairo, Egypt; Software Engineering Faculty of Computer and Information Sciences, Ain Shams University, Cairo, Egypt; Software Engineering Faculty of Computer and Information Sciences, Ain Shams University, Cairo, Egypt";2023 Eleventh International Conference on Intelligent Computing and Information Systems (ICICIS);18 Jan 2024;2023;;;598;603;The increasing prevalence of manipulated media, particularly deepfake videos, poses significant challenges in distinguishing real from fake content. This paper addresses the issue of detecting deepfake videos using advanced CNN architectures such as EfficientNet-B4 and XceptionNet. The FF++ and Celeb-DF (v2) datasets are used to compare real and fake videos. The methodology involves preprocessing the Celeb- DF dataset by extracting frames and isolating faces, training the models, and evaluating their performance using log loss and Area Under the Curve (AUC) metrics. The study shows that both models are effective in accurately classifying real and fake videos and highlights the importance of continuously updating deepfake detection algorithms in response to evolving deepfake generation techniques.;2831-5952;979-8-3503-2210-1;10.1109/ICICIS58388.2023.10391114;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10391114;"Deepfake Detection;Extracting Frames;cropping faces;accuracy;XceptionNet;EfficientNet";"Training;Measurement;Deepfakes;Computational modeling;Computer architecture;Detection algorithms;Faces";;6;;21;IEEE;18 Jan 2024;21-23 Nov. 2023;21-23 Nov. 2023;IEEE;IEEE Conferences
Deepfake Video Detection Methods using Deep Neural Networks;"M. Kshirsagar; S. Suratkar; F. Kazi";"CoE-CNDS, VJTI, Mumbai, India; CoE-CNDS, VJTI, Mumbai, India; CoE-CNDS, VJTI, Mumbai, India";2022 Third International Conference on Intelligent Computing Instrumentation and Control Technologies (ICICICT);18 Oct 2022;2022;;;27;34;Nowadays, humans are dealing with incipient trouble known as deepfake videos, advanced with the usage of deep learning. Due to freely accessible deep fake technology equipment and inexpensive computational power, internet is flooded with fake media like fake images, videos, audios etc. Fake images and videos are causing threats to privacy, reputation and the very identity of common people. Researchers are taking efforts to develop tools using various Convolutional Neural Networks (CNNs) to automatically detect this fake media however the existing tools are not able to cope with the evolution of deep fakes. In this paper, 26 unique deep convolutional models are utilised for the task of deepfake video detection. The models can natively classify objects like table, face, humans, cars etc. However, the paper highlights the use of these models in detection of deepfake/manipulated images and videos by changing the top layer of the model with sigmoid layer hence, detecting artifacts in an image produced by Generative Adversarial Networks (GANs)[11]. Once the models are trained, the paper demonstrates the usefulness of model ensemble to improve the accuracy of proposed system and thereby making the system more reliable.;;978-1-6654-1005-2;10.1109/ICICICT54557.2022.9917701;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9917701;"Deep learning;deepfake detection;ensemble learning;autoencoders";"Deep learning;Deepfakes;Visualization;Computational modeling;Neural networks;Predictive models;Media";;4;;35;IEEE;18 Oct 2022;11-12 Aug. 2022;11-12 Aug. 2022;IEEE;IEEE Conferences
Deepfake Detection on Videos Based on Ratio Images;"R. L. Testa; A. Machado-Lima; F. L. S. Nunes";"School of Arts, Sciences and Humanities University of São Paulo, São Paulo, Brazil; School of Arts, Sciences and Humanities University of São Paulo, São Paulo, Brazil; School of Arts, Sciences and Humanities University of São Paulo, São Paulo, Brazil";2022 12th International Congress on Advanced Applied Informatics (IIAI-AAI);23 Sep 2022;2022;;;403;408;Deepfake detection comes as a countermeasure to identify fake media content to reduce its harmful implications. Most detection approaches rely on identifying specific artifacts that can quickly become obsolete due to the fast advance in facial forgery methods. Some facial manipulation detection methods use temporal information to classify the video as real or fake. These methods mainly rely on 3D CNN architectures or two-stream networks using frame and video features. Our method not only considers temporal aspects, but it comes from a different perspective: extracting features that can account for inter-frame changes on a video. Inspired by the concept of ratio images, we extract features based on the ratio between adjacent frames for the face and its background. The experimental evaluation showed better results in intra- and cross-dataset tests on FaceForensics++ (FF++) and CelebDF datasets compared to the state-of-the-art deepfake detection approaches in the assessment with seen and unseen facial manipulation methods, as well as in seen and unseen video settings. In the intra-dataset experiment, the model resulted in an AUC of 100% for both CelebDF and FF++ datasets. In the cross dataset experiment, the model resulted in an AUC of 98% when trained with CelebDF and tested with FF++ and 86% when trained with FF++ and tested with CelebDF.;2472-0070;978-1-6654-9755-8;10.1109/IIAIAAI55812.2022.00086;"Coordenação de Aperfeiçoamento de Pessoal de Nível Superior; ";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9894567;"Deepfake detection;facial forgery;facial manipulation;Expression Ratio Image;spatial-temporal;video";"Deepfakes;Three-dimensional displays;Media;Feature extraction;Forgery;Informatics;Faces";;;;30;IEEE;23 Sep 2022;2-8 July 2022;2-8 July 2022;IEEE;IEEE Conferences
DeepFake Image Detection Using Adaptive Discriminator Augmentation (ADA);"D. A. Talib; A. A. Abed";"Department of Computer Engineering, University of Basrah, Basrah, Iraq; Department of Computer Engineering, University of Basrah, Basrah, Iraq";2023 1st International Conference on Advanced Engineering and Technologies (ICONNIC);21 Mar 2024;2023;;;248;253;The proliferation of Deepfake technology, driven by artificial intelligence (AI), poses a growing threat as it facilitates the dissemination of hate speech and misinformation through convincingly fabricated images. Deepfakes, a subdomain of AI, manipulate and superimpose one person's face onto another's, exploiting the power of machine learning to create deceptive content at an unprecedented pace and affordability. Despite the controversial nature of Deepfakes, their use is expanding both commercially and collectively. This paper offers an in-depth investigation into the effectiveness of StyleGAN2-ADA in identifying fake images, with a particular focus on detecting Deepfakes. We propose a novel GAN Discriminator model designed to enhance the accuracy of this detection process. Our model's training dataset comprises an extensive collection of 76,400 images from the FFHQ dataset. In our experimental evaluation, we subjected our model to 100 fake images, achieving an impressive detection rate of 95.71 %. This remarkable outcome underscores the efficacy of our approach in identifying Deepfakes. Furthermore, our technique demonstrates exceptional precision in distinguishing between real and fake images, promising a robust defense against the harmful impact of AI-generated fake content.;;979-8-3503-0648-4;10.1109/ICONNIC59854.2023.10467610;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10467610;"DeepFake images;Detection Fake;Image datasets;StyleGAN2-ADA;Adaptive Discriminator Augmentation";"Training;Deepfakes;Image synthesis;Hate speech;Machine learning;Generative adversarial networks;Multitasking";;;;47;IEEE;21 Mar 2024;14-14 Oct. 2023;14-14 Oct. 2023;IEEE;IEEE Conferences
Dynamic Lip Motion Analysis for Deepfake Detection;"A. Castiglione; L. Cimmino; V. Loia; M. Nappi; C. Sorrentino";"Dept. of Management & Innovation Systems, University of Salerno, Italy; Dept. of Computer Science, University of Salerno, Italy; Dept. of Management & Innovation Systems, University of Salerno, Italy; Dept. of Computer Science, University of Salerno, Italy; Dept. of Computer Science, University of Salerno, Italy";2025 25th International Conference on Control Systems and Computer Science (CSCS);30 Sep 2025;2025;;;452;459;The proliferation of deepfake videos poses a significant threat to the integrity of digital media, given their capacity to disseminate misinformation and undermine the reliability of visual content. As synthetic audiovisual forgeries become increasingly realistic, they are being used in coordinated disinformation efforts, contributing to the broader issue of information disorder, which compromises public trust, media authenticity, and the verifiability of digital evidence. This study investigates the effectiveness of spatio-temporal features, extracted using Local Binary Patterns on Three Orthogonal Planes (LBP-TOP), in distinguishing synthetic from authentic video content. The approach focuses on the dynamic characteristics of the labial region, where inconsistencies in facial motion are more likely to occur in deepfake videos. LBP-TOP is employed to capture subtle texture and motion variations across spatial and temporal dimensions. Preliminary empirical evaluations conducted on benchmark deepfake datasets demonstrate the efficacy of the proposed approach, emphasizing the importance of localized temporal analysis in enhancing detection accuracy. The results highlight the potential of region-specific facial modelling as a computationally efficient yet discriminative strategy in the context of video forensics and the mitigation of synthetic media-based disinformation.;2379-0482;979-8-3315-7343-0;10.1109/CSCS66924.2025.00073;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11181647;"Deepfake Detection;Misinformation;Spatiotemporal Feature Extraction;Local Binary Patterns on Three Orthogonal Planes (LBP-TOP);Digital Video Forensics";"Deepfakes;Adaptation models;Visualization;Forensics;Computational modeling;Dynamics;Benchmark testing;Feature extraction;Robustness;Forgery";;;;29;IEEE;30 Sep 2025;27-30 May 2025;27-30 May 2025;IEEE;IEEE Conferences
Detecting Digital Deception: A CNN-RNN hybrid Approach of Deepfake Detection;"H. Singh; R. Kumar; M. Gupta; V. S. Babu Chilluri";"Department of CSE, Chandigarh University, Mohali, India; Department of CSE, Chandigarh University, Mohali, India; Department of CSE, Chandigarh University, Mohali, India; Intuit Inc., Mountain View, CA, USA";2025 International Conference on Pervasive Computational Technologies (ICPCT);1 Apr 2025;2025;;;667;672;Deepfake technology has forced digital deception to create high demand for detection tools. This paper presents an approach for deepfake video detection using Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) architecture that targets the artifacts present in the output from the generative models including Generative adversarial network (GAN). This approach looks at many strategies in terms of frames, among them for frame comparison, feature extraction based on CNNs, and for the purpose of temporal analysis CNN with long-short-term memory (LSTM) networks. The described model is trained on the set of the genuine vs. forged images and videos and demonstrates quite stable results with respect to digital forging detection. It is discovered that this proposed model achieves higher accuracy than previously used detection approaches in addressing face-swapping and face-reenactment deepfakes. The findings of this research demonstrate that CNN & RNN based deepfake detection is promising for media forensics, as it advances multimedia security and digital media credibility. This proposed method shows an accuracy of 81% in the Deepfake Detection Dataset (DFDS), respectively, with a very reduced number of sample size of ⩽ 100 samples(frames). This promises early detection of fake contents compared to existing modalities.;;979-8-3315-0868-5;10.1109/ICPCT64145.2025.10940830;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10940830;"Deepfake Detection;Convolutional Neural Network (CNN);Digital Deception;Image Manipulation;Artificial Intelligence (AI);Machine Learning;Multimedia Forensics;Video Analysis;Face Recognition;Image Authentication";"Deepfakes;Recurrent neural networks;Accuracy;Forensics;Machine learning;Streaming media;Generative adversarial networks;Convolutional neural networks;Security;Long short term memory";;11;;21;IEEE;1 Apr 2025;8-9 Feb. 2025;8-9 Feb. 2025;IEEE;IEEE Conferences
Spatiotemporal Deepfake Video Detection: A Hybrid CNN-Transformer Approach with Frequency Analysis;"N. Celebi; Q. Liu";"Department of Computer Science, Sam Houston State University, Huntsville, TX, USA; Department of Computer Science, Sam Houston State University, Huntsville, TX, USA";2025 IEEE International Conference on Information Reuse and Integration and Data Science (IRI);12 Sep 2025;2025;;;216;221;Deepfakes are AI-generated manipulated videos that closely mimic real individuals, posing significant risks to privacy, digital security, and information authenticity. To address these threats, we propose DFD-V, a novel deepfake detection framework that combines spatial, frequency, and temporal analysis to capture diverse forgery artifacts. The model extracts per-frame features using an EfficientNet-B0 backbone for spatial cues and a custom CNN operating on 2D FFT spectra to detect frequency-domain anomalies. A Motion-Aware Frequency Attention (MAF) module further emphasizes temporal inconsistencies in spectral patterns. These dual features are fused via Selective Cross-Domain Attention Fusion (SCDAF), aligning complementary evidence. The fused representations are then modeled over time using a Bidirectional LSTM, enabling detection of frame-level inconsistencies such as flicker or jitter. We preprocess videos by extracting aligned facial regions and apply standard augmentations to improve robustness. The model is trained using binary cross-entropy loss, with optional adversarial domain adaptation to enhance cross-dataset generalization. Experimental results demonstrate that DFD-V achieves strong performance on multiple benchmarks, offering a reliable and interpretable framework for robust deepfake video detection.;2835-5776;979-8-3315-9944-7;10.1109/IRI66576.2025.00048;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11153098;"DeepFake video detection;deep learning;digital forensics;machine learning;multimedia security";"Deepfakes;Adaptation models;Privacy;Streaming media;Feature extraction;Robustness;Spatiotemporal phenomena;Rough surfaces;Security;Standards";;;;26;IEEE;12 Sep 2025;6-8 Aug. 2025;6-8 Aug. 2025;IEEE;IEEE Conferences
Video Forensic Analysis Using Deep Learning Models;"V. T. R.; A. Ajina; H. Dongare; S. Joshi; G. L. S. Varma; R. D. Rathod";"Dept. of AI & DS, Ramaiah Institute of Technology, Bengaluru, India; Dept. of AI & ML, Ramaiah Institute of Technology, Bengaluru, India; Dept. of AI & DS, Ramaiah Institute of Technology, Bengaluru, India; Dept. of AI & DS, Ramaiah Institute of Technology, Bengaluru, India; Dept. of AI & DS, Ramaiah Institute of Technology, Bengaluru, India; Dept. of AI & DS, Ramaiah Institute of Technology, Bengaluru, India";2025 International Conference on Emerging Technologies in Computing and Communication (ETCC);12 Aug 2025;2025;;;1;6;Recent advancements in deep learning have significantly improved video forensics, crucial for security and law enforcement. This field addresses video tampering detection, source identification, and content analysis, requiring sophisticated methods due to complex manipulations. This paper introduces a novel framework leveraging Convolutional Neural Networks (CNNs) and Long Short-Term Memory (LSTM) networks. CNNs extract spatial features, identifying tampering through pixel-level inconsistencies. LSTMs model temporal dependencies, detecting anomalies over time and sophisticated forgeries like DeepFakes. This hybrid combination of CNNs and LSTMs provides a comprehensive approach, capturing spatial details and temporal dynamics, and enhancing forgery detection accuracy. Experiments on Deepfake Detection Challenge(DFDC) dataset, it includes a wide variety of deepfake and real videos, to show this framework overcomes the limitations in previous technologies used in models like XceptionNet and is robust in real-world scenarios. This research highlights the potential for secure digital media platforms and future advancements in forensic techniques.;;979-8-3315-2476-0;10.1109/ETCC65847.2025.11108521;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11108521;"Deepfake detection;deep learning;Convolutional Neural Networks;LSTMs;video forensics";"Deep learning;Deepfakes;Analytical models;Accuracy;Forensics;Feature extraction;Solids;Forgery;Convolutional neural networks;Long short term memory";;;;21;IEEE;12 Aug 2025;26-27 June 2025;26-27 June 2025;IEEE;IEEE Conferences
Enhancing Deepfake Detection Through Dynamics of Facial Expressions;"V. K. Sharma; S. Rawat";"Amity School of Engineering & Technology, Amity University, Noida, Uttar Pradesh, India; Amity School of Engineering & Technology, Amity University, Noida, Uttar Pradesh, India";2025 6th International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV);25 Jul 2025;2025;;;70;79;The rapid evolution of deepfake technology poses significant threats to digital security, media integrity, and public trust, necessitating the development of robust detection frame-works. Traditional deepfake detection methods primarily rely on pixel inconsistencies, frequency-domain analysis, or handcrafted features, but these approaches are increasingly vulnerable to advanced generative models that produce high-fidelity manipulations. In this study, we introduce MADDM, a Masked Autoencoder-based deepfake detection model that leverages facial expression dynamics to identify inconsistencies in muscle coordination—an aspect that remains challenging for deepfake generators to replicate accurately. Our model is trained in a self-supervised manner, first learning natural facial expressions from real datasets and then detecting anomalies in synthetic videos by reconstructing masked facial regions. Evaluations on Celeb-DF, DFDC, and FaceForensics++ datasets demonstrate that MADDM significantly outperforms existing detection methods, achieving an average accuracy of 81.1%, with state-of-the-art performance on Celeb-DF (86.3%). Further analysis through intra-dataset and cross-dataset testing confirms the model’s superior generalization capabilities. The results highlight the potential of expression-based deepfake detection as a powerful and scalable solution for digital forensics and misinformation control. Future research should explore real-time implementation, transformer-based optimizations, and adversarial training strategies to enhance detection efficiency against evolving deepfake techniques.;;979-8-3315-1175-3;10.1109/ICICV64824.2025.11085942;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11085942;"deepfake detection;facial expressions analysis;spatio temporal;convolutional neural network;masked auto encoders";"Training;Deepfakes;Frequency-domain analysis;Autoencoders;Transformers;Feature extraction;Generators;Facial muscles;Security;Optimization";;;;24;IEEE;25 Jul 2025;17-19 June 2025;17-19 June 2025;IEEE;IEEE Conferences
Artifacts-Disentangled Adversarial Learning for Deepfake Detection;"X. Li; R. Ni; P. Yang; Z. Fu; Y. Zhao";"Institute of Information Science, Beijing Jiaotong University, Beijing, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China; Hubei Key Laboratory of Intelligent Vision Based Monitoring for Hydroelectric Engineering, China Three Gorges University, Yichang, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China";IEEE Transactions on Circuits and Systems for Video Technology;4 Apr 2023;2023;33;4;1658;1670;Due to the development of facial manipulation technologies, the generated deepfake videos cause a severe trust crisis in society. Existing methods prove that effective extraction of the artifacts introduced during the forgery process is essential for deepfake detection. However, since the features extracted by supervised binary classification contain a lot of artifact-irrelevant information, existing algorithms suffer severe performance degradation in the case of the mismatch between training and testing datasets. To overcome this issue, we propose an Artifacts-Disentangled Adversarial Learning (ADAL) framework to achieve accurate deepfake detection by disentangling the artifacts from irrelevant information. Furthermore, the proposed algorithm provides visual evidence by effectively estimating artifacts. Specifically, Multi-scale Feature Separator (MFS) in the disentanglement generator is designed to precisely transmit the artifact features and optimize the connection between the encoder and decoder. In addition, we design an Artifacts Cycle Consistency Loss (ACCL) which uses the disentangled artifacts to construct new samples and enables pixel-level supervised training for the generator to estimate more accurate artifacts. The symmetric discriminators are paralleled to differentiate the constructed samples from the original images in both fake and real domains, making the adversarial training process more stable. Extensive experiments on existing benchmarks demonstrate that the proposed method outperforms the state-of-the-art approaches.;1558-2205;;10.1109/TCSVT.2022.3217950;"National Key Research and Development Program of China(grant numbers:2021ZD0112100); National Natural Science Foundation of China(grant numbers:U1936212,62120106009); Beijing Natural Science Foundation(grant numbers:4222014);";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9931753;"Deepfake detection;video forensics;artifacts;disentanglement learning";"Deepfakes;Feature extraction;Forgery;Face recognition;Faces;Visualization;Training";;60;;48;IEEE;28 Oct 2022;April 2023;;IEEE;IEEE Journals
DFFMD: A Deepfake Face Mask Dataset for Infectious Disease Era With Deepfake Detection Algorithms;"N. M. Alnaim; Z. M. Almutairi; M. S. Alsuwat; H. H. Alalawi; A. Alshobaili; F. S. Alenezi";"Computer Science Department, College of Sciences and Humanities in Jubail, Imam Abdulrahman Bin Faisal University, Dammam, Saudi Arabia; Information Technology Department, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia; Computer Science Department, College of Computer Science and Information System, Umm Al-Qura University, Mecca, Saudi Arabia; Computer Science Department, College of Computer Science and Information System, Umm Al-Qura University, Mecca, Saudi Arabia; Computer Science Department, College of Computer, Qassim University, Buraydah, Saudi Arabia; Department of Electrical Engineering, College of Engineering, Jouf University, Sakaka, Saudi Arabia";IEEE Access;24 Feb 2023;2023;11;;16711;16722;Deepfake is a technology that creates fake images and videos with replaced or synthesized faces. Deepfakes are becoming a concerning social phenomenon, as they can be maliciously used to generate false political news, disseminate dangerous information, falsify electronic evidence, and commit digital harassment and fraud. The ease and accuracy of creating Deepfakes have been bolstered by the popularity of wearing face masks since the beginning of the infectious disease outbreak (2020). Because these masks obstruct defining facial features, fake videos are now even more challenging to identify, increasing the necessity for advanced Deepfake detection technology. The research also creates a real/fake video dataset with face masks because the field lacks the dataset required for detection-model training. The proposed research proposes a Deepfake Face Mask Dataset (DFFMD) based on a novel Inception-ResNet-v2 with preprocessing stages, feature-based, residual connection, and batch normalization. The combination of preprocessing stages, feature-based, residual connection, and batch normalization increases the detection accuracy of deepfake videos in the presence of facemasks, unlike the traditional methods. The study’s results compared with existing state-of-the-art methods detect face-mask-Deepfakes with 99.81% accuracy compared to the traditional InceptionResNetV2 and VGG19, whose accuracy is 77.48%, and 99.25%, respectively. Future work should evaluate the accuracy of developing a subsequent experimental work for increased detection of deepfake with facemasks.;2169-3536;;10.1109/ACCESS.2023.3246661;"Deputyship for Research & Innovation, Ministry of Education in Saudi Arabia(grant numbers:223202);";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10049065;"Deepfake;deep learning;CNN;generation;detection;fake videos;neural network;mask;face mask";"Deepfakes;Face recognition;Convolutional neural networks;Animation;Transformers;Feature extraction;Deep learning";;52;;49;CCBYNCND;20 Feb 2023;2023;;IEEE;IEEE Journals
Deepfake Video Detection Based on Spatial, Spectral, and Temporal Inconsistencies Using Multimodal Deep Learning;"J. K. Lewis; I. E. Toubal; H. Chen; V. Sandesera; M. Lomnitz; Z. Hampel-Arias; C. Prasad; K. Palaniappan";"Florida Southern College; University of Missouri; University of Maryland, College Park; IQT Labs; IQT Labs; IQT Labs; University of Missouri; University of Missouri";2020 IEEE Applied Imagery Pattern Recognition Workshop (AIPR);10 May 2021;2020;;;1;9;"Authentication of digital media has become an ever-pressing necessity for modern society. Since the introduction of Generative Adversarial Networks (GANs), synthetic media has become increasingly difficult to identify. Synthetic videos that contain altered faces and/or voices of a person are known as deepfakes and threaten trust and privacy in digital media. Deep-fakes can be weaponized for political advantage, slander, and to undermine the reputation of public figures. Despite imperfections of deepfakes, people struggle to distinguish between authentic and manipulated images and videos. Consequently, it is important to have automated systems that accurately and efficiently classify the validity of digital content. Many recent deepfake detection methods use single frames of video and focus on the spatial information in the image to infer the authenticity of the video. Some promising approaches exploit the temporal inconsistencies of manipulated videos; however, research primarily focuses on spatial features. We propose a hybrid deep learning approach that uses spatial, spectral, and temporal content that is coupled in a consistent way to differentiate real and fake videos. We show that the Discrete Cosine transform can improve deepfake detection by capturing spectral features of individual frames. In this work, we build a multimodal network that explores new features to detect deepfake videos, achieving 61.95% accuracy on the Facebook Deepfake Detection Challenge (DFDC) dataset.";2332-5615;978-1-7281-8243-8;10.1109/AIPR50011.2020.9425167;"National Science Foundation; ";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9425167;"deepfake detection;deep learning;multi-modal;computer vision";"Visualization;Pipelines;Mouth;Nose;Predictive models;Media;Feature extraction";;40;;50;IEEE;10 May 2021;13-15 Oct. 2020;13-15 Oct. 2020;IEEE;IEEE Conferences
MSVT: Multiple Spatiotemporal Views Transformer for DeepFake Video Detection;"Y. Yu; R. Ni; Y. Zhao; S. Yang; F. Xia; N. Jiang; G. Zhao";"Institute of Information Science, Beijing Jiaotong University, Beijing, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China; Rapid-Rich Object Search Laboratory, Interdisciplinary Graduate Program, Nanyang Technological University, Jurong West, Singapore; Mashang Consumer Finance Company Ltd., Chongqing, China; Mashang Consumer Finance Company Ltd., Chongqing, China; Mashang Consumer Finance Company Ltd., Chongqing, China";IEEE Transactions on Circuits and Systems for Video Technology;5 Sep 2023;2023;33;9;4462;4471;Recently, DeepFake videos have developed rapidly, causing new security issues in society. Due to the rough spatiotemporal view, existing video-based detection methods struggle to capture fine-grained spatiotemporal information, resulting in limited generalization ability. In addition, although the transformer has achieved great success in the past few years, the application of transformer on deepfake video detection still needs to be studied. To solve this problem, in this paper, we propose a novel Multiple Spatiotemporal Views Transformer (MSVT) with Local Spatiotemporal View (LSV) and Global Spatiotemporal View (GSV), to mine more detailed spatiotemporal information. Firstly, for establishing the LSV, different from existing works that sparsely sample a single frame to build the input sequence, we employ the local-consecutive temporal view to capture vital dynamic inconsistency. Furthermore, the extracted frame features within each group are fed to the temporal transformer followed by the feature fusion module, to generate group-level spatiotemporal features. Then, we further establish Global Spatiotemporal View (GSV) by feeding all the frame features within the whole video to the temporal transformer followed by the feature fusion module. Finally, we propose a novel global-local transformer (GLT) to effectively integrate these multi-level features for mining more subtle and comprehensive features. Extensive experiments on six large datasets demonstrate that our MSVT outperforms state-of-the-art detection methods.;1558-2205;;10.1109/TCSVT.2023.3281448;"National Key Research and Development Program of China(grant numbers:2021ZD0112100); National NSF of China(grant numbers:U1936212,62120106009); Beijing NSF(grant numbers:4222014);";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10138555;"Generalized DeepFake detection;multiple spatiotemporal views;global-local transformer";"Transformers;Feature extraction;Spatiotemporal phenomena;Deepfakes;Feeds;Faces;Task analysis";;36;;78;IEEE;30 May 2023;Sept. 2023;;IEEE;IEEE Journals
Deepfakes Detection Methods: A Literature Survey;"M. Weerawardana; T. Fernando";"Department of Computer Science, University of Sri Jayewardenepura, Nugegoda, Sri Lanka; Department of Computer Science, University of Sri Jayewardenepura, Nugegoda, Sri Lanka";2021 10th International Conference on Information and Automation for Sustainability (ICIAfS);10 Nov 2021;2021;;;76;81;Recently, a great amount of concern has been attracted to the phenomena of DeepFake, which has been created for capturing and reenacting faces in a video and swap a face with someone else’s face using neural networks. In Deepfake technology, a computer-generated fake video shows fictional contents as real things. Many unbelievable applications in this technology are starting to be explored. Currently, malicious usages of fake videos are gaining in the computerized world like fake news, celebrity pornographic videos, revenge porn, and financial frauds. So, celebrities, politicians and famous people are facing mostly to Deepfake detection problem. Human’s naked eyes are weak to directly identify the difference between real videos and Deepfake videos because they are quite realistic. So, bothered people require an automated computerized Deepfake detection tool. This paper reviews existing Deepfake detection methods using traditional methods and deep learning technologies. Further this paper discussing the limitations of current methods and availability of datasets in the society. According to the literature, there is not a highly accurate and automated detection method to identify Deepfakes. The unavailability of efficient Deepfake detection method is a big challenge to the world due to the ease of generating Deepfake videos and their rapid spread. However, there are many efforts to solve this phenomenon and deep learning related methods show remarkable performance than other methods.;2151-1810;978-1-6654-4429-3;10.1109/ICIAfS52090.2021.9606067;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9606067;"Deepfake technology;dataset;fake detection;machine learning;deep learning";"Deep learning;Image coding;Automation;Neural networks;Tools;Sustainable development;Faces";;16;;48;IEEE;10 Nov 2021;11-13 Aug. 2021;11-13 Aug. 2021;IEEE;IEEE Conferences
MCL: Multimodal Contrastive Learning for Deepfake Detection;"X. Liu; Y. Yu; X. Li; Y. Zhao";"Institute of Information Science, Beijing Jiaotong University, Beijing, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China";IEEE Transactions on Circuits and Systems for Video Technology;4 Apr 2024;2024;34;4;2803;2813;Advancements in computer vision and deep learning have led to difficulty in distinguishing Deepfake and real videos. In particular, forgery audios are also generated to accompany fake videos and make them more realistic, which makes Deepfake detection more difficult. Existing Deepfake detection methods that use multimodal information ignore the representation gap between different modalities, resulting in limited performance. To address this problem, in this paper, a novel Deepfake detection method utilizing multimodal contrastive learning (MCL) is proposed to better explore intra-modal and cross-modal forgery clues. To reduce the cross-modal gap and explore multimodal forgery artifacts, a cross-modal contrastive learning strategy is designed to learn a compositional embedding from multimodal information, which facilitates pulling together representations across uni-modalities and multi-modalities. Moreover, to supplement the intra-frame forgery clues mining ability of the video network, the frame knowledge is distilled to the video network without adding additional computation. Specifically, to mine intra-modal clues, three modality features are first extracted from audio, frame and video, respectively. Secondly, the audio and frame features are separately composed with the video feature to derive two cross-modal representations. Subsequently, these cross-modal features are contrastive with the intra-modal features to reduce cross-modal gap. By jointly pulling together the unimodal and multimodal features through MCL, a more effective representation that contains intra-modal and cross-modal forgery artifacts can be learned. Finally, a noise-based feature augmentation (NFA) module is proposed to adaptively perturb the audio-visual feature and further improve generalization performance. Extensive experiments demonstrate that the proposed framework outperforms SOTA methods.;1558-2205;;10.1109/TCSVT.2023.3312738;"National Key Research and Development Program of China(grant numbers:2020AAA0140003); National NSF of China(grant numbers:U1936212,62120106009); Government of Shandong Province(grant numbers:ZR2022LZH011);";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10243082;"Deepfake detection;contrastive learning;knowledge distillation";"Feature extraction;Deepfakes;Forgery;Data mining;Visualization;Training;Data augmentation";;16;;77;IEEE;7 Sep 2023;April 2024;;IEEE;IEEE Journals
Generalizable Deepfake Detection With Phase-Based Motion Analysis;"E. Prashnani; M. Goebel; B. S. Manjunath";"Department of Electrical and Computer Engineering, University of California at Santa Barbara, Santa Barbara, CA, USA; Department of Electrical and Computer Engineering, University of California at Santa Barbara, Santa Barbara, CA, USA; Department of Electrical and Computer Engineering, University of California at Santa Barbara, Santa Barbara, CA, USA";IEEE Transactions on Image Processing;12 Dec 2024;2025;34;;100;112;We propose PhaseForensics, a DeepFake (DF) video detection method that uses a phase-based motion representation of facial temporal dynamics. Existing methods that rely on temporal information across video frames for DF detection have many advantages over the methods that only utilize the per-frame features. However, these temporal DF detection methods still show limited cross-dataset generalization and robustness to common distortions due to factors such as error-prone motion estimation, inaccurate landmark tracking, or the susceptibility of the pixel intensity-based features to adversarial distortions and the cross-dataset domain shifts. Our key insight to overcome these issues is to leverage the temporal phase variations in the band-pass frequency components of a face region across video frames. This not only enables a robust estimate of the temporal dynamics in the facial regions, but is also less prone to cross-dataset variations. Furthermore, we show that the band-pass filters used to compute the local per-frame phase form an effective defense against the perturbations commonly seen in gradient-based adversarial attacks. Overall, with PhaseForensics, we show improved distortion and adversarial robustness, and state-of-the-art cross-dataset generalization, with 92.4% video-level AUC on the challenging CelebDFv2 benchmark (a recent state of-the-art method, FTCN, compares at 86.9%).;1941-0042;;10.1109/TIP.2024.3441821;"NSF(grant numbers:1664172); Computational Facilities Purchased under NSF(grant numbers:1925717); Dissertation Fellowship funded by the Department of Electrical and Computer Engineering at UC Santa Barbara;";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10685029;"Deepfake detection;deep learning;video analysis;video forensics";"Feature extraction;Deepfakes;Faces;Robustness;Detectors;Dynamics;Generators";;12;;85;IEEE;20 Sep 2024;2025;;IEEE;IEEE Journals
Deepfake Video Prediction Using Attention-Based CNN and Mel-Frequency Cepstral Coefficients;"G. S; S. G. A; J. D; A. J";"Department of Information Technology, Agni College of Technology, Chennai, India; Department of Information Technology, Agni College of Technology, Chennai, India; Department of Information Technology, Agni College of Technology, Chennai, India; Department of Information Technology, Agni College of Technology, Chennai, India";2024 Third International Conference on Electrical, Electronics, Information and Communication Technologies (ICEEICT);23 Oct 2024;2024;;;1;6;Deepfake technology seriously threatens the integrity of digital media since it makes it harder to detect fraudulent deepfake videos using traditional methods. In this research, we describe a unique method for audio and visual analysis utilizing Mel-Frequency Cepstral Coefficients (MFCCs) and Attention-based CNN to detect fraudulent deepfakes. Our methodology addresses the evolving field of deepfake manipulation and offers a more comprehensive and dependable detection framework by combining audio and visual modalities. Utilizing the FakeAVceleb dataset, a carefully chosen collection of audio-visual deepfake videos created especially for research is one of the keystones of our methodology. The breadth of actual and deepfake sounds and videos provided by the FakeAVceleb dataset makes it possible to test and evaluate our detection model in great detail. We use attention-based CNN to analyze extracted visual features from video frames, with a focus on regions that can be manipulated to detect subtle audio features that indicate deepfake manipulation, thereby increasing our model's overall discriminative capability. We assess how well our method works for identifying deepfake audio and video. Our results demonstrate the efficacy of combining audio and visual analysis in deepfake detection, as our model achieves promising performance metrics including an accuracy of 94.00% using the FakeAVceleb dataset.;;979-8-3503-6908-3;10.1109/ICEEICT61591.2024.10718393;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10718393;"Deepfake Detection;Audio Analysis;Visual Analysis;Attention-based CNN;Mel-Frequency Cepstral Coefficients;Audio-Visual Integration;FakeAVCeleb";"Measurement;Deepfakes;Visualization;Analytical models;Accuracy;Predictive models;Feature extraction;Data models;Information and communication technology;Mel frequency cepstral coefficient";;8;;17;IEEE;23 Oct 2024;24-26 July 2024;24-26 July 2024;IEEE;IEEE Conferences
WaterLo: Protect Images from Deepfakes Using Localized Semi-Fragile Watermark;"N. Beuve; W. Hamidouche; O. Déforges";"CNRS, IETR - UMR 6164, Univ. Rennes, INSA Rennes, Rennes, France; Technology Innovation Institute, Masdar City, Abu Dhabi, UAE; CNRS, IETR - UMR 6164, Univ. Rennes, INSA Rennes, Rennes, France";2023 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW);25 Dec 2023;2023;;;393;402;Most existing contributions in the field of Deepfake detection focus on passive detection methods, where the detector only analyzes the doctored image. However, this approach often lacks the ability to generalize to unseen data and struggles to detect Deepfakes generated using new deepfake models. To address this limitation, our paper proposes an active detection approach, where we have access to the image before the Deepfake is generated. Our solution involves applying a watermark that disappears in modified regions, allowing our detector to identify image modifications and localize them accurately. Additionally, we incorporate a compression module into our training pipeline to enhance the watermark’s robustness against JPEG compression. Experimental results demonstrate the effectiveness of our proposed solution, achieving a remarkable detection accuracy of 97.83% while maintaining significantly higher image quality compared to previous works. Furthermore, by incorporating the compression module in the training pipeline, we improve the detection accuracy on compressed samples, albeit with a slight decrease in accuracy for non-compressed samples. This contribution also provides a valuable tool for video owners to verify if their videos have been tampered with and safeguard them against unauthorized use. The code of the proposed framework is available at https://github.com/beuve/waterlo.;2473-9944;979-8-3503-0744-3;10.1109/ICCVW60793.2023.00046;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10350953;"deepfake detection;deep learning;watermarking";"Training;Deepfakes;Image coding;Pipelines;Transform coding;Watermarking;Detectors";;7;;35;IEEE;25 Dec 2023;2-6 Oct. 2023;2-6 Oct. 2023;IEEE;IEEE Conferences
Detection of Deepfake Environmental Audio;"H. Ouajdi; O. Hadder; M. Tailleur; M. Lagrange; L. M. Heller";"École Centrale Nantes, Nantes, France; École Centrale Nantes, Nantes, France; Nantes Université, École Centrale Nantes, CNRS, LS2N, UMR 6004, Nantes, France; Nantes Université, École Centrale Nantes, CNRS, LS2N, UMR 6004, Nantes, France; Dept. of Psychology, Carnegie Mellon University, Pittsburgh, PA, U.S.";2024 32nd European Signal Processing Conference (EUSIPCO);23 Oct 2024;2024;;;196;200;With the ever-rising quality of deep generative models, it is increasingly important to be able to discern whether the audio data at hand have been recorded or synthesized. Although the detection of fake speech signals has been studied extensively, this is not the case for the detection of fake environmental audio. We propose a simple and efficient pipeline for detecting fake environmental sounds based on the CLAP audio embedding. We evaluate this detector using audio data from the 2023 DCASE challenge task on Foley sound synthesis. Our experiments show that fake sounds generated by 44 state-of-the-art synthesizers can be detected on average with 98% accuracy. We show that using an audio embedding trained specifically on environmental audio is beneficial over a standard VGGish one as it provides a 10% increase in detection performance. The sounds misclassified by the detector were tested in an experiment on human listeners who showed modest accuracy with nonfake sounds, suggesting there may be unexploited audible features.;2076-1465;978-9-4645-9361-7;10.23919/EUSIPCO63174.2024.10715076;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10715076;"Fake detection;Environmental sound;Deep learning;Classification;Deepfake audio";"Deepfakes;Accuracy;Synthesizers;Pipelines;Europe;Detectors;Signal processing;Feature extraction;Generators;Standards";;5;;20;;23 Oct 2024;26-30 Aug. 2024;26-30 Aug. 2024;IEEE;IEEE Conferences
FairSSD: Understanding Bias in Synthetic Speech Detectors;"A. K. Singh Yadav; K. Bhagtani; D. Salvi; P. Bestagini; E. J. Delp";"Video and Image Processing Lab (VIPER), Purdue University, West Lafayette, Indiana, USA; Video and Image Processing Lab (VIPER), Purdue University, West Lafayette, Indiana, USA; Dipartimento di Elettronica, Informazione e Bioingegneria, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Milano, Italy; Video and Image Processing Lab (VIPER), Purdue University, West Lafayette, Indiana, USA";2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW);27 Sep 2024;2024;;;4418;4428;Methods that can generate synthetic speech which is perceptually indistinguishable from speech recorded by a human speaker, are easily available. Several incidents report misuse of synthetic speech generated from these methods to commit fraud. To counter such misuse, many methods have been proposed to detect synthetic speech. Some of these detectors are more interpretable, can generalize to detect synthetic speech in the wild and are robust to noise. However, limited work has been done on understanding bias in these detectors. In this work, we examine bias in existing synthetic speech detectors to determine if they will unfairly target a particular gender, age and accent group. We also inspect whether these detectors will have a higher misclassification rate for bona fide speech from speech-impaired speakers w.r.t fluent speakers. Extensive experiments on 6 existing synthetic speech detectors using more than 0.9 million speech signals demonstrate that most detectors are gender, age and accent biased, and future work is needed to ensure fairness. To support future research, we release our evaluation dataset, models used in our study and source code at https://gitlab.com/viper-purdue/fairssd.;2160-7516;979-8-3503-6547-4;10.1109/CVPRW63382.2024.00445;"Air Force Research Laboratory; ";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10677928;"Deepfake Detection;AntiSpoofing;Media Forensics;Fairness;Bias Study;Synthetic Speech Detectors";"Computer vision;Source coding;Conferences;Noise;Detectors;Pattern recognition;Fraud";;4;;75;IEEE;27 Sep 2024;17-18 June 2024;17-18 June 2024;IEEE;IEEE Conferences
Detecting Manipulated Audio Using Adaboost Machine Learning Algorithm;"B. V. Kumar; Y. Ayyappa; P. J. Sai; T. Varun; S. N. Babu; Y. U. S. S. Teja";"Computer Science and Engineering, P.V.P. Siddhartha Institute of Technology, Vijayawada, India; CSE, VelTech Rangarajan Dr.Sagunthala R&D Institute of Science and Technology; Computer Science and Engineering, P.V.P. Siddhartha Institute of Technology, Vijayawada, India; Computer Science and Engineering, P.V.P. Siddhartha Institute of Technology, Vijayawada, India; Computer Science and Engineering, P.V.P. Siddhartha Institute of Technology, Vijayawada, India; Computer Science and Engineering, P.V.P. Siddhartha Institute of Technology, Vijayawada, India";2024 2nd International Conference on Advancement in Computation & Computer Technologies (InCACCT);11 Jun 2024;2024;;;252;257;"The proliferation of deepfake audio necessitates robust detection methods. This work explores the efficacy of Mel- Frequency Cepstral Coefficients (MFCC) features and AdaBoost for deepfake audio identification. This proposed a pipeline involving extraction of MFCC features from segmented audio, followed by training an AdaBoost classifier on a labelled dataset of genuine and deepfake audio samples. The classifier leverages the discriminative power of MFCC features and AdaBoost ensemble learning capabilities to distinguish between authentic and manipulated audio. Among the advantages of this method are its ability to capture speech traits, strong resistance to noise and low computational requirements compared with certain deep learning methods. The recognition in this study is that we must keep updating models continuously and training them with various data sets as long as ever-changing tactics applied by creators of deepfakes continue to be an issue. Additionally, consider other audio functions which can be incorporated into it as well as hybrid methods where deep learning techniques would also be used. They have raised points about ethics concerning these technologies for detecting fake videos and call for their responsible development and use. With a research background, the proposed model described in this paper has achieved 92% accuracy rate; being better than any other models discussed here. In general terms then, what has been done here shows us just how much potential there could be behind MFCC features together with AdaBoost technique when it comes down detecting fake audios but still needs some adjustments here and there so that we apply them responsibly.";;979-8-3503-7131-4;10.1109/InCACCT61598.2024.10550994;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10550994;"Mel-Frequency Cepstral Coefficients;AdaBoost Ensemble Learning;Deepfake Audio Detection;Lower Computational Demands";"Training;Deep learning;Deepfakes;Ethics;Technological innovation;Noise;Feature extraction";;3;;23;IEEE;11 Jun 2024;2-3 May 2024;2-3 May 2024;IEEE;IEEE Conferences
Towards Quantifying and Reducing Language Mismatch Effects in Cross-Lingual Speech Anti-Spoofing;"T. Liu; I. Kukanov; Z. Pan; Q. Wang; H. B. Sailor; K. A. Lee";"Institute for Infocomm Research (I2 R) Agency for Science Technology and Research (A⋆STAR), Singapore; KLASS Engineering and Solutions, Singapore; Institute for Infocomm Research (I2 R) Agency for Science Technology and Research (A⋆STAR), Singapore; Institute for Infocomm Research (I2 R) Agency for Science Technology and Research (A⋆STAR), Singapore; Institute for Infocomm Research (I2 R) Agency for Science Technology and Research (A⋆STAR), Singapore; The Hong Kong Polytechnic University, Hong Kong";2024 IEEE Spoken Language Technology Workshop (SLT);16 Jan 2025;2024;;;1185;1192;The effects of language mismatch impact speech anti-spoofing systems, while investigations and quantification of these effects remain limited. Existing anti-spoofing datasets are mainly in English, and the high cost of acquiring multilingual datasets hinders training language-independent models. We initiate this work by evaluating top-performing speech anti-spoofing systems that are trained on English data but tested on other languages, observing notable performance declines. We propose an innovative approach - Accent-based data expansion via TTS (ACCENT), which introduces diverse linguistic knowledge to monolingual-trained models, improving their cross-lingual capabilities. We conduct experiments on a large-scale dataset consisting of over 3 million samples, including 1.8 million training samples and nearly 1.2 million testing samples across 12 languages. The language mismatch effects are preliminarily quantified and remarkably reduced over 15% by applying the proposed ACCENT. This easily implementable method shows promise for multilingual and low-resource language scenarios.;;979-8-3503-9225-8;10.1109/SLT61566.2024.10832142;"National Research Foundation; ";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10832142;"multilingual;cross-lingual;speech anti-spoofing;deepfake detection;accent";"Training;Analytical models;Costs;Conferences;Data models;Robustness;Multilingual;Testing";;3;;45;IEEE;16 Jan 2025;2-5 Dec. 2024;2-5 Dec. 2024;IEEE;IEEE Conferences
Boosting Deep Feature Fusion-Based Detection Model for Fake Faces Generated by Generative Adversarial Networks for Consumer Space Environment;"F. Alrowais; A. Abbas Hassan; W. Sulaiman Almukadi; M. H. Alanazi; R. Marzouk; A. Mahmud";"Department of Computer Sciences, College of Computer and Information Sciences, Princess Nourah bint Abdulrahman University, P.O. Box 84428, Riyadh, Saudi Arabia; Department of Computer Science, Applied College at Mahayil, King Khalid University, Abha, Saudi Arabia; Department of Software Engineering, College of Engineering and Computer Science, University of Jeddah, Jeddah, Saudi Arabia; Department of Computer Science, College of Sciences, Northern Border University, Arar, Saudi Arabia; Department of Information Systems, College of Computer and Information Sciences, Princess Nourah bint Abdulrahman University, P.O. Box 84428, Riyadh, Saudi Arabia; Research Center, Future University in Egypt, New Cairo, Egypt";IEEE Access;18 Oct 2024;2024;12;;147680;147693;In the consumer space, deep fakes refer to highly realistic, AI-generated images, audio, or videos that mimic real people generated by cutting-edge technologies such as Generative Adversarial Networks (GANs). In the digital age, recognizing and detecting deepfakes is a critical problem. The most common solutions for deepfake creation are those based on GANs, which can efficiently manipulate multimedia data or create from scratch. GANs comprise two neural networks, a Generator (G) and a Discriminator (D), that concurrently work during competition. The generator generates artificial data, whereas the discriminator calculates the authenticity of generated and real data. This adversarial procedure causes the generator to generate more realistic content. Identifying deep fakes produced by GANs using deep learning (DL) includes leveraging complex neural networks to detect subtle anomalies and artefacts that GANs accidentally introduce. Convolutional Neural Network (CNN) are very effective for these tasks, as they learn to discern inconsistencies and complex features in image textures, lighting, and facial features frequently missed by human eyes. This CNN model is trained on a massive database of fake and authentic images, allowing them to detect minor defects. This study presents a Deep Feature Fusion-based Fake Face Detection Generated by Generative Adversarial Networks (DF4D-GGAN) technique for Consumer Space Environment. The goal of the DF4D-GGAN technique is to detect the presence of real or deepfake images generated by DL. In the DF4D-GGAN technique, the Gaussian filtering (GF) approach is used for preprocessing the input images. Besides, the feature fusion process uses EfficientNet-b4 and ShuffleNet. Moreover, the hyperparameter selection of the DL models is performed by an improved slime mould algorithm (ISMA). Finally, an extreme learning machine (ELM) classifier has been employed to proficiently recognize real and fake images. To validate the results of the DF4D-GGAN technique, a series of simulations were made on benchmark datasets. The results stated that the DF4D-GGAN technique gains improved results over other models.;2169-3536;;10.1109/ACCESS.2024.3470128;"Deanship of Research and Graduate Studies at King Khalid University for funding this work through Large Research Project(grant numbers:RGP2/319/45); Princess Nourah bint Abdulrahman University Researchers(grant numbers:PNURSP2024R77); Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia; Deanship of Scientific Research at Northern Border University, Arar, KSA(grant numbers:NBU-FFR-2024-1180-09);";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10699337;"Consumer space;deepfake image detection;generative adversarial network;slime mould algorithm;image processing;CNN";"Feature extraction;Deepfakes;Generative adversarial networks;Training;Convolutional neural networks;Accuracy;Image recognition;Generators;Forgery;Image processing";;3;;82;CCBYNCND;30 Sep 2024;2024;;IEEE;IEEE Journals
Deepfake Detection: A Multi-Algorithmic and Multi-Modal Approach for Robust Detection and Analysis;"S. Nailwal; S. Singhal; N. T. Singh; A. Raza";"Department of Computer Science and Engineering, Chandigarh University, Punjab, India; Department of Computer Science and Engineering, Chandigarh University, Punjab, India; Department of Computer Science and Engineering, Chandigarh University, Punjab, India; Department of Computer Science and Engineering, Chandigarh University, Punjab, India";2023 International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE);3 Jan 2024;2023;;;1;8;In a time when deepfakes are eroding the reliability of digital media, our innovative research introduces a multi-faceted framework that achieves unprecedented levels of detection accuracy. Boasting a 97% success rate in verifying visual content and an almost unblemished 98.5% in audio analysis, our system serves as a formidable barrier against the malicious alteration of digital assets. Central to our model's stellar performance is the seamless integration of convolutional neural networks (CNNs) with ReLU activation mechanisms, all fine-tuned via stochastic gradient descent (SGD). This expertly engineered architecture is highly proficient at analyzing the nuanced spatial features of visual media, and it works in synergy with cutting-edge machine learning algorithms. For the audio detection aspect, we employ random forest algorithms, celebrated for their robustness and versatility. This ensemble learning approach adds an extra layer of complexity to the model, effectively identifying the intricate spectral and temporal characteristics of audio streams, thereby boosting the overall efficacy of our detection system. Our methodology is further fortified by meticulous data preprocessing methods, such as normalization and data augmentation, which ensure the model's robustness against a myriad of deepfake techniques. This groundbreaking research not only establishes a new benchmark in the arena of deepfake detection but also has significant ramifications for the wider field of cybersecurity and the preservation of digital authenticity. With its unmatched performance metrics, our research represents a pivotal advancement in combating the growing menace of deepfakes in today's digital society.;;979-8-3503-0570-8;10.1109/RMKMATE59243.2023.10369155;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10369155;"deepfake detection;SGD;CNN;deep learning;random forest;ReLu;GAN";"Measurement;Deepfakes;Visualization;Machine learning algorithms;Stochastic processes;Media;Robustness";;3;;27;IEEE;3 Jan 2024;1-2 Nov. 2023;1-2 Nov. 2023;IEEE;IEEE Conferences
ConTrans-Detect: A Multi-Scale Convolution-Transformer Network for DeepFake Video Detection;"W. Sun; Y. Ma; H. Zhang; R. Wang";"School of Mathematical and Computational Sciences, Massey University, Auckland, New Zealand; School of Mathematical and Computational Sciences, Massey University, Auckland, New Zealand; School of Mathematical and Computational Sciences, Massey University, Auckland, New Zealand; School of Mathematical and Computational Sciences, Massey University, Auckland, New Zealand";2023 29th International Conference on Mechatronics and Machine Vision in Practice (M2VIP);2 Feb 2024;2023;;;1;6;With the recent advancement of generative deep learning technologies, DeepFakes are the outcome of the manipulation to generate synthetic images, such as swapping a person's face in a video with another face in another video. Nowadays, deep generative models make it easy to generate fake videos, which is hard to detect. Existing methods have utilized Convolutional Neural Networks (CNNs) to identify manipulated regions for DeepFake video detection. However, these methods might not entirely tackle the difficulties of learning low-level spatial features and capturing temporal variations in temporal information, which are crucial for face forgery detection. Therefore, we propose a Convolution-Transformer Deepfake Detection (ConTrans-Detect) model, comprising a multi-scale CNN module for spatial feature representation and a multi-branch Transformer for temporal feature modeling. The multi-scale CNN module uses 3D Inception block to extract multi-scale low-level features (e.g., edges, corners, and angles) from videos. The multi-branch Transformer module consists of multi-stream Transformer layers, each taking different temporal resolutions and spatial feature dimensions as input to perceive various motion variations. Our model achieves an AUC of 0.929 and 0.920 f1 score, surpassing several state-of-the-art performances on the DeepFake Detection Challenge Datasets (DFDC).;;979-8-3503-2562-1;10.1109/M2VIP58386.2023.10413387;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10413387;"Convolutional neural network;Vision transformer;DeepFake video detection;Security;Privacy";"Deepfakes;Three-dimensional displays;Transformers;Feature extraction;Convolutional neural networks;Spatial resolution;Faces";;2;;44;IEEE;2 Feb 2024;21-24 Nov. 2023;21-24 Nov. 2023;IEEE;IEEE Conferences
Learning to Listen and Listening to Learn: Spoofed Audio Detection Through Linguistic Data Augmentation;"Z. Khanjani; L. Davis; A. Tuz; K. Nwosu; C. Mallinson; V. P. Janeja";"University of Maryland; University of Maryland; University of Maryland; University of Maryland; University of Maryland; University of Maryland";2023 IEEE International Conference on Intelligence and Security Informatics (ISI);1 Nov 2023;2023;;;1;6;Spoofed audio, both human or machine generated, causes deception and disinformation and as such is a societal challenge. This study advances the detection of spoofed audio through a novel approach that augments knowledge about audio data by incorporating linguistic information. Using perceptual methods, for English audio samples, experts in sociolinguistics listened for audio cues, and used binary labels to indicate the perceived authenticity of a set of speech samples, based on phonetic and phonological features that occur frequently in spoken English. These Expert Defined Linguistic Features (EDLFs) were then used in supervised spoofed audio detection methods to augment AI models. An ensemble method based on multi-domain features both from the audio data itself and the EDLFs was also created to evaluate the spoofed audio detection, and to demonstrate how EDLFs can improve traditional methods of spoofed audio detection. We found that augmenting the audio data with expertinformed linguistic annotation increased the accuracy of spoofed audio detection significantly in both the training and testing datasets across the evaluated single and ensemble models. Our findings indicate the promising avenue of augmenting audio data with perceptual linguistic techniques, as a method of human discernment, to enhance AI-based approaches for spoofed audio detection. These features also establish a foundation for direct linguistic annotations on new audio clips for robust spoofed audio detection.;;979-8-3503-3773-0;10.1109/ISI58743.2023.10297267;"National Science Foundation(grant numbers:2210011);";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10297267;"audio deepfake;spoofed audio detection;Artificial Intelligence;linguistics;sociolinguistics;linguistic perception";"Training;Annotations;Linguistics;Phonetics;Media;Feature extraction;Security";;2;;28;IEEE;1 Nov 2023;2-3 Oct. 2023;2-3 Oct. 2023;IEEE;IEEE Conferences
Deepfake Detection From Face-swapped Videos Using Transfer Learning Approach;"M. T. Hasan Fuad; F. Bin Amin; S. M. Masudul Ahsan";"Department of Computer Science and Engineering, Khulna University of Engineering & Technology, Khulna, Bangladesh; Department of Computer Science and Engineering, Khulna University of Engineering & Technology, Khulna, Bangladesh; Department of Computer Science and Engineering, Khulna University of Engineering & Technology, Khulna, Bangladesh";2023 26th International Conference on Computer and Information Technology (ICCIT);27 Feb 2024;2023;;;1;6;Deepfakes are synthetic media created using artificial intelligence and machine learning techniques. Deepfakes are produced by employing a generative model to alter photos, videos, or sounds and then producing a new piece of media that mimics the original. With improvements in AI technology and the availability of significant computer resources, deepfake production has become increasingly feasible. Although there are many potential uses for deepfakes in the domains of entertainment, art, and research, they also present significant ethical and security issues. Deepfakes have the potential to influence people and spread false information, which could have detrimental effects on both the individual and the larger society. To stop malicious exploitation, it's crucial to create methods for spotting deepfakes and to control their use. This paper focuses on proposing a model for detecting deepfake videos with higher accuracy on a created dataset and the existing state-of-the-art dataset. A transfer learning based model has been proposed for deepfake detection. Wide ResNet and CNN have been implemented in the proposed model. The proposed model has been tested on both the created dataset of 121 videos and 3762 videos from Deepfake Detection Challenge dataset and achieved 83.47% and 82.4% accuracy respectively which is better than other pretrained models. High computational requirement has been one of the major challenges of this work.;;979-8-3503-5901-5;10.1109/ICCIT60459.2023.10441067;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10441067;"Deepfake;synthetic facial image;transfer learning;deep learning;detection";"Deepfakes;Computer vision;Social networking (online);Computational modeling;Transfer learning;Lighting;Task analysis";;2;;22;IEEE;27 Feb 2024;13-15 Dec. 2023;13-15 Dec. 2023;IEEE;IEEE Conferences
Enhancing Authenticity Verification with Transfer Learning and Ensemble Techniques in Facial Feature-Based Deepfake Detection;"N. Qazi; I. Ahmed";"Computer and Digitial Technolgies, University of East London, London, UK; Research and Development, Tietoevry Finland Oy, Finland";2024 14th International Conference on Pattern Recognition Systems (ICPRS);23 Sep 2024;2024;;;1;6;Deepfake technology, facilitated by deep learning algorithms, has emerged as a significant concern due to its potential to deceive humans with fabricated content indistinguishable from reality. The proliferation of deepfake videos presents a formidable challenge, propagating misinformation across various sectors such as social media, politics, and healthcare. Detecting and mitigating these threats is imperative for fortifying defenses and safeguarding information integrity.This paper tackles the complexities associated with deepfake detection, emphasizing the necessity for innovative approaches given the constraints of available data and the evolving nature of forgery techniques. Our proposed solution focuses on leveraging facial features and transfer learning to discern fake videos from genuine ones, aiming to identify subtle manipulations in visual content. We systematically break down videos into frames, employ the Haar cascade algorithm for facial recognition, and utilize transfer learning to extract discriminative features. We evaluate multiple pre-trained models, including VGG16, ConvNeXtTiny, EfficientNetB0, EfficientNetB7, DenseNet201, ResNet152V2, Xception, NASNetMobile, and MobileNetV2, for feature extraction. Subsequently, we feed these features into a Deep Artificial Neural Network (DANN) for deepfake detection and employ ensemble learning to combine the strengths of the best-performing models for enhanced accuracy.We found that the ensemble model comprising ConvNextTiny, EfficientNetB0, and EfficientNetB7 showed enhanced accuracy in detecting deep fakes compared to alternative models achieving up to 98% accuracy through ensemble learning.;;979-8-3503-7565-7;10.1109/ICPRS62101.2024.10677831;"Technische Universiteit Eindhoven; European Commission; ";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10677831;"Deepfake detection;video classification;Transfer learning;EfficentNetB0;DenseNet;Ensemble learning";"Deepfakes;Visualization;Accuracy;Social networking (online);Transfer learning;Medical services;Feature extraction";;2;;20;IEEE;23 Sep 2024;15-18 July 2024;15-18 July 2024;IEEE;IEEE Conferences
Towards Analysis Detection of Deepfake Video via Deep Learning Models: A Review;"S. Altamimi; W. Salameh";"Department of Cybersecurity, King Hussein School of Computing Sciences, Princess Sumaya University for Technology, Amman, Jordan; Department of Cybersecurity, King Hussein School of Computing Sciences, Princess Sumaya University for Technology, Amman, Jordan";2024 International Jordanian Cybersecurity Conference (IJCC);21 Jan 2025;2024;;;87;92;The core of deepfake technology is the technique of altering the reality of the images and videos, where Deep Learning (DL) models can confirm the authenticity of digital media. Videos produced by these sophisticated advancements can seem to be created from actual photos, which might have consequences for security, entertainment, and politics. Experts are investigating deepfakes using DL techniques in response to this growing issue. Starting with hybrid designs, Recurrent Neural Networks (RNNs), and Convolutional Neural Networks (CNNs), To deal with deepfake. Where deepfake detection techniques are categorized according to their working mechanisms. Success in deepfake detection depends on the resolution of three main problems: model stability, dataset collection and modification, and generalization of new changes. The main contribution of this study is the comprehensive analysis and comparison of various DL algorithms for deepfake video detection, emphasizing the effectiveness of advanced models. Also, the study highlights the importance of ongoing research and innovation in developing robust detection systems to address the evolving challenges posed by deepfake technology. Additionally, the study identifies gaps in current methodologies, suggesting future directions for enhancing detection accuracy and generalizability across diverse datasets.;;979-8-3315-1846-2;10.1109/IJCC64742.2024.10847278;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10847278;"Deepfake;Deep Learning;Convolutional Neural Networks;Recurrent Neural Networks;Video Detection and Cybersecurity";"Deep learning;Deepfakes;Technological innovation;Analytical models;Accuracy;Biological system modeling;Face recognition;Ecosystems;Media;Computer security";;1;;25;IEEE;21 Jan 2025;17-18 Dec. 2024;17-18 Dec. 2024;IEEE;IEEE Conferences
A Comprehensive Comparative Analysis of Deepfake Detection Techniques in Visual, Audio, and Audio-Visual Domains;"A. A. Bekheet; A. Ghoneim; G. Khoriba";"Computer Science Department, Faculty of Computers and Artificial Intelligence, Helwan University, Cairo, Egypt; Computer Science Department, Faculty of Computers and Artificial Intelligence, Helwan University, Cairo, Egypt; Centre for Informatics Science (CIS), School of Information Technology and Computer Science (ITCS), Nile University, Giza, Egypt";2024 Intelligent Methods, Systems, and Applications (IMSA);5 Sep 2024;2024;;;122;129;In recent years, the rise of social media platforms has made them vital channels for sharing news, where audio and visual content play a crucial role in enhancing the credibility of news content. However, significant Artificial Intelligence (AI) progress has introduced new techniques and tools for manipulating multimedia content. These advancements have made it easier to create fabricated digital media, leading to a harmful impact on sharing misinformation, especially in fake news. Consequently, an urgent need arises to explore prevailing methodologies for detecting fake images, audio, and videos, accompanied by a comprehensive exposition of their strengths and limitations. Our survey addresses these methodologies and conducts a rigorous comparative analysis of diverse approaches using various metrics and datasets. We categorize these approaches into visual-based, audio-based, and audio-visual-based deepfake detection methods, encompassing techniques employed across domains. Additionally, we examine notable datasets utilized in detecting image, video, and audio deepfakes, offering insights into their attributes and appropriateness for evaluation purposes. Our findings highlight the effectiveness and limitations of current detection methods, providing a roadmap for future research in multimodal deepfake detection. This includes exploring emerging facets of video manipulation, such as text overlays and motion patterns, investigating advanced deep learning architectures like Transformers, and emphasizing the need for extensive, diverse, and publicly accessible datasets to enhance the robustness and validation of detection methods.;;979-8-3503-6263-3;10.1109/IMSA61967.2024.10652683;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10652683;"Audio-visual Deepfake Detection;Convolutional Neural Networks (CNNs);Recurrent Neural Networks (RNNs);Transformers;Mel Frequency Cepstral Coefficients (MFCC);Mel-spectrogram;Text-to-Speech Synthesis (TTS) Voice Conversion (VC)";"Surveys;Measurement;Deepfakes;Visualization;Social networking (online);Neural networks;Streaming media";;1;;68;IEEE;5 Sep 2024;13-14 July 2024;13-14 July 2024;IEEE;IEEE Conferences
Detection of Compressed DeepFake Video Drawbacks and Technical Developments;"A. -S. Humidan; L. N. Abdullah; A. A. Halin";"Faculty of Computer Science and Information Technology, Universiti Putra Malaysia, Serdang, Malaysia; Faculty of Computer Science and Information Technology, Universiti Putra Malaysia, Serdang, Malaysia; Faculty of Computer Science and Information Technology, Universiti Putra Malaysia, Serdang, Malaysia";2022 5th International Conference on Signal Processing and Information Security (ICSPIS);2 Jan 2023;2022;;;11;16;The rapid advancement in artificial intelligence (AI) has revolutionized the creation of synthesized multimedia and given rise to DeepFake, a highly realistic fake video or image depicting a person doing or saying something he/ she has never done or said in reality. Attackers use DeepFake to tarnish individuals’ reputations and disseminate fake news, which in turn undermines societies’ stability and security. In response to this cyber security threat, many DeepFake detection methods have been proposed, which show outstanding performance in detecting high-quality DeepFake videos. However, their performance decreases when detecting compressed fake videos. This article investigates the problem of compressed DeepFake video detection. Firstly, popular detection methodologies are reviewed focusing on their abilities to distinguish between real and fake compressed video footage. Then, we attempt to identify and discuss the weaknesses of the methods by examining factors that contribute to decreasing detection efficiency. At the end of this article, we present new generation DeepFake detector techniques that reportedly exhibit improved performance and robustness against video compression. We hope that the contribution from this work inspires innovation for more reliable solutions to combat potential security threats posed by DeepFake videos.;2831-3844;978-1-6654-9265-2;10.1109/ICSPIS57063.2022.10002433;"Organization for Women in Science for the Developing World; ";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10002433;"Compressed DeepFake video;digital media forensics;social media disinformation;video manipulation detection";"Deepfakes;Technological innovation;Social networking (online);Information security;Video compression;Streaming media;Signal processing";;1;;50;IEEE;2 Jan 2023;7-8 Dec. 2022;7-8 Dec. 2022;IEEE;IEEE Conferences
Multimodal Cognitive Learning for Media Forgery Detection: A Comprehensive Framework Combining Random Forest and Deep Ensemble Architectures (Xception, ResNeXt) across Image, Video, and Audio Modalities;"A. Abirami; S. Bhuvaneswari; K. Krithika; I. Nithyasree; B. Prashithaa Abhirami";"Computer science and engineering Easwari engineering college, Chennai, India; Computer science and engineering Easwari engineering college, Chennai, India; Computer science and engineering Easwari engineering college, Chennai, India; Computer science and engineering Easwari engineering college, Chennai, India; Computer science and engineering Easwari engineering college, Chennai, India";2023 3rd International Conference on Innovative Mechanisms for Industry Applications (ICIMIA);18 Apr 2024;2023;;;1083;1091;Deepfake content has become more prevalent in the age of quickly evolving technology, which has significantly undermined the reliability and integrity of digital media. An integrated multimodal deepfake detection system is presented in this study as a response to the ubiquitous threat posed by altered photos, videos, and audio recordings. The image deepfake detection module examines visual data for telltale signs of manipulation using Convolutional Neural Networks (CNNs), Xception, and ResNeXT. This module successfully distinguishes between real and fake photos by carefully examining pixel-level attributes and contextual data. With the use of spatiotemporal CNNs (Xception & ResNeXT), it parses video frames to find minute discrepancies, making it possible to accurately identify deepfake films. This multi-modal system is finished with the addition of deepfake audio detection. This module excels in differentiating between authentic and faked audio recordings using Mel spectrograms and Convolutional Neural Networks, adding to a thorough protection against audio deepfakes. Additionally, a unifying framework has been provided that effectively unifies these three detection modules, boosting the system’s effectiveness and performance as a whole. The solution has been thoroughly assessed using measures like accuracy, F1 score, ROC curve, and AUC, and the model structures for in-depth comprehension. This multi-modal deepfake detection technology acts as a crucial precaution in a time when false information is widely disseminated, enabling consumers to distinguish fact from fiction across numerous media types. This study highlights the importance of integrated solution in maintaining the legitimacy of digital content in today’s information-driven world while also showcasing its technological capability.;;979-8-3503-4363-2;10.1109/ICIMIA60377.2023.10426415;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10426415;"Deepfake detection;Multi-modal system;Image manipulation;Video forgery;Audio spoofing;Convolutional Neural Networks (CNNs);Xception;ResNeXT;Spatiotemporal analysis;Mel spectrograms;F1 score;ROC curve;AUC";"Deepfakes;Visualization;Audio recording;Spatiotemporal phenomena;Convolutional neural networks;Security;Spectrogram";;1;;20;IEEE;18 Apr 2024;21-23 Dec. 2023;21-23 Dec. 2023;IEEE;IEEE Conferences
BSM-DND: Bias and Sensitivity-Aware Multilingual Deepfake News Detection Using Bloom Filters and Recurrent Feature Elimination;"M. Al-Naeem; M. M. Hafizur Rahman; A. Banerjee; A. Sufian";"Department of Computer Networks and Communications, CCSIT, King Faisal University, Al Ahsa, Saudi Arabia; Department of Computer Networks and Communications, CCSIT, King Faisal University, Al Ahsa, Saudi Arabia; Department of Computer Applications, Kalyani Government Engineering College, Kalyani, India; Institute of Applied Sciences and Intelligent Systems (ISASI), National Research Council (CNR), Lecce, Italy";IEEE Access;23 Sep 2025;2025;13;;163218;163234;The rapid spread of deepfake news across digital media platforms poses a growing threat to societal trust, public safety, and global security. With the increasing realism of AI-generated content, distinguishing between authentic and fabricated information has become increasingly challenging, especially in low-resource and multilingual content. In this work, we propose a novel bias and sensitivity-aware multilingual deepfake news detection framework, BSM-DND, which classifies news articles into three categories: Authentic (A), Fake but Not Dangerous (FND), and Fake and Dangerous (FD). Our approach incorporates language-specific preprocessing to extract features related to sensitive keywords, sentiment polarity, and structural complexity. To enhance efficiency in large-scale detection, the Bloom filter technique has been applied for rapid parallel keyword matching. By leveraging Support Vector Machines (SVMs), Random Forest (RF), and recursive feature elimination, we have optimized classification performance across multiple languages. Experimental results on English, Italian, and Bengali datasets demonstrate that our method has achieved high detection accuracy, with the most significant improvements observed for English language content, while also yielding substantial gains in the other two languages. In addition, the BSM-DND framework is scalable in low-resource environments, adaptable to multilingual scenarios with minimal overhead, and effective in quantifying the potential societal impact of deepfake news.;2169-3536;;10.1109/ACCESS.2025.3609831;"Deanship of Scientific Research, Vice Presidency for Graduate Studies and Scientific Research, King Faisal University, Saudi Arabia(grant numbers:KFU253123);";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11169321;"Bias;bloom filter;deepfake news detection;machine learning;random forest (RF);recursive feature elimination (RFE);sensitivity;support vector machine (SVM)";"Deepfakes;Multilingual;Accuracy;Filters;Computational modeling;Social networking (online);Feature extraction;Electronic mail;Support vector machines;Radio frequency";;1;;69;CCBY;17 Sep 2025;2025;;IEEE;IEEE Journals
Identification of Deepfakes using Strategic Models and Architectures;"S. R. Nallapati; D. Dommeti; S. Medhalavalasa; K. K. Bonku; P. V. V. S. Srinivas; D. Bhattacharyya";"Department of CSE, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India; Department of CSE, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India; Department of CSE, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India; Department of CSE, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India; Department of CSE, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India; Department of CSE, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India";2023 International Conference on Sustainable Computing and Data Communication Systems (ICSCDS);25 Apr 2023;2023;;;75;82;Deepfake technology has been rapidly evolving and expanding in recent years. It has become increasingly easy to manipulate multimedia content, making it harder to detect what is real and what is manipulated. The research aims to explore how neural networks can be used to detect deepfake in multimedia, helping to protect users from potentially malicious and deceptive content. The aim is to explore what neural networks are, how they can be used to detect deepfakes and the potential implications of this technology. The research also aims to evaluate the advantages and disadvantages of using neural networks for deepfake detection. As the world of deepfake technology continues to evolve, this research will provide an overview of the latest developments in deepfake detection and their potential impact. The goal of this research is to use neural networks to detect deepfakes and to identify suspicious content to alert users. This could help protect users from being exposed to malicious content and help content producers ensure the integrity of their work. As deepfake technology continues to evolve, neural networks may become an essential tool for quickly and accurately detecting deepfakes in multimedia. The research explores topics like, CNN, 3D CNN, GATED RECURRENT UNIT and Architectures like Xception, VGG16, InceptionV3 and ResNet50V2. The outcomes are graphically represented and analyzed. the comparative stratification of the approach is done to analyze and detect deepfakes.;;978-1-6654-9199-0;10.1109/ICSCDS56580.2023.10104880;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10104880;"Deepfake Detection;Deep Learning;Convolutional Neural Network;Gated Recurrent Unit;Image Noise Patterns";"Deepfakes;Visualization;Three-dimensional displays;Neural networks;Computer architecture;Media;Logic gates";;1;;18;IEEE;25 Apr 2023;23-25 March 2023;23-25 March 2023;IEEE;IEEE Conferences
Hierarchical ST-CEN with Dynamic Attention Mechanisms for Enhanced Deepfake Image Detection;"P. GS; A. T";"Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Amritapuri, India; Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Amritapuri, India";2023 International Conference on Intelligent Computing, Communication & Convergence (ICI3C);28 Oct 2024;2023;;;377;383;The increasing complexity of deepfake technologies necessitates the development of detection methods to counter their harmful propagation. This research introduces a ground-breaking approach, to detecting deepfake images by utilizing Hierarchical Spatial Temporal Contextual Embedding Networks (HST CEN) in combination with Dynamic Attention Mechanisms (DAM).By addressing the challenges in understanding temporal context within deepfake images HST CEN incorporates multi level contextual embeddings that capture subtle spatial and temporal cues. At the time DAM employs evolving attention mechanisms that hierarchically identify important features at multiple levels enabling robust detection of manipulated imagery.The methodology includes an evaluation on the ForgeryNet dataset showcasing the superiority of the model in discerning deepfake images compared to architectures. The results demonstrate performance leading to improved accuracy, specificity and generalization across various forgery techniques and different identity contexts. The qualitative analysis reveals attention value distributions providing insights into how the model identifies manipulated features for nuanced analysis, by end users. The impacts of this detection method have implications, in scenarios providing a strong defense against the spread of sophisticated deepfake content. The suggested HST CEN with DAM not enhances the capabilities of identifying manipulated images but also highlights the importance of having a deep understanding of spatial temporal context and utilizing dynamic attention mechanisms to combat the widespread use of artificially created visuals, in todays digital world.;;979-8-3503-4392-2;10.1109/ICI3C60830.2023.00078;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10729784;"Deepfake Detection;FaceForensics++;DFDC Dataset;Ablation Study;Transfer Learning;Multiple Attention Mechanisms;Regional Independence Loss;Attention-Guided Data Augmentation;Compression Sensitivity;Cross-Dataset Evaluation";"Deepfakes;Visualization;Analytical models;Attention mechanisms;Dams;Feature extraction;Forgery;Complexity theory;Manipulator dynamics;Convergence";;;;22;IEEE;28 Oct 2024;16-17 Dec. 2023;16-17 Dec. 2023;IEEE;IEEE Conferences
Forensic Challenges in Face Manipulated Videos;"N. Sharma; K. Mallampalli; R. S. Iyengar";"pi-Labs; pi-Labs; pi-Labs";2025 International Conference on Multimedia Analysis and Pattern Recognition (MAPR);29 Aug 2025;2025;;;1;6;Rapid advancements in deepfake generation techniques have significantly enabled highly realistic video manipulations, including face swapping and lip synchronization, while simultaneously raising serious ethical and security concerns. The detection of such deepfake videos has emerged as a critical challenge in digital forensics. However, an equally important but less explored aspect is the identification of generative model. In this paper, findings related to the attribution of face-manipulated videos are presented, where distinguishing artifacts introduced by different deepfake generation methods are analyzed and exploited for forensic investigations. The attribution of a deepfake video to a specific source is crucial for investigations, misinformation mitigation, and forensic analysis. Identifying the source of deep-fakes plays a crucial role in countering their malicious use, and the results contribute to strengthening the reliability of digital forensics in an age increasingly shaped by AI-generated content.;2770-6850;979-8-3315-5466-8;10.1109/MAPR67746.2025.11134019;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11134019;"deepfake;video manipulation;face swap;source detection";"Deepfakes;Face recognition;Prevention and mitigation;Digital forensics;Measurement uncertainty;Fingerprint recognition;Streaming media;Synchronization;Security;Reliability";;;;53;IEEE;29 Aug 2025;14-15 Aug. 2025;14-15 Aug. 2025;IEEE;IEEE Conferences
Enhancing the Detection of Deepfake Audio Using Explainable AI Techniques for Secure and Trustworthy Applications;"B. Naresh; R. Ch; K. S. Reddy; S. Srinivas; A. N. Sheikh; K. Raghavendar";"Department of CSE-CS, CVR College of Engineering, Hyderabad, India; Department of CSE, Sreenidhi University, Hyderabad, India; CSE Department, TKR College of Engineering and Technology, Hyderabad, India; Department of CSE, CVR College of Engineering, Hyderabad, India; Department of AI&DS, Chaitanya Bharathi Institute of Technology, Hyderabad, India; Department of CSE, TKR Engineering College, Hyderabad, India";2025 International Conference on Applications of Machine Intelligence and Data Analytics (ICAMIDA);3 Nov 2025;2025;;;1;6;The increasing sophistication and popularity of generative artificial intelligence (AI) has introduced the phenomenon of deepfake audio which poses serious problems to digital legitimacy and security. Even as there are improvements in the development of synthetic voices, detector systems are found to have a low accuracy, with only 82.56 on standard datasets. This paper will fill this gap by adopting the explainable artificial intelligence (XAI) method, which is capable of detecting deepfake audio more significantly yet with higher interpretability of the non-expert users. This research helps in contributing to the field since it examines top audio attributes, including Mel-Frequency Cepstral Coefficients (MFCCs) and spectrograms, alongside incorporating XAI mechanisms, including layer-wise relevance propagation, integrated gradients, and Deep Taylor decomposition, to identify the processes of choice made by detection models. Lightweight and interpretable architecture, e.g. convolutional neural networks (CNNs) and long short-term memory networks (LSTMs), are applied to achieve a trade-off between performance and interpretability. The methodology is tested on two benchmark datasets: ASVspoof 2019 Logical Access and LJSpeech which correspond to real world and constrained environments. Findings indicate that the proposed models increase not only the recognition rate within the whole text system but also offer information about what distinguishes genuine and synthetic speech, thus it becomes understandable to a wider audience. By addressing the challenge of marrying technical prowess and practical applicability, this research aims at supplying a robust and effective framework of identifying and counteracting the malicious use of deepfake audio streams in malicious uses. Future research will also be able to look into multi-modal discoveries and varying datasets to enhance more of the reliability and scalability of detection schemas.;;979-8-3315-2276-6;10.1109/ICAMIDA64673.2025.11209741;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11209741;"Deepfake detection;explainable AI;audio forensics;convolutional neural networks;Mel-Frequency Cepstral Coefficients";"Deepfakes;Accuracy;Explainable AI;Generative AI;Cepstral analysis;Text recognition;Benchmark testing;Convolutional neural networks;Long short term memory;Standards";;;;28;IEEE;3 Nov 2025;21-22 Aug. 2025;21-22 Aug. 2025;IEEE;IEEE Conferences
Comparative Analysis Of Deep Learning for Robust Deepfake Detection;"R. Kapoor; V. Mehndiratta; J. Singh";"Christ University, Bangalore; Christ University, Bangalore; Christ University, Bangalore";2024 4th International Conference on Advancement in Electronics & Communication Engineering (AECE);13 Mar 2025;2024;;;1067;1072;With Deepfake technology rapidly growing and its use on the rise, there is an increased demand for effectiveness of its detection. This paper performs a comparative analysis of 4 deep learning algorithms – Meso-4, MesoInception-4, Resnet50, DenseNet-121. We will investigate each algorithm’s architecture, performance validation and versatility. The indepth overview will shed some light on accuracy, precision, recall, F1 score, etc. The dataset will encompass the real and fake community videos for a well-rounded assess on each algorithm’s effectiveness. The results of the research will help to with the potential practical applications of the reviewed algorithms, and mention possible changes and improvements. The results of the research have shown both strengths and weaknesses of each algorithm, giving clarity as to the potential use in practice, and changes that could be made in future. The overall aim of the dissolution is to guide the reader through the process of understanding the difference between the 4 algorithms – Meso-4, MesoInception-4, Resnet-50 and DenseNet-121.;;979-8-3503-6472-9;10.1109/AECE62803.2024.10911049;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10911049;"Deepfake detection;Deep learning;Meso-4;MesoInception-4;ResNet-50;DenseNet-121";"Deep learning;Deepfakes;Accuracy;Decision making;Media;Feature extraction;Security;Reliability;Residual neural networks;Overfitting";;;;15;IEEE;13 Mar 2025;22-23 Nov. 2024;22-23 Nov. 2024;IEEE;IEEE Conferences
Navigating Deepfakes with Data Science: A Multi-Modal Analysis and Blockchain-Based Detection Framework;"S. Patil; A. Bhat; N. Jain; V. Javalkar";"University of Texas at Dallas, Richardson, Texas, USA; EY(Ernst & Young), Dallas, Texas, USA; Oracle America Inc, Sterling, VA, USA; Independent Researcher, Frisco, Texas, USA";2025 International Conference on Pervasive Computational Technologies (ICPCT);1 Apr 2025;2025;;;772;777;Deepfake technology, fueled by advancements in artificial intelligence, presents a dual-use phenomenon with innovative applications in entertainment, education, and communication alongside significant ethical and societal risks, such as misinformation, identity theft, and privacy violations. This paper proposes a novel framework combining multi-modal analysis and blockchain verification to enhance deepfake detection. The multi-modal approach employs audio-visual analysis, temporal and spatial inconsistencies, and advanced feature extraction techniques to identify manipulations, while blockchain provides a tamper-proof mechanism for authenticating digital content at its source. By addressing research gaps such as cross-domain adaptability and limited training datasets, the framework offers a holistic solution to escalating challenges. Moreover, the paper emphasizes the importance of transparency, privacy preservation, and global collaboration to align technological innovation with ethical accountability. This work contributes to building a trustworthy digital ecosystem, enabling responsible applications of deepfake technology while mitigating its risks.;;979-8-3315-0868-5;10.1109/ICPCT64145.2025.10940229;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10940229;"Deepfake detection;multi-modal analysis;blockchain;audio-visual inconsistencies;temporal analysis;spatial analysis;feature extraction;content hashing;ethical AI;dataset augmentation;synthetic data generation";"Deepfakes;Ethics;Technological innovation;Privacy;Ecosystems;Entertainment industry;Collaboration;Feature extraction;Blockchains;Artificial intelligence";;;;26;IEEE;1 Apr 2025;8-9 Feb. 2025;8-9 Feb. 2025;IEEE;IEEE Conferences
Hybrid Deepfake Detection Using ResNet50 and Vision Transformer for Enhanced Feature Extraction;"A. Naitali; M. Ridouani; F. Salahdine; N. Kaabouch";"RITM Laboratory, CED Engineering Sciences, Hassan II University, Casablanca, Morocco; RITM Laboratory, CED Engineering Sciences, Hassan II University, Casablanca, Morocco; Department of Electrical and Computer Engineering, University of North Carolina, Charlotte, NC, USA; Artificial Intelligence Research (AIR) Center, University of North Dakota, Grand Forks, ND, USA";2025 11th International Conference on Optimization and Applications (ICOA);19 Nov 2025;2025;;;1;7;"Deepfakes create a digital content verification problem that is difficult to solve, with a pressing demand for trustworthy detection mechanisms. In this paper, we review a deepfake detection approach based on complementary characteristics of convolutions and transformers. In particular, we employ ResNet50, a convolutional neural network (CNN) that extracts rich spatial features and local textures from images, and the Vision Transformer (ViT) which learns long-range dependencies and global context by treating images as sequences of patches. Concatenated representations derived from the two models are fed into classification algorithms. In this work, we experiment with the OpenForensics dataset which contains both real and fake images. The results show that features from both ResNet50 and ViT provide significantly improved classification performance when the features are combined together to form a new feature vector; than when either model is used alone. Furthermore, we evaluate the performance of these features using a Random Forest classifier and dense layers, and show that the feature representations on their own extracted from both of the models can generalize and perform well using both classification methods.";2768-6388;979-8-3315-9957-7;10.1109/ICOA66896.2025.11236531;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11236531;"Deepfake Detection;ResNet50;Vision Transformer";"Deep learning;Deepfakes;Computer vision;Accuracy;Feature extraction;Transformers;Classification algorithms;Convolutional neural networks;Random forests;Residual neural networks";;;;12;IEEE;19 Nov 2025;16-17 Oct. 2025;16-17 Oct. 2025;IEEE;IEEE Conferences
The Growing Need for Deepfakes Detection in the Age of AI-Generated Media;"P. Badoni; M. S. Dildar; M. N. Ahmed; A. S. Zamani; M. R. Hussain; M. Wadhwa";"CSE, Chandigarh University, Mohali, India; Department of Business Informatics, King Khalid University, Abha, Saudi Arabia; CSE, King Khalid University, Abha, Saudi Arabia; Department of Computer & Self Development, Prince Sattam bin Abdulaziz University, AlKharj, Saudi Arabia; Department of Business Informatics, King Khalid University, Abha, Saudi Arabia; CSE, Chandigarh University, Mohali, India";2025 12th International Conference on Emerging Trends in Engineering & Technology - Signal and Information Processing (ICETET - SIP);16 Sep 2025;2025;;;1;6;Deepfakes detection is now a necessity because deep learning methods for producing highly realistic synthetic media are advancing at an alarming rate. These doctored photos, videos, and audio files can mislead their audience, disseminate disinformation, and represent a major security risk. Detection techniques utilize convolutional neural networks, recurrent neural networks, and transformer models to detect minor artifacts, inconsistencies, and unnatural patterns in multimedia content. Methods such as frequency analysis, facial landmark tracking, and adversarial training are used to improve detection accuracy. The ongoing development of generative models requires constant research to create resilient and flexible detection systems that can counter the threats from synthetic media manipulation.;2157-0485;979-8-3315-0099-3;10.1109/ICETETSIP64213.2025.11156944;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11156944;"Deepfakes detection;synthetic media;convolutional neural networks;misinformation;adversarial training;facial landmark tracking;generative models;multimedia forensics;digital security";"Training;Deepfakes;Recurrent neural networks;Biological system modeling;Medical services;Media;Benchmark testing;Security;Convolutional neural networks;Biomedical monitoring";;;;37;IEEE;16 Sep 2025;1-2 Aug. 2025;1-2 Aug. 2025;IEEE;IEEE Conferences
A Review on Deepfake Image Detection Approaches, Techniques and Methods;"J. C. Ng; M. B. Jasser; B. Issa; S. -S. M. Ajibade; H. N. Chua";"School of Computing and Artificial Intelligence, Faculty of Engineering and Technology, Sunway University, No. 5, Jalan Universiti, Bandar Sunway, Selangor Darul Ehsan, Malaysia; School of Computing and Artificial Intelligence, Faculty of Engineering and Technology, Sunway University, No. 5, Jalan Universiti, Bandar Sunway, Selangor Darul Ehsan, Malaysia; Faculty of Informatics Engineering, University of Aleppo, Syria; School of Computing and Artificial Intelligence, Faculty of Engineering and Technology, Sunway University, No. 5, Jalan Universiti, Bandar Sunway, Selangor Darul Ehsan, Malaysia; School of Computing and Artificial Intelligence, Faculty of Engineering and Technology, Sunway University, No. 5, Jalan Universiti, Bandar Sunway, Selangor Darul Ehsan, Malaysia";2025 IEEE International Conference on Automatic Control and Intelligent Systems (I2CACIS);7 Aug 2025;2025;1;;512;517;Deepfake technology has been increasingly advanced and highly capable of generating and modifying media contents. Deepfake technologies like automated generation of scripts and avatars creation are applicable on many distinct fields and industries, helping in improving and enhancing the visuals and media contents to be published and shared with the public. However, Deepfake technologies also, being widely used in various malicious activities and crime cases, like financial frauds and scams, as well as sexual abuse and harassment. Hence, Deepfake detection is essential, to reduce the problems and avoid the consequences brought by Deepfake technologies. In this work, several existing Deepfake detection approaches, techniques and methods are explored and discussed. To understand better the effects and consequences caused by Deepfake, this work includes cases studies on real-world Deepfake incidents, conducted by searching through the news information accessible through internet. In addition, a thorough survey is conducted by searching for related articles and papers via Google Scholar using a suitable set of keywords. Results are presented via taxonomy. Some comparisons are presented to give some insights on the deepfake image detection approaches.;2995-2859;979-8-3315-4294-8;10.1109/I2CACIS65476.2025.11100461;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11100461;"Deepfake detection;Neural Network;Texture Analysis;Frequency Analysis and Biological Analysis";"Surveys;Deepfakes;Automatic frequency control;Visualization;Reviews;Taxonomy;Neural networks;Media;Internet;Intelligent systems";;;;40;IEEE;7 Aug 2025;27-28 June 2025;27-28 June 2025;IEEE;IEEE Conferences
Dual Acoustic Feature Fusion for Enhanced Audio Deepfake Detection Using VGG-16 Architecture: Mitigating Speech Tampering with MFCC and ELTP;"C. Ahmadi; S. -H. Wang; S. -P. Chiu; J. -L. Chen";"Dept. Electrical Engineering, National Taiwan University of Science and Technology (NTUST), Taipei, Taiwan; Dept. Electrical Engineering, National Taiwan University of Science and Technology (NTUST), Taipei, Taiwan; Dept. Electrical Engineering, National Taiwan University of Science and Technology (NTUST), Taipei, Taiwan; Dept. Electrical Engineering, National Taiwan University of Science and Technology (NTUST), Taipei, Taiwan";2024 RIVF International Conference on Computing and Communication Technologies (RIVF);28 May 2025;2024;;;216;220;In recent years, the rise of audio deepfakes, where artificial intelligence (AI) is used to manipulate or synthesize speech, has posed significant challenges in distinguishing between authentic and falsified audio content. Despite advancements in detection methods, current systems often struggle with accurately identifying deepfakes due to the complexity of modern voice cloning technologies. This study addresses this gap by proposing a novel dual-input convolutional neural network (CNN) model utilizing Mel-Frequency Cepstral Coefficients (MFCC) and Extended Local Ternary Patterns (ELTP) for enhanced audio forgery detection. Here, we present a system based on the VGG-16 architecture, which integrates MFCC and ELTP features to detect manipulated audio with high accuracy. Our approach achieves a detection accuracy of 94.21% on the Fake-or-Real and ASVspoof 2019 datasets, demonstrating a robust improvement over existing single-feature methods. These results suggest that combining MFCC and ELTP features can better capture both the spectral and textural properties of audio, leading to more reliable detection of audio tampering. This advancement has important implications for cybersecurity and the integrity of voice-based authentication systems, providing a stronger defense against potential fraud and misinformation through audio deepfakes.;2473-0130;979-8-3315-0507-3;10.1109/RIVF64335.2024.11009070;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11009070;"Audio deepfake detection;convolutional neural network;dual acoustic features;ELTP;MFCC;VGG-16";"Deepfakes;Accuracy;Authentication;Computer architecture;Feature extraction;Forgery;Fraud;Convolutional neural networks;Mel frequency cepstral coefficient;Artificial intelligence";;;;18;IEEE;28 May 2025;21-23 Dec. 2024;21-23 Dec. 2024;IEEE;IEEE Conferences
Deep Fake Detection with Hybrid Activation Function Enabled Adaptive Milvus Optimization-Based Deep Convolutional Neural Network;"H. Mashetty; N. Erukulla; S. Belidhe; N. Jella; V. r. Pishati; B. K. Enesheti";"AI Research Independent Researcher, GA; Enterprise Data Analytics, Duluth, GA; Information Technology Independent Researcher; Information Technology Independent Researcher; Information Technology Independent Researcher; Information Technology Independent Researcher";2025 6th International Conference on Mobile Computing and Sustainable Informatics (ICMCSI);20 Feb 2025;2025;;;1159;1166;Deep fake detection plays an essential role in digital world platforms that effectively identify the fake content of audio and video streams, which disseminated more on social media platforms in recent years. Several researchers have undertaken to detect the fake context, which faced certain challenges such as information authentication, media security, stolen identities, damaging someone's personal life, and so on. Thus, to enhance the detection accuracy and to overcome the challenges of existing methods, the Hybrid activation function enabled adaptive Milvus optimization-based Deep Convolutional Neural Network (HA2MilO-DCN) model is developed in the research. The integration of the hybrid activation function with the base DCNN model effectively enhanced the scalability and efficiency to achieve the desired detection results. Furthermore, the adaptive Milvus optimization (AMilO) effectively tunes the hyperparameter of the model, which is inspired by the social behavior of Milvus and aids in attaining prominent detection outcomes. Therefore, the HA2MilO-DCN attains a high range of detection accuracy with performance metrics such as Accuracy, Recall, and Precision. Under the utilization of the Faceforensics++ dataset, the model attains effective detection outcomes when compared with other conventional methods. The obtained evaluation metrics values are 95.72%, 94.91%, and 96.52% respectively.;;979-8-3315-2266-7;10.1109/ICMCSI64620.2025.10883193;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10883193;"Deepfake detection;Deep Convolutional Neural network;Adaptive Milvus optimization;Audio signals;Video streams";"Measurement;Adaptation models;Deepfakes;Accuracy;Adaptive systems;Social networking (online);Streaming media;Convolutional neural networks;Time complexity;Streams";;;;28;IEEE;20 Feb 2025;7-8 Jan. 2025;7-8 Jan. 2025;IEEE;IEEE Conferences
Deepfake Image Detection using Deep Learning;"A. K. S; A. K. M; R. R. Vincent; U. U. Hegde; A. M. S; N. N. Pasha";"Dept. of Computer Studies, Symbiosis Institute of Computer Studies and Research (SICSR), Pune, India; Dept. of Information Science and Engineering, Bio-Intelligence Lab, Presidency University, Bangaluru, India; Dept. of Computer Science and Engineering, Bio-Intelligence Lab, Presidency University, Bangaluru, India; Dept. of Computer Science and Engineering, Bio-Intelligence Lab, Presidency University, Bangaluru, India; Dept. of Computer Science and Engineering, Bio-Intelligence Lab, Presidency University, Bangaluru, India; Dept. of Computer Science and Engineering, Bio-Intelligence Lab, Presidency University, Bangaluru, India";2025 International Conference on Artificial Intelligence and Data Engineering (AIDE);12 May 2025;2025;;;492;497;Deepfake images are generated by modifying existing visuals and are frequently exploited in harmful ways. When executed proficiently, these images can be almost indistinguishable from authentic ones. The increasing development of deep learning techniques has largely fueled the increase in deepfake content. While numerous techniques are available for creating deepfake images, the most commonly employed are GANs and autoencoders. This paper presents a way to make deepfake detection more accurate by using a combination of the YOLOv8 model and a Recurrent Neural Network (RNN). YOLOv8 extracts spatial details from the images, while the RNN identifies temporal patterns and subtle irregularities across image frames, signaling potential manipulation. This methodology presents an efficient solution for identifying deepfake images and reducing their misuse.;;979-8-3315-2751-8;10.1109/AIDE64228.2025.10987437;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10987437;"Deepfake detection;Recurrent Neural Networks (RNN);YOLO v8;GANs";"YOLO;Deep learning;Deepfakes;Adaptation models;Analytical models;Visualization;Recurrent neural networks;Accuracy;Computational modeling;Faces";;;;20;IEEE;12 May 2025;6-7 Feb. 2025;6-7 Feb. 2025;IEEE;IEEE Conferences
Deepfake Video Detection: A Comprehensive Survey of Advanced Machine Learning and Deep Learning Techniques to Combat Synthetic Video Manipulation;"T. Anusha; A. Srinagesh";"Department of CSE, Acharya Nagarjuna University, Guntur, Andhra Pradesh, INDIA; Department of CSBS, R.V.R. & J.C College of Engineering, Guntur, Andhra Pradesh, INDIA";2025 International Conference on Multi-Agent Systems for Collaborative Intelligence (ICMSCI);27 Feb 2025;2025;;;1033;1041;The detection of deepfake videos has become a critical area of research due to the widespread use of manipulated content across digital platforms. With the increasing sophistication of generative models deepfake videos have reached a level of realism that makes them challenging to detect. This survey paper provides an extensive review of 70 research papers published from 2021 to 2024, categorizing the existing detection techniques into three primary groups such as supervised learning techniques, unsupervised learning techniques, and hybrid methods. These methods leverage labelled datasets to train models to identify subtle artefacts in manipulated videos. Notable advancements have been made by integrating CNNs with RNNs to capture both spatial and temporal patterns, enhancing detection accuracy. Unsupervised learning techniques, such as clustering algorithms and anomaly detection methods, are increasingly being explored for deepfake detection. Hybrid methods combine the strengths of both supervised and unsupervised techniques, improving detection performance. CNN-RNN architectures integrated with attention mechanisms are an example, as they enhance the focus on manipulated regions within videos. Additionally, multimodal approaches that combine both visual and audio cues have been introduced to address the complexity of detecting deepfakes across various media types. This review identifies the challenges faced by current detection systems, such as limitations in datasets, high computational costs, and a lack of robustness against evolving manipulation techniques. To address these challenges, future research should focus on developing more diverse datasets, enhancing the generalizability of models, and improving computational efficiency to support real-time applications. The most promising approach for advancing deepfake detection systems involves integrating multi-modal techniques, advanced deep learning architectures, and scalable designs.;;979-8-3315-0982-8;10.1109/ICMSCI62561.2025.10894187;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10894187;"Deepfake detection;Supervised learning;Unsupervised learning;Hybrid methods;Generative Adversarial Networks;Convolutional Neural Networks;Recurrent Neural Networks";"Surveys;Measurement;Deepfakes;Reviews;Supervised learning;Neural networks;Media;Robustness;Real-time systems;Unsupervised learning";;;;40;IEEE;27 Feb 2025;20-22 Jan. 2025;20-22 Jan. 2025;IEEE;IEEE Conferences
CombinedNet: A Hybrid Model for Deepfake Audio Detection Using Deep Learning Techniques;"V. Gattulli; D. Impedovo";"Department of Computer Science, University of Bari ""Aldo Moro"", Bari; Department of Computer Science, University of Bari ""Aldo Moro"", Bari";2025 International Joint Conference on Neural Networks (IJCNN);14 Nov 2025;2025;;;1;8;In the digital age, deepfakes pose a growing threat to information security and integrity, with a particular focus on audio fakes. This paper explores and compares different machine-learning techniques for audio deepfake detection, analyzing both deep and shallow learning-based approaches. In particular, CombinedNet, a novel model obtained by combining two deep learning networks selected from the literature, is presented. Performance evaluation was conducted on public datasets through benchmarking based on standard metrics such as accuracy, precision, and F1-score. The experimental results show that CombinedNet outperforms the benchmark models, highlighting the potential of hybrid solutions in audio deepfake detection.;2161-4407;979-8-3315-1042-8;10.1109/IJCNN64981.2025.11229182;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11229182;"Deepfake audio;Deep learning;CombinedNet;Speech detection;Machine learning";"Deep learning;Voice activity detection;Deepfakes;Analytical models;Bandwidth;Benchmark testing;Predictive models;Data models;Mel frequency cepstral coefficient;Standards";;;;15;IEEE;14 Nov 2025;30 June-5 July 2025;30 June-5 July 2025;IEEE;IEEE Conferences
Near Real-Time Deepfake Audio Detection based on Speaker Diarization Techniques;"M. K. Zahur Bajwa; C. Negru; B. -C. Mocanu; A. Castiglione; C. Pero";"Department of Management & Innovation Systems, University of Salerno, Fisciano, Italy; Research Infrastructure for the Development of Intelligent Innovative Products, Processes and Services - PRECIS, National University of Science and Technology POLITEHNICA, Bucharest, Romania; Department of Computer Science & Engineering, National University of Science and Technology POLITEHNICA, Bucharest, Romania; Department of Management & Innovation Systems, University of Salerno, Fisciano, Italy; Department of Management & Innovation Systems, University of Salerno, Fisciano, Italy";2025 25th International Conference on Control Systems and Computer Science (CSCS);30 Sep 2025;2025;;;412;419;The spread of the deepfake phenomenon, and particularly of the audio deepfake, imposes the design of reliable detection techniques. Continuous efforts are being made to design reliable methods and systems to stop the spread of deep-fake audio and guarantee their detection. In this paper, we propose a real-time processing pipeline for audio deepfake detection. The novelty of our approach is that our system fully analyzes audio signals, going beyond feature extraction and analyzing the time and frequency components of the signals. This detailed examination is essential for identifying authentic or fraudulent audio signals. To improve signal clarity and increase the accuracy of audio deepfake detection, we also focus on data augmentation. The results obtained show that the proposed pipeline provides a reliable way to distinguish between real (authentic) and fake (fraudulent) audio content.;2379-0482;979-8-3315-7343-0;10.1109/CSCS66924.2025.00067;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11181580;"Audio deepfakes;single-speaker diarization;MEL Spectrograms;feature extraction;audio preprocessing;speech activity detection;data augmentation";"Deepfakes;Visualization;Forensics;Pipelines;Noise;Feature extraction;Reliability engineering;Data augmentation;Real-time systems;Spectrogram";;;;22;IEEE;30 Sep 2025;27-30 May 2025;27-30 May 2025;IEEE;IEEE Conferences
DeepViT-Detect: A Deep Vision Transformer-Based Approach for Robust Deepfake Video Detection;"V. K. R. Mannepalli; V. K. Kondra; J. P. Gourabathuni";"Dept. of Computer Science & Enigineering, VNR Vignana Jyothi Institute of Engineering & Technology, Hyderabad, India; Dept. of Computer Science & Engineering (Software Engineering), VNR Vignana Jyothi Institute of Engineering & Technology, Hyderabad, India; Dept. of Computer Science, Northern Arizona University, Flagstaff, Arizona, United States";2025 4th International Conference on Innovative Mechanisms for Industry Applications (ICIMIA);20 Oct 2025;2025;;;1118;1125;Deepfake videos are all over the place now, and it's getting tough to know what's real online. The ways we try to spot them now often miss the little things that show they're fake. So, we made something new called DeepViT-Detect that uses Vision Transformers (ViT) to find deepfakes. ViT is good at spotting both the big picture and tiny details because it uses self-attention, so it can see even the smallest weird things in video frames. Our model looks at frames from real and fake videos and learns to tell the difference between what's real and what's been messed with. We trained it a lot using all sorts of videos. Testing shows that DeepViT-Detect does much better than other methods at being accurate and strong, so it's a good step in the fight against deepfakes. This shows that using transformers could be a great way to find tricky fakes and keep visual media trustworthy.;;979-8-3315-5386-9;10.1109/ICIMIA67127.2025.11200731;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11200731;"Deepfake Detection;Vision Transformer(ViT);Self-Attention;Frame-Based Analysis;Digital media security";"Deepfakes;Computer vision;Visualization;Accuracy;Forensics;Media;Transformers;Long short term memory;Standards;Testing";;;;15;IEEE;20 Oct 2025;3-5 Sept. 2025;3-5 Sept. 2025;IEEE;IEEE Conferences
Detecting Cross-domain Deepfake Videos with Contrastive Prototype Learning;"Y. Li; P. Angelov";"School of Computing and Communications, Lancaster University, Lancaster, UK; School of Computing and Communications, Lancaster University, Lancaster, UK";2025 International Joint Conference on Neural Networks (IJCNN);14 Nov 2025;2025;;;1;8;Deepfake videos are synthetic media generated using advanced deep learning techniques that manipulate or replace the visual and audio content of an original recording, enabling the creation of highly realistic yet entirely fabricated audiovisual content. The proliferation of such manipulated media poses significant societal risks, including potential misinformation, reputation damage, psychological manipulation, and erosion of trust in digital visual communication. Recent deep learning methods for deepfake detection have emerged, leveraging sophisticated machine learning models that analyze multi-modal cues, including facial inconsistencies, unnatural temporal dynamics, and visual misalignments to distinguish between authentic and synthetic content. However, these state-of-the-art detection approaches often struggle with the domain-shift challenge, where models trained on specific deepfake datasets fail to generalize effectively when confronted with unseen generation techniques or evolving synthesis technologies. To address this critical limitation, we propose a self-supervised contrastive learning framework called CPDD, introducing contrast between features and prototypes of original data to alleviate domain-specific distractions (i.e., deepfake generative models or datasets). We calculate the cosine similarity between two features or prototypes to scale the original distance, clustering the features around closely related prototypes. This process encodes the semantic structures discovered through clustering into the learned embedding space. The extensive experiments show that, compared to various benchmark deepfake detection models and domain generalization techniques, the proposed model achieves state-of-the-art performance on the cross-domain deepfake detection task across a wide range of scenarios.;2161-4407;979-8-3315-1042-8;10.1109/IJCNN64981.2025.11227763;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11227763;"Deepfake video detection;self-supervised learning;contrastive learning;domain generalization;prototype learning";"Deep learning;Deepfakes;Visualization;Visual communication;Semantics;Neural networks;Prototypes;Psychology;Contrastive learning;Recording";;;;50;IEEE;14 Nov 2025;30 June-5 July 2025;30 June-5 July 2025;IEEE;IEEE Conferences
Benchmarking Audio Deepfake Detection Robustness in Real-World Communication Scenarios;"H. Shi; X. Shi; S. Dogan; S. Alzubi; T. Huang; Y. Zhang";"Institute for Digital Technologies, Loughborough University London, London, UK; Institute for Digital Technologies, Loughborough University London, London, UK; Institute for Digital Technologies, Loughborough University London, London, UK; Department of Computer Science, University of Exeter, Exeter, UK; Department of Computer Science, University of Exeter, Exeter, UK; Department of Computer Science, University of Exeter, Exeter, UK";2025 33rd European Signal Processing Conference (EUSIPCO);17 Nov 2025;2025;;;566;570;Existing Audio Deepfake Detection (ADD) systems often struggle to generalise effectively due to the significantly degraded audio quality caused by audio codec compression and channel transmission effects in real-world communication scenarios. To address this challenge, we developed a rigorous benchmark to evaluate the performance of the ADD system under such scenarios. We introduced ADD-C, a new test dataset to evaluate the robustness of ADD systems under diverse communication conditions, including different combinations of audio codecs for compression and packet loss rates. Benchmarking three baseline ADD models on the ADD-C dataset demonstrated a significant decline in robustness under such conditions. A novel Data Augmentation (DA) strategy was proposed to improve the robustness of ADD systems. Experimental results demonstrated that the proposed approach significantly enhances the performance of ADD systems on the proposed ADD-C dataset. Our benchmark can assist future efforts towards building practical and robustly generalisable ADD systems.;;978-9-4645-9362-4;10.23919/EUSIPCO63237.2025.11226601;"Loughborough University(grant numbers:GS1016); China Scholarship Council(grant numbers:202208060237);";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11226601;"Audio Deepfake Detection;Audio Signal Processing;Audio Codec;Robustness;Wireless Communication";"Wireless communication;Deepfakes;Codecs;Packet loss;Europe;Benchmark testing;Signal processing;Solids;Robustness;Machine listening";;;;43;;17 Nov 2025;8-12 Sept. 2025;8-12 Sept. 2025;IEEE;IEEE Conferences
A CNN Algorithm Based DeepFake Detection System;"S. M. Mangalampalli; M. J. Mistry; A. M. Pal; J. Pereira";"Vidyavardhini's College of Engg. &Tech., Mumbai, India; Vidyavardhini's College of Engg. &Tech., Mumbai, India; Vidyavardhini's College of Engg. &Tech., Mumbai, India; Vidyavardhini's College of Engg. &Tech., Mumbai, India";2025 12th International Conference on Computing for Sustainable Global Development (INDIACom);21 Aug 2025;2025;;;1;6;DeepFake is a technology that has garnered significant attention in the modern world and is often used for unlawful and immoral practices. The consequences and aftereffects of generation and publication of deepfakes in the public domain can tamper the social image of organizations or individuals. The objective of this study is to find a solution to this upcoming societal horror which can ruin lives and stigmatize the affected individuals. This project mainly concentrated on the development of a DeepFake Detection model that leverages a custom Convolutional Neural Network (CNN) to identify facemanipulated images or video content by extracting frames from images or videos. The model achieved high accuracy in demonstration of effectiveness of custom CNN architecture in identification of subtle facial inconsistencies and performed robustly across the dataset which highlighted the capability for generalization and detection of face-manipulated content in images and videos, alike. In essence, this CNN model stands out as a comprehensive solution not only addressing and amending the challenges faced by current systems but also enables people to be alert. This research serves as a foundational step towards the development of robust and scalable solutions to effectively counter DeepFake technology.;;978-93-80544-60-1;10.23919/INDIACom66777.2025.11115232;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11115232;"Convolutional Neural Network;DeepFake Detection;face manipulation;visual features;video classification;frame extraction";"Deepfakes;Visualization;Accuracy;Organizations;Computer architecture;Feature extraction;Classification algorithms;Convolutional neural networks;Faces";;;;23;;21 Aug 2025;2-4 April 2025;2-4 April 2025;IEEE;IEEE Conferences
A Deep Learning Framework for the Detection of Deepfake Audio;"Z. Rasheed; H. Albarakaty; H. Almutairi; J. Alhuzali; H. Al-Mabadi; H. Himdi; F. Alhayan; K. Shaalan";"Department of Computer Science and Artificial Intelligence, University of Jeddah, Jeddah, Saudi Arabia; Department of Computer Science and Artificial Intelligence, University of Jeddah, Jeddah, Saudi Arabia; Department of Computer Science and Artificial Intelligence, University of Jeddah, Jeddah, Saudi Arabia; Department of Computer Science and Artificial Intelligence, University of Jeddah, Jeddah, Saudi Arabia; Department of Computer Science and Artificial Intelligence, University of Jeddah, Jeddah, Saudi Arabia; Department of Computer Science and Artificial Intelligence, University of Jeddah, Jeddah, Saudi Arabia; Department of Information Systems, College of Computer and Information Sciences Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia; Faculty of Engineering and IT, The British University in Dubai), Dubai, United Arab Emirates";2025 3rd International Conference on Business Analytics for Technology and Security (ICBATS);3 Dec 2025;2025;;;1;7;The rapid advancements in artificial intelligence have enabled the creation of highly realistic cloned voices, posing severe threats to the integrity and security of digital communications. These synthetic voices facilitate identity impersonation and fraudulent activities such as phone scams and social engineering attacks. This paper introduces deep learning-driven models designed to detect and mitigate the impact of DeepFake audio. It incorporates deep learning models, including Convolutional Neural Networks (CNN), Bidirectional Long Short- Term Memory (BiLSTM), and a hybrid model combining both, to classify real and fake/cloned audios. A robust spectrogram- based feature extraction process, coupled with data normalization and augmentation strategies, were employed to enhance audio detection. The experiments reveal that the CNN model achieved the highest accuracy of 93.54 %, demonstrating its superior capability to identify fake/cloned audio. To ensure applicability, this study also developed a web-based DeepFake audio detector prototype, leveraging the optimized CNN model. The proposed system presents a significant step forward in strengthening digital communication security against emerging threats.;;979-8-3315-3827-9;10.1109/ICBATS66542.2025.11258404;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11258404;"Pattern recognition;Deep Learning;DeepFake Audio Detection";"Deep learning;Deepfakes;Accuracy;Bidirectional long short term memory;Feature extraction;Digital communication;Data augmentation;Convolutional neural networks;Security;Spectrogram";;;;26;IEEE;3 Dec 2025;1-2 May 2025;1-2 May 2025;IEEE;IEEE Conferences
DeepFake Creation and Detection:A Survey;"S. P; S. Sk";"CSE Department, Maulana Azad National Institute of Technology(MANIT), Bhopal, M.P., India; CSE Department, Maulana Azad National Institute of Technology(MANIT), Bhopal, M.P., India";2021 Third International Conference on Inventive Research in Computing Applications (ICIRCA);1 Oct 2021;2021;;;584;588;"DeepFake has become very popular of late. The term DeepFake refers to any multimedia content generated using deep learning technology appearing realistic to people. Despite the beneficial advances of DeepFake, it has been a major cause of threats to a person's privacy, where one person's face can be swapped with another in an indistinguishable way without consent. Also, it is easy for malicious parties to take over public events like elections by spreading misinformation and leaving a negative impact on national security. Thus, detection of such DeepFake is a crucial yet challenging problem. Human-eye-based segregation of DeepFaked contents from real ones has always been a difficult task; but recent works have shown the use of different technologies recording good results for the same, although with some limitations. The paper thus explores different algorithms used for DeepFake creation and detection; presenting a comprehensive overview of the techniques used and aimed at identifying their pros and cons.";;978-1-6654-3877-3;10.1109/ICIRCA51532.2021.9544522;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9544522;"DeepFake Creation and Detection;Face swapping;Encoder-Decoder;Generative adversarial network;LSTM;Convolutional neural network;Recurrent neural network";"Deep learning;Computational modeling;Voting;Neural networks;Tools;Generative adversarial networks;Convolutional neural networks";;15;;27;IEEE;1 Oct 2021;2-4 Sept. 2021;2-4 Sept. 2021;IEEE;IEEE Conferences
Advancing Deepfake Detection: An Optimized Neural Network Model with Keyframe Analysis;F. T. Tarannom Esty;Department of Computer Science and Engineering, University of Information Technology and Sciences, Dhaka, Bangladesh;2025 2nd International Conference on Next-Generation Computing, IoT and Machine Learning (NCIM);17 Sep 2025;2025;;;1;6;"Artificial intelligence (AI) can rapidly progress and foster AI algorithms to create a new machine-created video called deepfakes. These misleading videos are serious threats to our society and politics, or they can be used as weapons against the viewers. Deepfakes refer to synthetic media created with AI; therefore, such techniques can produce real-looking visual and auditory content. The first element of mitigating the malice of such videos is detecting them on social media platforms. This paper proposes a novel neural network-based method for deepfake video detection, focusing on critical video frame extraction to lessen computational complexity. The proposed method utilizes the architecture of a CNN coupled with a classifier network and a unique algorithm to accurately detect deepfake videos while keeping very low computational needs. Processing key video frames achieves impressive results based on single-keyframe processing for deepfake video detection. The technique is simple and efficient in authenticating video content concerning the social and economic problems of false videos. After evaluation over an entire dataset of 600 videos downloaded from various websites, the model detects deepfakes across different databases with an overall accuracy of 97.3%. Its performance surpasses that of earlier methods with reduced computation time, thus providing an efficient solution for deepfake detection.";;979-8-3315-5542-9;10.1109/NCIM65934.2025.11160287;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11160287;"Deepfake detection;Recurrent Neural Networks;Short-Term Memory (LSTM);Convolutional neural networks (CNN);Digital media forensics";"Deepfakes;Visualization;Accuracy;Recurrent neural networks;Social networking (online);Computational modeling;Weapons;Media;Topology;Convolutional neural networks";;;;23;IEEE;17 Sep 2025;27-28 June 2025;27-28 June 2025;IEEE;IEEE Conferences
UniForensics: Face Forgery Detection via General Facial Representation;"Z. Fang; H. Zhao; T. Wei; W. Zhou; M. Wan; Z. Wang; W. Zhang; N. Yu";"University of Science and Technology of China, Hefei, Anhui, China; University of Science and Technology of China, Hefei, Anhui, China; University of Science and Technology of China, Hefei, Anhui, China; University of Science and Technology of China, Hefei, Anhui, China; Qianxin Technology Group Co. Ltd, Beijing, China; Qianxin Technology Group Co. Ltd, Beijing, China; University of Science and Technology of China, Hefei, Anhui, China; University of Science and Technology of China, Hefei, Anhui, China";IEEE Transactions on Dependable and Secure Computing;;2025;PP;99;1;15;The rise of deepfakes has significantly heightened concerns for privacy and the authenticity of digital media, bringing widespread attention to face forgery detection. Previous deepfake detection methods mostly depend on low-level textural features vulnerable to perturbations and fall short of detecting unseen forgery methods. In contrast, high-level semantic features are less susceptible to perturbations and not limited to forgery-specific artifacts, thus having stronger generalization. Motivated by this, we propose a detection method that utilizes high-level semantic features of faces to identify inconsistencies in temporal domain. We introduce UniForensics, a novel deepfake detection framework that leverages a transformer-based video classification network, initialized with a meta-functional face encoder for enriched facial representation. In this way, we can take advantage of both the powerful spatio-temporal model and the high-level semantic information of faces. Furthermore, to leverage easily accessible real face data and guide the model in focusing on spatio-temporal features, we design a Dynamic Video Self-Blending (DVSB) method to efficiently generate training samples with diverse spatio-temporal forgery traces using real facial videos. Based on this, we advance our framework with a two-stage training approach: The first stage employs a novel self-supervised contrastive learning, where we encourage the network to focus on forgery traces by impelling videos generated by the same forgery process to have similar representations. On the basis of the representation learned in the first stage, the second stage involves fine-tuning on face forgery detection dataset to build a deepfake detector. Extensive experiments validates that UniForensics outperforms existing face forgery detection methods in generalization ability and robustness. In particular, our method achieves 95.3% and 77.2% cross dataset AUC on the challenging Celeb-DFv2 and DFDC respectively. Code will be made publicly available.;1941-0018;;10.1109/TDSC.2025.3627420;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11250851;"Deepfake detection;self-supervised contrastive learning;data synthesis";"Forgery;Faces;Deepfakes;Semantics;Face recognition;Feature extraction;Training;Robustness;Data models;Contrastive learning";;;;;IEEE;17 Nov 2025;;;IEEE;IEEE Early Access Articles
MINTIME: Multi-Identity Size-Invariant Video Deepfake Detection;"D. A. Coccomini; G. K. Zilos; G. Amato; R. Caldelli; F. Falchi; S. Papadopoulos; C. Gennaro";"ISTI-CNR, Pisa, Italy; Faculty of Electrical Engineering, Czech Technical University in Prague, Prague, Czech Republic; ISTI-CNR, Pisa, Italy; CNIT, Florence, Italy; ISTI-CNR, Pisa, Italy; ITI-CERTH, Thessaloniki, Greece; ISTI-CNR, Pisa, Italy";IEEE Transactions on Information Forensics and Security;20 Jun 2024;2024;19;;6084;6096;In this paper, we present MINTIME, a video deepfake detection method that effectively captures spatial and temporal inconsistencies in videos that depict multiple individuals and varying face sizes. Unlike previous approaches that either employ simplistic a-posteriori aggregation schemes, i.e., averaging or max operations, or only focus on the largest face in the video, our proposed method learns to accurately detect spatio-temporal inconsistencies across multiple identities in a video through a Spatio-Temporal Transformer combined with a Convolutional Neural Network backbone. This is achieved through an Identity-aware Attention mechanism that applies a masking operation on the face sequence to process each identity independently, which enables effective video-level aggregation. Furthermore, our system incorporates two novel embedding schemes: (i) the Temporal Coherent Positional Embedding, which encodes the temporal information of the face sequences of each identity, and (ii) the Size Embedding, which captures the relative sizes of the faces to the video frames. MINTIME achieves state-of-the-art performance on the ForgeryNet dataset, with a remarkable improvement of up to 14% AUC in videos containing multiple people. Moreover, it demonstrates very robust generalization capabilities in cross-forgery and cross-dataset settings. The code is publicly available at: https://github.com/davide-coccomini/MINTIME-Multi-Identity-size-iNvariant-TIMEsformer-for-Video-Deepfake-Detection.;1556-6021;;10.1109/TIFS.2024.3409054;"NextGeneration EU (EU-NGEU) through the Project SERICS under the National Recovery and Resilience Plan (NRRP) Ministry of University and Research [Ministero dell’Università e della Ricerca (MUR)] Program(grant numbers:PE00000014); EU–NGEU through Empowering Knowledge Extraction to Empower Learners (EKEEL)(grant numbers:P20227PEPK,ERC PE6_7); H2020 Project AI4Media(grant numbers:951911); Italian MUR (Research Projects of National Relevance [Progetti di Rilevante Interesse Nazionale (PRIN)] 2022) through the FOSTERER Project; Junior Star Czech Science Foundation (GACR)(grant numbers:GM 21-28830M);";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10547206;"Deepfake detection;computer vision;deep learning;vision transformers;convolutional neural networks";"Deepfakes;Faces;Transformers;Vectors;Face recognition;Convolutional neural networks;Task analysis";;7;;74;CCBY;3 Jun 2024;2024;;IEEE;IEEE Journals
CIPHER: Counterfeit Image Pattern High-level Examination via Representation for GAN and Diffusion Discriminator Learning;"K. Kim; Y. Han; S. Ju; Y. Jean; Y. Kim; M. Choi; S. Lim; K. Park; S. Baek; S. Hyeon; N. -J. Kim; H. -J. Lee";"OUTTA; OUTTA; OUTTA; OUTTA; OUTTA; OUTTA; OUTTA; OUTTA; OUTTA; OUTTA; Seoul National University; Seoul National University";2025 IEEE/IEIE International Conference on Consumer Electronics-Asia (ICCE-Asia);4 Dec 2025;2025;;;1;6;The rapid progress of generative adversarial networks (GANs) and diffusion models has enabled the creation of synthetic faces that are increasingly difficult to distinguish from real images. This progress, however, has also amplified the risks of misinformation, fraud, and identity abuse, underscoring the urgent need for detectors that remain robust across diverse generative models. In this work, we introduce Counterfeit Image Pattern High-level Examination via Representation(CIPHER), a deepfake detection framework that systematically reuses and fine-tunes discriminators originally trained for image generation. By extracting scale-adaptive features from ProGAN discriminators and temporal-consistency features from diffusion models, CIPHER captures generation-agnostic artifacts that conventional detectors often overlook. Through extensive experiments across nine state-of-the-art generative models, CIPHER demonstrates superior cross-model detection performance, achieving up to 74.33% F1-score and outperforming existing ViT-based detectors by over 30% in F1-score on average. Notably, our approach maintains robust performance on challenging datasets where baseline methods fail, with up to 88% F1-score on CIFAKE compared to near-zero performance from conventional detectors. These results validate the effectiveness of discriminator reuse and cross-model fine-tuning, establishing CIPHER as a promising approach toward building more generalizable and robust deep-fake detection systems in an era of rapidly evolving generative technologies.;;979-8-3315-7402-4;10.1109/ICCE-Asia67487.2025.11263770;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11263770;"Deepfake detection;GAN;Diffusion;Discriminator learning;Representation learning";"Representation learning;Ciphers;Deepfakes;Social networking (online);Image synthesis;Detectors;Feature extraction;Diffusion models;Generative adversarial networks;Robustness";;;;48;IEEE;4 Dec 2025;27-29 Oct. 2025;27-29 Oct. 2025;IEEE;IEEE Conferences
Exploiting spatiotemporal inconsistencies to detect deepfake videos in the wild;"A. Khedkar; A. Peshkar; A. Nagdive; M. Gaikwad; S. Baudha";"Dept. of Artificial Intelligence, G.H. Raisoni College of Engineering, Nagpur, India; Dept. of Information Technology, G.H. Raisoni College of Engineering, Nagpur, India; Dept. of Information Technology, G.H. Raisoni College of Engineering, Nagpur, India; Dept. of Information Technology, G.H. Raisoni College of Engineering, Nagpur, India; Dept. of Electronics & Electrical Engineering, BITS Pilani, Goa, India";2022 10th International Conference on Emerging Trends in Engineering and Technology - Signal and Information Processing (ICETET-SIP-22);15 Jun 2022;2022;;;1;6;Cyberspace is an emerging battlefield and deepfakes are being constantly weaponized by malicious actors. With rapid advancements in media synthesis technologies, detecting deepfakes is becoming increasingly difficult. The following paper presents a unified approach focusing on the fusion of Convolutional Neural Networks and Long Short Term Memory Networks for spatial and temporal analysis of deepfake videos. This study compares the performance of the most prevalent and frequently used deepfake detection methods- convolutional neural networks (CNN) and convolutional neural networks combined with long-short term memory networks (CNN-LSTM) with our architecture on a combined dataset consisting of videos from Face Forensics++ and Deepfake Detection Challenge Dataset, which consists of multiple types of manipulated media- Deepfakes, Faceswaps, Neural Textures, Face Shifter and Face2Face. We find that our architecture provides a 2.5% increase in detection accuracy over the most frequently used current deepfake detection method (CNN-LSTM).;2157-0485;978-1-6654-6741-4;10.1109/ICETET-SIP-2254415.2022.9791719;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9791719;"Deepfake Detection;Image Processing;Deep learning;GAN;Generalization;Interpretation";"Weapons;Focusing;Cyberspace;Information processing;Media;Market research;Spatiotemporal phenomena";;2;;44;IEEE;15 Jun 2022;29-30 April 2022;29-30 April 2022;IEEE;IEEE Conferences
Benchmarking Joint Face Spoofing and Forgery Detection With Visual and Physiological Cues;"Z. Yu; R. Cai; Z. Li; W. Yang; J. Shi; A. C. Kot";"School of Computing and Information Technology, Great Bay University, Dongguan, China; ROSE Lab, Nanyang Technological University, Singapore; ROSE Lab, Nanyang Technological University, Singapore; Peng Cheng Laboratory, Shenzhen, China; Xi’an Jiaotong University, Xi’An, China; ROSE Lab, Nanyang Technological University, Singapore";IEEE Transactions on Dependable and Secure Computing;3 Sep 2024;2024;21;5;4327;4342;"Face anti-spoofing (FAS) and face forgery detection play vital roles in securing face biometric systems from presentation attacks (PAs) and vicious digital manipulation (e.g., deepfakes). Despite satisfactory performance upon large-scale data and powerful deep models, recent advances in face spoofing and forgery detection approaches usually focus on 1) unimodal visual appearance or physiological (i.e., remote photoplethysmography (rPPG)) cues; and 2) separated feature representation for FAS or face forgery detection. On one side, unimodal appearance and rPPG features are respectively vulnerable to high-fidelity face 3D mask and video replay attacks, inspiring us to design reliable multi-modal fusion mechanisms for generalized FAS. On the other side, there are rich common features across FAS and face forgery detection tasks (e.g., periodic rPPG rhythms and vanilla appearance for bonafides), providing solid evidence to design a joint FAS and face forgery detection system in a multi-task learning fashion. In this paper, we establish the first joint face spoofing and forgery detection benchmark using both visual appearance and physiological rPPG cues. To enhance the rPPG periodicity discrimination, we design a two-branch physiological network using both facial spatio-temporal rPPG signal map and its continuous wavelet transformed counterpart as inputs. To mitigate the modality bias and improve the fusion efficacy, we conduct a weighted batch and layer normalization for both appearance and rPPG features before multi-modal fusion. We also investigate prevalent deep models, feature fusion strategies and multi-task learning configurations for joint face spoofing and forgery detection. We find that the generalization capacities of both unimodal (appearance or rPPG) and multi-modal (appearance+rPPG) models can be obviously improved via joint training on these two tasks. We hope this new benchmark will facilitate the future research of both FAS and deepfake detection communities.";1941-0018;;10.1109/TDSC.2024.3352049;"National Natural Science Foundation of China(grant numbers:62306061); Basic and Frontier Research Project of PCL; Major Key Project of PCL; Shenzhen University;";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10387780;"Face anti-spoofing;face forgery detection;deepfake;rPPG;fusion;joint training;multi-task learning";"Faces;Forgery;Task analysis;Visualization;Physiology;Face recognition;Deepfakes";;42;;97;IEEE;10 Jan 2024;Sept.-Oct. 2024;;IEEE;IEEE Journals
WaveDIF: Wavelet Sub-Band based Deepfake Identification in Frequency Domain;"A. Dutta; A. K. Das; R. Naskar; R. S. Chakraborty";"IIT, Kharagpur; IIEST, Shibpur; IIEST, Shibpur; IIT, Kharagpur";2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW);15 Sep 2025;2025;;;6302;6311;With the more realistic convergence of Deepfakes, its' identification becomes more demanding. Recently, numerous deepfake detection techniques have been proposed, most of which are in the spatio-temporal domain. While these methods have shown promise, many of them neglect convincing artifacts that exhibit different patterns across frequency domains. This research proposes WaveDIF, a strict frequency domain, lightweight deepfake video detection algorithm using wavelet sub-band energies. In WaveDIF, for feature extraction, each video undergoes a Discrete Fourier Transform to filter out high-frequency noisy details (quite evident in deepfakes). These representations are then decomposed into their respective wavelet sub-bands -LL (Low-Low), LH (Low-High), HL (High-Low), and HH (High-High) passing them through a Haar Filter, following which the energy values (particular to each sub-band) are computed. These energy values are then used to learn a linear decision boundary (using regression analysis), which is then used for classification. This enables an interpretable, lightweight deterministic technique for the detection of synthesized videos, besides achieving an accuracy comparable to the state-of-the-art. Experimental results on popular deepfake video datasets shows over 92% accuracy for in-dataset evaluation, and 88% accuracy for cross dataset evaluation.;2160-7516;979-8-3315-9994-2;10.1109/CVPRW67362.2025.00627;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11148061;"lightweight deepfake detection;frequency domain analysis;wavelet sub-band energies;discrete fourier transform;discrete wavelet transform";"Deepfakes;Adaptation models;Accuracy;Wavelet domain;Frequency-domain analysis;Computational modeling;Discrete Fourier transforms;Pipelines;Feature extraction;Regression analysis";;2;;34;IEEE;15 Sep 2025;11-12 June 2025;11-12 June 2025;IEEE;IEEE Conferences
Within 3DMM Space: Exploring Inherent 3D Artifact for Video Forgery Detection;"C. Peng; T. Xu; D. Liu; N. Wang; X. Gao";"State Key Laboratory of Integrated Services Networks, School of Cyber Engineering, Xidian University, Xi’an, Shaanxi, China; State Key Laboratory of Integrated Services Networks, School of Cyber Engineering, Xidian University, Xi’an, Shaanxi, China; State Key Laboratory of Integrated Services Networks, School of Cyber Engineering, Xidian University, Xi’an, Shaanxi, China; State Key Laboratory of Integrated Services Networks, School of Telecommunications Engineering, Xidian University, Xi’an, Shaanxi, China; State Key Laboratory of Integrated Services Networks, School of Electronic Engineering, Xidian University, Xi’an, Shaanxi, China";IEEE Transactions on Information Forensics and Security;4 Aug 2025;2025;20;;7954;7965;Recently, the breathtaking development and potential misuse of deepfake technology has raised numerous privacy and security concerns, triggering widespread apprehension. Existing deepfake detection methods focus on the analysis of local regions for faces, such as mouth movement, eye blinking frequency, etc., which, however, are limited in their ability to capture the global inconsistencies present in forged faces. Some researchers attempt to seize 3D artifacts related to facial global information, but typically treat the 3D information as mere input, lacking the in-depth analysis. To address these shortcomings and mine the inherent and delicate 3D artifacts in the forged faces, this paper innovatively proposes the 3D Artifact Detector (3DAD) method, which leverages the spatio-temporal inconsistency on the 3D semantic space in the forgery videos to uncover the deepfake clues. Specifically, we employ 3D Analysis Unit (3DAU) to pre-train the face reconstruction task within 3D Morphable Model (3DMM) space, thereby obtaining the high-level inherent 3d representation. Concurrently, for the multi-levels of information in the face, we utilize the Texture Perception Unit (TPU) to extract the texture information in the low-level semantic space of the images. Ultimately we feed the two distinct modalities into the spatiotemporal fusion model for final detection. Through extensive intra- and cross-dataset experiments on publicly available datasets, we demonstrate the effectiveness and generalizability of the proposed method. The source code is available at https://github.com/Cookie-XT/3DAD;1556-6021;;10.1109/TIFS.2025.3592557;"National Natural Science Foundation of China(grant numbers:62276198,U22A2035,U22A2096,62036007,62306227); Innovation Capability Support Plan in Shaanxi Province(grant numbers:2025ZC-KJXX-22); Scientific and Technological Innovation Teams in Shaanxi Province(grant numbers:2025RS-CXTD-011); Young Elite Scientists Sponsorship Program by CAST(grant numbers:2022QNRC001); Shaanxi Province Core Technology Research and Development Project(grant numbers:2024QY2-GJHX-11); Open Research Project of Key Laboratory of Artificial Intelligence Ministry of Education(grant numbers:AI202401); Overseas Expertise Introduction Center for Discipline Innovation of Food Nutrition and Human Health (111 Center)(grant numbers:B16037); CCF-Baidu Open Fund; Fundamental Research Funds for the Central Universities(grant numbers:QTZX23083,QTZX23042,ZYTS24142);";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11095790;"Video forgery detection;Deepfake;3D information";"Three-dimensional displays;Forgery;Faces;Deepfakes;Feature extraction;Data mining;Semantics;Frequency-domain analysis;Visualization;Spatiotemporal phenomena";;;;79;IEEE;24 Jul 2025;2025;;IEEE;IEEE Journals
Leveraging Spatial-Temporal Illumination Features and Convolution-Transformer Hybrid Networks for Deepfake Video Detection;"G. Zhang; Y. Liang; K. Tian; J. Yi; H. Alsolai; M. Liu; X. Hu";"College of Computer Science, Beijing University of Technology, Beijing, China; College of Computer Science, Beijing University of Technology, Beijing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; Department of Economics, Cardiff University, Cardiff, United Kingdom; Department of Information Systems, College of Computer and Information Sciences, Princess Nourah bint Abdulrahman University, P. O. Box 84428, Riyadh, Saudi Arabia; Department of Computer Sciences, Northeastern University, MA, USA; College of Computer Science, Beijing University of Technology, Beijing, China";IEEE Transactions on Consumer Electronics;;2025;PP;99;1;1;Current deepfake detection methods primarily focus on exploring inter-frame inconsistencies using convolutional networks, neglecting the investigation of long-range spatiotemporal inconsistencies. Simultaneously, these methods rely on single-feature exploitation for forgery detection, resulting in limited generalization capability and robustness. To address these issues, this paper proposes a novel network that comprehensively utilizes illumination-geometric features and facial forgery trace features to excavate deepfake artifacts across multiple scales. The architecture comprises three main components: First, the Lighting-Geometric Information Capture Module (LGCM) integrates facial landmark normal vectors and illumination coefficients to construct comprehensive spatiotemporal representations. Then, the Bi-directional Multiscale Enhancement Module (BMEM) captures attention information between different frames in the spatial domain and models inter-frame discrepancy attention in the temporal domain. Furthermore, the Spatio-temporal Attention Module (STAM) mines global semantics and adaptively derives long-range spatiotemporal representations. Experimental results demonstrate that the proposed method achieves high AUC values on the four subsets of FF++ C40, Celeb-DF, and DFDC datasets, outperforming the comparative methods. Similarly, cross-forgery method detection validates the robustness and generalization capability of the proposed approach.;1558-4127;;10.1109/TCE.2025.3624764;"National Natural Science Foundation of China(grant numbers:62172227); Princess Nourah Bint Abdulrahman University(grant numbers:PNURSP2025R303);";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11215793;"Deepfake detection;Illumination features;Facial forgery trace features;Deep neural networks";"Deepfakes;Lighting;Feature extraction;Forgery;Vectors;Spatiotemporal phenomena;Data mining;Computational modeling;Transformers;Three-dimensional displays";;;;;IEEE;23 Oct 2025;;;IEEE;IEEE Early Access Articles
DF-VLAD: Deepfake Video Detection based on Feature Aggregation;"Y. Huang; Z. Luo; M. Zhang; W. Liu; S. Li";"Department of Artificial Intelligence, Xiamen University, Xiamen, China; Department of Artificial Intelligence, Xiamen University, Xiamen, China; Institute of Energy Research, Jiangxi Academy of Sciences, Nanchang, China; School of Software, East China Jiaotong University, Nanchang, China; Department of Artificial Intelligence, Xiamen University, Xiamen, China";2021 11th International Conference on Information Technology in Medicine and Education (ITME);15 Apr 2022;2021;;;91;95;"With the rapid development of Deepfake technology, face video forgery can produce highly deceptive video content and bring serious security threats. The detection of this kind of fake video is more urgent and challenging. Most of the existing detection methods regard this problem as a common binary classification problem, and using a simple average or maximum as the prediction of video results can easily lead to missed detection or false detection. While the video-based detection work such as LSTM, in Deepfake detection, too much focus on timing modeling will affect the performance of Deepfake video detection to a certain extent. Based on this, this paper proposes a VLAD-based aggregation module DF-VLAD, which advances the aggregation of multiple frames from the output layer to the feature layer, which on the one hand makes the aggregation more flexible, on the other hand, it also uses the objective function of forgery detection to directly guide the learning of frame-level depth representation; On the other hand, this paper deals with this problem as a special fine-grained classification problem, because the difference between fake face and real face is very subtle. It is found that the existing face forgery methods such as Face2Face and NeuralTextures leave some common artifacts in the spatial domain. Different forgery methods produce different artifacts, while natural faces have more similar features. To make the model pay more attention to artifacts, a forgery trace capture model based on the fusion of self-attention mechanism and channel attention mechanism is proposed in this paper. Like other fine-grained classification methods, note intentions are used to guide the network to pay attention to key parts of the face. Experimental results on different public data sets show that the proposed method achieves the latest performance.";2474-3828;978-1-6654-0679-6;10.1109/ITME53901.2021.00029;"National Nature Science Foundation of China(grant numbers:61876159,61806172,62076116,U1705286);";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9750563;"Deepfake detection;face manipulation;VLAD;attention";"Education;Feature extraction;Linear programming;Forgery;Timing;Security;Face detection";;2;;26;IEEE;15 Apr 2022;19-21 Nov. 2021;19-21 Nov. 2021;IEEE;IEEE Conferences
A Comparative Analysis of Machine Learning and Deep Learning Approaches in Deepfake Detection;"M. Vashistha; S. Jain; S. Pandey; A. Pradhan; S. Tarwani";"Artificial Intelligence and Data Science, Vivekananda Institute of Professional Studies - Technical Campus, Delhi, India; Artificial Intelligence and Data Science, Vivekananda Institute of Professional Studies - Technical Campus, Delhi, India; Artificial Intelligence and Data Science, Vivekananda Institute of Professional Studies - Technical Campus, Delhi, India; Artificial Intelligence and Data Science, Vivekananda Institute of Professional Studies - Technical Campus, Delhi, India; Artificial Intelligence and Data Science, Vivekananda Institute of Professional Studies - Technical Campus, Delhi, India";2024 IEEE Region 10 Symposium (TENSYMP);19 Nov 2024;2024;;;1;8;Deepfakes refer to the visual media where the faces, bodily movements have been digitally altered using some software or program, this has proven to be more of a double edged sword as it also contributes towards content creation and media creation that may be used for positive purposes. To combat this situation, measures to detect deep fake in the media is a credible approach. This work showcases a comparative analysis among 3 Deep Learning as well as 3 Machine Learning algorithms in order to reach a conclusive state of determining the best algorithms that can be implemented for Deepfake detection. For the machine learning algorithms, KNN, SVM and Logistic Regression have been used whereas CNN, TCN and CNN + LSTM have been used for the Deep Learning Algorithm. Detection of deepfakes through these algorithms works by sequentially processing, analyzing and classifying the features on the basis of the dataset fed for the algorithms. The chosen metrics for performing a comparison between each of the algorithms are Accuracy and F1 Score. The development, implementation and comparison of the algorithms was carried out on Google Collab and Jupyter Notebook. Upon comparative analysis of the algorithms between each other, it was found that CNN had the highest accuracy and Fl-score of 0.9409 and 0.7225 respectively with KNN being the worst-performing algorithm with an accuracy 0.5770 and F1 score of 0.4088 respectively.;2642-6102;979-8-3503-6486-6;10.1109/TENSYMP61132.2024.10752209;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10752209;"Deepfake Detection;Face Morphing;Convolutional Neural Networks;Machine Learning;Deep Learning;Support Vector Machine;K-Nearest Neighbour;Face Recognition";"Deep learning;Deepfakes;Visualization;Machine learning algorithms;Accuracy;Nearest neighbor methods;Media;Prediction algorithms;Feature extraction;Classification algorithms";;1;;21;IEEE;19 Nov 2024;27-29 Sept. 2024;27-29 Sept. 2024;IEEE;IEEE Conferences
Celeb-DF: A Large-Scale Challenging Dataset for DeepFake Forensics;"Y. Li; X. Yang; P. Sun; H. Qi; S. Lyu";"University at Albany, State University of New York, USA; University at Albany, State University of New York, USA; University of Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China; University at Albany, State University of New York, USA";2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR);5 Aug 2020;2020;;;3204;3213;AI-synthesized face-swapping videos, commonly known as DeepFakes, is an emerging problem threatening the trustworthiness of online information. The need to develop and evaluate DeepFake detection algorithms calls for datasets of DeepFake videos. However, current DeepFake datasets suffer from low visual quality and do not resemble DeepFake videos circulated on the Internet. We present a new large-scale challenging DeepFake video dataset, Celeb-DF, which contains 5,639 high-quality DeepFake videos of celebrities generated using improved synthesis process. We conduct a comprehensive evaluation of DeepFake detection methods and datasets to demonstrate the escalated level of challenges posed by Celeb-DF.;2575-7075;978-1-7281-7168-5;10.1109/CVPR42600.2020.00327;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9156368;;"Videos;Visualization;Image color analysis;Decoding;YouTube;Training;Detection algorithms";;1088;;55;IEEE;5 Aug 2020;13-19 June 2020;13-19 June 2020;IEEE;IEEE Conferences
PANDA: Pose Aligned Networks for Deep Attribute Modeling;"N. Zhang; M. Paluri; M. Ranzato; T. Darrell; L. Bourdev";"Facebook AI Research; Facebook AI Research; Facebook AI Research; EECS, UC Berkeley; Facebook AI Research";2014 IEEE Conference on Computer Vision and Pattern Recognition;25 Sep 2014;2014;;;1637;1644;We propose a method for inferring human attributes (such as gender, hair style, clothes style, expression, action) from images of people under large variation of viewpoint, pose, appearance, articulation and occlusion. Convolutional Neural Nets (CNN) have been shown to perform very well on large scale object recognition problems. In the context of attribute classification, however, the signal is often subtle and it may cover only a small part of the image, while the image is dominated by the effects of pose and viewpoint. Discounting for pose variation would require training on very large labeled datasets which are not presently available. Part-based models, such as poselets [4] and DPM [12] have been shown to perform well for this problem but they are limited by shallow low-level features. We propose a new method which combines part-based models and deep learning by training pose-normalized CNNs. We show substantial improvement vs. state-of-the-art methods on challenging attribute classification tasks in unconstrained settings. Experiments confirm that our method outperforms both the best part-based methods on this problem and conventional CNNs trained on the full bounding box of the person.;1063-6919;978-1-4799-5118-5;10.1109/CVPR.2014.212;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6909608;;"Training;Convolution;Hair;Feature extraction;Object recognition;Glass;Neural networks";;346;2;27;IEEE;25 Sep 2014;23-28 June 2014;23-28 June 2014;IEEE;IEEE Conferences
Age and gender classification using convolutional neural networks;"G. Levi; T. Hassncer";"Department of Mathematics and Computer Science, The Open University of Israel; Open University of Israel, Raanana, IL";2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW);26 Oct 2015;2015;;;34;42;Automatic age and gender classification has become relevant to an increasing amount of applications, particularly since the rise of social platforms and social media. Nevertheless, performance of existing methods on real-world images is still significantly lacking, especially when compared to the tremendous leaps in performance recently reported for the related task of face recognition. In this paper we show that by learning representations through the use of deep-convolutional neural networks (CNN), a significant increase in performance can be obtained on these tasks. To this end, we propose a simple convolutional net architecture that can be used even when the amount of learning data is limited. We evaluate our method on the recent Adience benchmark for age and gender estimation and show it to dramatically outperform current state-of-the-art methods.;2160-7516;978-1-4673-6759-2;10.1109/CVPRW.2015.7301352;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7301352;;"Face;Benchmark testing;Training;Estimation;Face recognition;Computer architecture;Neurons";;806;9;56;IEEE;26 Oct 2015;7-12 June 2015;7-12 June 2015;IEEE;IEEE Conferences
Deepfake Video Detection through Optical Flow Based CNN;"I. Amerini; L. Galteri; R. Caldelli; A. Del Bimbo";"Media Integration and Communication Center (MICC), University of Florence, Florence, Italy; Media Integration and Communication Center (MICC), University of Florence, Florence, Italy; Media Integration and Communication Center (MICC), University of Florence, Florence, Italy; Media Integration and Communication Center (MICC), University of Florence, Florence, Italy";2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW);5 Mar 2020;2019;;;1205;1207;"Recent advances in visual media technology have led to new tools for processing and, above all, generating multimedia contents. In particular, modern AI-based technologies have provided easy-to-use tools to create extremely realistic manipulated videos. Such synthetic videos, named Deep Fakes, may constitute a serious threat to attack the reputation of public subjects or to address the general opinion on a certain event. According to this, being able to individuate this kind of fake information becomes fundamental. In this work, a new forensic technique able to discern between fake and original video sequences is given; unlike other state-of-the-art methods which resorts at single video frames, we propose the adoption of optical flow fields to exploit possible inter-frame dissimilarities. Such a clue is then used as feature to be learned by CNN classifiers. Preliminary results obtained on FaceForensics++ dataset highlight very promising performances.";2473-9944;978-1-7281-5023-9;10.1109/ICCVW.2019.00152;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9022558;"Deepfake;Optical flow;Video forensics;CNN";"Optical imaging;Optical network units;Optical saturation;Computer vision;Conferences;Media;Integrated optics";;295;;14;IEEE;5 Mar 2020;27-28 Oct. 2019;27-28 Oct. 2019;IEEE;IEEE Conferences
In Ictu Oculi: Exposing AI Created Fake Videos by Detecting Eye Blinking;"Y. Li; M. -C. Chang; S. Lyu";"University at Albany, State University of New York, USA; University at Albany, State University of New York, USA; University at Albany, State University of New York, USA";2018 IEEE International Workshop on Information Forensics and Security (WIFS);31 Jan 2019;2018;;;1;7;The new developments in deep generative networks have significantly improve the quality and efficiency in generating realistically-looking fake face videos. In this work, we describe a new method to expose fake face videos generated with deep neural network models. Our method is based on detection of eye blinking in the videos, which is a physiological signal that is not well presented in the synthesized fake videos. Our method is evaluated over benchmarks of eye-blinking detection datasets and shows promising performance on detecting videos generated with DNN based software DeepFake.;2157-4774;978-1-5386-6536-7;10.1109/WIFS.2018.8630787;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8630787;;"Face;Gallium nitride;Training;Generators;Biological neural networks";;703;;35;IEEE;31 Jan 2019;11-13 Dec. 2018;11-13 Dec. 2018;IEEE;IEEE Conferences
Watch Your Up-Convolution: CNN Based Generative Deep Neural Networks Are Failing to Reproduce Spectral Distributions;"R. Durall; M. Keuper; J. Keuper";"Competence Center High Performance Computing, Fraunhofer ITWM, Kaiserslautern, Germany; Data and Web Science Group, University of Mannheim, Germany; Competence Center High Performance Computing, Fraunhofer ITWM, Kaiserslautern, Germany";2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR);5 Aug 2020;2020;;;7887;7896;Generative convolutional deep neural networks, e.g. popular GAN architectures, are relying on convolution based up-sampling methods to produce non-scalar outputs like images or video sequences. In this paper, we show that common up-sampling methods, i.e. known as up-convolution or transposed convolution, are causing the inability of such models to reproduce spectral distributions of natural training data correctly. This effect is independent of the underlying architecture and we show that it can be used to easily detect generated data like deepfakes with up to 100% accuracy on public benchmarks. To overcome this drawback of current generative models, we propose to add a novel spectral regularization term to the training optimization objective. We show that this approach not only allows to train spectral consistent GANs that are avoiding high frequency errors. Also, we show that a correct approximation of the frequency spectrum has positive effects on the training stability and output quality of generative networks.;2575-7075;978-1-7281-7168-5;10.1109/CVPR42600.2020.00791;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9157579;;"Gallium nitride;Convolution;Distortion;Neural networks;Training;Generative adversarial networks";;257;;61;IEEE;5 Aug 2020;13-19 June 2020;13-19 June 2020;IEEE;IEEE Conferences
Deepfake Video Detection Using Recurrent Neural Networks;"D. Güera; E. J. Delp";"Video and Image Processing Laboratory (VIPER), Purdue University; Video and Image Processing Laboratory (VIPER), Purdue University";2018 15th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS);14 Feb 2019;2018;;;1;6;"In recent months a machine learning based free software tool has made it easy to create believable face swaps in videos that leaves few traces of manipulation, in what are known as ""deepfake"" videos. Scenarios where these realistic fake videos are used to create political distress, blackmail someone or fake terrorism events are easily envisioned. This paper proposes a temporal-aware pipeline to automatically detect deepfake videos. Our system uses a convolutional neural network (CNN) to extract frame-level features. These features are then used to train a recurrent neural network (RNN) that learns to classify if a video has been subject to manipulation or not. We evaluate our method against a large set of deepfake videos collected from multiple video websites. We show how our system can achieve competitive results in this task while using a simple architecture.";;978-1-5386-9294-3;10.1109/AVSS.2018.8639163;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8639163;;"Face;Training;Feature extraction;Decoding;Recurrent neural networks;Streaming media";;750;3;42;IEEE;14 Feb 2019;27-30 Nov. 2018;27-30 Nov. 2018;IEEE;IEEE Conferences
MesoNet: a Compact Facial Video Forgery Detection Network;"D. Afchar; V. Nozick; J. Yamagishi; I. Echizen";"École des Ponts ParistechMarne-la-Vallée, France; LIGM, UMR 8049, UPEM, France; National Institute of Informatics, Tokyo, Japan; National Institute of Informatics, Tokyo, Japan";2018 IEEE International Workshop on Information Forensics and Security (WIFS);31 Jan 2019;2018;;;1;7;This paper presents a method to automatically and efficiently detect face tampering in videos, and particularly focuses on two recent techniques used to generate hyper-realistic forged videos: Deepfake and Face2Face. Traditional image forensics techniques are usually not well suited to videos due to the compression that strongly degrades the data. Thus, this paper follows a deep learning approach and presents two networks, both with a low number of layers to focus on the mesoscopic properties of images. We evaluate those fast networks on both an existing dataset and a dataset we have constituted from online videos. The tests demonstrate a very successful detection rate with more than 98% for Deepfake and 95% for Face2Face.;2157-4774;978-1-5386-6536-7;10.1109/WIFS.2018.8630761;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8630761;;"Face;Training;Convolutional codes;Forgery;Deep learning;Decoding";;1147;;30;IEEE;31 Jan 2019;11-13 Dec. 2018;11-13 Dec. 2018;IEEE;IEEE Conferences
Media Forensics and DeepFakes: An Overview;L. Verdoliva;Department of Industrial Engineering, University Federico II of Naples, Naples, Italy;IEEE Journal of Selected Topics in Signal Processing;25 Aug 2020;2020;14;5;910;932;With the rapid progress in recent years, techniques that generate and manipulate multimedia content can now provide a very advanced level of realism. The boundary between real and synthetic media has become very thin. On the one hand, this opens the door to a series of exciting applications in different fields such as creative arts, advertising, film production, and video games. On the other hand, it poses enormous security threats. Software packages freely available on the web allow any individual, without special skills, to create very realistic fake images and videos. These can be used to manipulate public opinion during elections, commit fraud, discredit or blackmail people. Therefore, there is an urgent need for automated tools capable of detecting false multimedia content and avoiding the spread of dangerous false information. This review paper aims to present an analysis of the methods for visual media integrity verification, that is, the detection of manipulated images and videos. Special emphasis will be placed on the emerging phenomenon of deepfakes, fake media created through deep learning tools, and on modern data-driven forensic methods to fight them. The analysis will help highlight the limits of current forensic tools, the most relevant issues, the upcoming challenges, and suggest future directions for research.;1941-0484;;10.1109/JSTSP.2020.3002101;"Defense Advanced Research Projects Agency(grant numbers:FA8750-16-2-0204);";https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9115874;"Deep learning;deepfakes;digital image forensics;video forensics";"Media;Forensics;Generative adversarial networks;Digital forensics;Information integrity;Videos;Deep learning";;550;;274;IEEE;12 Jun 2020;Aug. 2020;;IEEE;IEEE Journals
Adversarial Threats to DeepFake Detection: A Practical Perspective;"P. Neekhara; B. Dolhansky; J. Bitton; C. C. Ferrer";"UC San Diego; UC San Diego; UC San Diego; UC San Diego";2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW);1 Sep 2021;2021;;;923;932;Facially manipulated images and videos or DeepFakes can be used maliciously to fuel misinformation or defame individuals. Therefore, detecting DeepFakes is crucial to increase the credibility of social media platforms and other media sharing web sites. State-of-the art DeepFake detection techniques rely on neural network based classification models which are known to be vulnerable to adversarial examples. In this work, we study the vulnerabilities of state-of-the-art DeepFake detection methods from a practical stand point. We perform adversarial attacks on DeepFake detectors in a black box setting where the adversary does not have complete knowledge of the classification models. We study the extent to which adversarial perturbations transfer across different models and propose techniques to improve the transferability of adversarial examples. We also create more accessible attacks using Universal Adversarial Perturbations which pose a very feasible attack scenario since they can be easily shared amongst attackers. We perform our evaluations on the winning entries of the DeepFake Detection Challenge (DFDC) and demonstrate that they can be easily bypassed in a practical attack scenario by designing transferable and accessible adversarial attacks.1;2160-7516;978-1-6654-4899-4;10.1109/CVPRW53098.2021.00103;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9522903;;"Social networking (online);Perturbation methods;Neural networks;Multimedia Web sites;Detectors;Pattern recognition;Security";;67;;46;IEEE;1 Sep 2021;19-25 June 2021;19-25 June 2021;IEEE;IEEE Conferences
Towards Measuring Fairness in AI: The Casual Conversations Dataset;"C. Hazirbas; J. Bitton; B. Dolhansky; J. Pan; A. Gordo; C. C. Ferrer";"Meta AI, AI Integrity, Seattle, WA, USA; Meta AI, AI Integrity, Seattle, WA, USA; Meta AI, AI Integrity, Seattle, WA, USA; Meta AI, AI Integrity, Seattle, WA, USA; Meta AI, AI Integrity, Seattle, WA, USA; Meta AI, AI Integrity, Seattle, WA, USA";IEEE Transactions on Biometrics, Behavior, and Identity Science;19 Jul 2022;2022;4;3;324;332;This paper introduces a novel dataset to help researchers evaluate their computer vision and audio models for accuracy across a diverse set of age, genders, apparent skin tones and ambient lighting conditions. Our dataset is composed of 3,011 subjects and contains over 45,000 videos, with an average of 15 videos per person. The videos were recorded in multiple U.S. states with a diverse set of adults in various age, gender and apparent skin tone groups. A key feature is that each subject agreed to participate for their likenesses to be used. Additionally, our age and gender annotations are provided by the subjects themselves. A group of trained annotators labeled the subjects’ apparent skin tone using the Fitzpatrick skin type scale. Moreover, annotations for videos recorded in low ambient lighting are also provided. As an application to measure robustness of predictions across certain attributes, we provide a comprehensive study on the top five winners of the DeepFake Detection Challenge (DFDC). Experimental evaluation shows that the winning models are less performant on some specific groups of people, such as subjects with darker skin tones and thus may not generalize to all people. In addition, we also evaluate the state-of-the-art apparent age and gender classification methods. Our experiments provides a thorough analysis on these models in terms of fair treatment of people from various backgrounds.;2637-6407;;10.1109/TBIOM.2021.3132237;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9634168;"AI robustness;algorithmic fairness;deepfakes;dataset;age;gender;skin tone";"Skin;Videos;Artificial intelligence;Annotations;Information integrity;Lighting;Detectors";;45;;40;IEEE;3 Dec 2021;July 2022;;IEEE;IEEE Journals